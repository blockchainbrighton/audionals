<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes">
    <title>Audionals Algo Player</title>

<style>
        /* Basic Reset and Centering */
        body, html {
            height: 100%;
            margin: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #000;
            position: relative;
            /* Remove the transform: scale(0.7); */
        }

        /* Add scaling to the canvas container */
        #canvas-container {
            width: 50vmin; /* Responsive width */
            height: 50vmin; /* Responsive height */
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #fff;
            position: relative;
            z-index: 10;
            transform: scale(0.7); /* Scale only the canvas container */
        }

        /* Canvas for Visuals */
        canvas#cv {
            position: absolute; /* Overlay on the container */
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 9999; /* Above other elements */
            pointer-events: none; /* Prevent interference with mouse events */
        }

        /* Button Container for Additional Controls */
        #button-container {
            position: fixed;
            right: 10px;
            top: 60px;
            display: flex;
            flex-direction: column;
            gap: 10px;
            z-index: 10002;
        }

        /* Play Button Styles */
        #play-button {
            position: absolute; /* Cover the entire canvas */
            top: 0;
            left: 0;
            width: 100%; /* Full coverage */
            height: 100%; /* Full coverage */
            border: none; /* No border */
            background: transparent; /* Transparent background */
            cursor: pointer; /* Change cursor to pointer */
            z-index: 10000; /* Above all other elements */
            opacity: 0; /* Initially hidden */
            pointer-events: auto; /* Allow mouse events */
        }

        /* Styles for the Playing State of the Button */
        #play-button.playing {
            background-color: red; /* Change color when playing */
        }

        /* Hover Effects */
        #play-button:hover {
            background-color: #33c9ff; /* Light blue on hover */
        }

        #play-button.playing:hover {
            background-color: #ff4d4d; /* Darker red when playing */
        }

        /* New Information Panel Styles */
        /* New Information Panel Styles */
        #info-panel {
            position: fixed; /* Fixes the panel relative to the viewport */
            top: 0;          /* Aligns the panel to the top */
            right: 0;        /* Aligns the panel to the right */
            width: 300px;    /* Sets a fixed width for the panel */
            height: 100vh;   /* Makes the panel full height */
            background-color: rgba(255, 255, 255, 0.9); /* Semi-transparent background */
            box-shadow: -2px 0 5px rgba(0,0,0,0.5);    /* Adds a subtle shadow */
            padding: 20px;   /* Adds padding inside the panel */
            box-sizing: border-box; /* Ensures padding doesn't affect overall width */
            overflow-y: auto; /* Adds scroll if content overflows */
            z-index: 1000;    /* Ensures the panel is above other elements */
        }

        /* Hidden State for Information Panel */
        .hidden {
            display: none;
        }

        /* Optional: Add a class for the hidden state with transitions */
        #info-panel.hidden {
            transform: translateX(100%);
            opacity: 0;
        }

        /* Optional: Style the Information Content */
        #info-panel h2 {
            margin-top: 0;
            color: #333;
        }

        #info-canvas {
            display: block;
            margin: 20px 0;
            width: 100%;
            height: 100px; /* Adjust height as needed */
            border: 1px solid #ccc; /* Optional: Adds a border */
        }

        /* Style for the toggle button (Optional) */
        #toggle-info-button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }

        /* Styles for the information canvas */
        #info-canvas {
            display: block;
            margin: 20px 0;
            width: 100%;
            height: 100px; /* Adjust height as needed */
            border: 1px solid #ccc; /* Optional: Adds a border */
        }

        /* Background colors for Seed and BPM */
        :root {
            --seed-bg-color: #4CAF50; /* Green for Seed */
            --bpm-bg-color: #FF9800; /* Orange for BPM */
            --text-color: #FFFFFF; /* White text color */
            --font-size: 12px; /* Font size */
        }
        

        
</style>
</head>




<body>
    <div id="canvas-container">
        <img id="artwork" alt="Artwork">
        <canvas id="cv"></canvas> <!-- Removed width and height attributes -->
        <button id="play-button">Play</button>
    </div>

    <!-- Information Panel -->
<div id="info-panel">
        <h2>Information</h2>
        <div class="current-seed">
            <canvas id="info-canvas" width="200" height="100"></canvas>
            <div>
                <label for="seed-input">Enter Seed:</label>
                <input type="text" id="seed-input" />
                <button id="load-seed-button">Load Seed</button> <!-- Load Seed button -->
                <button id="clear-seeds-button">Clear Previous Seeds</button> <!-- Clear button -->
            </div>
            <div class="previous-seeds">
                <h3>Previous Seeds Played:</h3>
                <div id="previous-seeds-container"></div> <!-- Container for previously played seeds -->
            </div>
        </div>
</div>

<script id="globalMetadata">
       window.globalMetadata = {
            volumeLevels: {},
            playbackSpeeds: {},
            trimTimes: {},
            };
</script>

<seedAndBpmManagement>

    
    <script id="seedAndBpmManagement">
      (function() {
          /**
           * Retrieves the value of a query parameter from the URL.
           * @param {string} param - The name of the query parameter.
           * @returns {string|null} - The value of the query parameter or null if not found.
           */
          function getQueryParam(param) {
              const urlParams = new URLSearchParams(window.location.search);
              return urlParams.get(param);
          }
  
          // Initialize fixedSeed from query parameter if available
          const seedFromURL = getQueryParam('seed') || "";
          window.fixedSeed = seedFromURL;
  
          /**
           * Generates a seed.
           * @returns {string} - The generated seed.
           */
          function generateSeed() {
              if (typeof window.fixedSeed === "string" && window.fixedSeed.length > 0) {
                  return window.fixedSeed;
              }
              return Array.from({ length: 20 }, () => Math.floor(Math.random() * 10)).join("");
          }
  
          /**
           * Logs messages with a timestamp.
           * @param {string} message - The message to log.
           */
          function log(message) {
              console.log(`[${new Date().toISOString()}] ${message}`);
          }
  
          window.log = log;
  
          window.log("Generating new seed...");
          const newSeed = generateSeed();
          window.log(`New seed generated: ${newSeed}`);
  
          Object.defineProperty(window, "seed", {
              value: newSeed,
              writable: false,
              configurable: false,
              enumerable: true
          });
  
          window.generateAdditionalSeed = function() {
              const additionalSeed = generateSeed();
              window.log(`Generating additional seed: ${additionalSeed}`);
              return additionalSeed;
          };
  
          // If a seed was provided via URL, remove it to make the request temporary
          if (seedFromURL) {
              const url = new URL(window.location);
              url.searchParams.delete('seed');
              window.history.replaceState({}, document.title, url.toString());
              window.log("Seed parameter removed from URL to make it a one-time use.");
          }
  
          /**
           * Increments the current seed by 1 and reloads the page with the new seed.
           */
          window.incrementSeedAndReload = function() {
              // Convert the current seed to an integer
              let currentSeedInt = parseInt(window.seed, 10);
  
              // Handle potential NaN
              if (isNaN(currentSeedInt)) {
                  currentSeedInt = 0;
              }
  
              // Increment the seed
              const newSeedInt = currentSeedInt + 1;
  
              // Update window.fixedSeed
              window.fixedSeed = newSeedInt.toString();
  
              // Update the URL with the new seed
              const url = new URL(window.location.href);
              url.searchParams.set('seed', window.fixedSeed);
  
              // Reload the page with the updated URL
              window.location.href = url.toString();
          }
  
          /**
           * Toggles the visibility of the Information Panel.
           */
          function toggleInfoPanel() {
              const infoPanel = document.getElementById("info-panel");
              if (!infoPanel) {
                  window.log("Info panel element not found.");
                  return;
              }
              infoPanel.classList.toggle("hidden");
              // Store the state
              localStorage.setItem("infoPanelHidden", infoPanel.classList.contains("hidden"));
          }
  
          window.toggleInfoPanel = toggleInfoPanel;
  
          /**
           * Displays the Seed and BPM on the info canvas.
           * @param {string} seed - The seed value.
           * @param {number} bpm - The BPM value.
           */
          function displaySeedAndBPM(seed, bpm) {
              const infoCanvas = document.getElementById("info-canvas");
              if (!infoCanvas) {
                  window.log("Info canvas element not found.");
                  return;
              }
              const ctx = infoCanvas.getContext("2d");
  
              // Clear the canvas before drawing
              ctx.clearRect(0, 0, infoCanvas.width, infoCanvas.height);
  
              // Draw background rectangles using CSS variables or defaults
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--seed-bg-color') || 'green'; // Default to green
              ctx.fillRect(0, 0, infoCanvas.width, infoCanvas.height / 2);
  
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bpm-bg-color') || 'orange'; // Default to orange
              ctx.fillRect(0, infoCanvas.height / 2, infoCanvas.width, infoCanvas.height / 2);
  
              // Set text properties for Seed
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--text-color') || 'white'; // Default to white
              ctx.font = `${getComputedStyle(document.documentElement).getPropertyValue('--font-size') || '16px'} Arial`; // Default font size
              ctx.textAlign = "center";
              ctx.textBaseline = "middle";
              ctx.fillText(`Seed: ${seed}`, infoCanvas.width / 2, infoCanvas.height / 4);
  
              // Set text properties for BPM
              ctx.fillText(`BPM: ${bpm}`, infoCanvas.width / 2, (3 * infoCanvas.height) / 4);
  
              // Save the seed to local storage
              saveSeed(seed);
          }
  
          window.displaySeedAndBPM = displaySeedAndBPM;
  
          /**
           * Saves the seed to local storage and updates the list of previous seeds.
           * @param {string} seed - The seed to save.
           */
          function saveSeed(seed) {
              const previousSeeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
              
              // Avoid duplicates
              if (!previousSeeds.includes(seed)) {
                  previousSeeds.push(seed);
                  localStorage.setItem("previousSeeds", JSON.stringify(previousSeeds));
                  displayPreviousSeeds(previousSeeds);
              }
          }
  
          window.saveSeed = saveSeed;
  
          /**
           * Displays the list of previously played seeds.
           * @param {Array<string>} seeds - The array of previous seeds.
           */
          function displayPreviousSeeds(seeds) {
              const previousSeedsContainer = document.getElementById("previous-seeds-container");
              if (!previousSeedsContainer) {
                  window.log("Previous seeds container element not found.");
                  return;
              }
  
              // Clear existing seeds
              previousSeedsContainer.innerHTML = "";
  
              const seedList = document.createElement("ul");
  
              seeds.forEach(seed => {
                  const listItem = document.createElement("li");
                  listItem.textContent = seed;
  
                  // Create a copy button for each seed
                  const copyButton = document.createElement("button");
                  copyButton.textContent = "Copy";
                  copyButton.onclick = () => copyToClipboard(seed);
                  listItem.appendChild(copyButton);
  
                  seedList.appendChild(listItem);
              });
  
              previousSeedsContainer.appendChild(seedList);
          }
  
          window.displayPreviousSeeds = displayPreviousSeeds;
  
          /**
           * Copies the seed to the clipboard.
           * @param {string} seed - The seed to copy.
           */
          function copyToClipboard(seed) {
              navigator.clipboard.writeText(seed).then(() => {
                  alert("Seed copied to clipboard: " + seed);
              }).catch(err => {
                  console.error("Could not copy text: ", err);
              });
          }
  
          window.copyToClipboard = copyToClipboard;
  
          /**
           * Clears the previous seeds from local storage and updates the display.
           */
          function clearPreviousSeeds() {
              if (confirm("Are you sure you want to clear all previous seeds?")) {
                  localStorage.removeItem("previousSeeds"); // Clear local storage
                  displayPreviousSeeds([]); // Update the display to show an empty list
              }
          }
  
          window.clearPreviousSeeds = clearPreviousSeeds;
  
          /**
           * Maps the seed to a BPM value based on a predefined list.
           * @param {string} seed - The seed value.
           * @returns {number} - The selected BPM.
           */
          function mapSeedToBpm(seed) {
              const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
              const hash = seed.split("").reduce((acc, char) => {
                  return (10 * acc + parseInt(char, 10)) % 1000000007;
              }, 0);
              const selectedBpm = bpmOptions[hash % bpmOptions.length];
              window.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
              return selectedBpm;
          }
  
          window.mapSeedToBpm = mapSeedToBpm;
  
          /**
           * Displays the Seed and BPM on the info canvas.
           * @param {string} seed - The seed value.
           * @param {number} bpm - The BPM value.
           */
          window.displaySeedAndBPM = displaySeedAndBPM;
  
          // On page load, set the initial state
          window.addEventListener("DOMContentLoaded", () => {
              const infoPanel = document.getElementById("info-panel");
              if (!infoPanel) {
                  window.log("Info panel element not found.");
              } else {
                  const isHidden = localStorage.getItem("infoPanelHidden") === "true";
                  if (isHidden) {
                      infoPanel.classList.add("hidden");
                  }
              }
              
              // Load previously played seeds
              const previousSeeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
              displayPreviousSeeds(previousSeeds);
  
              // Display current seed and BPM
              const seed = window.seed;
              const bpm = mapSeedToBpm(seed);
              displaySeedAndBPM(seed, bpm);
          });
  
          /**
           * Event listener for the "I" key to toggle the Information Panel.
           */
          document.addEventListener("keydown", function(event) {
              if (event.key === "I" || event.key === "i") {
                  toggleInfoPanel();
              }
          });
  
          /**
           * Event handler for the "Clear Previous Seeds" button.
           */
          document.getElementById("clear-seeds-button").addEventListener("click", clearPreviousSeeds);
  
          /**
           * Event handler for the "Load Seed" button.
           */
          document.getElementById("load-seed-button").addEventListener("click", () => {
              const seedInput = document.getElementById("seed-input").value.trim();
              if (seedInput.length === 0) {
                  alert("Please enter a seed.");
                  return;
              }
              // Optional: Validate seed format (e.g., numeric)
              if (!/^\d+$/.test(seedInput)) {
                  alert("Seed must be numeric.");
                  return;
              }
              // Reload the page with the seed as a query parameter
              const url = new URL(window.location.href);
              url.searchParams.set('seed', seedInput);
              window.location.href = url.toString();
          });
  
      })();
    </script>
</seedAndBpmManagement>
  
<!-- Song Inputs -->
<script id="song-inputs">
    window.init = function() {
        window.log('Init function called. Preparing to process song data URLs...');

        const songDataUrls = [


            "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM

            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH

            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA

            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE ** MIGHT BE THIS ONE THAT IS OUT OF SYNC??


            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress

            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP

            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY // Turn Down Channels 1 + 2 (Apollo 13) Turn down Channel 5 - Hindenburg /  Turn channel 8 up - Hi hats

            "/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0", // MintyFresh Vibes

            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE

            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240

            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch

            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60

            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // ON-CHAIN IN THE MEMBRANE
            // Add or remove song URLs as needed
        ];

       // Filter out commented URLs
       const validSongUrls = songDataUrls.filter(url => !url.trim().startsWith('//'));

        window.log(`Found ${validSongUrls.length} valid song data URLs to process.`);

        // Determine playback mode based on the number of songs
        let playbackMode;
        if (validSongUrls.length === 1) {
            playbackMode = 'normal playback mode';
        } else if (validSongUrls.length > 1) {
            playbackMode = 'multiple playback mode';
        } else {
            window.log('No valid songs to process.');
            return;
        }

        window.log(`Player is now in ${playbackMode}.`);

        // Modify the first URL using the global seed
        const seed = window.seed;
        if (typeof seededRandom === 'function') {
            validSongUrls[0] += `?v=${Math.floor(seededRandom(seed) * 1000)}`;
            window.log(`First song URL has been modified using seeded random. New URL: ${validSongUrls[0]}`);
        } else {
            window.log("seededRandom function is not defined.");
        }

        if (validSongUrls.length) {
            window.log('Beginning processing of songDataUrls...');
            if (typeof processSerializedData === 'function') {
                processSerializedData(validSongUrls, VOLUME_CONTROLS, SPEED_CONTROLS);
            } else {
                window.log("processSerializedData function is not defined.");
            }
        } else {
            window.log('songDataUrls array is empty. No data to process.');
        }

        window.log('Init function execution complete.');
        };
        </script>

<!-- Main Initialization -->
<script id="main-initialization">
    window.initializeMultiplierArrays=async function(){window.log("Initializing multiplier arrays..."),window.multiplierArrays=[],window.log("Multiplier arrays initialized.")};

    (async function() {
        window.visualiserMode = false; // Set to true to enable visualiser scripts

        // Ensure the seed is already set
        if (!window.seed) {
            window.log('Seed is not set. Initialization aborted.');
            return;
        }

        // Initialize multiplier arrays
        if (typeof window.initializeMultiplierArrays === 'function') {
            await window.initializeMultiplierArrays();
        } else {
            window.log("initializeMultiplierArrays function is not defined.");
        }

        // Initialize the main application
        if (typeof window.init === 'function') {
            window.init();
            window.log("Main application initialized.");
        } else {
            window.log("init function is not defined.");
        }

        // Conditional Loading of Visualizer or Artwork Scripts
        if (window.visualiserMode && window.enableVisualizerScripts) {
            if (typeof window.loadVisualiserScripts === 'function') {
                await window.loadVisualiserScripts();
                window.log("Visualizer scripts loaded.");
            } else {
                window.log("loadVisualiserScripts function is not defined.");
            }
        } else {
            if (typeof window.loadArtworkScripts === 'function') {
                await window.loadArtworkScripts();
                window.log("Artwork scripts loaded.");
            } else {
                window.log("loadArtworkScripts function is not defined.");
            }
        }

        // Load the image
        document.getElementById('artwork').src = '/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0';
        document.getElementById('artwork').alt = 'Loaded Artwork';

        // Removed Event Listener for Song Completion
    })();
</script>


  



<mainInitialisation>

<script id="main-initialization">(async function(){window.visualiserMode=false;if(!window.seed){window.log('Seed is not set. Initialization aborted.');return;}if(typeof window.initializeMultiplierArrays=="function")await window.initializeMultiplierArrays();else window.log("initializeMultiplierArrays function is not defined.");if(typeof window.init=="function"){window.init();window.log("Main application initialized.");}else window.log("init function is not defined.");if(window.visualiserMode&&window.enableVisualizerScripts){if(typeof window.loadVisualiserScripts=="function"){await window.loadVisualiserScripts();window.log("Visualizer scripts loaded.");}else window.log("loadVisualiserScripts function is not defined.");}else{if(typeof window.loadArtworkScripts=="function"){await window.loadArtworkScripts();window.log("Artwork scripts loaded.");}else window.log("loadArtworkScripts function is not defined.");}document.getElementById("artwork").src="/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0";document.getElementById("artwork").alt="Loaded Artwork";})();</script>
</mainInitialisation>


<constants-and-variables> 
  
<script id="constants-and-variables">
    window.initializeMultiplierArrays=async function(){window.log("Initializing multiplier arrays..."),window.multiplierArrays=[],window.log("Multiplier arrays initialized.")};

const VOLUME_CONTROLS=[[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],SPEED_CONTROLS=[[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]];scheduleMultiplierOnOff=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1];let seedSet=!1,arraysInitialized=!1,audioElements=[];function applyScheduleMultiplier(e,l){try{e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,c)=>c<l.length&&l[c]?1.1*e:e)),console.log("Schedule multiplier applied successfully.")}catch(e){console.error("Error in applyScheduleMultiplier:",e)}}
</script>
</constants-and-variables>


<dataLoadingAndDeserialisation>

    <script>
        const loadPako = async () => {
            try {
                const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
                const textContent = await response.text();
                const scriptContent = (new DOMParser).parseFromString(textContent, "text/html").querySelector("script")?.textContent;
                if (!scriptContent?.includes("pako")) throw new Error("Pako library not found in the fetched content.");
                const scriptElement = document.createElement("script");
                scriptElement.textContent = scriptContent;
                document.head.appendChild(scriptElement);
                console.log("Pako library loaded successfully.");
            } catch (error) {
                console.error("Error occurred during Pako loading:", error);
                throw error;
            }
        };
        
        const fetchAndDeserialize = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                const arrayBuffer = await response.arrayBuffer();
                const inflatedData = pako.inflate(new Uint8Array(arrayBuffer));
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                return deserialize(JSON.parse(jsonString));
            } catch (error) {
                console.error("Error in fetchAndDeserialize:", error);
                throw error;
            }
        };
        
        const fetchAndProcessData = async (urls) => {
            try {
                const results = (await Promise.all(urls.map(async (url) => {
                    try {
                        const data = await fetchAndDeserialize(url);
                        if (!data?.projectSequences) throw new Error(`Invalid data at URL ${url}`);
                        return data;
                    } catch (error) {
                        console.error(`Error processing URL: ${url}`, error);
                        return null;
                    }
                }))).filter(Boolean);
        
                if (!results.length) throw new Error("No valid data was processed.");
                return results;
            } catch (error) {
                console.error("Error in fetchAndProcessData:", error);
                throw error;
            }
        };
        
        function mapSeedToBpm(seed) {
            const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
            const hash = seed.split("").reduce((acc, char) => (10 * acc + parseInt(char, 10)) % 1000000007, 0);
            const selectedBpm = bpmOptions[hash % bpmOptions.length];
            console.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
            return selectedBpm;
        }
        
        const processSerializedDataPart1 = async (songUrls, VOLUME_CONTROLS, SPEED_CONTROLS) => {
            try {
                await loadPako();
                const deserializedData = await fetchAndProcessData(songUrls);
                const selectedBPM = mapSeedToBpm(window.seed);
                
                // Display Seed and BPM in the information panel
                displaySeedAndBPM(window.seed, selectedBPM);
        
                // Initialize global metadata object
                window.globalMetadata = {
                    volumeLevels: {},
                    playbackSpeeds: {},
                    trimTimes: {},
                };
        
                // Populate globalMetadata with initial data
                deserializedData.forEach((songData, songIndex) => {
                    songData.channelURLs.forEach((url, channelIndex) => {
                        const channelId = `Channel_${songIndex}_${channelIndex}`;
                        // Store metadata in globalMetadata
                        window.globalMetadata.volumeLevels[channelId] = songData.channelVolume[channelIndex];
                        window.globalMetadata.playbackSpeeds[channelId] = songData.channelPlaybackSpeed[channelIndex];
                        window.globalMetadata.trimTimes[channelId] = songData.trimSettings[channelIndex];
                    });
                });
        
                window.processedData = {
                    deserializedData: deserializedData,
                    selectedBPM: selectedBPM,
                    VOLUME_CONTROLS: VOLUME_CONTROLS,
                    SPEED_CONTROLS: SPEED_CONTROLS,
                    songDataUrls: songUrls
                };
        
                console.log("Data loading and deserialization complete.");
                document.dispatchEvent(new CustomEvent("dataLoadingComplete"));
            } catch (error) {
                console.error("Error in processSerializedDataPart1:", error);
            }
        };
        window.processSerializedData = processSerializedDataPart1;
        console.log("DataLoadingAndDeserializationScript initialized.");
        </script>
</dataLoadingAndDeserialisation>


<localdataprocessing>

<script>
        const shuffleArray = (array, seed) => {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(seededRandom(seed++) * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        };
        
        const adjustChannelData = (songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS) => {
            const bpmRatio = selectedBPM / songData.projectBPM;
            songData.channelPlaybackSpeed = songData.channelPlaybackSpeed.map((speed, index) => {
                let adjustedSpeed = speed * bpmRatio * (SPEED_CONTROLS[songIndex]?.[index] || 1);
                return Math.max(isNaN(adjustedSpeed) ? 0.1 : adjustedSpeed, 0.1);
            });
        
            const volumeControl = VOLUME_CONTROLS[songIndex] || [];
            const globalVolume = volumeControl[0] || 1;
            songData.channelVolume = songData.channelVolume.map((volume, index) => {
                return volume * globalVolume * (volumeControl[index + 1] || 1);
            });
        
            // Update globalMetadata with adjusted values
            songData.channelURLs.forEach((url, channelIndex) => {
                const channelId = `Channel_${songIndex}_${channelIndex}`;
                window.globalMetadata.volumeLevels[channelId] = songData.channelVolume[channelIndex];
                window.globalMetadata.playbackSpeeds[channelId] = songData.channelPlaybackSpeed[channelIndex];
                // Trim times remain the same as they were already set
            });
        };
        
        const processSerializedDataPart2 = async () => {
            try {
                const { deserializedData, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS } = window.processedData;
                deserializedData.forEach((songData, songIndex) => adjustChannelData(songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS));
                const finalSong = assembleProcessedSong(deserializedData, selectedBPM);
        
                // Apply schedule multiplier if the function exists
                if (typeof applyScheduleMultiplier === 'function') {
                    applyScheduleMultiplier(finalSong, window.scheduleMultiplierOnOff);
                } else {
                    console.warn("applyScheduleMultiplier is not defined.");
                }
        
                window.globalJsonData = finalSong;
                window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(finalSong)], { type: "application/json" }));
                document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
                console.log("Local data processing complete.");
            } catch (error) {
                console.error("Error in processSerializedDataPart2:", error);
            }
        };
        
        // Event listener to start processing after data is loaded
        document.addEventListener("dataLoadingComplete", processSerializedDataPart2);
        console.log("LocalDataProcessingScript initialized and awaiting data.");
</script>
</localdataprocessing>


<helperfunctions>

<!-- Helper Functions -->
<script id="helper-functions">
    // Linear Congruential Generator (LCG) implementation for better randomness
    function createSeededRandomGenerator(seed) {
        var a = seed % 2147483647;
        if (a <= 0) a += 2147483646;
        return function() {
            a = (a * 16807) % 2147483647;
            return (a - 1) / 2147483646;
        };
    }
    
    // Function to convert a string seed to a 32-bit integer
    function stringToSeedInt(seedStr) {
        let seed = 0;
        for (let i = 0; i < seedStr.length; i++) {
            seed = (seed * 31 + seedStr.charCodeAt(i)) & 0x7fffffff;
        }
        return seed;
    }
        // Function to parse volume level
        function parseVolumeLevel(input) {
        const volume = typeof input === "number" ? input : parseFloat(input);
        return Math.max(0, Math.min(isNaN(volume) ? 1 : volume, 3));
    }


    const assembleProcessedSong = (deserializedData, selectedBPM) => {
        console.log("[songAssemblyLogs] Starting to assemble the processed song...");
    
        // Flatten all channels from all songs into a single array
        const allChannels = deserializedData.flatMap((song, songIndex) =>
            song.channelURLs.map((url, channelIndex) => ({
                url,
                volume: song.channelVolume[channelIndex],
                speed: song.channelPlaybackSpeed[channelIndex],
                trim: song.trimSettings[channelIndex],
                source: `data${songIndex + 1}`,
                index: channelIndex
            }))
        );
    
        // Log all channels before selection
        console.log("[songAssemblyLogs] All channels (before selection):", allChannels);
    
        // Total number of channels before selection
        const totalChannels = allChannels.length;
        console.log(`[songAssemblyLogs] Total number of channels in the array: ${totalChannels}`);
    
        // Convert the seed to an integer
        const seedInt = stringToSeedInt(window.seed);
    
        // Shuffle and slice the channels for final selection
        const shuffledChannels = shuffleArray(allChannels.slice(), seedInt); // Use a copy of allChannels
        const selectedChannels = shuffledChannels.slice(0, 28);
    
        // Add global index to selected channels
        selectedChannels.forEach((channel, index) => {
            channel.globalIndex = index;
        });
    
        // Log the selected channels
        console.log("[songAssemblyLogs] Selected channels for the new song:", selectedChannels);
    
        // Total number of selected channels
        const totalSelectedChannels = selectedChannels.length;
        console.log(`[songAssemblyLogs] Total number of selected channels for this song: ${totalSelectedChannels}`);
    
        // Split selected channels into groups for further processing
        const t = [
            selectedChannels.slice(0, 20),
            selectedChannels.slice(20, 24),
            selectedChannels.slice(24, 28)
        ];
    
        // Create the new song object
        const finalSong = {
            ...deserializedData[0], // Start with the structure of the first song
            projectBPM: selectedBPM,
            channelURLs: selectedChannels.map(channel => channel.url),
            channelVolume: selectedChannels.map(channel => channel.volume),
            channelPlaybackSpeed: selectedChannels.map(channel => channel.speed),
            trimSettings: selectedChannels.map(channel => channel.trim),
            projectSequences: {}
        };
    
        // Create a mapping for all song data
        const songDataMapping = deserializedData.reduce((acc, song, index) => {
            acc[`data${index + 1}`] = song;
            return acc;
        }, {});
    
        // Variables for logging channel addition
        let currentChannels = [];
        let totalChannelsAdded = 0;
        const channelAdditionLog = [];
    
        // Process sequences
        for (const sequenceId in deserializedData[0].projectSequences) {
            finalSong.projectSequences[sequenceId] = {};
            const sequenceNumber = parseInt(sequenceId.replace(/\D/g, ""), 10);
    
            // Select channels to add to each sequence based on sequence number
            if (sequenceNumber <= 1) {
                currentChannels = t[0];
            } else if (sequenceNumber <= 3) {
                currentChannels = [...t[0], ...t[1]];
            } else if (sequenceNumber <= 11) {
                currentChannels = [...t[0], ...t[1], ...t[2]];
            }
    
            // Log channels added for each sequence
            if (currentChannels.length > totalChannelsAdded) {
                channelAdditionLog.push({
                    sequenceNumber,
                    channelsAdded: currentChannels.length - totalChannelsAdded,
                    totalChannels: currentChannels.length
                });
                totalChannelsAdded = currentChannels.length;
            }
    
            // Map channels to the final song structure
            currentChannels.forEach((channel, index) => {
                const channelData = (songDataMapping[channel.source]?.projectSequences[sequenceId] || {})[`ch${channel.index}`] || { steps: [] };
                finalSong.projectSequences[sequenceId][`ch${index}`] = {
                    ...channelData,
                    steps: Array.isArray(channelData.steps) ? channelData.steps : [],
                    globalIndex: channel.globalIndex
                };
            });
        }
    
        // Log the number of sequences and the number of channels in each
        const totalSequences = Object.keys(finalSong.projectSequences).length;
        console.log(`[songAssemblyLogs] Total number of sequences in the new generative song: ${totalSequences}`);
        Object.keys(finalSong.projectSequences).forEach(sequenceId => {
            console.log(`[songAssemblyLogs] Sequence ${sequenceId} contains ${Object.keys(finalSong.projectSequences[sequenceId]).length} channels.`);
        });
    
        // Log channel addition log
        console.log("[songAssemblyLogs] Channel addition log:", channelAdditionLog);
    
        // Return the final song object
        return finalSong;
    };
    </script>

</helperfunctions>

<audioContextManager>

<script id="audio-context-manager">
!function(){if(!window.ACM){class t{constructor(){return t.instance||(this.aCtx=null,t.instance=this),t.instance}init(){this.aCtx&&"closed"!==this.aCtx.state||(this.aCtx=new(window.AudioContext||window.webkitAudioContext),this.aCtx.onstatechange=()=>{})}getCtx(){return this.aCtx||this.init(),this.aCtx}async resume(){this.init(),"suspended"===this.aCtx.state&&await this.aCtx.resume()}async suspend(){this.aCtx&&"running"===this.aCtx.state&&await this.aCtx.suspend()}async resetApp(){"function"==typeof stopPlayback&&await stopPlayback(),window.audioElements=[],window.activeSources=[],window.arraysInitialized=!1,window.isReadyToPlay=!1,globalJsonData=null,globalAudioBuffers=[],preprocessedSequences={},currentStep=0,beatCount=0,barCount=0,currentSequence=0,playbackTimeoutId=null,nextNoteTime=0,totalSequences=0,isPlaying=!1,globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalReversedAudioBuffers={},isReversePlay=!1,"function"==typeof cleanUpWorker&&await cleanUpWorker(),await initApp()}}window.ACM=new t}}();
</script>
</audioContextManager>


<audioControl>
<details>
  <summary>Audio Control Functions Documentation</summary>

  ### Overview
  This section contains functions responsible for controlling audio playback within the application. Specifically, it handles suspending and stopping audio contexts and active audio sources, ensuring smooth transitions and proper resource management.

  ### Functions

  #### `sS()`
  - **Purpose**: Suspends the audio context if it is currently running.
  - **Description**:
    - Checks if the `audioCtx` (Audio Context) state is `"running"`.
    - If running, it asynchronously suspends the `audioCtx`.
  - **Key Variables/Functions**:
    - `audioCtx`: The main Audio Context managing audio operations.
    - `audioCtx.state`: Indicates the current state of the Audio Context (`"running"`, `"suspended"`, etc.).
    - `audioCtx.suspend()`: Method to suspend the Audio Context.

  #### `sp()`
  - **Purpose**: Stops all active audio sources with a fade-out effect and suspends the audio context.
  - **Description**:
    - Iterates over all `activeSources`.
    - For each active source:
      - Cancels any scheduled gain values at the current time.
      - Sets the gain to its current value immediately.
      - Applies a linear ramp to reduce the gain to `0` over the duration specified by `fadeDuration`.
      - Stops the audio source after the fade-out completes.
      - Disconnects both the audio source and its associated gain node.
    - Clears the list of active sources.
    - After a short delay (50 milliseconds), suspends the `audioCtx` and resets the playback state.
  - **Key Variables/Functions**:
    - `activeSources`: An object tracking all currently active audio sources.
    - `audioCtx.currentTime`: The current time of the Audio Context, used for scheduling.
    - `gainNode`: Controls the volume of the audio source.
    - `fadeDuration`: Duration over which the audio fades out.
    - `a.stop()`: Stops the audio source after the fade-out.
    - `a.disconnect()`: Disconnects the audio source from the Audio Context.
    - `e.disconnect()`: Disconnects the gain node.
    - `setTimeout()`: Delays the suspension of the Audio Context and resets playback state.

  ### Organization
  - **Related Functions**: Both `sS()` and `sp()` deal with controlling the state of the Audio Context and managing active audio sources.
  - **Variables**:
    - `audioCtx`: Central to both functions for managing audio state.
    - `activeSources`: Managed within `sp()` to track and control audio sources.

  ### Identified Improvements
  - **Modularizing**:
    - **Separate Concerns**: Consider separating the suspension of the Audio Context (`sS()`) from the stopping of active sources (`sp()`) into different modules or utilities for better maintainability.
    - **Fade-Out Handling**: Extract the fade-out logic into a dedicated function to promote reusability and clarity.
  - **Optimizing**:
    - **Error Handling**: Implement error handling to manage potential issues when suspending the Audio Context or stopping sources.
    - **Performance**: Review the use of `setTimeout` to ensure it's the most efficient way to handle the delay. Consider using Promises or async/await for better readability and control.

  ### Playback Control Understanding
  - **Suspending Audio**: The `sS()` function ensures that the audio context can be paused, preventing further audio from playing without fully shutting down the resources.
  - **Stopping Audio**: The `sp()` function provides a controlled way to stop all active audio sources with a smooth fade-out, enhancing the user experience by avoiding abrupt stops.

  ### User Interaction Improvement
  - By clearly defining how audio playback can be suspended or stopped, these functions contribute to responsive and intuitive user controls, allowing users to manage audio playback seamlessly.

</details>
<script id="audio-control-functions">
async function sS(){"running"===audioCtx.state&&await audioCtx.suspend()}async function sp(){for(const a in activeSources)activeSources[a].forEach((({source:a,gainNode:e})=>{const n=audioCtx.currentTime;e.gain.cancelScheduledValues(n),e.gain.setValueAtTime(e.gain.value,n),e.gain.linearRampToValueAtTime(0,n+fadeDuration),a.stop(n+fadeDuration),a.disconnect(),e.disconnect()})),activeSources[a]=[];setTimeout((async()=>{await audioCtx.suspend(),resetPlaybackState()}),50)}
</script>
</audioControl>



<globalDefinitionsAndInitialisations>
<details>
  <summary>Global Definitions and Initialization Documentation</summary>

  ### Overview
  This script initializes and defines global variables, configurations, and essential functions required for the audio playback application. It sets up the audio context, manages global states such as volume, playback speed, and handles user interactions like stopping playback. Additionally, it establishes communication channels for playback messages.

  ### Global Variables and Constants

  #### Audio Context and Related Variables
  - **`audioCtx` / `aCtx`**
    - **Type**: `AudioContext`
    - **Purpose**: Manages all audio operations within the application.
    - **Initialization**:
      - Attempts to retrieve an existing Audio Context from `window.AudioContextManager`.
      - If unavailable, creates a new instance using `AudioContext` or `webkitAudioContext` for compatibility.
    - **Debugging**:
      - Logs a message to the console upon initialization: `"[globalDefinitionsDebug] AudioContext initialized outside of property definitions."`
  
  #### Volume and Playback Control
  - **`globalVolumeMultiplier`**
    - **Type**: `number`
    - **Default**: `1`
    - **Purpose**: Multiplies the global volume level, allowing for volume adjustments across all audio sources.
  - **`globalTrimTimes`**
    - **Type**: `object`
    - **Purpose**: Stores trim times for audio clips, allowing precise control over playback start and end points.
  - **`globalVolumeLevels`**
    - **Type**: `object`
    - **Purpose**: Manages individual volume levels for different audio sources or tracks.
  - **`globalPlaybackSpeeds`**
    - **Type**: `object`
    - **Purpose**: Controls the playback speed of audio sources, enabling effects like slow motion or fast-forward.
  
  #### Audio Source Management
  - **`activeSources` / `aS`**
    - **Type**: `array`
    - **Purpose**: Tracks currently active audio sources that are playing.
  - **`globalGainNodes` / `gGN`**
    - **Type**: `Map`
    - **Purpose**: Maps audio sources to their corresponding gain nodes for volume control.
  - **`gainNodes`**
    - **Type**: `object`
    - **Purpose**: Stores gain nodes used to adjust the volume of individual audio sources.
  
  #### Audio Buffers
  - **`globalAudioBuffers` / `gAB`**
    - **Type**: `array`
    - **Purpose**: Holds audio buffer data for loaded audio clips.
  - **`globalReversedAudioBuffers` / `gRAB`**
    - **Type**: `object`
    - **Purpose**: Contains reversed versions of audio buffers for effects that require playing audio backwards.
  
  #### Playback State Variables
  - **`isReversePlay` / `isRP`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates whether the current playback is in reverse mode.
  - **`isReadyToPlay` / `isReadyToPlay`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Signals whether the application is ready to start playback.
  - **`isToggleInProgress` / `isToggleInProgress`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Flags if a toggle action (like play/pause) is currently being processed.
  - **`isPlaying` / `isP`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates whether audio is currently playing.
  
  #### Playback Timing
  - **`currentStep` / `cS`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Tracks the current step in a sequence of audio playback.
  - **`currentSequence` / `cQ`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Identifies the current sequence being played.
  - **`nextNoteTime` / `nNT`**
    - **Type**: `number`
    - **Purpose**: Schedules the timing for the next note in the playback sequence.
  - **`fadeDuration` / `fD`**
    - **Type**: `number`
    - **Default**: `0.01`
    - **Purpose**: Duration for fade-in and fade-out effects during audio transitions.
  - **`defaultVolume` / `dV`**
    - **Type**: `number`
    - **Default**: `1`
    - **Purpose**: Sets the default volume level for audio playback.
  
  #### Data Structures
  - **`globalJsonData`**
    - **Type**: `object` or `null`
    - **Default**: `null`
    - **Purpose**: Stores JSON data related to audio configurations or sequences.
  - **`sourceChannelMap` / `gVM`**
    - **Type**: `Map`
    - **Purpose**: Maps audio sources to their respective channels for organized playback.
  - **`preprocessedSequences`**
    - **Type**: `object`
    - **Purpose**: Contains sequences that have been preprocessed for efficient playback.
  
  #### Playback Controls
  - **`bpm`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Beats per minute setting for timing audio sequences.
  - **`isReadyToPlay`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates if the application has loaded all necessary resources and is ready for playback.
  
  #### Broadcast Channels
  - **`AudionalPlayerMessages` / `APC`**
    - **Type**: `BroadcastChannel`
    - **Purpose**: Facilitates communication for playback messages across different contexts or threads.
  - **`window.enableVisualizerScripts` / `window.eVS`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Toggles the enabling of visualizer scripts for audio visualization.
  
  ### Functions

  #### `eACS()`
  - **Purpose**: Ensures the Audio Context is active and resumes it if suspended.
  - **Description**:
    - Checks if `aCtx` exists; if not, initializes it.
    - If the Audio Context state is `"suspended"`, it resumes the context asynchronously.
  - **Key Variables/Functions**:
    - `aCtx`: The Audio Context being managed.
    - `aCtx.state`: Current state of the Audio Context (`"running"`, `"suspended"`, etc.).
    - `aCtx.resume()`: Method to resume a suspended Audio Context.

  #### `sP()`
  - **Purpose**: Placeholder for a function to handle stopping playback.
  - **Description**:
    - Currently empty, intended to be implemented with logic to stop audio playback.
  - **Key Variables/Functions**:
    - To be defined based on playback stopping requirements.

  ### Property Definitions

  #### `window.isPlaying`
  - **Type**: `property` with getter and setter
  - **Purpose**: Provides controlled access to the `isP` variable.
  - **Getter**: Returns the current value of `isP`.
  - **Setter**: Updates the value of `isP` with the provided value `e`.

  #### `window.currentStep`
  - **Type**: `property` with getter and setter
  - **Purpose**: Manages access to the `cS` variable tracking the current playback step.
  - **Getter**: Returns the current value of `cS`.
  - **Setter**: Updates the value of `cS` with the provided value `e`.

  #### `window.currentSequence`
  - **Type**: `property` with getter and setter
  - **Purpose**: Manages access to the `cQ` variable tracking the current playback sequence.
  - **Getter**: Returns the current value of `cQ`.
  - **Setter**: Updates the value of `cQ` with the provided value `e`.

  ### Event Listeners

  #### Stop Button Listener
  - **Selector**: `document.getElementById("stop-button")`
  - **Event**: `click`
  - **Handler**: Asynchronously calls the `sP()` function when the stop button is clicked.
  - **Purpose**: Allows users to stop audio playback through the UI.

  ### Organization
  - **Global State Management**: Variables like `isPlaying`, `currentStep`, and `currentSequence` manage the overall playback state.
  - **Audio Control**: `audioCtx`, `aCtx`, and related gain nodes handle the audio processing and control.
  - **Playback Configuration**: Variables such as `globalVolumeMultiplier`, `bpm`, and `fadeDuration` configure playback settings.
  - **Communication Channels**: `AudionalPlayerMessages` and `APC` manage inter-process or inter-thread communication for playback control.

  ### Identified Improvements

  - **Modularizing**:
    - **Separate Initialization**: Divide the initialization of global variables and the Audio Context into separate modules or files to enhance readability and maintainability.
    - **Encapsulate State Management**: Group related state variables and their property definitions into a dedicated state management module or object.
    - **Event Handling**: Isolate event listeners into their own module to keep the global script uncluttered.

  - **Optimizing**:
    - **Redundant Variables**: There are duplicate variables (`audioCtx` and `aCtx`, `AudionalPlayerMessages` and `APC`, etc.). Consolidate these to avoid confusion and potential bugs.
    - **Lazy Initialization**: Initialize heavy objects like `AudioContext` only when needed to improve initial load performance.
    - **Use Constants Appropriately**: Ensure that values like `fadeDuration` and `defaultVolume` are defined as constants if they are not meant to change during runtime.

  - **Error Handling**:
    - **Audio Context Errors**: Implement error handling for scenarios where the Audio Context fails to initialize or resume.
    - **Event Listener Robustness**: Check for the existence of the stop button before adding an event listener to prevent potential errors.

  - **Performance Enhancements**:
    - **Efficient Data Structures**: Review the use of `Map` vs. plain objects for `sourceChannelMap`, `globalGainNodes`, etc., to ensure optimal performance based on usage patterns.
    - **Asynchronous Operations**: Utilize `async/await` consistently for asynchronous functions to improve code readability and maintainability.

  ### Playback Control Understanding
  - **Audio Context Management**: The script ensures that the Audio Context is properly initialized and managed, allowing for control over the audio processing lifecycle.
  - **Global State Tracking**: Variables like `isPlaying`, `currentStep`, and `currentSequence` provide a mechanism to track and control the playback state, enabling features like play, pause, stop, and sequence navigation.
  - **User Interaction Handling**: The stop button event listener allows users to interact with the playback controls, enhancing the application's responsiveness and usability.

  ### User Interaction Improvement
  - **Responsive Controls**: By managing playback states and providing event listeners for user actions, the application ensures that user interactions are handled smoothly and intuitively.
  - **Feedback Mechanisms**: Implementing state tracking variables allows the UI to provide real-time feedback to users about the current playback status, improving the overall user experience.

</details>
<script>
window.enableVisualizerScripts=!1;let globalVolumeMultiplier=1,globalJsonData=null,bpm=0;const sourceChannelMap=new Map;let globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalGainNodes=new Map,globalAudioBuffers=[],globalReversedAudioBuffers={},isReversePlay=!1;const gainNodes={};let audioCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext);console.log("[globalDefinitionsDebug] AudioContext initialized outside of property definitions.");let preprocessedSequences={},isReadyToPlay=!1,currentStep=0,currentSequence=0,nextNoteTime=0;const fadeDuration=.01,defaultVolume=1;let isToggleInProgress=!1,isPlaying=!1;const AudionalPlayerMessages=new BroadcastChannel("channel_playback");
window.eVS=!1;let gVM=1,gJD=null,gTM=new Map,gTT={},gVL={},gPS={},aS=[],gGN=new Map,gAB=[],gRAB={},isRP=!1,gN={},aCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext),pS={},isR=!1,cS=0,cQ=0,nNT=0;const fD=.01,dV=1,tIP=!1,isP=!1,APC=new BroadcastChannel("channel_playback");async function eACS(){aCtx||(aCtx=new(window.AudioContext||window.webkitAudioContext)),"suspended"===aCtx.state&&await aCtx.resume()}async function sP(){}Object.defineProperty(window,"isPlaying",{get:()=>isP,set(e){isP=e}}),Object.defineProperty(window,"currentStep",{get:()=>cS,set(e){cS=e}}),Object.defineProperty(window,"currentSequence",{get:()=>cQ,set(e){cQ=e}}),document.getElementById("stop-button")?.addEventListener("click",(async()=>{await sP()}));
</script>   
</globalDefinitionsAndInitialisations>


<jsonloadingandplayback>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is responsible for loading JSON data that defines the structure and sequences of the generative song. It processes this JSON data to prepare it for playback by performing the following tasks:
            <ul>
                <li><strong>Fetching JSON Data:</strong> Retrieves the JSON file from a specified URL.</li>
                <li><strong>Analyzing JSON Structure:</strong> Recursively examines the JSON to gather statistics about sequences, channels, and data types.</li>
                <li><strong>Preparing Playback Data:</strong> Organizes the JSON data into a format suitable for playback, calculating timings based on the BPM and segregating normal and reverse steps.</li>
                <li><strong>Managing Global Metadata:</strong> Stores essential metadata such as volume levels, playback speeds, and trim times in the global <code>window.globalMetadata</code> object to ensure accessibility across the application.</li>
                <li><strong>Audio Data Processing:</strong> Initiates the fetching and decoding of audio files associated with each channel and schedules them for playback.</li>
                <li><strong>Scheduling Playback:</strong> Preprocesses the playback data to calculate precise timings and schedules the playback loop.</li>
            </ul>
            <br/>
            **Key Components:**
            <ul>
                <li><strong>Global Metadata:</strong> <code>window.globalMetadata</code> stores <code>trimTimes</code>, <code>volumeLevels</code>, and <code>playbackSpeeds</code> for each channel, ensuring consistent access and modification throughout the application.</li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>loadJsonFromUrl(url)</code>: Fetches and processes the JSON data from the provided URL.</li>
                        <li><code>analyzeJsonStructure(jsonData, stats)</code>: Analyzes the JSON structure to collect statistics.</li>
                        <li><code>findAndSetEndSequence(projectData)</code>: Identifies and sets the end sequence in the project data.</li>
                        <li><code>prepareForPlayback(jsonData, stats)</code>: Prepares the JSON data for playback, setting up metadata and organizing sequences.</li>
                        <li><code>preprocessAndSchedulePlayback(playbackData)</code>: Preprocesses playback data to calculate timings and schedules the playback.</li>
                        <li><code>processSteps(steps)</code>: Calculates the timing for each step based on BPM.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong> Comprehensive logging is implemented to track each step of the data loading and processing pipeline, aiding in debugging and ensuring transparency in data handling.</li>
            </ul>
            <br/>
            **Error Handling:**
            <ul>
                <li>Errors during data fetching, JSON parsing, or processing are caught and logged to the console, preventing the application from crashing and facilitating easier debugging.</li>
            </ul>
        </p>
    </details>
<script>
    
    // Fetch and process the audio data
    const fetchAndProcessAudioData = async (urls) => {
        // Process each URL and create reversed buffers after all are processed
        await Promise.all(urls.map((url, index) => processAudioUrl(url, index + 1)));
        createReversedBuffers();
    };

    // Get or create a gain node for the given channel
    const getOrCreateGainNode = (channel) => {
        // If the gain node doesn't exist for this channel, create it
        if (!gainNodes[channel]) {
            const gainNode = audioCtx.createGain(); // Create a gain node
            gainNode.connect(audioCtx.destination); // Connect it to the audio context destination (output)
            gainNodes[channel] = gainNode; // Store the gain node for this channel
        }
        return gainNodes[channel]; // Return the gain node
    };

   // Process the audio URL for each channel
const processAudioUrl = async (url, channelIndex) => {
    const channelName = `Channel ${channelIndex}`; // Name the channel based on the index

    // Log the URL being processed
    console.log(`[LOG] Processing URL: ${url} for channel: ${channelName}`);

    // Log specific processing for the targeted URL
    if (url.endsWith("3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0")) {
        console.log(`[LOG] Processing targeted URL for channel: ${channelName}`);
    }

    try {
        const response = await fetch(url); // Fetch the audio URL

        // Check if the fetch was successful
        if (!response.ok) {
            throw new Error(`Fetch failed: ${url}, Status: ${response.status}`);
        }

        const contentType = response.headers.get("Content-Type"); // Get the content type
        const audioBuffer = await fetchAndDecodeAudio(response, contentType); // Decode the audio based on the content type

        if (audioBuffer) {
            const gainNode = getOrCreateGainNode(channelName); // Get or create the gain node for the channel
            gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channelName]) * globalVolumeMultiplier; // Set the gain value based on global settings

            // Log audio buffer processing completion for the targeted URL
            if (url.endsWith("3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0")) {
                console.log(`[LOG] Successfully processed audio buffer for targeted URL: ${url}, Channel: ${channelName}`);
            }

            // Push the decoded buffer and gain node to the global audio buffer array
            globalAudioBuffers.push({
                buffer: audioBuffer,
                gainNode: gainNode,
                channel: channelName
            });

            // Log completion of audio buffer processing for the URL
            console.log(`[LOG] Successfully processed audio buffer for URL: ${url}, Channel: ${channelName}`);
        } else {
            console.error(`Decoding failed for ${channelName}: ${url}`);
        }
    } catch (error) {
        console.error(`Error processing ${channelName}:`, error);
    }
};


    // Set the global volume multiplier and apply it to all gain nodes
    const setGlobalVolumeMultiplier = (multiplier) => {
        globalVolumeMultiplier = Math.max(0, multiplier); // Ensure the multiplier is non-negative

        // Update the gain value for each channel based on the global volume multiplier
        globalAudioBuffers.forEach(({ gainNode, channel }) => {
            gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channel]) * globalVolumeMultiplier;
        });
    };

    // Fetch and decode the audio data based on the content type
    const fetchAndDecodeAudio = async (response, contentType) => {
        try {
            if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer(); // Get the audio data as an ArrayBuffer
                return audioCtx.decodeAudioData(arrayBuffer); // Decode the audio data
            }

            const textData = await response.text(); // If it's not audio, get it as text
            let base64Data = null;

            if (/application\/json/.test(contentType)) {
                base64Data = JSON.parse(textData).audioData; // Extract audio data from JSON
            } else if (/text\/html/.test(contentType)) {
                base64Data = extractBase64FromHTML(textData); // Extract base64 from HTML
            }

            if (base64Data) {
                const audioBuffer = base64ToArrayBuffer(base64Data.split(",")[1]); // Convert base64 to ArrayBuffer
                return audioCtx.decodeAudioData(audioBuffer); // Decode the audio data
            }

            if (/audio\//.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer(); // Get the audio data
                return audioCtx.decodeAudioData(arrayBuffer); // Decode the audio data
            }
        } catch (error) {
            console.error("[fetchAndDecodeAudio] Decoding error:", error);
        }
        return null; // Return null if decoding fails
    };

    // Create reversed buffers for channels that require it
    const createReversedBuffers = () => {
        const channelsToReverse = new Set(); // Set to keep track of channels to reverse

        // Iterate through project sequences to find channels with steps marked to reverse
        Object.values(globalJsonData.projectSequences).forEach((sequence) => {
            Object.entries(sequence).forEach(([trackId, trackData]) => {
                if (trackData.steps.some(step => step.reverse)) {
                    const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;
                    channelsToReverse.add(channelName); // Add the channel to the set if it has any steps to reverse
                }
            });
        });

        // Reverse the audio buffers for the channels that need reversing
        globalAudioBuffers.forEach(({ buffer, channel }) => {
            if (channelsToReverse.has(channel)) {
                globalReversedAudioBuffers[channel] = reverseBuffer(buffer); // Store the reversed buffer
            }
        });
    };

    // Reverse the audio buffer for a given channel
    const reverseBuffer = (buffer) => {
        const reversedBuffer = audioCtx.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate); // Create a new buffer for reversed audio

        // Reverse the audio data for each channel
        for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
            const originalChannelData = buffer.getChannelData(channel); // Get the original channel data
            const reversedChannelData = reversedBuffer.getChannelData(channel); // Get the reversed channel data

            for (let i = 0; i < originalChannelData.length; i++) {
                reversedChannelData[i] = originalChannelData[originalChannelData.length - i - 1]; // Reverse the data
            }
        }

        return reversedBuffer; // Return the reversed buffer
    };

    // Convert base64 encoded data to an ArrayBuffer
    const base64ToArrayBuffer = (base64) => {
        try {
            const binaryString = atob(base64); // Decode base64
            const len = binaryString.length;
            const bytes = new Uint8Array(len);

            // Convert binary string to a byte array
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer; // Return the ArrayBuffer
        } catch (error) {
            console.error("[base64ToArrayBuffer] Conversion error:", error);
            return null; // Return null on error
        }
    };

    // Extract base64 encoded audio data from an HTML response
    const extractBase64FromHTML = (html) => {
        try {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, "text/html");
            const audioSrc = doc.querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");

            if (/^data:audio\/(wav|mp3|mp4);base64,/.test(audioSrc?.toLowerCase()) || /audio\//.test(audioSrc?.toLowerCase())) {
                return audioSrc; // Return the base64 encoded audio source
            }

            console.error("[extractBase64FromHTML] Invalid audio source format.");
        } catch (error) {
            console.error("[extractBase64FromHTML] Parsing error:", error);
        }
        return null; // Return null on error
    };

    // Initialization log
    console.log("Audio processing script loaded.");
   
// Load JSON from a URL, process it, and prepare for playback
const loadJsonFromUrl = async (url) => {
    try {
        // Fetch JSON data from the URL
        const response = await fetch(url);
        
        // Check if the request was successful
        if (!response.ok) {
            throw new Error(`HTTP error: ${response.status}`);
        }

        // Parse the JSON data and store it in globalJsonData
        globalJsonData = await response.json();

        // Initialize an object to collect stats and details about the JSON structure
        const stats = {
            channelsWithUrls: 0, // Count channels with URLs
            sequencesCount: 0, // Count the number of sequences
            activeStepsPerSequence: {}, // Active steps per sequence
            activeChannelsPerSequence: {}, // Active channels per sequence
            types: {} // Data types found in the JSON structure
        };

        // Analyze the structure of the JSON data and populate stats
        analyzeJsonStructure(globalJsonData, stats);

        // Prepare the JSON data for playback
        const playbackData = prepareForPlayback(globalJsonData, stats);

        // Fetch and process audio data based on the channel URLs
        await fetchAndProcessAudioData(playbackData.channelURLs);

        // Preprocess the data and schedule it for playback
        preprocessAndSchedulePlayback(playbackData);

    } catch (error) {
        console.error("Failed to load JSON:", error);
    }
};

// Analyze the structure of the JSON data and gather stats
const analyzeJsonStructure = (jsonData, stats) => {
    // Check if projectSequences exists and is an object
    if (jsonData.projectSequences && typeof jsonData.projectSequences === 'object') {
        // Iterate through projectSequences entries
        Object.entries(jsonData.projectSequences).forEach(([sequenceId, sequenceData]) => {
            // Initialize step counts and active channels for each sequence
            stats.activeStepsPerSequence[sequenceId] = 0;
            stats.activeChannelsPerSequence[sequenceId] = [];

            // Iterate through each track in the sequence
            Object.entries(sequenceData).forEach(([trackId, trackData]) => {
                const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;

                // Count the number of steps for the track
                stats.activeStepsPerSequence[sequenceId] += trackData.steps.length;

                // Add the channel to the list of active channels for this sequence
                stats.activeChannelsPerSequence[sequenceId].push(channelName);
            });
        });
    }

    // Analyze the rest of the JSON structure
    Object.entries(jsonData).forEach(([key, value]) => {
        if (key !== "projectSequences") {
            // Determine the type of each top-level key
            const type = Array.isArray(value) ? "array" : typeof value;
            stats.types[type] = (stats.types[type] || 0) + 1;

            // Recursively analyze nested objects or arrays
            if (["object", "array"].includes(type)) {
                analyzeJsonStructure(value, stats);
            }
        }
    });
};

// Find and set the end sequence for the project
const findAndSetEndSequence = (projectData) => {
    if (projectData?.sequences) {
        let lastNonEmptySequence = null;

        // Iterate through the sequences to find the last one with normal steps
        for (const [sequenceId, sequenceData] of Object.entries(projectData.sequences)) {
            // Check if the sequence has any non-empty normal steps
            const isEmpty = Object.values(sequenceData.normalSteps).every(steps => !steps.length);

            // If it's non-empty, save it as the last non-empty sequence
            if (!isEmpty) {
                lastNonEmptySequence = sequenceData;
            }

            // Set the end sequence when an empty sequence is found after a non-empty one
            if (isEmpty && lastNonEmptySequence) {
                projectData.endSequence = lastNonEmptySequence;
                break;
            }
        }

        // If no end sequence is set, use the last non-empty sequence
        if (!projectData.endSequence && lastNonEmptySequence) {
            projectData.endSequence = lastNonEmptySequence;
        }
    }
};

// Prepare the JSON data for playback
const prepareForPlayback = (jsonData, stats) => {
    const {
        channelURLs, // List of channel URLs
        trimSettings = [], // Trim settings for each channel
        channelVolume = [], // Volume settings for each channel
        channelPlaybackSpeed = [], // Playback speed settings for each channel
        projectSequences, // Sequences data
        projectName, // Name of the project
        projectBPM, // BPM for the project
        currentSequence // Current sequence being played
    } = jsonData;

    // Set global variables for playback
    bpm = projectBPM;
    totalSequences = currentSequence;
    globalTrimTimes = {};
    globalVolumeLevels = {};
    globalPlaybackSpeeds = {};

    // Initialize trim times, volume, and playback speed for each channel
    channelURLs.forEach((url, index) => {
        const channelName = `Channel ${index + 1}`;
        const trimSetting = trimSettings[index] || {};

        globalTrimTimes[channelName] = {
            startTrim: +(trimSetting.startSliderValue || 0) / 100,
            endTrim: +(trimSetting.endSliderValue || 100) / 100
        };

        globalVolumeLevels[channelName] = +parseVolumeLevel(channelVolume[index] || 1).toFixed(3);
        globalPlaybackSpeeds[channelName] = +Math.min(Math.max(channelPlaybackSpeed[index] || 1, 0.1), 100).toFixed(3);
    });

    // Reduce the project sequences to a more manageable format for playback
    const sequences = Object.entries(projectSequences).reduce((acc, [sequenceId, sequenceData]) => {
        const normalSteps = {};
        const reverseSteps = {};

        // Iterate through each track in the sequence
        Object.entries(sequenceData).forEach(([trackId, trackData]) => {
            const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;
            normalSteps[channelName] = [];
            reverseSteps[channelName] = [];

            // Sort steps into normal and reverse steps
            trackData.steps.forEach(step => {
                const stepIndex = typeof step === 'object' ? step.index : step;
                if (step.reverse) {
                    reverseSteps[channelName].push(stepIndex);
                } else {
                    normalSteps[channelName].push(stepIndex);
                }
            });
        });

        acc[sequenceId] = { normalSteps, reverseSteps };
        return acc;
    }, {});

    // Create a playback data object
    const playbackData = {
        projectName,
        bpm: projectBPM,
        channels: channelURLs.length,
        channelURLs,
        trimTimes: globalTrimTimes,
        stats,
        sequences
    };

    // Find and set the end sequence
    findAndSetEndSequence(playbackData);

    return playbackData;
};

// Preprocess and schedule the playback data
const preprocessAndSchedulePlayback = (playbackData) => {
    if (!playbackData?.sequences) {
        return console.error("Playback data missing.");
    }

    // Set the BPM globally
    bpm = playbackData.bpm;

    // Preprocess the steps for each sequence
    preprocessedSequences = Object.fromEntries(
        Object.entries(playbackData.sequences).map(([sequenceId, sequenceData]) => [
            sequenceId,
            {
                normalSteps: processSteps(sequenceData.normalSteps),
                reverseSteps: processSteps(sequenceData.reverseSteps)
            }
        ])
    );

    // Check if the sequences are ready for playback
    isReadyToPlay = Object.values(preprocessedSequences).some(
        sequence => Object.keys(sequence.normalSteps).length || Object.keys(sequence.reverseSteps).length
    );
};

// Process the steps of a sequence by calculating timing based on BPM
const processSteps = (steps) => {
    return Object.fromEntries(
        Object.entries(steps)
            .filter(([, stepArray]) => stepArray.length)
            .map(([channelName, stepArray]) => [
                channelName,
                stepArray.map(step => ({
                    step,
                    timing: +(step * (60 / bpm)).toFixed(3) // Calculate the timing based on the BPM
                }))
            ])
    );
};
</script>
</jsonloadingandplayback>





<hashingAndRandomnessUtilities>
 <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is a crucial part of the application responsible for processing and preparing JSON data that defines the structure and sequences of the generative song. Here's a comprehensive breakdown of its functionalities:

            <h3>1. **Hashing and Randomness Utilities**</h3>
            <ul>
                <li><strong>hashString(e):</strong>
                    <ul>
                        <li>Takes a string input `e` and generates a numerical hash value.</li>
                        <li>Extracts a number from the string by splitting at the character "i" and parsing the subsequent substring.</li>
                        <li>Rearranges the string based on the extracted number and performs a reduction using a polynomial rolling hash method.</li>
                        <li>Ensures the hash value stays within the range of `0` to `1.4e8` (140,000,000).</li>
                    </ul>
                </li>
                <li><strong>seededRandom(e):</strong>
                    <ul>
                        <li>Generates a pseudo-random number based on the input `e` using the sine function.</li>
                        <li>Multiplies the sine of `e` by `10,000` and returns the fractional part, ensuring a deterministic yet varied output.</li>
                    </ul>
                </li>
            </ul>

            <h3>2. **Playback Status Management**</h3>
            <ul>
                <li><strong>setPlaybackStatus(e):</strong>
                    <ul>
                        <li>Updates the global playback status by setting `window.playbackStarted` to the value of `e`.</li>
                        <li>This flag is used to control and monitor the playback state across the application.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Key and Channel Mappings**</h3>
            <ul>
                <li><strong>keyMap:</strong>
                    <ul>
                        <li>An object that maps numerical indices (0-15) to specific project-related keys such as "projectName", "artistName", "projectBPM", etc.</li>
                        <li>Facilitates the translation of numerical identifiers into meaningful property names during data processing.</li>
                    </ul>
                </li>
                <li><strong>reverseKeyMap:</strong>
                    <ul>
                        <li>Creates an inverse mapping from `keyMap`, allowing retrieval of numerical indices based on key names.</li>
                        <li>Essential for scenarios where reverse lookup from key names to indices is required.</li>
                    </ul>
                </li>
                <li><strong>channelMap:</strong>
                    <ul>
                        <li>Generates an array of uppercase alphabet letters (A-Z) representing channel identifiers.</li>
                        <li>Used to standardize channel naming and indexing throughout the application.</li>
                    </ul>
                </li>
                <li><strong>reverseChannelMap:</strong>
                    <ul>
                        <li>Creates an inverse mapping from `channelMap`, mapping each letter back to its corresponding index.</li>
                        <li>Facilitates quick and efficient channel index retrieval based on channel identifiers.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Step Decompression and Deserialization**</h3>
            <ul>
                <li><strong>decompressSteps(e):</strong>
                    <ul>
                        <li>Processes an array of steps, handling different representations:</li>
                        <li>Numbers are treated as direct step indices.</li>
                        <li>Objects with an `r` property represent a range of steps, which are expanded into individual step indices.</li>
                        <li>Strings ending with an "r" denote steps that should be reversed, creating objects with `index` and `reverse` properties.</li>
                    </ul>
                </li>
                <li><strong>deserialize(e):</strong>
                    <ul>
                        <li>Transforms a nested data structure into a more usable format for the application.</li>
                        <li>Utilizes `keyMap` to translate numerical keys into meaningful property names.</li>
                        <li>Handles "projectSequences" specially by mapping track IDs to channel IDs using `reverseChannelMap` and decompressing steps with `decompressSteps`.</li>
                        <li>Ensures that the final data structure is organized and accessible for playback and other functionalities.</li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Initialization and Seed Generation**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Initializes playback-related functionalities. (Note: The actual implementation details are not provided in this script.)</li>
                    </ul>
                </li>
                <li><strong>seedValue:</strong>
                    <ul>
                        <li>Generated by passing a specific string to `hashString`, producing a deterministic seed value.</li>
                        <li>This seed value is used to ensure consistent randomness across different parts of the application.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Logs the generated seed value and indicates that the processing utilities have been initialized.</li>
                        <li>Provides transparency into the initialization process, aiding in debugging and monitoring.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Window Load Event Handler**</h3>
            <ul>
                <li><strong>window.onload:</strong>
                    <ul>
                        <li>Sets up an event handler that logs a message when the window's load event is triggered.</li>
                        <li>Indicates that the entire page has been loaded, which can be useful for triggering subsequent initialization steps.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Overall Role within the Program:**</h3>
            <p>
                This script serves as a utility module that prepares and structures the JSON data defining the generative song for playback. By handling hashing, randomness, key and channel mappings, step decompression, and deserialization, it ensures that the data is in the correct format and that all necessary metadata is accessible globally through `window.globalMetadata`. This centralization facilitates consistent access and manipulation of playback settings across different parts of the application, enhancing maintainability and scalability.
            </p>

            <h3>**Dependencies and Interactions:**</h3>
            <ul>
                <li><strong>Global Variables:</strong>
                    <ul>
                        <li><code>window.globalMetadata</code>: Stores metadata related to channels, including volume levels, playback speeds, and trim times.</li>
                        <li><code>window.playbackStarted</code>: Indicates the playback status, controlled by <code>setPlaybackStatus</code>.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>initializePlayback()</code>: Initializes playback functionalities.</li>
                        <li><code>deserialize()</code>: Transforms raw JSON data into a structured format.</li>
                        <li><code>decompressSteps()</code>: Processes and expands step data for playback.</li>
                        <li><code>hashString()</code> and <code>seededRandom()</code>: Generate deterministic values for consistent randomness.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Provides detailed console logs for tracking the initialization process, seed generation, and any potential errors.</li>
                        <li>Aids in debugging by offering insights into the internal state and data transformations.</li>
                    </ul>
                </li>
            </ul>
        </p>
</details>

<script>
    // Hash a string by rotating it based on a numeric value extracted from the string
const hashString = (input) => {
    // Parse the integer part after 'i' in the string
    const rotateIndex = parseInt(input.split("i")[1], 10);

    // Rotate the string by the parsed index and then reduce it to a hash value
    const rotatedString = (input.slice(rotateIndex) + input.slice(0, rotateIndex));
    
    // Reduce the rotated string to a number using character codes
    return rotatedString.split("").reduce((accumulator, char) => {
        return (31 * accumulator + char.charCodeAt(0)) % Number.MAX_SAFE_INTEGER;
    }, 0) % 1400000000;  // Result modded to a maximum value
};

// Generate a seeded random value based on an input seed
const seededRandom = (seed) => {
    const randomValue = 10000 * Math.sin(seed);
    return randomValue - Math.floor(randomValue);
};

// Set the playback status (true for started, false for stopped)
const setPlaybackStatus = (status) => {
    window.playbackStarted = status;
};

// Key mapping for deserialization process
const keyMap = {
    0: "projectName",
    1: "artistName",
    2: "projectBPM",
    3: "currentSequence",
    4: "channelURLs",
    5: "channelVolume",
    6: "channelPlaybackSpeed",
    7: "trimSettings",
    8: "projectChannelNames",
    9: "startSliderValue",
    10: "endSliderValue",
    11: "totalSampleDuration",
    12: "start",
    13: "end",
    14: "projectSequences",
    15: "steps"
};

// Reverse the keyMap for reverse lookup
const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([key, value]) => [value, +key]));

// Create a map of letters 'A' to 'Z' representing channels
const channelMap = Array.from({ length: 26 }, (value, index) => String.fromCharCode(65 + index));  // 'A' to 'Z'

// Reverse map to convert channel letters back to their index
const reverseChannelMap = Object.fromEntries(channelMap.map((letter, index) => [letter, index]));

// Decompress the steps data
// If the step is a number, return it as-is
// If it contains a range 'r', expand the range into individual numbers
// If it's a reverse step (ends with 'r'), convert it into an object with 'reverse: true'
const decompressSteps = (steps) => steps.flatMap(step => {
    if (typeof step === "number") return step;
    
    if (step && typeof step === "object" && "r" in step) {
        const [start, end] = step.r;
        return Array.from({ length: end - start + 1 }, (v, i) => start + i);
    }
    
    if (typeof step === "string" && step.endsWith("r")) {
        return { index: parseInt(step.slice(0, -1), 10), reverse: true };
    }
    
    return [];
});

// Deserialize function that converts encoded data into a usable format
const deserialize = (data) => {
    const recursiveDeserialize = (obj) => {
        if (Array.isArray(obj)) {
            return obj.map(item => (typeof item === "object" ? recursiveDeserialize(item) : item));
        }
        if (obj && typeof obj === "object") {
            return Object.entries(obj).reduce((acc, [key, value]) => {
                const mappedKey = keyMap[key] || key;
                if (mappedKey === "projectSequences") {
                    acc[mappedKey] = Object.entries(value).reduce((sequenceAcc, [seqKey, seqValue]) => {
                        const sequenceName = seqKey.replace(/^s/, "Sequence");
                        sequenceAcc[sequenceName] = Object.entries(seqValue).reduce((trackAcc, [trackKey, trackValue]) => {
                            const channelName = `ch${reverseChannelMap[trackKey]}`;
                            const steps = trackValue[reverseKeyMap.steps] || [];
                            trackAcc[channelName] = {
                                steps: decompressSteps(steps)
                            };
                            return trackAcc;
                        }, {});
                        return sequenceAcc;
                    }, {});
                } else {
                    acc[mappedKey] = recursiveDeserialize(value);
                }
                return acc;
            }, {});
        }
        return obj;
    };

    return recursiveDeserialize(data);
};



// Hash a string and set a seed value based on it
const seedValue = hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");
console.log(`Seed value: ${seedValue}`);

// Log when the processing utilities are initialized
console.log("ProcessingUtilities initialized.");

// Handle window load event
window.onload = () => {
    console.log("window.onload triggered.");
};
</script>

</hashingAndRandomnessUtilities>


<playback>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script manages the playback of the generative song by handling sequences, steps, and audio controls. It ensures that the song progresses through its sequences and steps in a controlled manner, allowing for play, pause, resume, and stop functionalities. Additionally, it handles the incrementing of seeds to regenerate or alter the song upon completion.

            <h3>1. **Playback State Variables**</h3>
            <ul>
                <li><strong>totalSequencesInNewSong:</strong> Tracks the total number of sequences in the new song.</li>
                <li><strong>currentSequenceIndex:</strong> Indicates the index of the currently playing sequence.</li>
                <li><strong>currentStepIndex:</strong> Represents the index of the current step within the active sequence.</li>
                <li><strong>playbackTimeoutId:</strong> Stores the identifier for the playback timeout, allowing for control over the playback loop.</li>
            </ul>

            <h3>2. **Playback Loop Initialization**</h3>
            <ul>
                <li><strong>startPlaybackLoop():</strong>
                    <ul>
                        <li>Checks if `globalJsonData` and its `projectSequences` are defined.</li>
                        <li>Sets the BPM (`bpm`) from the JSON data.</li>
                        <li>Retrieves all sequence keys and determines the total number of sequences.</li>
                        <li>Logs the start of playback and initiates the first sequence using `playSequence()`.</li>
                        <li>Handles scenarios where no sequences are found by logging an error.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Sequence Playback Management**</h3>
            <ul>
                <li><strong>playSequence(sequenceKey):</strong>
                    <ul>
                        <li>Retrieves the specific sequence data using the provided `sequenceKey`.</li>
                        <li>Determines the total number of steps in the current sequence by finding the maximum steps across all channels.</li>
                        <li>Logs the sequence being played and calls `playNextStep()` to begin step playback.</li>
                        <li>Handles cases where the sequence data is missing by logging an error.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Step Playback Control**</h3>
            <ul>
                <li><strong>playNextStep():</strong>
                    <ul>
                        <li>Checks if playback is active (`isPlaying` is `true`).</li>
                        <li>If there are remaining steps in the current sequence:
                            <ul>
                                <li>Logs the current step number.</li>
                                <li>Increments the `currentStepIndex`.</li>
                                <li>Schedules the next step playback using `setTimeout` based on the BPM.</li>
                            </ul>
                        </li>
                        <li>If the sequence is complete:
                            <ul>
                                <li>Logs the completion of the current sequence.</li>
                                <li>Resets the `currentStepIndex` and increments the `currentSequenceIndex`.</li>
                                <li>Logs the progress of sequence playback.</li>
                                <li>Determines if there are more sequences to play:
                                    <ul>
                                        <li>If yes, initiates the next sequence with `playSequence()`.</li>
                                        <li>If no, logs that the end of the song is reached, increments the seed, and reloads the page to generate a new song.</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Playback Initialization**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Checks if the `audioCtx` (Audio Context) is in a suspended state and resumes it if necessary.</li>
                        <li>Logs the state of the Audio Context.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to start playback from the beginning.</li>
                        <li>Sets the `isPlaying` flag to `true` to indicate active playback.</li>
                        <li>Logs the initiation of the playback loop.</li>
                        <li>Starts the playback loop by calling `startPlaybackLoop()`.</li>
                        <li>Checks if `startWorker` is defined and invokes it to handle any additional playback-related tasks.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Playback Control Functions**</h3>
            <ul>
                <li><strong>pausePlayback():</strong>
                    <ul>
                        <li>Logs the pause action.</li>
                        <li>Sets `isPlaying` to `false` to halt the playback loop.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps.</li>
                        <li>Checks if the Audio Context is running and suspends it if so.</li>
                        <li>Updates the play button's appearance and text to reflect the paused state.</li>
                    </ul>
                </li>
                <li><strong>resumePlayback():</strong>
                    <ul>
                        <li>Resumes the Audio Context if it's suspended.</li>
                        <li>Logs the resumption of the Audio Context.</li>
                        <li>Checks if playback is not active and resumes playback by setting `isPlaying` to `true` and calling `playNextStep()`.</li>
                        <li>Updates the play button's appearance and text to reflect the active playback state.</li>
                        <li>Logs if playback is already running to prevent redundant actions.</li>
                    </ul>
                </li>
                <li><strong>stopPlayback():</strong>
                    <ul>
                        <li>Logs the stop action.</li>
                        <li>Sets `isPlaying` to `false` to halt playback.</li>
                        <li>Clears any existing playback timeouts.</li>
                        <li>Iterates through all active audio sources and:
                            <ul>
                                <li>Cancels any scheduled gain value changes.</li>
                                <li>Ramps down the gain to zero over a short duration (`fadeDuration`).</li>
                                <li>Stops the audio source after the fade-out.</li>
                                <li>Disconnects the audio source and gain node to release resources.</li>
                            </ul>
                        </li>
                        <li>Resets the `activeSources` array for all channels.</li>
                        <li>Schedules the suspension of the Audio Context and resets playback state after a brief delay.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to prepare for a fresh start.</li>
                        <li>Logs the completion of the stop action and reset.</li>
                        <li>Updates the play button's appearance and text to reflect the stopped state.</li>
                    </ul>
                </li>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Checks if a playback toggle is not already in progress to prevent overlapping actions.</li>
                        <li>Sets the `isToggleInProgress` flag to `true` to indicate an ongoing toggle action.</li>
                        <li>Attempts to either stop or start playback based on the current state (`isPlaying`).</li>
                        <li>Catches and logs any errors that occur during the toggle process.</li>
                        <li>Resets the `isToggleInProgress` flag after the action is complete.</li>
                    </ul>
                </li>
            </ul>

            <h3>7. **Seed Management and Page Reloading**</h3>
            <ul>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Parses the current seed from `window.seed` and ensures it is a valid integer.</li>
                        <li>Increments the seed by 1 to generate a new seed value.</li>
                        <li>Updates the `window.seed` with the new seed value.</li>
                        <li>Modifies the current URL to include the new seed as a query parameter.</li>
                        <li>Logs the action of reloading the page with the new seed.</li>
                        <li>Reloads the page to apply the new seed, thereby generating a new version of the song.</li>
                    </ul>
                </li>
            </ul>

            <h3>8. **Logging Functionality**</h3>
            <ul>
                <li><strong>log(message):</strong>
                    <ul>
                        <li>Assumed to be a custom logging function that prefixes messages with a specific tag or formatting.</li>
                        <li>Used extensively throughout the playback functions to provide real-time feedback on playback status and actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Overall Role within the Program:**</h3>
            <p>
                This playback script orchestrates the flow of the generative song by managing sequences and steps, controlling the Audio Context, and handling user interactions such as play, pause, resume, and stop. It ensures that audio is played in the correct order and timing based on the BPM and sequence data. Additionally, it handles the regeneration of the song by incrementing the seed and reloading the page upon completion of all sequences. By maintaining and updating global state variables, it ensures consistent behavior across the application's different components.
            </p>

            <h3>**Key Components and Their Interactions:**</h3>
            <ul>
                <li><strong>Global Variables:</strong>
                    <ul>
                        <li><code>globalJsonData:</code> Contains the parsed JSON data defining the song's structure and sequences.</li>
                        <li><code>audioCtx:</code> The Audio Context used for audio processing and playback.</li>
                        <li><code>activeSources:</code> Tracks active audio sources for each channel to manage playback controls.</li>
                        <li><code>isPlaying:</code> A flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress:</code> Prevents simultaneous playback toggle actions.</li>
                        <li><code>fadeDuration:</code> Defines the duration for audio fade-out during stop actions.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>startPlaybackLoop()</code>: Initiates the playback loop by starting the first sequence.</li>
                        <li><code>playSequence(sequenceKey)</code>: Handles the playback of a specific sequence, determining the total steps and initiating step playback.</li>
                        <li><code>playNextStep()</code>: Manages the progression through steps within a sequence, scheduling subsequent steps based on BPM.</li>
                        <li><code>initializePlayback()</code>: Sets up the initial playback state and starts the playback loop.</li>
                        <li><code>pausePlayback()</code>: Pauses the ongoing playback, suspending the Audio Context and updating UI elements.</li>
                        <li><code>resumePlayback()</code>: Resumes playback from a paused state, resuming the Audio Context and continuing step playback.</li>
                        <li><code>stopPlayback()</code>: Completely stops playback, fades out audio, disconnects sources, and resets playback state.</li>
                        <li><code>togglePlayback()</code>: Toggles between play and pause states, ensuring no overlapping actions occur.</li>
                        <li><code>incrementSeedAndReload()</code>: Increments the seed value and reloads the page to generate a new version of the song.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Provides detailed logs at each critical step to monitor the playback process, aiding in debugging and ensuring transparency in operations.</li>
                        <li>Logs actions such as starting playback, playing sequences and steps, pausing, resuming, stopping, and reloading with new seeds.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Potential Areas for Modularization and Optimization:**</h3>
            <ul>
                <li><strong>Logging Function:</strong>
                    <ul>
                        <li>The current script assumes a <code>log()</code> function exists. It would be beneficial to define a centralized logging utility to standardize log messages across the application.</li>
                    </ul>
                </li>
                <li><strong>Playback Control Functions:</strong>
                    <ul>
                        <li>Functions like <code>pausePlayback()</code>, <code>resumePlayback()</code>, and <code>stopPlayback()</code> share common operations (e.g., updating UI elements). These can be refactored into helper functions to reduce code duplication.</li>
                    </ul>
                </li>
                <li><strong>State Management:</strong>
                    <ul>
                        <li>Consider using a state management library or pattern to handle playback states more efficiently, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Seed Management:</strong>
                    <ul>
                        <li>The <code>incrementSeedAndReload()</code> function handles both seed incrementation and page reloading. These responsibilities can be separated to enhance clarity and flexibility.</li>
                    </ul>
                </li>
                <li><strong>Audio Source Handling:</strong>
                    <ul>
                        <li>The management of <code>activeSources</code> involves iterating over channels and handling gain nodes. Encapsulating this logic within dedicated classes or modules can improve maintainability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement more granular error handling and possibly user notifications for playback errors to enhance user experience.</li>
                    </ul>
                </li>
                <li><strong>Playback Timing:</strong>
                    <ul>
                        <li>Utilize more precise timing mechanisms (e.g., Web Audio's scheduling capabilities) to ensure accurate step playback, reducing reliance on <code>setTimeout</code>.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Error Handling and Edge Cases:**</h3>
            <ul>
                <li>Ensures that playback does not start if `globalJsonData` or `projectSequences` are undefined, logging appropriate errors.</li>
                <li>Handles missing sequence data gracefully by logging errors without disrupting the entire playback process.</li>
                <li>Prevents multiple simultaneous playback toggles with the `isToggleInProgress` flag.</li>
                <li>Manages audio source cleanup to prevent memory leaks or unintended audio playback after stopping.</li>
                <li>Validates and safely increments seed values, ensuring that page reloads do not result in invalid URLs or states.</li>
            </ul>
        </p>
    </details>
    <script>
        // Playback State Variables
        let totalSequencesInNewSong = 0;
        let currentSequenceIndex = 0;
        let currentStepIndex = 0;
        let playbackTimeoutId = null;



        // Initialize Playback Loop
        const startPlaybackLoop = () => {
            if (globalJsonData?.projectSequences) {
                bpm = globalJsonData.projectBPM;
                const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                totalSequencesInNewSong = sequenceKeys.length;

                log(`Starting playback of song with ${totalSequencesInNewSong} sequences.`);
                if (totalSequencesInNewSong > 0) {
                    playSequence(sequenceKeys[currentSequenceIndex]);
                } else {
                    console.error("[songAssemblyLogs] No sequences found in the project data.");
                }
            } else {
                console.error("[songAssemblyLogs] Playback cannot start because globalJsonData or projectSequences are undefined.");
            }
        };

        // Play a Specific Sequence
        const playSequence = (sequenceKey) => {
            const sequence = globalJsonData.projectSequences[sequenceKey];
            if (!sequence) {
                console.error(`[songAssemblyLogs] Sequence data missing for key: ${sequenceKey}`);
                return;
            }

            const channelKeys = Object.keys(sequence);
            totalStepsInCurrentSequence = channelKeys.reduce(
                (maxSteps, channelKey) => Math.max(maxSteps, (sequence[channelKey].steps || []).length),
                0
            );

            log(`Playing sequence: ${sequenceKey}`);
            playNextStep();
        };

        // Play the Next Step in the Sequence
        const playNextStep = () => {
            if (isPlaying) {
                if (currentStepIndex < totalStepsInCurrentSequence) {
                    log(`Current Step: ${currentStepIndex + 1}/${totalStepsInCurrentSequence}`);
                    currentStepIndex++;
                    playbackTimeoutId = setTimeout(playNextStep, (60 / bpm) * 1000);
                } else {
                    log("Finished current sequence. Moving to the next sequence.");
                    currentStepIndex = 0;
                    currentSequenceIndex++;
                    log(`Current Sequence Index: ${currentSequenceIndex} / Total Sequences: ${totalSequencesInNewSong}`);

                    if (currentSequenceIndex < totalSequencesInNewSong) {
                        const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                        playSequence(sequenceKeys[currentSequenceIndex]);
                    } else {
                        log("Reached the end of the last sequence. Incrementing seed and reloading...");
                        incrementSeedAndReload(); // Increment seed and reload
                    }
                }
            }
        };

        // Initialize Playback
        const initializePlayback = async () => {
            if (audioCtx.state === "suspended") {
                await audioCtx.resume();
            }
            log(`AudioContext resumed: ${audioCtx.state}`);
            currentSequenceIndex = 0;
            currentStepIndex = 0;
            isPlaying = true;
            log("Starting playback loop from the beginning.");
            startPlaybackLoop();
            if (typeof startWorker === "function") {
                startWorker();
            }
        };

        // Pause Playback
        const pausePlayback = async () => {
            log("Pausing playback.");
            isPlaying = false;
            if (playbackTimeoutId !== null) {
                clearTimeout(playbackTimeoutId);
                playbackTimeoutId = null;
            }
            if (audioCtx.state === "running") {
                await audioCtx.suspend();
                log(`AudioContext suspended: ${audioCtx.state}`);
            }
            const playButton = document.getElementById("play-button");
            if (playButton) {
                playButton.textContent = "Play";
                playButton.classList.remove("playing");
            }
        };

        // Resume Playback
        const resumePlayback = async () => {
            if (audioCtx.state === "suspended") {
                await audioCtx.resume();
            }
            log(`AudioContext resumed: ${audioCtx.state}`);
            if (!isPlaying) {
                isPlaying = true;
                log("Resuming playback.");
                playNextStep();
                const playButton = document.getElementById("play-button");
                if (playButton) {
                    playButton.textContent = "Stop";
                    playButton.classList.add("playing");
                }
            } else {
                log("Playback is already running.");
            }
        };

        // Stop Playback
        const stopPlayback = async () => {
            log("Stopping playback...");
            isPlaying = false;
            if (playbackTimeoutId !== null) {
                clearTimeout(playbackTimeoutId);
                playbackTimeoutId = null;
            }
            for (const channel in activeSources) {
                activeSources[channel].forEach(({ source, gainNode }) => {
                    const currentTime = audioCtx.currentTime;
                    gainNode.gain.cancelScheduledValues(currentTime);
                    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
                    gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeDuration);
                    source.stop(currentTime + fadeDuration);
                    source.disconnect();
                    gainNode.disconnect();
                });
                activeSources[channel] = [];
            }
            setTimeout(async () => {
                if (audioCtx.state === "running") {
                    await audioCtx.suspend();
                    log(`AudioContext suspended: ${audioCtx.state}`);
                }
                resetPlaybackState();
            }, 50);
            currentSequenceIndex = 0;
            currentStepIndex = 0;
            log("Playback stopped and reset to initial state.");
            const playButton = document.getElementById("play-button");
            if (playButton) {
                playButton.textContent = "Play";
                playButton.classList.remove("playing");
            }
        };

        // Toggle Playback (Play/Pause)
        const togglePlayback = async () => {
            if (!isToggleInProgress) {
                isToggleInProgress = true;
                try {
                    isPlaying ? await stopPlayback() : await initializePlayback();
                } catch (error) {
                    console.error(`Error during playback toggle: ${error}`);
                } finally {
                    isToggleInProgress = false;
                }
            }
        };

        /**
         * Increments the current seed by 1 and reloads the page with the new seed as a query parameter.
         */
        function incrementSeedAndReload() {
            let currentSeedInt = parseInt(window.seed, 10);
            if (isNaN(currentSeedInt)) {
                currentSeedInt = 0;
            }
            const newSeedInt = currentSeedInt + 1;
            window.seed = newSeedInt.toString();

            const url = new URL(window.location.href);
            url.searchParams.set('seed', window.seed);
            log(`Reloading page with new seed: ${window.seed}`);
            window.location.href = url.toString();
        }
    </script>
</playback>






<bigSection>>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is responsible for managing all event listeners related to user interactions and playback controls within the generative audio application. It ensures that user actions, such as clicking the play button, trigger the appropriate responses in the audio playback system. Additionally, it handles various playback states, updates the user interface accordingly, and maintains synchronization between different parts of the application through event dispatching and handling.

            <h3>1. **Utility Functions**</h3>
            <ul>
                <li><strong>log(message):</strong>
                    <ul>
                        <li>A utility function that logs messages to the console with a timestamp. This aids in debugging and tracking the flow of events by providing a clear and chronological record of actions and state changes.</li>
                    </ul>
                </li>
                <li><strong>clampVolume(volume):</strong>
                    <ul>
                        <li>Ensures that the volume level stays within the acceptable range of 0 to 3. This prevents audio distortion by avoiding excessively high or negative volume values.</li>
                    </ul>
                </li>
                <li><strong>calculateReversedTrimTimes(trimTimes):</strong>
                    <ul>
                        <li>Calculates reversed trim times based on the provided start and end trim points. This is useful for handling audio playback in reverse, ensuring that the audio segments are correctly trimmed when played backwards.</li>
                    </ul>
                </li>
                <li><strong>resumeAudioContext():</strong>
                    <ul>
                        <li>Attempts to resume the AudioContext if it has been suspended. This is essential for browsers that require user interaction to start audio playback, ensuring that audio can resume smoothly after being paused or interrupted.</li>
                    </ul>
                </li>
                <li><strong>ensureAudioContextState():</strong>
                    <ul>
                        <li>Checks the current state of the AudioContext and resumes it if it is not already running. This function ensures that the audio system is in the correct state before initiating playback, preventing issues related to inactive audio contexts.</li>
                    </ul>
                </li>
                <li><strong>resetPlaybackState():</strong>
                    <ul>
                        <li>Resets playback-related state variables to their initial values. This is important when stopping playback to ensure a clean state for the next playback session, preventing residual states from affecting future playback.</li>
                    </ul>
                </li>
                <li><strong>normalizeBuffer(buffer, normalizationLevel):</strong>
                    <ul>
                        <li>Normalizes an AudioBuffer so that its peak amplitude does not exceed the specified threshold. This function maintains audio quality by preventing clipping and ensuring consistent volume levels across different audio buffers.</li>
                    </ul>
                </li>
                <li><strong>loadAndNormalizeAudio(url):</strong>
                    <ul>
                        <li>Fetches an audio file from the provided URL, decodes it into an AudioBuffer, and normalizes the audio buffer. It includes specific logging for targeted audio samples to monitor their properties, such as duration, number of channels, sample rate, and amplitude levels.</li>
                        <li>Handles errors gracefully by logging them and throwing exceptions to prevent the application from proceeding with faulty audio data.</li>
                    </ul>
                </li>
                <li><strong>loadMultipleAudio(audioUrls):</strong>
                    <ul>
                        <li>Loads and normalizes multiple audio files concurrently. It stores the resulting AudioBuffers in a global object for later playback, ensuring that all necessary audio data is prepared before playback begins.</li>
                        <li>Uses `Promise.all` to handle multiple asynchronous fetch and decode operations efficiently.</li>
                    </ul>
                </li>
                <li><strong>waitForAudioContext():</strong>
                    <ul>
                        <li>Waits until the AudioContext is in a running state before proceeding. This ensures that all audio operations can execute smoothly without interruptions caused by an inactive audio context.</li>
                        <li>Implements an event listener for state changes to resolve or reject the promise based on the AudioContext's state, enhancing reliability in audio playback initialization.</li>
                    </ul>
                </li>
                <li><strong>playBuffer(buffer, options, trackId, startTime):</strong>
                    <ul>
                        <li>Handles the playback of a specific AudioBuffer with given options such as trim times and volume control. It manages the creation of buffer sources and gain nodes, applies volume ramping for smooth audio transitions, and tracks active audio sources for each channel.</li>
                        <li>Ensures that audio buffers are played with the correct playback rate and volume, and that they are properly connected to the AudioContext's destination.</li>
                        <li>Manages the lifecycle of audio sources by tracking them in `activeSources` and cleaning them up once playback ends, preventing memory leaks and ensuring efficient resource utilization.</li>
                    </ul>
                </li>
            </ul>

            <h3>2. **Playback Control Variables**</h3>
            <ul>
                <li><strong>Playback State Variables:</strong>
                    <ul>
                        <li><em>totalSequencesInNewSong:</em> Keeps track of the total number of sequences in the newly generated song, enabling the playback system to know when it has reached the end of the song.</li>
                        <li><em>currentSequenceIndex:</em> Indicates the index of the currently playing sequence, allowing the system to navigate through sequences sequentially.</li>
                        <li><em>currentStepIndex:</em> Represents the index of the current step within the active sequence, facilitating step-by-step playback control.</li>
                        <li><em>playbackTimeoutId:</em> Stores the identifier for the playback timeout, allowing the system to control the playback loop by scheduling and clearing timeouts as needed.</li>
                    </ul>
                </li>
                <li><strong>Active Sources:</strong>
                    <ul>
                        <li>Manages the active audio sources and their corresponding gain nodes for each channel. This ensures that audio can be controlled (e.g., paused, stopped) effectively and that resources are properly managed during playback.</li>
                    </ul>
                </li>
                <li><strong>isPlaying:</strong>
                    <ul>
                        <li>A flag indicating whether playback is currently active. This flag is used to control the flow of the playback loop, preventing unwanted actions when playback is paused or stopped.</li>
                    </ul>
                </li>
                <li><strong>isToggleInProgress:</strong>
                    <ul>
                        <li>Prevents multiple simultaneous toggles of playback state, ensuring that play/pause actions are processed sequentially and avoiding race conditions.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Event Listeners**</h3>
            <ul>
                <li><strong>Play Button Click Listener:</strong>
                    <ul>
                        <li>Attached to the play button element in the user interface. When the play button is clicked, it logs the action, ensures that the AudioContext is in the correct state, toggles playback (either playing or pausing), and dispatches a custom event (`playbackStarted`) to indicate that playback has begun.</li>
                        <li>Includes error handling to log issues if the `ensureAudioContextState` function is not defined or fails during execution, ensuring that playback cannot proceed without a valid AudioContext state.</li>
                    </ul>
                </li>
                <li><strong>Playback Started Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackStarted` custom event. Upon receiving this event, it updates the user interface to display the current seed used for generating the song, manages the display timing (shows the seed for 10 seconds before hiding it), updates playback status flags, and calls functions to update the UI accordingly.</li>
                        <li>Handles scenarios where the seed display element is not found by logging an error, ensuring that UI updates do not fail silently.</li>
                    </ul>
                </li>
                <li><strong>Data Loading Complete Listener:</strong>
                    <ul>
                        <li>Listens for the `dataLoadingComplete` custom event, which is dispatched after the JSON data defining the song's structure has been loaded and processed. When triggered, it initiates the second part of data processing by calling `processSerializedDataPart2()`, ensuring that playback is set up with the newly loaded data.</li>
                        <li>Logs the initiation of local data processing for transparency and debugging purposes.</li>
                    </ul>
                </li>
                <li><strong>Window Load Listener:</strong>
                    <ul>
                        <li>Attaches an event listener to the window's load event. Once the window is fully loaded, it logs the event, attempts to initialize the application by calling `initApp()`, and handles any errors that occur during initialization.</li>
                        <li>This ensures that the application only starts initializing once all resources are fully loaded, preventing issues related to incomplete resource loading.</li>
                    </ul>
                </li>
                <li><strong>Sequence Updated Listener:</strong>
                    <ul>
                        <li>Listens for the `sequenceUpdated` custom event, which carries details about the current sequence and step. This event is likely dispatched during the playback loop to indicate progression through sequences and steps.</li>
                        <li>Tracks the last sequence played to log only when a new sequence starts, thereby reducing console verbosity by avoiding step-by-step logs.</li>
                        <li>Logs the start of a new sequence, aiding in monitoring the progression of playback and ensuring that sequence transitions are functioning correctly.</li>
                    </ul>
                </li>
                <li><strong>Playback Paused Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackPaused` custom event. When triggered, it logs that playback has been paused, allowing for UI updates or other pause-related actions to be handled elsewhere in the application.</li>
                    </ul>
                </li>
                <li><strong>Playback Stopped Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackStopped` custom event. When triggered, it logs that playback has been stopped, facilitating UI resets or other stop-related actions to ensure the application reflects the paused state.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Playback Control Functions**</h3>
            <ul>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Handles the play/pause toggle functionality. It checks if a toggle operation is already in progress to prevent race conditions.</li>
                        <li>Depending on the current playback state (`isPlaying`), it either stops or initializes playback by calling `stopPlayback()` or `initializePlayback()` respectively.</li>
                        <li>Ensures that only one toggle operation occurs at a time by using the `isToggleInProgress` flag, enhancing the reliability of playback controls.</li>
                        <li>Includes error handling to log any issues encountered during the toggle process, aiding in debugging and maintaining application stability.</li>
                    </ul>
                </li>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Increments the current seed value by 1 to generate a new seed, which is used to create a new generative song with different parameters.</li>
                        <li>Updates the seed in the URL's query parameters to reflect the new seed value, ensuring that the new seed is used upon page reload.</li>
                        <li>Reloads the page with the updated seed, triggering the generation of a new song based on the new seed.</li>
                        <li>Logs the new seed value and the action of reloading the page for transparency and to aid in tracking seed changes during development and debugging.</li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Utility Functions for Playback Control**</h3>
            <ul>
                <li><strong>clampVolume(volume):</strong>
                    <ul>
                        <li>Ensures that the volume level remains within the range of 0 to 3. This prevents audio distortion by avoiding excessively high or negative volume levels.</li>
                    </ul>
                </li>
                <li><strong>calculateReversedTrimTimes(trimTimes):</strong>
                    <ul>
                        <li>Calculates reversed trim times based on the provided start and end trim points. This is useful for handling audio playback in reverse, ensuring that the audio segments are correctly trimmed when played backwards.</li>
                    </ul>
                </li>
                <li><strong>resumeAudioContext():</strong>
                    <ul>
                        <li>Attempts to resume the AudioContext if it has been suspended. Essential for browsers that require user interaction to start audio playback, ensuring that audio can resume smoothly after being paused or interrupted.</li>
                    </ul>
                </li>
                <li><strong>ensureAudioContextState():</strong>
                    <ul>
                        <li>Checks the current state of the AudioContext and resumes it if it is not already running. This function ensures that the audio system is in the correct state before initiating playback, preventing issues related to inactive audio contexts.</li>
                    </ul>
                </li>
                <li><strong>resetPlaybackState():</strong>
                    <ul>
                        <li>Resets playback-related state variables to their initial values. This is important when stopping playback to ensure a clean state for the next playback session, preventing residual states from affecting future playback.</li>
                    </ul>
                </li>
                <li><strong>normalizeBuffer(buffer, normalizationLevel):</strong>
                    <ul>
                        <li>Normalizes an AudioBuffer so that its peak amplitude does not exceed the specified threshold. This prevents clipping and maintains audio quality by ensuring consistent volume levels across different audio buffers.</li>
                    </ul>
                </li>
                <li><strong>loadAndNormalizeAudio(url):</strong>
                    <ul>
                        <li>Fetches an audio file from the provided URL, decodes it into an AudioBuffer, and normalizes the audio buffer. It includes specific logging for targeted audio samples to monitor their properties, such as duration, number of channels, sample rate, and amplitude levels.</li>
                        <li>Handles errors gracefully by logging them and throwing exceptions to prevent the application from proceeding with faulty audio data.</li>
                    </ul>
                </li>
                <li><strong>loadMultipleAudio(audioUrls):</strong>
                    <ul>
                        <li>Loads and normalizes multiple audio files concurrently. It stores the resulting AudioBuffers in a global object for later playback, ensuring that all necessary audio data is prepared before playback begins.</li>
                        <li>Uses `Promise.all` to handle multiple asynchronous fetch and decode operations efficiently.</li>
                    </ul>
                </li>
                <li><strong>waitForAudioContext():</strong>
                    <ul>
                        <li>Waits until the AudioContext is in a running state before proceeding. This ensures that all audio operations can execute smoothly without interruptions caused by an inactive audio context.</li>
                        <li>Implements an event listener for state changes to resolve or reject the promise based on the AudioContext's state, enhancing reliability in audio playback initialization.</li>
                    </ul>
                </li>
                <li><strong>playBuffer(buffer, options, trackId, startTime):</strong>
                    <ul>
                        <li>Handles the playback of a specific AudioBuffer with given options such as trim times and volume control. It manages the creation of buffer sources and gain nodes, applies volume ramping for smooth audio transitions, and tracks active audio sources for each channel.</li>
                        <li>Ensures that audio buffers are played with the correct playback rate and volume, and that they are properly connected to the AudioContext's destination.</li>
                        <li>Manages the lifecycle of audio sources by tracking them in `activeSources` and cleaning them up once playback ends, preventing memory leaks and ensuring efficient resource utilization.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Playback Flow Control**</h3>
            <ul>
                <li><strong>startPlaybackLoop():</strong>
                    <ul>
                        <li>Initiates the playback loop by checking if `globalJsonData` and its `projectSequences` are defined.</li>
                        <li>Sets the BPM (`bpm`) from the JSON data.</li>
                        <li>Retrieves all sequence keys and determines the total number of sequences.</li>
                        <li>Logs the start of playback and initiates the first sequence using `playSequence()`.</li>
                        <li>Handles scenarios where no sequences are found by logging an error, ensuring that playback does not proceed without valid data.</li>
                    </ul>
                </li>
                <li><strong>playSequence(sequenceKey):</strong>
                    <ul>
                        <li>Retrieves the specific sequence data using the provided `sequenceKey`.</li>
                        <li>Determines the total number of steps in the current sequence by finding the maximum steps across all channels, enabling accurate step-by-step playback.</li>
                        <li>Logs the sequence being played and calls `playNextStep()` to begin step playback.</li>
                        <li>Handles cases where the sequence data is missing by logging an error, preventing playback from proceeding with invalid sequence data.</li>
                    </ul>
                </li>
                <li><strong>playNextStep():</strong>
                    <ul>
                        <li>Checks if playback is active (`isPlaying` is `true`).</li>
                        <li>If there are remaining steps in the current sequence:
                            <ul>
                                <li>Logs the current step number.</li>
                                <li>Increments the `currentStepIndex` to move to the next step.</li>
                                <li>Schedules the next step playback using `setTimeout` based on the BPM, ensuring timing consistency.</li>
                            </ul>
                        </li>
                        <li>If the sequence is complete:
                            <ul>
                                <li>Logs the completion of the current sequence.</li>
                                <li>Resets the `currentStepIndex` and increments the `currentSequenceIndex` to move to the next sequence.</li>
                                <li>Logs the progress of sequence playback.</li>
                                <li>Determines if there are more sequences to play:
                                    <ul>
                                        <li>If yes, initiates the next sequence with `playSequence()`.</li>
                                        <li>If no, logs that the end of the song is reached, increments the seed, and reloads the page to generate a new song.</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>7. **Playback Control Functions**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Ensures that the AudioContext is active by resuming it if it's in a suspended state.</li>
                        <li>Logs the state of the AudioContext for debugging purposes.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to start playback from the beginning.</li>
                        <li>Sets the `isPlaying` flag to `true` to indicate active playback.</li>
                        <li>Logs the initiation of the playback loop and starts it by calling `startPlaybackLoop()`.</li>
                        <li>Checks if `startWorker` is defined and invokes it to handle any additional playback-related tasks, such as visualizations or background processing.</li>
                    </ul>
                </li>
                <li><strong>pausePlayback():</strong>
                    <ul>
                        <li>Logs the pause action.</li>
                        <li>Sets `isPlaying` to `false` to halt the playback loop.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps, preventing further step playback until resumed.</li>
                        <li>Checks if the AudioContext is running and suspends it if so, conserving system resources during pause.</li>
                        <li>Updates the play button's appearance and text to reflect the paused state, enhancing user interface feedback.</li>
                    </ul>
                </li>
                <li><strong>resumePlayback():</strong>
                    <ul>
                        <li>Checks if the AudioContext is suspended and resumes it if necessary, ensuring that audio playback can continue.</li>
                        <li>Logs the state of the AudioContext after attempting to resume.</li>
                        <li>If playback is not currently active (`isPlaying` is `false`), it sets `isPlaying` to `true`, logs the resumption, calls `playNextStep()` to continue playback, and updates the play button's appearance and text to indicate active playback.</li>
                        <li>If playback is already running, it logs that no action is needed, preventing redundant operations.</li>
                    </ul>
                </li>
                <li><strong>stopPlayback():</strong>
                    <ul>
                        <li>Logs the stop action and sets `isPlaying` to `false` to halt playback.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps.</li>
                        <li>Iterates through all active audio sources, applying a fade-out effect to the gain nodes to ensure smooth audio cessation.</li>
                        <li>Stops and disconnects all audio sources and gain nodes, effectively terminating all audio playback and freeing resources.</li>
                        <li>Suspends the AudioContext after a short delay to ensure all audio processes have been properly terminated.</li>
                        <li>Resets playback state variables (`currentSequenceIndex` and `currentStepIndex`) to their initial values, preparing the system for a new playback session.</li>
                        <li>Logs the completion of the stop process and updates the play button's appearance and text to reflect the stopped state.</li>
                    </ul>
                </li>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Handles the play/pause toggle functionality. It checks if a toggle operation is already in progress to prevent race conditions.</li>
                        <li>Depending on the current playback state (`isPlaying`), it either stops or initializes playback by calling `stopPlayback()` or `initializePlayback()` respectively.</li>
                        <li>Ensures that only one toggle operation occurs at a time by using the `isToggleInProgress` flag, enhancing the reliability of playback controls.</li>
                        <li>Includes error handling to log any issues encountered during the toggle process, aiding in debugging and maintaining application stability.</li>
                    </ul>
                </li>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Increments the current seed value by 1 to generate a new seed, which is used to create a new generative song with different parameters.</li>
                        <li>Updates the seed in the URL's query parameters to reflect the new seed value, ensuring that the new seed is used upon page reload.</li>
                        <li>Reloads the page with the updated seed, triggering the generation of a new song based on the new seed.</li>
                        <li>Logs the new seed value and the action of reloading the page for transparency and to aid in tracking seed changes during development and debugging.</li>
                    </ul>
                </li>
            </ul>

            <h3>8. **Playback Flow Control**</h3>
            <ul>
                <li><strong>playSequenceStep(time):</strong>
                    <ul>
                        <li>Manages the playback of each step within the current sequence. It checks if the system is ready to play and if there are any preprocessed sequences available.</li>
                        <li>Ensures that the `currentSequence` index wraps around based on the total number of sequences, maintaining continuous playback.</li>
                        <li>Retrieves the current sequence data and initiates playback of its steps by calling `playSteps()`.</li>
                        <li>Handles step incrementation and sequence transitions by calling `incrementStepAndSequence()` after each step.</li>
                    </ul>
                </li>
                <li><strong>playSteps(steps, time, isReverse):</strong>
                    <ul>
                        <li>Iterates through the provided steps for each channel, identifying and playing the steps that match the `currentStep` index.</li>
                        <li>Determines whether the steps should be played in reverse based on the `isReverse` flag.</li>
                        <li>Calls `playChannelStep()` for each matching step, passing along the necessary parameters for playback.</li>
                        <li>Returns a boolean indicating whether any steps were played, allowing for conditional logic in the playback flow.</li>
                    </ul>
                </li>
                <li><strong>playChannelStep(channel, stepData, time, isReverse):</strong>
                    <ul>
                        <li>Handles the playback of a specific step for a given channel. It retrieves the appropriate audio buffer and trim times from the global metadata.</li>
                        <li>Determines whether to use the reversed audio buffer based on the `isReverse` flag and calculates the adjusted trim times accordingly.</li>
                        <li>Calls `playBuffer()` to play the audio segment, passing along the buffer, trim times, channel identifier, and scheduled start time.</li>
                        <li>Notifies the visualizer (likely a UI component) of the current step, enabling real-time visual feedback during playback.</li>
                    </ul>
                </li>
                <li><strong>scheduleNotes():</strong>
                    <ul>
                        <li>Continuously schedules playback steps by calculating the next note time based on the current BPM.</li>
                        <li>Ensures that steps are played within a short window (0.1 seconds ahead of the current time) to maintain timing accuracy.</li>
                        <li>Calls `playSequenceStep()` to handle the playback of each scheduled step, maintaining the rhythm and progression of the song.</li>
                    </ul>
                </li>
                <li><strong>incrementStepAndSequence(totalSequences):</strong>
                    <ul>
                        <li>Increments the `currentStep` index, looping back to 0 after reaching 64 to maintain a consistent step cycle.</li>
                        <li>Increments the `currentSequence` index when a full cycle of steps is completed, looping back based on the total number of sequences to ensure continuous playback.</li>
                        <li>Dispatches a `sequenceUpdated` custom event with details about the current sequence and step, enabling other parts of the application (e.g., UI components) to respond to sequence changes.</li>
                    </ul>
                </li>
                <li><strong>logChannelAddition():</strong>
                    <ul>
                        <li>Retrieves and processes channel addition logs from `globalJsonData`, specifically looking for entries that match the current sequence number.</li>
                        <li>Handles the logging of channel additions without cluttering the console with excessive information, maintaining a clean and informative logging environment.</li>
                    </ul>
                </li>
            </ul>

            <h3>9. **Overall Role within the Program**</h3>
            <p>
                The Playback script is essential for managing the flow and control of audio playback within the generative audio application. It handles the sequencing of audio steps, manages playback states (play, pause, stop), and ensures that audio is played in sync with the defined BPM and sequence structure. By handling user interactions through event listeners and maintaining playback state variables, the script ensures a responsive and dynamic audio experience. Additionally, it manages the progression through sequences and steps, handles the incrementing of seeds to generate new songs, and integrates with other parts of the application through custom events and global metadata. This centralizes playback logic, making the system modular and maintainable, while also providing hooks for UI updates and other interactive features.
            </p>

            <h3>10. **Potential Areas for Modularization and Optimization**</h3>
            <ul>
                <li><strong>Separation of Concerns:</strong>
                    <ul>
                        <li>Consider moving utility functions like `log`, `clampVolume`, and `normalizeBuffer` to a separate utility module. This promotes reusability and keeps the playback script focused solely on playback logic.</li>
                    </ul>
                </li>
                <li><strong>Playback State Management:</strong>
                    <ul>
                        <li>Encapsulate playback state variables and related functions within a dedicated playback controller object or class. This enhances maintainability and allows for easier state management, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Event Handling:</strong>
                    <ul>
                        <li>Abstract event listener setups into separate functions or modules. For instance, creating a function to attach playback control listeners can reduce redundancy and improve readability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement a centralized error handling mechanism to uniformly manage and log errors across different functions. This enhances debugging and ensures consistent error management.</li>
                    </ul>
                </li>
                <li><strong>Logging Enhancements:</strong>
                    <ul>
                        <li>Integrate a more sophisticated logging system that can toggle verbosity levels or categorize logs. This makes it easier to trace issues during development and production without overwhelming the console with unnecessary information.</li>
                    </ul>
                </li>
                <li><strong>Performance Optimization:</strong>
                    <ul>
                        <li>Review the use of global variables and consider minimizing their usage by encapsulating related data and functions within modules or classes. This reduces the risk of variable collisions and improves code clarity.</li>
                        <li>Optimize the playback loop to handle a larger number of sequences and steps without performance degradation, possibly by implementing more efficient scheduling mechanisms.</li>
                    </ul>
                </li>
                <li><strong>Asynchronous Operations:</strong>
                    <ul>
                        <li>Ensure that all asynchronous operations, especially those involving AudioContext and playback controls, are handled efficiently to prevent blocking the main thread and ensure smooth user interactions.</li>
                    </ul>
                </li>
            </ul>

            <h3>11. **Dependencies and Interactions**</h3>
            <ul>
                <li><strong>Global Objects:</strong>
                    <ul>
                        <li><code>window.globalJsonData</code>: Stores the JSON data defining the song's structure and sequences.</li>
                        <li><code>window.globalMetadata</code>: Holds global metadata such as volume levels, playback speeds, and trim times for each channel.</li>
                        <li><code>audioCtx</code>: The AudioContext instance used for managing and playing audio.</li>
                        <li><code>activeSources</code>: Tracks active audio sources and their gain nodes for each channel, enabling effective control over ongoing audio playback.</li>
                        <li><code>preprocessedSequences</code>: Contains sequences that have been processed and are ready for playback, including their normal and reverse steps.</li>
                        <li><code>globalReversedAudioBuffers</code>: Stores reversed audio buffers for channels that require reverse playback.</li>
                        <li><code>isPlaying</code>: A boolean flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress</code>: A boolean flag preventing multiple simultaneous playback toggle operations.</li>
                        <li><code>fadeDuration</code>: Specifies the duration over which volume fades occur, ensuring smooth transitions during playback control actions.</li>
                        <li><code>globalVolumeMultiplier</code>: A global multiplier applied to all channel volumes, allowing for overall volume control.</li>
                        <li><code>nextNoteTime</code>: Tracks the scheduled time for the next playback step, ensuring precise timing based on BPM.</li>
                        <li><code>audioBuffers</code>: Stores loaded and normalized audio buffers for playback.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>togglePlayback()</code>: Toggles the playback state between play and pause, managing the initiation and cessation of the playback loop.</li>
                        <li><code>initializePlayback()</code>: Initializes the playback process, ensuring the AudioContext is active and starting the playback loop.</li>
                        <li><code>stopPlayback()</code>: Stops the playback, clears active sources, and resets playback state variables.</li>
                        <li><code>playNextStep()</code>: Advances to the next step in the sequence, scheduling the next step based on BPM.</li>
                        <li><code>playSequence()</code>: Initiates playback of a specific sequence.</li>
                        <li><code>startPlaybackLoop()</code>: Begins the playback loop by starting the first sequence.</li>
                        <li><code>incrementSeedAndReload()</code>: Generates a new seed to create a new song and reloads the page with the updated seed.</li>
                        <li><code>playSequenceStep(time)</code>: Manages the playback of each step within the current sequence.</li>
                        <li><code>playSteps(steps, time, isReverse)</code>: Iterates through the provided steps for each channel, identifying and playing the steps that match the current step index.</li>
                        <li><code>playChannelStep(channel, stepData, time, isReverse)</code>: Handles the playback of a specific step for a given channel, including buffer selection and trim time adjustments.</li>
                        <li><code>scheduleNotes()</code>: Continuously schedules playback steps based on BPM to maintain timing accuracy.</li>
                        <li><code>incrementStepAndSequence(totalSequences)</code>: Increments the step and sequence indices, managing the transition between steps and sequences.</li>
                        <li><code>logChannelAddition()</code>: Retrieves and processes channel addition logs from `globalJsonData`, handling logging for channel additions without excessive verbosity.</li>
                    </ul>
                </li>
                <li><strong>Custom Events:</strong>
                    <ul>
                        <li><code>playbackStarted</code>: Dispatched when playback begins, triggering UI updates and other related actions.</li>
                        <li><code>dataLoadingComplete</code>: Dispatched after JSON data is loaded and processed, initiating the next phase of data handling.</li>
                        <li><code>sequenceUpdated</code>: Dispatched when a new sequence starts, allowing for sequence-specific logging or UI updates.</li>
                        <li><code>playbackPaused</code>: Dispatched when playback is paused, enabling UI changes or other pause-related actions.</li>
                        <li><code>playbackStopped</code>: Dispatched when playback is stopped, facilitating UI resets or other stop-related actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>12. **Overall Role within the Program**</h3>
            <p>
                The Playback script is central to managing the flow and control of audio playback within the generative audio application. It orchestrates the sequencing of audio steps, handles user interactions through event listeners, and maintains playback state variables to ensure smooth and consistent audio playback. By integrating with global metadata and responding to custom events, it ensures that playback is synchronized with the application's state and user interface. The script also facilitates the generation of new songs through seed incrementation and page reloading, allowing for dynamic and varied audio experiences. Its comprehensive management of playback states, timing, and audio resources ensures that the application delivers a seamless and responsive user experience.
            </p>

            <h3>13. **Potential Areas for Modularization and Optimization**</h3>
            <ul>
                <li><strong>Separation of Concerns:</strong>
                    <ul>
                        <li>Utility functions like `log`, `clampVolume`, and `normalizeBuffer` could be moved to a separate utility module to promote reusability and cleaner code organization.</li>
                    </ul>
                </li>
                <li><strong>Playback State Management:</strong>
                    <ul>
                        <li>Encapsulate playback state variables and related functions within a dedicated playback controller object or class. This enhances maintainability and allows for easier state management, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Event Handling:</strong>
                    <ul>
                        <li>Abstract event listener setups into separate functions or modules. For instance, creating a function to attach playback control listeners can reduce redundancy and improve readability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement a centralized error handling mechanism to uniformly manage and log errors across different functions. This enhances debugging and ensures consistent error management.</li>
                    </ul>
                </li>
                <li><strong>Logging Enhancements:</strong>
                    <ul>
                        <li>Integrate a more sophisticated logging system that can toggle verbosity levels or categorize logs. This makes it easier to trace issues during development and production without overwhelming the console with unnecessary information.</li>
                    </ul>
                </li>
                <li><strong>Performance Optimization:</strong>
                    <ul>
                        <li>Review the use of global variables and consider minimizing their usage by encapsulating related data and functions within modules or classes. This reduces the risk of variable collisions and improves code clarity.</li>
                        <li>Optimize the playback loop to handle a larger number of sequences and steps without performance degradation, possibly by implementing more efficient scheduling mechanisms.</li>
                    </ul>
                </li>
                <li><strong>Asynchronous Operations:</strong>
                    <ul>
                        <li>Ensure that all asynchronous operations, especially those involving AudioContext and playback controls, are handled efficiently to prevent blocking the main thread and ensure smooth user interactions.</li>
                    </ul>
                </li>
            </ul>

            <h3>14. **Dependencies and Interactions**</h3>
            <ul>
                <li><strong>Global Objects:</strong>
                    <ul>
                        <li><code>window.globalJsonData</code>: Stores the JSON data defining the song's structure and sequences.</li>
                        <li><code>window.globalMetadata</code>: Holds global metadata such as volume levels, playback speeds, and trim times for each channel.</li>
                        <li><code>audioCtx</code>: The AudioContext instance used for managing and playing audio.</li>
                        <li><code>activeSources</code>: Tracks active audio sources and their gain nodes for each channel, enabling effective control over ongoing audio playback.</li>
                        <li><code>preprocessedSequences</code>: Contains sequences that have been processed and are ready for playback, including their normal and reverse steps.</li>
                        <li><code>globalReversedAudioBuffers</code>: Stores reversed audio buffers for channels that require reverse playback.</li>
                        <li><code>isPlaying</code>: A boolean flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress</code>: A boolean flag preventing multiple simultaneous playback toggle operations.</li>
                        <li><code>fadeDuration</code>: Specifies the duration over which volume fades occur, ensuring smooth transitions during playback control actions.</li>
                        <li><code>globalVolumeMultiplier</code>: A global multiplier applied to all channel volumes, allowing for overall volume control.</li>
                        <li><code>nextNoteTime</code>: Tracks the scheduled time for the next playback step, ensuring precise timing based on BPM.</li>
                        <li><code>audioBuffers</code>: Stores loaded and normalized audio buffers for playback.</li>
                        <li><code>defaultVolume</code>: Specifies a default volume level to be used if no specific volume setting is provided for a channel.</li>
                        <li><code>fadeDuration</code>: Defines the duration for fade-in and fade-out effects during playback transitions.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>togglePlayback()</code>: Toggles the playback state between play and pause, managing the initiation and cessation of the playback loop.</li>
                        <li><code>initializePlayback()</code>: Initializes the playback process, ensuring the AudioContext is active and starting the playback loop.</li>
                        <li><code>stopPlayback()</code>: Stops the playback, clears active sources, and resets playback state variables.</li>
                        <li><code>playNextStep()</code>: Advances to the next step in the sequence, scheduling the next step based on BPM.</li>
                        <li><code>playSequence()</code>: Initiates playback of a specific sequence.</li>
                        <li><code>startPlaybackLoop()</code>: Begins the playback loop by starting the first sequence.</li>
                        <li><code>incrementSeedAndReload()</code>: Generates a new seed to create a new song and reloads the page with the updated seed.</li>
                        <li><code>playSequenceStep(time)</code>: Manages the playback of each step within the current sequence.</li>
                        <li><code>playSteps(steps, time, isReverse)</code>: Iterates through the provided steps for each channel, identifying and playing the steps that match the current step index.</li>
                        <li><code>playChannelStep(channel, stepData, time, isReverse)</code>: Handles the playback of a specific step for a given channel, including buffer selection and trim time adjustments.</li>
                        <li><code>scheduleNotes()</code>: Continuously schedules playback steps based on BPM to maintain timing accuracy.</li>
                        <li><code>incrementStepAndSequence(totalSequences)</code>: Increments the step and sequence indices, managing the transition between steps and sequences.</li>
                        <li><code>logChannelAddition()</code>: Retrieves and processes channel addition logs from `globalJsonData`, handling logging for channel additions without excessive verbosity.</li>
                    </ul>
                </li>
                <li><strong>Custom Events:</strong>
                    <ul>
                        <li><code>playbackStarted</code>: Dispatched when playback begins, triggering UI updates and other related actions.</li>
                        <li><code>dataLoadingComplete</code>: Dispatched after JSON data is loaded and processed, initiating the next phase of data handling.</li>
                        <li><code>sequenceUpdated</code>: Dispatched when a new sequence starts, allowing for sequence-specific logging or UI updates.</li>
                        <li><code>playbackPaused</code>: Dispatched when playback is paused, enabling UI changes or other pause-related actions.</li>
                        <li><code>playbackStopped</code>: Dispatched when playback is stopped, facilitating UI resets or other stop-related actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>14. **Overall Role within the Program**</h3>
            <p>
                The EventListeners script is pivotal in managing user interactions and controlling the playback flow within the generative audio application. It listens for user actions, such as clicking the play button, and orchestrates the playback process by interacting with other parts of the system, including audio buffer management and playback state variables. By handling custom events, it ensures that different components of the application remain synchronized, providing a seamless and responsive user experience. The script also includes utility functions that support audio processing tasks, such as normalizing audio buffers and managing the AudioContext state, further enhancing the robustness and flexibility of the playback system.
            </p>
        </p>
    </details>

    <script>
        // Utility log function with timestamp
        const log = message => console.log(`[${new Date().toISOString()}] ${message}`);

        // Play button click listener
        document.getElementById("play-button").addEventListener("click", async () => {
            log("[eventListeners] Play button clicked.");
            if (typeof window.ensureAudioContextState === "function") {
                try {
                    log("[eventListeners] Ensuring AudioContext state.");
                    await window.ensureAudioContextState();
                    await togglePlayback();
                    document.dispatchEvent(new CustomEvent("playbackStarted"));
                    log("[eventListeners] Dispatched playbackStarted event.");
                } catch (error) {
                    console.error("[eventListeners] Error during playback toggle:", error);
                }
            } else {
                console.error("[eventListeners] ensureAudioContextState is not defined or not a function");
            }
        });

        // Playback started listener
        document.addEventListener("playbackStarted", () => {
            log("Playback started. Displaying seed.");
          
            const seedDisplay = document.getElementById("seed-display");
            if (seedDisplay) {
                log("[eventListeners] Updating seed display with seed:", window.seed);
                seedDisplay.textContent = `Seed: ${window.seed}`;
                seedDisplay.style.opacity = "1";
                setTimeout(() => {
                    seedDisplay.style.opacity = "0";
                    log("[eventListeners] Seed display hidden.");
                }, 10000);
            } else {
                console.error("[eventListeners] Seed display element not found.");
            }

            window.psTime = Date.now();
            setPlaybackStatus(true);
            log("[eventListeners] Playback status set to true.");
            if (typeof displayPlayText === "function") {
                displayPlayText();
                log("[eventListeners] Called displayPlayText function.");
            }
        });

        // Data loading complete listener
        document.addEventListener("dataLoadingComplete", () => {
            log("[eventListeners] Received dataLoadingComplete event. Starting local data processing.");
            processSerializedDataPart2();
        });

        // Window load listener
        window.addEventListener("load", async () => {
            log("Window load event triggered. Starting app initialization.");
            try {
                await initApp();
                log("initApp function execution complete.");
            } catch (error) {
                console.error("[eventListeners] Error during app initialization:", error);
            }
        });

        // Sequence updated listener - refined to log only when a new sequence starts
        let lastSequence = null;
        document.addEventListener("sequenceUpdated", ({ detail: { currentSequence, currentStep } }) => {
            if (currentSequence !== lastSequence) {
                log(`[songAssemblyLogs] Sequence ${currentSequence} started.`);
                lastSequence = currentSequence;
            }
            // Removed logging for every step to reduce verbosity
        });

        // Playback paused listener
        document.addEventListener("playbackPaused", () => {
            log("[eventListeners] Playback paused.");
        });

        // Playback stopped listener
        document.addEventListener("playbackStopped", () => {
            log("[eventListeners] Playback stopped.");
        });

    // Clamp volume between 0 and 3
    function clampVolume(volume) {
        return Math.max(0, Math.min(volume, 3));
    }

    
    // Calculate reversed trim times based on start and end trim points
    function calculateReversedTrimTimes(trimTimes) {
        return {
            startTrim: 1 - trimTimes.endTrim,
            endTrim: 1 - trimTimes.startTrim
        };
    }
    
    // Resume the AudioContext if it has been suspended
    async function resumeAudioContext() {
        try {
            await audioCtx.resume();
        } catch (error) {
            console.error("Error resuming AudioContext:", error);
        }
    }
    
    // Ensure that the AudioContext is in a running state before playback
    async function ensureAudioContextState() {
        if (audioCtx.state !== "running") {
            await resumeAudioContext();
        }
    }
    
    // Reset playback state variables to their initial values
    function resetPlaybackState() {
        currentSequence = 0;
        currentStep = 0;
        isReversePlay = false;
        nextNoteTime = 0;
    }
    
    // Normalize an audio buffer so that its peak amplitude does not exceed the given threshold
    function normalizeBuffer(buffer, normalizationLevel = 0.9) {
        console.log("Normalizing buffer...");
        if (!(buffer instanceof AudioBuffer)) return buffer;
        
        const numberOfChannels = buffer.numberOfChannels;
        let maxAmplitude = 0;
        
        // Find the maximum absolute amplitude across all channels
        for (let channel = 0; channel < numberOfChannels; channel++) {
            const channelData = buffer.getChannelData(channel);
            for (let i = 0; i < channelData.length; i++) {
                const amplitude = Math.abs(channelData[i]);
                if (amplitude > maxAmplitude) {
                    maxAmplitude = amplitude;
                }
            }
        }
        
        // Calculate normalization ratio
        const normalizationFactor = normalizationLevel / maxAmplitude;
        
        // Apply normalization if needed
        if (normalizationFactor < 1) {
            for (let channel = 0; channel < numberOfChannels; channel++) {
                const channelData = buffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    channelData[i] *= normalizationFactor;
                }
            }
        }
        
        return buffer;
    }
    
    // Load and normalize an audio file from a URL
    async function loadAndNormalizeAudio(url) {
        console.log(`[loadAndNormalizeAudio] Loading and normalizing audio from URL: ${url}`);
        try {
            const response = await fetch(url);
            if (!response.ok) {
                throw new Error(`Network response was not ok for ${url}: ${response.statusText}`);
            }
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            
            /**
             * Specific Audio Sample ID to Monitor
             */
            const targetSampleId = "3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0";
            
            /**
             * Check if the current URL corresponds to the target sample ID
             * This assumes that the sample ID is part of the URL.
             * Adjust the condition below if the mapping between URL and sample ID is different.
             */
            if (url.includes(targetSampleId)) {
                console.log(`\n=== Specific Audio Sample Loaded ===`);
                console.log(`Sample ID: ${targetSampleId}`);
                console.log(`URL: ${url}`);
                console.log(`Duration: ${audioBuffer.duration.toFixed(2)} seconds`);
                console.log(`Number of Channels: ${audioBuffer.numberOfChannels}`);
                console.log(`Sample Rate: ${audioBuffer.sampleRate} Hz`);
                console.log(`Total Length (samples per channel): ${audioBuffer.length}`);
                console.log(`===================================\n`);
                
                /**
                 * Additional Useful Information:
                 * - Peak Amplitude
                 * - Average Amplitude
                 * - Any metadata if available
                 */
                
                // Calculate Peak Amplitude
                let peakAmplitude = 0;
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        const amplitude = Math.abs(channelData[i]);
                        if (amplitude > peakAmplitude) {
                            peakAmplitude = amplitude;
                        }
                    }
                }
                console.log(`Peak Amplitude: ${peakAmplitude.toFixed(4)}`);
                
                // Calculate Average Amplitude
                let sumAmplitude = 0;
                let totalSamples = 0;
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        sumAmplitude += Math.abs(channelData[i]);
                        totalSamples++;
                    }
                }
                const averageAmplitude = sumAmplitude / totalSamples;
                console.log(`Average Amplitude: ${averageAmplitude.toFixed(4)}\n`);
            }
            
            return normalizeBuffer(audioBuffer);
        } catch (error) {
            console.error("Error loading and normalizing audio:", error);
            throw error;
        }
    }
    
    // Load multiple audio files and normalize them
    async function loadMultipleAudio(audioUrls) {
        const promises = audioUrls.map(async (url, index) => {
            try {
                const buffer = await loadAndNormalizeAudio(url);
                audioBuffers[index] = buffer;
            } catch (error) {
                console.error("Error loading multiple audio files:", error);
                throw error;
            }
        });
        await Promise.all(promises);
    }
    
    // Wait until the AudioContext is in a running state
    async function waitForAudioContext() {
        if (audioCtx.state !== "running") {
            return new Promise((resolve, reject) => {
                const checkState = () => {
                    if (audioCtx.state === "running") {
                        audioCtx.removeEventListener("statechange", checkState);
                        resolve();
                    } else if (audioCtx.state === "closed") {
                        audioCtx.removeEventListener("statechange", checkState);
                        reject(new Error("AudioContext was closed."));
                    }
                };
                audioCtx.addEventListener("statechange", checkState);
            });
        }
    }
    
    // Play a section of an AudioBuffer with trimming and volume control
    function playBuffer(buffer, { startTrim, endTrim }, trackId, startTime) {
        if (!(buffer instanceof AudioBuffer)) return;
        
        const startTrimClamped = Math.max(0, Math.min(startTrim, 1));
        const endTrimClamped = Math.max(startTrimClamped, Math.min(endTrim, 1));
        const normalizedBuffer = normalizeBuffer(buffer);
        
        // Create a buffer source and gain node for playback
        const source = audioCtx.createBufferSource();
        source.buffer = normalizedBuffer;
        source.playbackRate.value = globalPlaybackSpeeds[trackId] || 1;
        
        const gainNode = audioCtx.createGain();
        const volumeLevel = parseVolumeLevel(globalVolumeLevels[trackId] || defaultVolume) * globalVolumeMultiplier;
        const currentTime = audioCtx.currentTime;
        
        // Set the gain (volume) with a fade-in effect
        gainNode.gain.cancelScheduledValues(currentTime);
        gainNode.gain.setValueAtTime(0, currentTime);
        gainNode.gain.linearRampToValueAtTime(volumeLevel, currentTime + fadeDuration);
        
        source.connect(gainNode);
        gainNode.connect(audioCtx.destination);
        
        const startTimeOffset = startTrimClamped * normalizedBuffer.duration;
        const playbackDuration = (endTrimClamped - startTrimClamped) * normalizedBuffer.duration;
        
        source.start(startTime, startTimeOffset, playbackDuration);
        
        // Track active sources
        if (!activeSources[trackId]) {
            activeSources[trackId] = [];
        }
        activeSources[trackId].push({ source, gainNode });
        
        source.onended = () => {
            activeSources[trackId] = activeSources[trackId].filter(({ source: s }) => s !== source);
        };
    }
    
    // Load multiple audio files and normalize them
    const audioBuffers = {};
    async function loadMultipleAudio(audioUrls) {
        const promises = audioUrls.map(async (url, index) => {
            try {
                const buffer = await loadAndNormalizeAudio(url);
                audioBuffers[index] = buffer;
            } catch (error) {
                console.error("Error loading multiple audio files:", error);
                throw error;
            }
        });
        await Promise.all(promises);
    }
    
    // Example of waiting for AudioContext and playing audio
    (async () => {
        try {
            await waitForAudioContext();
            const buffer = await loadAndNormalizeAudio(audioUrl);
            playBuffer(buffer, { startTrim: 0, endTrim: 1 }, 0, audioCtx.currentTime);
        } catch (error) {
            console.error("Error during audio playback:", error);
        }
    })();

    const dispatchSequenceEvent = (eventName, detail) => {
    document.dispatchEvent(new CustomEvent(eventName, { detail }));
};

const playSequenceStep = (time) => {
    if (!isReadyToPlay || !Object.keys(preprocessedSequences).length) return;

    const sequenceKeys = Object.keys(preprocessedSequences);
    currentSequence %= sequenceKeys.length;
    const currentSequenceData = preprocessedSequences[sequenceKeys[currentSequence]];

    if (currentStep === 0) {
        logChannelAddition();
    }

    if (currentSequenceData) {
        playSteps(currentSequenceData.normalSteps, time) || playSteps(currentSequenceData.reverseSteps, time, true);
    }

    incrementStepAndSequence(sequenceKeys.length);
};

const playSteps = (steps, time, isReverse = false) => {
    if (!steps || typeof steps !== "object") return false;

    Object.entries(steps).forEach(([channel, channelSteps]) => {
        if (Array.isArray(channelSteps)) {
            const stepData = channelSteps.find(step => step.step === currentStep);
            if (stepData) playChannelStep(channel, stepData, time, isReverse);
        }
    });

    return true;
};

const playChannelStep = (channel, stepData, time, isReverse) => {
    const audioBuffer = globalAudioBuffers.find(buffer => buffer.channel === channel);
    const trimTime = globalTrimTimes[channel];

    if (audioBuffer?.buffer && trimTime) {
        const bufferToPlay = isReverse ? globalReversedAudioBuffers[channel] : audioBuffer.buffer;
        const adjustedTrimTime = isReverse ? calculateReversedTrimTimes(trimTime) : trimTime;
        playBuffer(bufferToPlay, adjustedTrimTime, channel, time);
        notifyVisualizer(parseInt(channel.slice(8)) - 1, stepData.step);
    }
};

const scheduleNotes = () => {
    const currentTime = audioCtx.currentTime;

    for (nextNoteTime = Math.max(nextNoteTime, currentTime); nextNoteTime < currentTime + 0.1;) {
        playSequenceStep(nextNoteTime);
        nextNoteTime += getStepDuration();
    }
};

const incrementStepAndSequence = (totalSequences) => {
    currentStep = (currentStep + 1) % 64;
    if (currentStep === 0) {
        currentSequence = (currentSequence + 1) % totalSequences;
    }

    const eventName = "sequenceUpdated";
    const detail = { currentSequence, currentStep };
    document.dispatchEvent(new CustomEvent(eventName, { detail }));
};

const logChannelAddition = () => {
    const channelAddition = globalJsonData?.channelAdditionLog?.find(log => log.sequenceNumber === currentSequence);
    if (channelAddition) {
        const { channelsAdded, totalChannels } = channelAddition;
        // Removed logging for channel addition
    }
};
</script>
</bigSection>>

<script>
const LOOKAHEAD=.1,SCHEDULE_INTERVAL=50;let audioWorker,lastBPM,workerUrl;const debounce=(e,o)=>{let r;return(...t)=>{clearTimeout(r),r=setTimeout((()=>e(...t)),o)}},workerBlob="\n        self.onmessage = e => {\n            const { action, stepDuration, lookahead, scheduleInterval } = e.data;\n            let timerID, workloadTimerID, scheduleNotesCount = 0;\n\n            const startScheduling = (sd, la, si) => {\n                clearInterval(timerID);\n                clearInterval(workloadTimerID);\n                timerID = setInterval(() => {\n                    self.postMessage({ action: 'scheduleNotes' });\n                    scheduleNotesCount++;\n                }, si);\n                workloadTimerID = setInterval(() => {\n                    self.postMessage({ action: 'audioWorkerWorkloadDebug', scheduleNotesCount });\n                    scheduleNotesCount = 0;\n                }, 1000);\n            };\n\n            if (action === 'start') startScheduling(stepDuration, lookahead, scheduleInterval);\n            else if (action === 'stop') { clearInterval(timerID); clearInterval(workloadTimerID); }\n            else if (action === 'updateStepDuration') stepDuration = e.data.stepDuration;\n            else console.warn(\"[Worker] Unknown action:\", action);\n        };\n    ",initializeWorker=()=>{window.Worker?audioWorker?console.warn("[AudioWorker] Worker already initialized."):(workerUrl=URL.createObjectURL(new Blob([workerBlob],{type:"application/javascript"})),audioWorker=new Worker(workerUrl),audioWorker.onmessage=handleWorkerMessage,window.addEventListener("bpmChanged",debounce(updateWorkerStepDuration,100)),console.log("[AudioWorker] Worker initialized.")):console.error("[AudioWorker] Web Workers not supported.")},handleWorkerMessage=({data:{action:e,message:o,scheduleNotesCount:r}})=>{"scheduleNotes"===e?scheduleNotes?.():"audioWorkerWorkloadDebug"===e||("error"===e?console.error("[AudioWorker] Worker Error:",o):console.warn("[AudioWorker] Unknown action from worker:",e))},startWorker=()=>{audioWorker?audioWorker.postMessage({action:"start",stepDuration:getStepDuration(),lookahead:.1,scheduleInterval:50}):console.error("[AudioWorker] Initialize worker first.")},stopWorker=()=>{audioWorker&&audioWorker.postMessage({action:"stop"})},getStepDuration=()=>{const e=window.globalJsonData?.projectBPM||120;return e!==lastBPM&&console.log(`[getStepDuration] BPM changed: ${lastBPM} -> ${e}`),lastBPM=e,60/(4*e)},cleanUpWorker=async()=>{audioWorker&&(audioWorker.terminate(),audioWorker=null),workerUrl&&(URL.revokeObjectURL(workerUrl),workerUrl=null),"undefined"!=typeof audioCtx&&"closed"!==audioCtx.state&&await audioCtx.close(),window.removeEventListener("bpmChanged",updateWorkerStepDuration),console.log("[AudioWorker] Cleanup completed.")},updateWorkerStepDuration=()=>{audioWorker&&audioWorker.postMessage({action:"updateStepDuration",stepDuration:getStepDuration()})};window.addEventListener("beforeunload",cleanUpWorker),document.getElementById("loadVisualizerButton")?.addEventListener("click",initializeWorker),document.getElementById("visualizerCanvas")?.addEventListener("click",startWorker);
</script>
<visualiserScripts>
<script>
function resetVisualState(){"undefined"!=typeof cci2&&"undefined"!=typeof initialCCI2&&(cci2=initialCCI2),isChannel11Active=isPlaybackActive=!1,activeChannelIndex=null,activeArrayIndex={},renderingState={},"function"==typeof immediateVisualUpdate&&immediateVisualUpdate()}function resetAllStates(){resetPlaybackState?.(),resetVisualState()}function notifyVisualizer(e,t){const a={action:"activeStep",channelIndex:e,step:t};AudionalPlayerMessages.postMessage(a),document.dispatchEvent(new CustomEvent("internalAudioPlayback",{detail:a}))}const loadScript=e=>new Promise(((t,a)=>{const c=document.createElement("script");c.src=e,c.async=!0,c.onload=()=>{console.log(`Loaded: ${e}`),t()},c.onerror=()=>{console.error(`Failed to load script: ${e}`),a(new Error(`Failed to load script: ${e}`))},document.body.appendChild(c)})),loadScriptsSequentially=async(e,t)=>{for(const a of e)try{await loadScript(a)}catch(e){console.error(`Error loading ${t} script ${a}:`,e)}console.log(`All ${t} scripts loaded successfully.`)},loadVisualiserScripts=()=>loadScriptsSequentially(window.visualizerScripts||[],"visualizer"),loadArtworkScripts=()=>loadScriptsSequentially(window.artworkScripts||[],"artwork");window.artworkScripts=[],window.visualizerScripts=["/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0","/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0","/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0","/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0","/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0","/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0","/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0","/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0","/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0","/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0","/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0","/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0","/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0","/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0","/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0","/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0","/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0","/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0"],async function(){const e=Object.assign(document.createElement("canvas"),{id:"cv"});document.body.appendChild(e),Object.assign(document.body.style,{display:"flex",justifyContent:"center",alignItems:"center",height:"100vh",margin:"0"});const t=async()=>{window.cci2=window.initialCCI2=0,resetAllStates(),loadJsonFromUrl?.(window.jsonDataUrl),initializeWorker?.(),window.visualiserMode?(await loadScriptsSequentially(window.visualizerScripts||[],"visualizer"),(window.log||console.log)("Visualizer scripts loaded.")):(await loadScriptsSequentially(window.artworkScripts||[],"artwork"),(window.log||console.log)("Artwork scripts loaded."))};try{await new Promise((e=>{const t=()=>window.jsonDataUrl?e():setTimeout(t,100);t()})),console.log("Fetching from URL:",window.jsonDataUrl);const e=await fetch(window.jsonDataUrl);if(!e.ok)throw new Error(`HTTP error! status: ${e.status}`);window.settings=await e.json(),console.log("Settings loaded:",window.settings),await(ensureAudioContextState?.()),"loading"===document.readyState?document.addEventListener("DOMContentLoaded",t):await t()}catch(e){console.error("Error initializing the app:",e)}console.log(`[${(new Date).toISOString()}] [debugScriptLoading] ScriptLoader initialized.`)}();
</script>
