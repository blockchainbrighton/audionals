<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Audionals - Web3 Music Player</title>
<link rel="stylesheet" href="/content/7a309a161e838ba93740684338b3d97f3c1226c046d8b1137afc2353b4bf16e1i0">
<style>
:root {--panel-bg-color: #333;--panel-text-color: #fff;--track-list-panel-bg-color: #444;--button-bg-color: #444;--button-hover-bg-color: #555;--button-active-bg-color: #777;--input-bg-color: #555;--border-radius: 8px;--padding: 10px;--box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);--transition-duration: 0.3s;--text-color: #fff;--bpm-bg-color: orange;--seed-bg-color: green;--font-size: 16px;}#seed-management-panel, #track-list-panel {position: fixed;background-color: var(--panel-bg-color);color: var(--panel-text-color);padding: var(--padding);border-radius: var(--border-radius);z-index: 10000;box-shadow: var(--box-shadow);transition: all var(--transition-duration) ease;}#seed-management-panel {top: 10px;right: 10px;width: 320px;}#track-list-panel {bottom: 10px;left: 10px;width: 300px;background-color: var(--track-list-panel-bg-color);}.hidden {display: none;}@media (max-width: 600px) {#seed-management-panel, #track-list-panel {width: 90%;left: 5%;right: 5%;}}#seed-mgmt-canvas {width: 100%;height: 100px;border: 1px solid #555;border-radius: 4px;background-color: #222;}#previous-seeds-container {margin-top: 15px;}#previous-seeds-container h3, #seed-input-section h3 {margin-bottom: 5px;}#previous-seeds-container ul {list-style: none;padding: 0;max-height: 150px;overflow-y: auto;border: 1px solid #555;border-radius: 4px;background-color: #444;}#previous-seeds-container li {display: flex;justify-content: space-between;align-items: center;padding: 5px 10px;border-bottom: 1px solid #555;}#previous-seeds-container li:last-child {border-bottom: none;}#previous-seeds-container button {background-color: #666;color: #fff;border: none;border-radius: 4px;padding: 2px 6px;cursor: pointer;transition: background-color var(--transition-duration) ease;margin-left: 10px;}#previous-seeds-container button:hover {background-color: #888;}#seed-input-section {margin-top: 15px;}#seed-input {width: 100%;padding: 8px;margin-bottom: 5px;border: 1px solid #555;border-radius: 4px;background-color: var(--input-bg-color);color: var(--panel-text-color);transition: border 0.2s ease;}#seed-input:focus {border: 2px solid #00f;outline: none;}#clear-seeds-section {margin-top: 15px;text-align: center;}#clear-seeds-button {width: 100%;padding: 8px;background-color: #b22222;color: #fff;border: none;border-radius: 4px;cursor: pointer;transition: background-color var(--transition-duration) ease;margin-top: 5px;}#clear-seeds-button:hover {background-color: #ff6347;}button {background-color: var(--button-bg-color);color: var(--panel-text-color);border: none;border-radius: 4px;cursor: pointer;transition: background-color var(--transition-duration) ease;padding: 10px 15px;margin: 5px;}button:hover {background-color: var(--button-hover-bg-color);}button:active {background-color: var(--button-active-bg-color);}button:focus {outline: 2px solid #00f;}#loadingSpinner {z-index: 1000;}#artworkCover img {max-width: 100%;height: auto;border-radius: 4px;}#nowPlayingContainer {position: fixed;bottom: 0;left: 50%;transform: translateX(-50%);background-color: rgba(20, 20, 20, 0.95);color: #fff;padding: 10px;display: flex;flex-direction: column;justify-content: center;align-items: center;box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.5);z-index: 10000;text-align: center;border-radius: 8px;width: 90%;max-width: 600px;transition: background-color 0.3s ease;}#nowPlayingContainer:hover {background-color: rgba(20, 20, 20, 1);}#nowPlayingText {display: flex;flex-direction: column;align-items: center;margin: 0;padding: 5px;text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);}#nowPlayingContainer .current-seed {display: block;font-size: 0.9em;color: #ccc;margin-bottom: 5px;}#nowPlayingContainer .title {display: block;font-size: 1.2em;font-weight: bold;color: #fff;}
</style>
</head>
<body>
<HTMLsection>
<span class="songTitle">The Infinite Ordinal Remix</span><h1>Audionals</h1><div id="seed-management-panel" class="hidden" role="dialog" aria-labelledby="seed-panel-title" aria-hidden="true"><h2 id="seed-panel-title">Seed Management</h2><canvas id="seed-mgmt-canvas" width="300" height="100" aria-label="Seed and BPM Information"></canvas><div id="previous-seeds-container"><h3>Previous Seeds</h3><ul></ul></div><div id="seed-input-section"><h3>Load a Specific Seed</h3><input type="text" id="seed-input" placeholder="Enter 16-digit Seed" aria-label="Enter Seed"><button id="load-seed-button" aria-label="Load Seed">Load Seed</button></div><div class="bpm-selection"><h3>Select BPM(s) to Filter</h3><div class="bpm-options, hidden"><div class="bpm-option"><input type="checkbox" id="bpm-60" value="60" checked="checked"><label for="bpm-60">60 BPM</label></div><div class="bpm-option"><input type="checkbox" id="bpm-120" value="120" checked="checked"><label for="bpm-120">120 BPM</label></div><div class="bpm-option"><input type="checkbox" id="bpm-140" value="140" checked="checked"><label for="bpm-140">140 BPM</label></div><div class="bpm-option"><input type="checkbox" id="bpm-160" value="160" checked="checked"><label for="bpm-160">160 BPM</label></div><div class="bpm-option"><input type="checkbox" id="bpm-180" value="180" checked="checked"><label for="bpm-180">180 BPM</label></div><div class="bpm-option"><input type="checkbox" id="bpm-240" value="240" checked="checked"><label for="bpm-240">240 BPM</label></div></div></div><div id="clear-seeds-section"><button id="clear-seeds-button" aria-label="Clear Previous Seeds">Clear Previous Seeds</button></div><div id="generate-mixes-section" style="margin-top:15px;text-align:center"><button id="generate-mixes-button" aria-label="Generate Mixes">Generate Mixes</button></div></div><div id="loadingSpinner"></div><div id="artworkCover"><img id="artworkImage" src="" alt="Artwork Cover"></div><div id="trackListingPanel"><h2>Track Listings:</h2><div id="metadataContent"></div></div><div id="nowPlayingContainer"><span class="current-seed">Seed: N/A</span><span class="title">The Infinite Ordinal Remix</span><span class="artistName">melophonic</span><span class="songBPM">BPM: N/A</span><span class="timeLeft">Time Left: N/A</span><span class="songTitle" style="display:none"></span></div><div id="buttonContainer"><button id="playButton" onclick="globalData.togglePlayback()" aria-label="Play or Stop Music">Play / Stop</button><button id="prevButton" onclick="handlePreviousSong()" aria-label="Previous Song">Previous</button><button id="nextButton" onclick="handleNextSong()" aria-label="Next Song">Next</button><button id="toggle-track-panel-button" onclick="toggleTrackListAndPopulate()" class="hidden" aria-label="Toggle Track List Panel">Track List</button><button id="toggle-seed-panel-button" onclick='togglePanel("seed-management-panel")' aria-label="Toggle Seed Management Panel">Seed Panel</button></div><div id="track-list-panel" class="hidden" role="dialog" aria-labelledby="track-list-title" aria-hidden="true"><h2 id="track-list-title" class="hidden">Track List</h2><div id="track-list-container"></div></div>
</HTMLsection>
<!-- Songs and Artwork -->
<script src="/content/616ef4c1bef02cb6c0f785ef76b98df4e379e8f01e2b31e2ae9e68449485f2bci0"></script>    
<!--Global Data -->
<script>
    (function() {
        // Check if globalData already exists to prevent re-initialization
        if (!window.globalData) {
            // Initialize globalData
            window.globalData = {
                isPlaying: false,
                currentSongIndex: 0,
                songsArray: [],
                audioBuffers: {},
                reverseAudioBuffers: {},
                audioContext: new (window.AudioContext || window.webkitAudioContext)(),
                masterGain: null,
                gainNodes: {},
                startPlayback: null,
                stopPlayback: null,
                togglePlayback: null,
                resetPlayback: null,
                isArtworkCover: true,
                isVisualiserCover: false,
                // Flags to indicate initialization status
                isMasterGainInitialized: false,
                isAudioContextInitialized: true, // AudioContext is initialized upon creation
                isPlaybackStarting: false, // New flag
                isProceedingToNextSong: false,
                playbackInterval: null,
                seedList: [], // Added seedList here
                currentSeed: null, // Track the current seed
                hasProceededToNextSong: false,
                hasLoggedPlaybackNotActive: false,
                hasCompletedSequences: false,
                
                // Define loopSampleIds with additional data in globalData
                loopSampleData: [
                    {
                        id: "7c42769c1763cc8f045aada7914e8158223e45e7a4f197b49f918b1c005d36fci0", // Sample ID 1
                        bpm: 92.5, // BPM for this sample
                        trimStart: 0, // Trim start (no trimming)
                        trimEnd: 0 // Trim end (no trimming)
                    },
                    {
                        id: "3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0", // Sample ID 2
                        bpm: 105, // BPM for this sample
                        trimStart: 0.009, // Trim 0.9% from the start
                        trimEnd: 0 // Trim end (no trimming)
                    }
                ],

                // You can now access the sample information easily
                getLoopSampleInfo: function(sampleId) {
                    return this.loopSampleData.find(sample => sample.id === sampleId);
                }
            };

            console.log("[Global Data] Initialized globalData.");
    
            // Initialize masterGain only once
            window.globalData.masterGain = window.globalData.audioContext.createGain();
            window.globalData.masterGain.connect(window.globalData.audioContext.destination);
            window.globalData.isMasterGainInitialized = true;
            console.log("[Global Data] Master gain node created and connected.");
        } else {
            console.log("[Global Data] globalData already exists. Skipping initialization.");
        }
    
        // Define navigation functions only if they haven't been defined yet
        if (!window.globalData.nextSong) {
            window.globalData.nextSong = function() {
                if (this.songsArray.length === 0) {
                    // console.warn("[Global Data] No songs available to navigate.");
                    return;
                }
                this.currentSongIndex = (this.currentSongIndex + 1) % this.songsArray.length;
                console.log(`Switched to next song: Index ${this.currentSongIndex}`);
            };
            console.log("[Global Data] nextSong function defined.");
        }
    
        if (!window.globalData.previousSong) {
            window.globalData.previousSong = function() {
                if (this.songsArray.length === 0) {
                    // console.warn("[Global Data] No songs available to navigate.");
                    return;
                }
                this.currentSongIndex = (this.currentSongIndex - 1 + this.songsArray.length) % this.songsArray.length;
                console.log(`Switched to previous song: Index ${this.currentSongIndex}`);
            };
            console.log("[Global Data] previousSong function defined.");
        }
    })();
</script>

    
<!-- Seed Management -->
<script>
    (function() {
        // Utility function for logging
        const log = (message) => console.log(`[${new Date().toISOString()}] ${message}`);
        
        // Utility function to generate a random 16-digit seed
        function generateRandomSeed() {
            let seed = '';
            for (let i = 0; i < 16; i++) {
                seed += Math.floor(Math.random() * 10);
            }
            return seed;
        }

        // Linear Congruential Generator (LCG) for PRNG
        function lcg64(seed) {
            let m = 0x10000000000000n; // 2^52
            let a = 6364136223846793005n;
            let c = 1n;
            let state = BigInt(seed) || 0n;
            return function() {
                state = (a * state + c) % m;
                return Number(state) / Number(m);
            };
        }

        // Function to generate sequential seeds based on an initial seed
        function generateSequentialSeeds(initialSeed, count) {
            const seeds = [initialSeed];
            let currentSeed = BigInt(initialSeed);
            for (let i = 1; i < count; i++) {
                currentSeed += 1n;
                seeds.push(currentSeed.toString());
            }
            return seeds;
        }

        // Function to handle seed validation
        function isValidSeed(seed) {
            return /^\d{16}$/.test(seed) && BigInt(seed) <= BigInt(Number.MAX_SAFE_INTEGER);
        }

        // Retrieve seeds from URL or generate if not present
        function initializeSeedList() {
            const urlParams = new URLSearchParams(window.location.search);
            let seeds = [];

            if (urlParams.has('seed')) {
                seeds = urlParams.get('seed').split(/[\s,]+/).map(s => s.trim()).filter(s => s !== '');
                seeds = seeds.map(s => {
                    if (!isValidSeed(s)) {
                        log(`Invalid seed provided: "${s}". Generating a new seed.`);
                        return generateRandomSeed();
                    }
                    return s;
                });
                log(`Using user-provided seed(s): ${seeds.join(", ")}`);
                // Remove seed parameter from URL for cleanliness
                urlParams.delete('seed');
                history.replaceState(null, '', `${window.location.pathname}?${urlParams.toString()}`);
            } else {
                // No seed provided; generate a random seed and 99 sequential seeds
                const randomSeed = generateRandomSeed();
                seeds = generateSequentialSeeds(randomSeed, 100);
                log(`No user-provided seeds. Generated random seed "${randomSeed}" and created 100 sequential seeds.`);
            }

            // Assign seedList and currentSeed to globalData
            window.globalData.seedList = seeds;
            window.globalData.currentSeed = seeds[0];

            // Initialize songsArray based on seedList
            window.globalData.songsArray = seeds.map((seed, index) => ({
                id: `Remix ${index + 1}`, // Assigning Remix number as ID
                projectName: `Remix ${index + 1}`, // Assigning Remix number as Project Name
                artist: "Unknown Artist", // Default artist
                bpm: selectBPM(seed, index),
                channels: [], // To be populated elsewhere
                projectSequences: {}, // To be populated elsewhere
                seed: seed,
            }));

            log(`Initialized seedList with ${window.globalData.seedList.length} seeds.`);
        }

        // Function to select BPM based on seed and index using PRNG
        function selectBPM(seed, index) {
            const bpmOptions = [60, 120, 140, 160, 180, 240];
            const prng = lcg64(seed + index); // Slight variation per song
            return bpmOptions[Math.floor(prng() * bpmOptions.length)];
        }

        // Initialize seedList on script load
        initializeSeedList();

        // Utility functions for UI interactions
        window.togglePanel = function(panelId) {
            const panel = document.getElementById(panelId);
            if (panel) {
                panel.classList.toggle("hidden");
                const isHidden = panel.classList.contains("hidden");
                panel.setAttribute("aria-hidden", isHidden);
            } else {
                console.error(`${panelId.replace(/-/g, " ")} not found.`);
            }
        };

        window.populateTrackList = function() {
            const container = document.getElementById("track-list-container");
            if (!container) {
                // console.warn("Track list container not found.");
                return;
            }
            container.innerHTML = "";

            const songs = window.globalData.songsArray;
            if (songs.length) {
                songs.forEach(({ id, artist }) => {
                    const trackItem = document.createElement("div");
                    trackItem.className = "track-item";
                    trackItem.innerHTML = `
                        <div class="track-name">${id}</div>
                        <div class="track-artist">${artist}</div>
                    `;
                    container.appendChild(trackItem);
                });
            } else {
                container.textContent = "No tracks available.";
            }
        };

        window.toggleTrackListAndPopulate = function() {
            togglePanel("track-list-panel");
            const panel = document.getElementById("track-list-panel");
            if (panel && !panel.classList.contains("hidden")) {
                populateTrackList();
            }
        };

        window.copyToClipboard = function(text) {
            navigator.clipboard.writeText(text).then(() => {
                alert(`Seed copied to clipboard: ${text}`);
            }).catch(err => {
                console.error("Could not copy text:", err);
            });
        };

        window.clearPreviousSeeds = function() {
            if (confirm("Are you sure you want to clear all previous seeds?")) {
                localStorage.removeItem("previousSeeds");
                populatePreviousSeedsUI([]);
                log("All previous seeds have been cleared.");
            }
        };

        window.loadSeedsFromInput = function() {
            const input = document.getElementById("seed-input");
            if (!input) {
                alert("Seed input field not found.");
                return;
            }
            const inputSeeds = input.value.trim().split(/[\s,]+/).map(s => s.trim()).filter(s => s !== '');
            if (inputSeeds.length === 0) {
                alert("Please enter at least one seed.");
                return;
            }
            for (const seed of inputSeeds) {
                if (!isValidSeed(seed)) {
                    alert(`Invalid seed format: "${seed}". Seeds must be 16-digit numeric strings up to ${Number.MAX_SAFE_INTEGER}.`);
                    return;
                }
            }
            // Update seedList and reload page with new seeds
            window.globalData.seedList = inputSeeds;
            window.globalData.currentSeed = inputSeeds[0];
            window.globalData.songsArray = inputSeeds.map((seed, index) => ({
                id: `Remix ${index + 1}`,
                projectName: `Remix ${index + 1}`,
                artist: "Unknown Artist",
                bpm: selectBPM(seed, index),
                channels: [],
                projectSequences: {},
                seed: seed,
            }));
            log(`Loaded new seeds: ${inputSeeds.join(", ")}`);
            // Optionally, reload the page or reinitialize playback
            location.reload();
        };

        window.displaySeedAndBPM = function(seed, bpm, title) {
            const canvas = document.getElementById("seed-mgmt-canvas");
            if (!canvas) {
                console.warn("Seed management canvas not found.");
                return;
            }
            const ctx = canvas.getContext("2d");
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Draw background
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue("--seed-bg-color") || "green";
            ctx.fillRect(0, 0, canvas.width, canvas.height / 2);
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue("--bpm-bg-color") || "orange";
            ctx.fillRect(0, canvas.height / 2, canvas.width, canvas.height / 2);

            // Draw text
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue("--text-color") || "white";
            ctx.font = `${getComputedStyle(document.documentElement).getPropertyValue("--font-size") || "16px"} Arial`;
            ctx.textAlign = "center";
            ctx.textBaseline = "middle";
            ctx.fillText(`Seed: ${seed}`, canvas.width / 2, canvas.height / 4);
            ctx.fillText(`BPM: ${bpm}`, canvas.width / 2, (3 * canvas.height) / 4);

            // Save seed to previous seeds in localStorage
            saveSeedToPrevious(seed);

            // Update UI elements
            const seedDisplay = document.querySelector("#nowPlayingContainer .current-seed");
            if (seedDisplay) {
                seedDisplay.textContent = `Seed: ${seed}`;
                log(`Updated current seed display: ${seed}`);
            }

            const titleDisplay = document.querySelector("#nowPlayingContainer .title");
            if (titleDisplay && title) {
                titleDisplay.textContent = title;
                log(`Updated current song title: ${title}`);
            }
        };

        // Save seed to previous seeds in localStorage
        function saveSeedToPrevious(seed) {
            let previousSeeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
            if (!previousSeeds.includes(seed)) {
                previousSeeds.push(seed);
                localStorage.setItem("previousSeeds", JSON.stringify(previousSeeds));
                populatePreviousSeedsUI(previousSeeds);
                log(`Seed saved: ${seed}`);
            }
        }

        // Populate previous seeds in UI
        function populatePreviousSeedsUI(seeds) {
            const container = document.getElementById("previous-seeds-container");
            if (!container) {
                console.warn("Previous seeds container not found.");
                return;
            }
            const ul = container.querySelector("ul");
            if (!ul) {
                console.warn("Previous seeds list not found.");
                return;
            }
            ul.innerHTML = seeds.length ? seeds.map(seed => `
                <li>
                    <span>${seed}</span>
                    <button onclick="copyToClipboard('${seed}')">Copy</button>
                </li>
            `).join("") : "<li>No previous seeds.</li>";
        }

        // Event listeners for DOMContentLoaded
        document.addEventListener("DOMContentLoaded", () => {
            if (window.globalData.songsArray.length > 0) {
                const currentSong = window.globalData.songsArray[window.globalData.currentSongIndex];
                displaySeedAndBPM(currentSong.seed, currentSong.bpm, currentSong.projectName);
            } else {
                // console.warn("No song mixes generated.");
            }
            populatePreviousSeedsUI(JSON.parse(localStorage.getItem("previousSeeds")) || []);
        });

        // Event listeners for buttons
        const clearSeedsButton = document.getElementById("clear-seeds-button");
        if (clearSeedsButton) {
            clearSeedsButton.addEventListener("click", window.clearPreviousSeeds);
        }

        const loadSeedsButton = document.getElementById("load-seed-button");
        if (loadSeedsButton) {
            loadSeedsButton.addEventListener("click", window.loadSeedsFromInput);
        }

        const seedInput = document.getElementById("seed-input");
        if (seedInput) {
            seedInput.addEventListener("keypress", (e) => {
                if (e.key === "Enter") {
                    e.preventDefault();
                    loadSeedsButton.click();
                }
            });
        }
    })();
</script>


<!-- Seed Display -->
<script>

window.updateSeedDisplay = function() {
        const currentSong = globalData.songsArray[globalData.currentSongIndex];
        if (currentSong) {
            const seed = currentSong.seed;
            const bpm = currentSong.bpm;
            const title = currentSong.id;
            displaySeedAndBPM(seed, bpm, title);
            globalData.currentSeed = seed; // Set the current seed
            // Additional logic to update the playback based on the new seed
            // For example, reload audio buffers if necessary
        } else {
            // console.warn("Current song index is out of bounds.");
        }
    };
    //   window.updateSeedDisplay = updateSeedDisplay;

      /**
       * Handles transitioning to the next song in the playlist.
       */
      window.handleNextSong = function() {
          globalData.nextSong();
          updateSeedDisplay();
      };

      /**
       * Handles transitioning to the previous song in the playlist.
       */
      window.handlePreviousSong = function() {
          globalData.previousSong();
          updateSeedDisplay();
      };
      </script>



<!-- Combined Effects Configuration, Audio Effects Module, and GainNode Management -->
<script>
    /*
    #region Combined Effects Configuration, Audio Effects Module, and GainNode Management

    ## Purpose:
    - **Effects Configuration:**
      Establishes a comprehensive framework for managing and configuring various audio effects within the application. Enables dynamic and randomized application of audio effects based on predefined configurations and probabilities.
    - **Audio Effects Module:**
      Defines and exports various audio effect application functions used for processing audio channels within the application.
    - **GainNode Management:**
      Ensures that GainNodes are correctly created and mapped for each channel, allowing for volume control and audio effects management.

    ## Key Functionalities:

    ### Effects Configuration:
    - **Effects Module Initialization:**
      - Initializes or utilizes an existing `EffectsModule` within the global `window` object to store and manage effects configurations.
    - **Effects Configuration:**
      - Defines a variety of audio effects (e.g., pitchShift, harmonize, delay, chorus, leslie, synthBass, synth) with specific properties:
        - **enabled:** Boolean flag to activate or deactivate the effect.
        - **defaultProbability:** Determines the likelihood of the effect being applied.
        - **Parameter Ranges:** Specifies ranges or options for effect-specific parameters (e.g., rate, depth, feedback).
    - **Parameter Generation (`getEffectParams`):**
      - Generates random parameters for each effect based on their configurations and a pseudo-random number generator (`prng`).
      - Ensures that effects are applied with varied and dynamic settings each time they are triggered.
      - Handles different parameter requirements for each effect type, allowing for extensibility and customization.
    - **Event Dispatching:**
      - Emits an `effectsLoaded` event once the effects configurations are fully set up, signaling other parts of the application that the effects system is ready for use.
    - **Extensibility:**
      - Designed to easily incorporate additional effects by adding new configurations and corresponding parameter generation logic.
      - Facilitates scalability, allowing the effects system to grow with application requirements.

    ### Audio Effects Module:
    - **Effect Application Functions:**
      - `applyChorusEffect`
      - `applyRandomPitchShift`
      - `addHarmony`
      - `applyIntermittentDelay`
      - `applyReverseEffect`
      - `applyVolumeChange`
      - `applyPanEffect`
      - `applyReverbEffect`
      - `applyFilterEffect`
      - `applyTremoloEffect`
      - `applyDistortionEffect`
      - `applyBitcrusherEffect`
      - `applyLeslieEffect`
      - `applyBpmLinkedDelay`
      - Each function is responsible for applying specific audio effects to audio channels based on provided parameters.

    ### GainNode Management:
    - **GainNode Creation and Mapping:**
      - Ensures that each channel has an associated GainNode for volume control.
      - Maps GainNodes to their corresponding channels within each song.
    - **GainNode Initialization Functions:**
      - `createGainNodesForSong`: Creates GainNodes for all channels in a given song.
      - `prepareNextSong`: Prepares GainNodes for the next song (if applicable).
      - `cleanupGainNodesForSong`: Cleans up GainNodes for a song when it's no longer needed.
    - **Global Data Structure:**
      - Maintains a global `gainNodes` map within `globalData` to manage GainNodes for all songs and channels.
      - Ensures that GainNodes are correctly connected to the audio context's master gain node.

    ## Overall Functionality:
    This combined script provides a flexible and scalable approach to audio effect management and GainNode handling. By centralizing effect configurations, parameter generation, dedicated effect application functions, and GainNode management, it ensures consistency, ease of maintenance, and rich, randomized audio experiences tailored to user interactions or predefined conditions across the application's audio processing components.

    #endregion
    */

    (() => {
        // ================================
        // Effects Configuration Section
        // ================================
        window.EffectsModule = window.EffectsModule || {};

        window.EffectsModule.effectsConfig = { 
            pitchShift: { 
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                shifts: [0.25, 0.5, 1, 2, 4]
            },
            harmonize: { 
                enabled: true, 
                defaultProbability: 0.0025, // needs to range from 0.0025 to 0.1 - More stable mixes in general at 0.01 but interesting mixes around 0.1
                intervals: [0.25, 0.5, 1, 1.5, 2, 4],
                maxHarmonyChannels: 1 
            },
            delay: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                noteValue: 'sixteenth',
                maxDelayRepeats: 8 // Reduced from 16
            },
            reverse: {
                enabled: true, 
                defaultProbability: 0.3 // Reduced from 1
            },
            pan: {
                enabled: true,
                defaultProbability: 1, // Safe to keep at 1
                positions: [-1, 1]
            },
            reverb: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                decayTimeRange: [1, 5], // Narrowed range
                mixRange: [0.2, 0.7] // Narrowed range
            },
            filter: {
                enabled: true, 
                defaultProbability: 0.7, 
                types: ['lowpass', 'highpass', 'bandpass'], 
                frequencyRange: [300, 8000], 
                QRange: [1, 8] // Narrowed range
            },
            tremolo: {
                enabled: true, 
                defaultProbability: 0.6, 
                rateRange: [4, 12],   
                depthRange: [0.6, 1]
            },
            distortion: {
                enabled: false, 
                defaultProbability: 0.3, // Reduced and kept disabled
                amountRange: [1, 10] // Adjusted range
            },
            bitcrusher: {
                enabled: true, 
                defaultProbability: 0.3, 
                bitDepthRange: [2, 6],    
                sampleRateRange: [8000, 22050]
            },
            chorus: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.5
                rateRange: [0.1, 5],       
                depthRange: [0.1, 1],      
                feedbackRange: [0, 0.3],   
                mixRange: [0, 0.8]         
            },
            leslie: {
                enabled: true,
                defaultProbability: 0.2, // Reduced from 0.3
                speedRange: [0.5, 1.5],    
                depthRange: [0.5, 1],      
                mixRange: [0, 1]            
            },
            delayBpmLinked: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.4
                delayTimes: ['quarter', 'eighth', 'sixteenth'], 
                feedbackRange: [0.3, 0.6], // Narrowed range
                mixRange: [0, 0.7]        // Narrowed range
            },
            // Removed 'synthBassLine' as it's undefined
        };

        window.EffectsModule.getEffectParams = function(effectName, currentSequence, bpm, prng) {
            const effect = this.effectsConfig[effectName];
            if (!effect || !effect.enabled) return null;
            if (prng() < effect.defaultProbability) {
                // Generate random parameters within the specified ranges
                const params = {};
                switch(effectName) {
                    case 'pitchShift':
                        params.shifts = effect.shifts;
                        break;
                    case 'harmonize':
                        params.intervals = effect.intervals;
                        params.maxHarmonyChannels = effect.maxHarmonyChannels;
                        break;
                    case 'delay':
                        params.noteValue = effect.noteValue;
                        params.maxDelayRepeats = effect.maxDelayRepeats;
                        break;
                    case 'chorus':
                        params.rate = prng() * (effect.rateRange[1] - effect.rateRange[0]) + effect.rateRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'leslie':
                        params.rotationSpeed = prng() * (effect.speedRange[1] - effect.speedRange[0]) + effect.speedRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'delayBpmLinked':
                        params.time = effect.delayTimes[Math.floor(prng() * effect.delayTimes.length)];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;

                    // Add cases for other effects as needed
                    default:
                        // For effects without additional parameters
                        break;
                }
                return { ...effect, ...params };
            }
            return null;
        };

        // ================================
        // Audio Effects Module Section
        // ================================


        // Helper function to clamp values to a range
        const clamp = (value, min, max) => {
            if (value < min || value > max) {
                // console.warn(`Value ${value} is out of bounds. Clamping to range [${min}, ${max}]`);
            }
            return Math.min(Math.max(value, min), max);
        };
        // Apply Chorus Effect
        window.applyChorusEffect = (channel, { rate, depth, feedback, mix }, prng) => {
            channel.metadata.chorus = {
                rate,       // Modulation rate in Hz
                depth,      // Modulation depth (0 to 1)
                feedback,   // Feedback amount (0 to 0.5)
                mix         // Wet/Dry mix (0 to 1)
            };
            console.log(`[effectsDebug][ChorusEffect] Channel "${channel.id}" chorus set with rate: ${rate}Hz, depth: ${depth}, feedback: ${feedback}, mix: ${mix}`);
        };

        // Apply Random Pitch Shift
        window.applyRandomPitchShift = (channel, { shifts }, prng) => {
            const shift = shifts[Math.floor(prng() * shifts.length)];
            channel.metadata.playbackSpeed *= shift;
            console.log(`[effectsDebug][PitchShift] Channel "${channel.id}" playback speed shifted by factor ${shift}`);
        };

        // Add Harmony
        window.addHarmony = (originalChannel, index, newSong, { intervals, maxHarmonyChannels }, context, prng) => {
            if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
            intervals.forEach(interval => {
                if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
                const harmony = JSON.parse(JSON.stringify(originalChannel));
                harmony.id = `${originalChannel.id}_harmony_${index}_${interval}`;
                harmony.metadata.playbackSpeed *= interval;
                harmony.metadata.volume = clamp((harmony.metadata.volume || 1) * 0.5, 1);
                newSong.channels.push(harmony);
                context.harmonyChannelsAdded++;
                context.totalGain += harmony.metadata.volume || 1; // Update totalGain
                console.log(`[effectsDebug][Harmony] Added harmony channel "${harmony.id}" with interval ${interval}`);
            });
        };

        // Apply Intermittent Delay
        window.applyIntermittentDelay = (channel, { noteValue, maxDelayRepeats }, bpm) => {
            const beatDuration = 60000 / bpm;
            const delayMap = { 'quarter': beatDuration, 'eighth': beatDuration / 2, 'sixteenth': beatDuration / 4 };
            channel.metadata.delay = { time: delayMap[noteValue] || beatDuration, repeats: maxDelayRepeats };
            console.log(`[effectsDebug][IntermittentDelay] Channel "${channel.id}" delay set with time: ${channel.metadata.delay.time}ms, repeats: ${channel.metadata.delay.repeats}`);
        };

        // Apply Reverse Effect
        window.applyReverseEffect = channel => {
            channel.metadata.requiresReversal = true;
            console.log(`[effectsDebug][ReverseEffect] Channel "${channel.id}" reversal enabled`);
        };

       
        // Apply Volume Change
        window.applyVolumeChange = (channel, { range }, prng) => {
            const [min, max] = range;

            // Ensure the range is within valid limits
            if (min < 0 || max > 1) {
                console.error(`Invalid volume range: [${min}, ${max}]. Clamping to [0.5, 1].`);
            }

            // Clamp range to valid limits
            const clampedMin = clamp(min, 0.5, 1);
            const clampedMax = clamp(max, 0.5, 1);

            // Calculate random factor within the clamped range
            const randomFactor = prng() * (clampedMax - clampedMin) + clampedMin;
            const newVolume = clamp((channel.metadata.volume || 1) * randomFactor, 0.5, 1);

            // Set the new volume with two decimal places
            channel.metadata.volume = parseFloat(newVolume.toFixed(2));

            console.log(`[effectsDebug][VolumeChange] Channel "${channel.id}" volume set to ${channel.metadata.volume}`);
        };

        // Apply Pan Effect
        window.applyPanEffect = (channel, { positions }, prng) => {
            if (!positions || !Array.isArray(positions) || positions.length === 0) {
                console.warn(`[PanEffect] Invalid or empty 'positions' array for Channel "${channel.id}". Assigning default pan value 0.`);
                channel.metadata.pan = 0; // Default center pan
                return;
            }

            const selectedPan = clamp(positions[Math.floor(prng() * positions.length)], -1, 1);
            channel.metadata.pan = parseFloat(selectedPan.toFixed(2));
            console.log(`[effectsDebug][PanEffect] Channel "${channel.id}" pan set to ${channel.metadata.pan}`);
        };

        // Apply Reverb Effect
        window.applyReverbEffect = (channel, { decayTimeRange, mixRange }, prng) => {
            // Generate random decay time within range
            let decayTime = prng() * (decayTimeRange[1] - decayTimeRange[0]) + decayTimeRange[0];
            decayTime = clamp(decayTime, decayTimeRange[0], decayTimeRange[1]);

            // Generate random mix within range
            let mix = prng() * (mixRange[1] - mixRange[0]) + mixRange[0];
            mix = clamp(mix, mixRange[0], mixRange[1]);

            channel.metadata.reverb = {
                decayTime: parseFloat(decayTime.toFixed(2)), // Rounded for consistency
                mix: parseFloat(mix.toFixed(2))
            };

            console.log(`[effectsDebug][ReverbEffect] Channel "${channel.id}" reverb set with decayTime: ${channel.metadata.reverb.decayTime}s, mix: ${channel.metadata.reverb.mix}`);
        };

       // Apply Filter Effect
        window.applyFilterEffect = (channel, { types, frequencyRange, QRange }, prng) => {
            // Ensure the types array is valid
            if (!Array.isArray(types) || types.length === 0) {
                console.error("Invalid filter types array. Using default type 'lowpass'.");
                types = ['lowpass']; // Default to lowpass if no types provided
            }

            // Select a random filter type from the available types
            const selectedType = types[Math.floor(prng() * types.length)];

            // Validate and clamp frequency range
            const [minFreq, maxFreq] = frequencyRange;
            if (minFreq < 20 || maxFreq > 22000) {
                console.warn(`Frequency range out of bounds: [${minFreq}, ${maxFreq}]. Clamping to [20, 22000].`);
            }

            const frequency = clamp(prng() * (maxFreq - minFreq) + minFreq, 20, 22000);

            // Validate and clamp Q range
            const [minQ, maxQ] = QRange;
            if (minQ < 0.1 || maxQ > 20) {
                console.warn(`Q range out of bounds: [${minQ}, ${maxQ}]. Clamping to [0.1, 20].`);
            }

            const Q = clamp(prng() * (maxQ - minQ) + minQ, 0.1, 20);

            // Apply filter settings to the channel metadata
            channel.metadata.filter = {
                type: selectedType,
                frequency: parseFloat(frequency.toFixed(2)),
                Q: parseFloat(Q.toFixed(2)),
            };

            console.log(`[effectsDebug][FilterEffect] Channel "${channel.id}" filter set to type: ${channel.metadata.filter.type}, frequency: ${channel.metadata.filter.frequency}Hz, Q: ${channel.metadata.filter.Q}`);
        };

        // Apply Tremolo Effect
        window.applyTremoloEffect = (channel, { rateRange, depthRange }, prng) => {
            // Generate random rate within range
            let rate = prng() * (rateRange[1] - rateRange[0]) + rateRange[0];
            rate = clamp(rate, rateRange[0], rateRange[1]);

            // Generate random depth within range
            let depth = prng() * (depthRange[1] - depthRange[0]) + depthRange[0];
            depth = clamp(depth, depthRange[0], depthRange[1]);

            channel.metadata.tremolo = {
                rate: parseFloat(rate.toFixed(2)),   // Rounded for consistency
                depth: parseFloat(depth.toFixed(2))
            };

            console.log(`[effectsDebug][TremoloEffect] Channel "${channel.id}" tremolo set to rate: ${channel.metadata.tremolo.rate}Hz, depth: ${channel.metadata.tremolo.depth}`);
        };

        // Apply Distortion Effect
        window.applyDistortionEffect = (channel, { amountRange }, prng) => {
            // Generate random amount within range
            let amount = prng() * (amountRange[1] - amountRange[0]) + amountRange[0];
            amount = clamp(amount, amountRange[0], amountRange[1]);

            channel.metadata.distortion = {
                amount: parseFloat(amount.toFixed(2)) // Rounded for consistency
            };

            console.log(`[effectsDebug][DistortionEffect] Channel "${channel.id}" distortion set to amount: ${channel.metadata.distortion.amount}`);
        };

        // Apply Bitcrusher Effect
        window.applyBitcrusherEffect = (channel, { bitDepthRange, sampleRateRange }, prng) => {
            // Generate random bit depth within range
            let bitDepth = Math.floor(prng() * (bitDepthRange[1] - bitDepthRange[0] + 1)) + bitDepthRange[0];
            bitDepth = clamp(bitDepth, bitDepthRange[0], bitDepthRange[1]);

            // Generate random sample rate within range
            let sampleRate = prng() * (sampleRateRange[1] - sampleRateRange[0]) + sampleRateRange[0];
            sampleRate = clamp(sampleRate, sampleRateRange[0], sampleRateRange[1]);
            sampleRate = parseFloat(sampleRate.toFixed(0)); // Rounded to nearest integer

            channel.metadata.bitcrusher = {
                bitDepth: bitDepth,
                sampleRate: sampleRate
            };

            console.log(`[effectsDebug][BitcrusherEffect] Channel "${channel.id}" bitcrusher set to bitDepth: ${channel.metadata.bitcrusher.bitDepth}, sampleRate: ${channel.metadata.bitcrusher.sampleRate}Hz`);
        };

        // Apply Leslie Effect
        window.applyLeslieEffect = (channel, { rotationSpeed, depth, mix }, bpm) => {
            channel.metadata.leslie = {
                rotationSpeed, // Rotation speed in Hz
                depth,         // Depth of the effect
                mix            // Wet/Dry mix
            };
            console.log(`[effectsDebug][LeslieEffect] Channel "${channel.id}" Leslie effect set with rotationSpeed: ${rotationSpeed}Hz, depth: ${depth}, mix: ${mix}`);
        };

        // Apply BPM-Linked Delay
        window.applyBpmLinkedDelay = (channel, { time, feedback, mix }, bpm) => {
            channel.metadata.delayBpmLinked = {
                time,       // Delay time in ms
                feedback,   // Feedback amount (0 to 1)
                mix         // Wet/Dry mix (0 to 1)
            };
            console.log(`[effectsDebug][BpmLinkedDelay] Channel "${channel.id}" BPM-linked delay set with time: ${time}ms, feedback: ${feedback}, mix: ${mix}`);
        };

        // ================================
        // GainNode Management Section
        // ================================

        window.GainNodeHelper = (() => {
            // Initialize globalData if not present
            const globalData = window.globalData || (window.globalData = { 
                gainNodes: {}, 
                audioContext: new (window.AudioContext || window.webkitAudioContext)(), 
                masterGain: null 
            });

            // Initialize masterGain if not already set
            if (!globalData.masterGain) {
                globalData.masterGain = globalData.audioContext.createGain();
                globalData.masterGain.connect(globalData.audioContext.destination);
                // console.log(`[GainNodeHelper] Master GainNode initialized and connected to destination.`);
            }

            /**
             * Initializes GainNodes for all channels in a given song.
             *
             * @param {Object} song - The song object containing channels.
             */
            const createGainNodesForSong = (song) => {
                const songId = song.id;
                if (!song.channels || song.channels.length === 0) {
                    console.warn(`[GainNodeHelper] No channels found for Song "${songId}".`);
                    return;
                }

                globalData.gainNodes[songId] = globalData.gainNodes[songId] || {};

                song.channels.forEach(channel => {
                    if (!globalData.gainNodes[songId][channel.id]) {
                        const gainNode = globalData.audioContext.createGain();
                        gainNode.gain.value = channel.metadata.volume || 1;
                        gainNode.connect(globalData.masterGain);
                        globalData.gainNodes[songId][channel.id] = gainNode;
                        // console.log(`[GainNodeHelper] GainNode created for Channel "${channel.id}" in Song "${songId}".`);
                    }
                });
            };

            /**
             * Prepares GainNodes for the next song.
             *
             * @param {Object} song - The next song object.
             */
            const prepareNextSongGainNodes = (song) => {
                createGainNodesForSong(song);
                // console.log(`[GainNodeHelper] Prepared GainNodes for next Song "${song.id}".`);
            };

            /**
             * Cleans up GainNodes for a specific song.
             *
             * @param {string} songId - The ID of the song to clean up.
             */
            const cleanupGainNodesForSong = (songId) => {
                const songGainNodes = globalData.gainNodes[songId];
                if (songGainNodes) {
                    Object.values(songGainNodes).forEach(gainNode => gainNode.disconnect());
                    delete globalData.gainNodes[songId];
                    // console.log(`[GainNodeHelper] Cleaned up GainNodes for Song "${songId}".`);
                } else {
                    console.warn(`[GainNodeHelper] No GainNodes found to clean up for Song "${songId}".`);
                }
            };

            // Expose public methods
            return {
                createGainNodesForSong,
                prepareNextSongGainNodes,
                cleanupGainNodesForSong
            };
        })();

        // ================================
        // Finalize Configuration
        // ================================

        // Dispatch 'effectsLoaded' event to signal that the effects system is ready
        document.dispatchEvent(new Event('effectsLoaded'));
    })();
</script>

<!-- GainNode Helpers (gainNodeHelpers.js) -->
<script>
window.GainNodeHelper = (() => {
  const n =
    window.globalData ||
    (window.globalData = {
      gainNodes: {},
      audioContext: new (window.AudioContext || window.webkitAudioContext)(),
      masterGain: null,
    });

  if (!n.masterGain) {
    n.masterGain = n.audioContext.createGain();
    n.masterGain.connect(n.audioContext.destination);
  }

  const e = {
    targetLoudness: 0.8,
    transientThreshold: 1.2,
    smoothingFactor: 0.7,
  };

  const o = (song, isNextSong = false) => {
    const i = song.id;

    // Initialize GainNodes for the song
    if (isNextSong) {
      // Preparing next song: i
    } else {
      // Setting current song: i
    }

    if (song.channels && song.channels.length > 0) {
      if (!n.gainNodes[i]) {
        n.gainNodes[i] = {};
      }

      // Create GainNodes for each channel if they don't exist
      song.channels.forEach((channel) => {
        if (!n.gainNodes[i][channel.id]) {
          const gainNode = n.audioContext.createGain();
          gainNode.gain.value = channel.metadata.volume || 1;
          gainNode.connect(n.masterGain);
          n.gainNodes[i][channel.id] = gainNode;
        }
      });

      // Normalize volumes across all channels
      if (!song.channels || song.channels.length === 0) {
        return;
      }

      const volumes = song.channels.map((ch) => ch.metadata.volume || 1);
      const maxVolume = Math.max(...volumes);
      song.channels.forEach((ch) => {
        const normalizedGain =
          ((ch.metadata.volume || 1) / maxVolume) * e.targetLoudness;
        a(song.id, ch.id, normalizedGain);
      });

      // Apply transient control to each channel
      if (song.channels && song.channels.length !== 0) {
        song.channels.forEach((channel) => {
          const gainNode = n.gainNodes?.[song.id]?.[channel.id];
          if (gainNode) {
            const adjustedGain = Math.min(
              gainNode.gain.value * e.transientThreshold,
              e.targetLoudness
            );
            gainNode.gain.setTargetAtTime(
              adjustedGain,
              n.audioContext.currentTime,
              e.smoothingFactor
            );
          }
        });
      }

      // All GainNodes initialized for Song ID: i
    } else {
      // No channels found for Song "i"
    }
  };

  const a = (songId, channelId, gainValue) => {
    const t = n.gainNodes?.[songId]?.[channelId];
    if (t) {
      t.gain.setValueAtTime(gainValue, n.audioContext.currentTime);
    } else {
      // No GainNode found for Channel "channelId" of Song "songId"
    }
  };

  return {
    /**
     * Creates GainNodes for a given song.
     * @param {Object} song - The song object containing channels.
     */
    createGainNodesForSong: (song) => o(song, false),

    /**
     * Prepares GainNodes for the next song.
     * @param {Object} song - The next song object containing channels.
     */
    prepareNextSongGainNodes: (song) => o(song, true),

    /**
     * Cleans up GainNodes for a given song.
     * @param {string} songId - The ID of the song to clean up.
     */
    cleanupGainNodesForSong: (songId) => {
      const gainNodesForSong = n.gainNodes[songId];
      if (gainNodesForSong) {
        Object.values(gainNodesForSong).forEach((gainNode) => {
          gainNode.disconnect();
        });
        delete n.gainNodes[songId];
      } else {
        // No GainNodes found to clean up for Song ID: songId
      }
    },

    /**
     * Sets the gain value for a specific channel of a song.
     * @param {string} songId - The ID of the song.
     * @param {string} channelId - The ID of the channel.
     * @param {number} gainValue - The gain value to set.
     */
    setChannelGain: (songId, channelId, gainValue) =>
      a(songId, channelId, gainValue),

    /**
     * Sets mastering controls by merging new settings.
     * @param {Object} newSettings - The new mastering settings.
     */
    setMasteringControls: (newSettings) =>
      Object.assign(e, newSettings),
  };
})();
</script>



<!-- Main Script (main.js) -->
<script>
    /* 
    #region Main Script
    **Purpose:**
    [Unchanged: Comprehensive documentation as provided by the user]
    #endregion
    */
    
    (async () => {
        const globalData = window.globalData; // Ensure consistent access
        const audioContext = globalData.audioContext; // Standardize AudioContext access

        // // Embed the seed list directly
        // window.globalData.seedList = [
        //         '1378012087872054',
        //         '8577097119065499',
        //         '8651019588475341',
        //         '8651019588475378'
        //     ];
            

        function waitForEffects() {
            return new Promise((resolve) => {
                if (window.EffectsModule && window.EffectsModule.effectsConfig) {
                    resolve();
                } else {
                    document.addEventListener('effectsLoaded', resolve, { once: true });
                }
            });
        }
        await waitForEffects();
    

        // Adjustable controls for gain reduction when layering
        const layeringControls = {
            gainReductionPerLayer: 0.7, // Gain multiplier per additional layer (e.g., 0.7 reduces gain by 30% per layer)
            maxLayers: 4 // Maximum number of layers per channel to prevent excessive gain reduction
        };

     /**
 * Applies a series of audio effects to a given channel, ensuring volume consistency and balance.
 *
 * @param {Object} channel - The audio channel to apply effects to.
 * @param {number} index - The index of the channel.
 * @param {Object} newSong - The song object containing channel and sequence information.
 * @param {number} currentSequence - The current sequence number.
 * @param {number} bpm - Beats per minute of the song.
 * @param {Object} effectsContext - Context object to manage total gain and harmony channels.
 * @param {Function} prng - Pseudo-random number generator function.
 */
function applyEffects(channel, index, newSong, currentSequence, bpm, effectsContext, prng) {
    console.log(`[effectsDebug][Song: "${newSong.id}"] Applying effects to Channel "${channel.id}"...`);
    const MAX_EFFECTS_PER_CHANNEL = 3; // Define a reasonable limit
    const duplicationEffects = new Set(['harmonize', 'delay', 'delayBpmLinked']); // Effects that duplicate layers
    const loggedEffectInfo = new Set(); // To keep track of logged effects

    const effectsMap = [
        { name: 'pitchShift', applyFn: (ch, params) => applyRandomPitchShift(ch, params, prng) },
        { name: 'harmonize', applyFn: (ch, params) => addHarmony(ch, index, newSong, params, effectsContext, prng) },
        { name: 'delay', applyFn: (ch, params) => applyIntermittentDelay(ch, params, bpm) },
        { name: 'reverse', applyFn: (ch, params) => applyReverseEffect(ch) },
        { name: 'filter', applyFn: (ch, params) => applyFilterEffect(ch, params, prng) },
        { name: 'tremolo', applyFn: (ch, params) => applyTremoloEffect(ch, params, prng) },
        { name: 'distortion', applyFn: (ch, params) => applyDistortionEffect(ch, params, prng) },
        { name: 'bitcrusher', applyFn: (ch, params) => applyBitcrusherEffect(ch, params, prng) },
        { name: 'pan', applyFn: (ch, params) => applyPanEffect(ch, params, prng) },
        { name: 'reverb', applyFn: (ch, params) => applyReverbEffect(ch, params, prng) },
        { name: 'volumeChange', applyFn: (ch, params) => applyVolumeChange(ch, params, prng) },
        { name: 'chorus', applyFn: (ch, params) => applyChorusEffect(ch, params, prng) },
        { name: 'leslie', applyFn: (ch, params) => applyLeslieEffect(ch, params, bpm, prng) },
        { name: 'delayBpmLinked', applyFn: (ch, params) => applyBpmLinkedDelay(ch, params, bpm, prng) },
    ];

    // Shuffle the effectsMap to randomize effect application order
    const shuffledEffects = effectsMap.sort(() => 0.5 - Math.random());

    let appliedEffectsCount = 0;

    // Iterate through each effect in the shuffledEffectsMap
    for (const effect of shuffledEffects) {
        if (appliedEffectsCount >= MAX_EFFECTS_PER_CHANNEL) break; // Stop if max effects reached

        const effectParams = window.EffectsModule.getEffectParams(effect.name, currentSequence, bpm, prng);
        if (effectParams) {
            // Apply the effect to the channel
            effect.applyFn(channel, effectParams);
            appliedEffectsCount++;

            // If the effect is a duplication effect, adjust gain accordingly
            if (duplicationEffects.has(effect.name)) {
                // Initialize layer count if not present
                if (!effectsContext.channelLayers[channel.id]) {
                    effectsContext.channelLayers[channel.id] = 1; // Original layer
                }

                // Increment layer count
                if (effectsContext.channelLayers[channel.id] < layeringControls.maxLayers) {
                    effectsContext.channelLayers[channel.id]++;
                }

                // Calculate the new gain based on the number of layers
                const layers = effectsContext.channelLayers[channel.id];
                const newGain = (1 / layers) * layeringControls.gainReductionPerLayer ** (layers - 1);

                // Update the channel's metadata volume
                channel.metadata.volume = newGain;

                // Apply the new gain using GainNodeHelper
                GainNodeHelper.setChannelGain(newSong.id, channel.id, newGain);

                // Log the duplication effect application only once per effect
                if (!loggedEffectInfo.has(effect.name)) {
                    loggedEffectInfo.add(effect.name);
                    // console.log(`[Effects][Song: "${newSong.id}"] Applied duplication effect "${effect.name}" to Channel "${channel.id}". Layers: ${layers}, New Gain: ${newGain.toFixed(2)}`);
                }
            }

            // Log the application of the effect with song and channel information only once
            if (!loggedEffectInfo.has(effect.name)) {
                loggedEffectInfo.add(effect.name);
                // console.log(`[Effects][Song: "${newSong.id}"] Applied effect "${effect.name}" to Channel "${channel.id}" with parameters:`, effectParams);
            }
        }
    }

    // Define volume clamping constants
    const MIN_CHANNEL_VOLUME = 0.5; // Minimum volume factor to prevent channels from being too quiet
    const MAX_CHANNEL_VOLUME = 1.5; // Maximum volume factor to prevent channels from being too loud
    const MAX_TOTAL_GAIN = 1;       // Maximum total gain across all channels to prevent overall mix from being too loud

    const MAX_GAIN = 1541.27;
    const MIN_GAIN = -3.40282e+38; // Adjust based on your filter type

    function setFilterGain(filterNode, value) {
        // Clamp the value
        const clampedValue = Math.min(Math.max(value, MIN_GAIN), MAX_GAIN);
        filterNode.gain.setValueAtTime(clampedValue, audioContext.currentTime);
        if (value !== clampedValue) {
            // log(`Gain value ${value} clamped to ${clampedValue}.`);
        }
    }
    // After applying all effects, perform volume normalization and clamping

    // Ensure the total gain across all channels does not exceed MAX_TOTAL_GAIN
    if (effectsContext.totalGain > MAX_TOTAL_GAIN) {
        const reductionFactor = MAX_TOTAL_GAIN / effectsContext.totalGain;
        channel.metadata.volume = (channel.metadata.volume || 1) * reductionFactor;

        // Log the normalization action only once
        if (!loggedEffectInfo.has('normalization')) {
            loggedEffectInfo.add('normalization');
            // console.log(`[Normalization][Song: "${newSong.id}"] Normalized Channel "${channel.id}" volume by factor ${reductionFactor.toFixed(2)} to maintain total gain within ${MAX_TOTAL_GAIN}.`);
        }
    }

    // Update the total gain in the effects context
    effectsContext.totalGain += channel.metadata.volume || 1;

    // Clamp the channel's volume within defined bounds to maintain balance
    if (channel.metadata.volume < MIN_CHANNEL_VOLUME) {
        channel.metadata.volume = MIN_CHANNEL_VOLUME;
        // Log clamping action only once
        if (!loggedEffectInfo.has('clamping_min')) {
            loggedEffectInfo.add('clamping_min');
            // console.log(`[Clamping][Song: "${newSong.id}"] Clamped Channel "${channel.id}" volume to minimum ${MIN_CHANNEL_VOLUME}.`);
        }
    } else if (channel.metadata.volume > MAX_CHANNEL_VOLUME) {
        channel.metadata.volume = MAX_CHANNEL_VOLUME;
        // Log clamping action only once
        if (!loggedEffectInfo.has('clamping_max')) {
            loggedEffectInfo.add('clamping_max');
            // console.log(`[Clamping][Song: "${newSong.id}"] Clamped Channel "${channel.id}" volume to maximum ${MAX_CHANNEL_VOLUME}.`);
        }
    }

    // Update the GainNode's gain value using GainNodeHelper
    GainNodeHelper.setChannelGain(newSong.id, channel.id, channel.metadata.volume || 1);
}
 

    
        const keyNames = [
            "projectName",
            "artistName",
            "projectBPM",
            "currentSequence",
            "channelURLs",
            "channelVolume",
            "channelPlaybackSpeed",
            "trimSettings",
            "projectChannelNames",
            "startSliderValue",
            "endSliderValue",
            "totalSampleDuration",
            "start",
            "end",
            "projectSequences",
            "steps"
        ];
    
        const keyMap = keyNames.reduce((map, key, index) => {
            map[key] = index;
            return map;
        }, {});
    
        const channelIds = Array.from({ length: 16 }, (_, index) => String.fromCharCode(65 + index)); // 'A' to 'P'
        const channelIdMap = channelIds.reduce((map, id, index) => {
            map[id] = index;
            return map;
        }, {});
    
        const fetchAndProcessSongData = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network error for ${url}`);
                const compressedData = new Uint8Array(await response.arrayBuffer());
                const inflatedData = window.pako.inflate(compressedData);
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                const parsedData = JSON.parse(jsonString);
                const processParsedData = (data) => {
                    const recurse = (obj) => {
                        if (Array.isArray(obj)) {
                            return obj.map(recurse);
                        } else if (obj && typeof obj === "object") {
                            return Object.entries(obj).reduce((accumulator, [key, value]) => {
                                const mappedKey = keyNames[key] || key;
                                accumulator[mappedKey] = mappedKey === "projectSequences"
                                    ? Object.fromEntries(
                                        Object.entries(value).map(([seqKey, seqValue]) => {
                                            const sequenceName = `Sequence${seqKey.replace(/^s/, "")}`;
                                            const channels = Object.fromEntries(
                                                Object.entries(seqValue).map(([channelKey, channelValue]) => {
                                                    const steps = channelValue[keyMap.steps] || [];
                                                    const processedSteps = steps.flatMap((step) => {
                                                        if (typeof step === "number") {
                                                            return step;
                                                        } else if (step?.r) {
                                                            const [start, end] = step.r;
                                                            return Array.from({ length: end - start + 1 }, (_, idx) => start + idx);
                                                        } else if (typeof step === "string" && step.endsWith("r")) {
                                                            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
                                                        } else {
                                                            return [];
                                                        }
                                                    });
                                                    return [`ch${channelIdMap[channelKey]}`, { steps: processedSteps }];
                                                })
                                            );
                                            return [sequenceName, channels];
                                        })
                                    )
                                    : recurse(value);
                                return accumulator;
                            }, {});
                        } else {
                            return obj;
                        }
                    };
                    return recurse(data);
                };
                return processParsedData(parsedData);
            } catch (error) {
                console.error(`[Initialization] Error fetching/deserializing ${url}:`, error);
                throw error;
            }
        };
    
        const prepareInitialSampleOrder = ({ projectSequences }) => {
            const sampleSet = new Set();
            const sampleOrder = [];
            Object.keys(projectSequences)
                .sort((a, b) => +a.slice(9) - +b.slice(9))
                .forEach(seqK => {
                    Object.entries(projectSequences[seqK]).forEach(([chId, { steps }]) => {
                        steps.forEach(step => {
                            if (typeof step === "number" || step?.index !== undefined) {
                                const id = `${chId}_${step.reverse ? 'r' : 'f'}`;
                                if (!sampleSet.has(id)) {
                                    sampleSet.add(id);
                                    sampleOrder.push({ channelId: chId, reverse: step.reverse || false });
                                }
                            }
                        });
                    });
                });
            return sampleOrder;
        };
    
        const setArtworkImage = url => {
            const el = document.getElementById("artworkImage");
            if (el) {
                el.src = url;
                el.parentElement.style.display = "flex";
            }
        };
    
        const normalizeAudioBuffer = (audioBuffer) => {
            const numChannels = audioBuffer.numberOfChannels;
            let globalMaxAmplitude = 0;
    
            // First pass: Find the global maximum amplitude across all channels
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                const channelMax = Math.max(...channelData.map(sample => Math.abs(sample)));
                if (channelMax > globalMaxAmplitude) {
                    globalMaxAmplitude = channelMax;
                }
            }
    
            // Define target peak amplitude to prevent clipping
            const TARGET_PEAK = 0.95; // 0.95 to leave some headroom
    
            // Calculate normalization factor
            const normalizationFactor = globalMaxAmplitude > 0 ? TARGET_PEAK / globalMaxAmplitude : 1;
    
            // Apply normalization
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                for (let j = 0; j < channelData.length; j++) {
                    channelData[j] *= normalizationFactor;
                }
            }
    
            // console.log(`[Normalization] Applied normalization factor: ${normalizationFactor.toFixed(4)} to audio buffer.`);
            return audioBuffer;
        };
       
       
        // Define maximum cache size
        const MAX_CACHE_SIZE = 100; // Adjust based on available memory and application needs
    
        // Use a Map for sampleCache to maintain insertion order for LRU eviction
        const sampleCache = new Map();
    // Function to generate a unique key for each sample based on URL and processing parameters
const generateSampleKey = (url, params = {}) => {
    let key = url;
    if (params.reversed) key += '_reversed';
    if (params.playbackSpeed && params.playbackSpeed !== 1) key += `_speed_${params.playbackSpeed}`;
    // Include other parameters as needed
    return key;
};

// Helper function to log URL issues
const logUrlIssue = (url, songId, channelId) => {
    console.error(`[URL Issue] URL "${url}" not found in Song: "${songId}", Channel: "${channelId}". Check if the URL is correct or the resource is available.`);
};

// Process song data and channels
const validSongDataUrls = songDataUrls.filter((url) => url.trim() && !url.trim().startsWith("//"));

if (validSongDataUrls.length) {
    if (!window.pako) {
        await (async function loadPako() {
            try {
                const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
                const textContent = await response.text();
                const scriptElement = new DOMParser().parseFromString(textContent, "text/html").querySelector("script");
                if (!scriptElement || !scriptElement.textContent.includes("pako")) {
                    throw new Error("Pako library not found.");
                }
                document.head.append(
                    Object.assign(document.createElement("script"), { textContent: scriptElement.textContent })
                );
                console.log("[Initialization] Pako library loaded successfully.");
            } catch (error) {
                console.error("[Initialization] Error loading Pako:", error);
            }
        })();
    }
    const songDataArray = await Promise.all(
        validSongDataUrls.map(async (url, index) => {
            try {
                const data = await fetchAndProcessSongData(url);
                return { data, index };
            } catch (error) {
                console.error(`[Initialization] Failed to fetch/process ${url}:`, error);
                return null;
            }
        })
    ).then(dataArray => {
        const validDataArray = dataArray.filter(Boolean);
        if (!validDataArray.length) throw new Error("[Initialization] No valid data.");
        return validDataArray;
    });

    const originalSongs = songDataArray
        .sort((a, b) => a.index - b.index)
        .map(({ data, index }) => {
            const {
                projectName = "The Infinite Ordinal",
                artistName = "melophonic",
                projectBPM = 120,
                projectSequences = {},
                channelURLs = [],
                channelVolume = [],
                channelPlaybackSpeed = [],
                trimSettings = {}
            } = data;

            const channels = channelIds.map((id, idx) => {
                const channelSequence = Object.entries(projectSequences).reduce((acc, [sequenceName, sequenceData]) => {
                    const channelData = sequenceData[`ch${idx}`];
                    if (channelData) acc.push({ sequenceName, steps: channelData.steps });
                    return acc;
                }, []);
                const metadata = {
                    volume: channelVolume[idx] ?? 1,
                    playbackSpeed: channelPlaybackSpeed[idx] ?? 1,
                    trimStartTime_Percentage: trimSettings[idx]?.start || 0,
                    trimEndTime_Percentage: trimSettings[idx]?.end || 100,
                    requiresReversal: channelSequence.some(seq => seq.steps.some(step => typeof step === "object" && step.reverse)),
                    channelSequence,
                    originalBPM: projectBPM
                };
                const sampleId = channelURLs[idx];

                if (!sampleId) {
                    logUrlIssue("URL_not_found", `Song ${index + 1}: ${projectName}`, `Channel ${id}`);
                }

                return { id, url: sampleId || "URL_not_found", metadata };
            });

            return {
                id: `Song ${index + 1}: ${projectName}`,
                artist: artistName,
                bpm: projectBPM,
                totalSequences: Object.keys(projectSequences).length,
                totalChannels: channels.length,
                channels,
                projectSequences
            };
        });

    const allChannels = originalSongs.flatMap(song => song.channels);

    
            function lcg64(seed) {
                let state = seed;
                const a = 6364136223846793005n;
                const c = 1442695040888963407n;
                const m = 18446744073709551616n; // 2^64
                return function() {
                    state = (a * state + c) % m;
                    return Number(state) / Number(m);
                }
            }
    
            const getRandomChannels = (channelsArray, num, prng) => {
                const shuffled = [...channelsArray];
                for (let i = shuffled.length - 1; i > 0; i--) {
                    const j = Math.floor(prng() * (i + 1));
                    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
                }
                return shuffled.slice(0, num);
            };
    
           
     /**
         * Generates a random 16-digit seed string.
         *
         * @returns {string} - A 16-digit random seed.
         */
         function generateRandomSeed() {
            let seed = '';
            for (let i = 0; i < 16; i++) {
                seed += Math.floor(Math.random() * 10).toString();
            }
            return seed;
        }

        /**
         * Generates a list of sequential seeds starting from the initial seed.
         *
         * @param {string} initialSeed - The starting 16-digit seed.
         * @param {number} count - Number of sequential seeds to generate.
         * @returns {string[]} - An array of 16-digit sequential seeds.
         */
        function generateSequentialSeeds(initialSeed, count = 100) {
            const seeds = [initialSeed];
            let seedNumber;
            try {
                seedNumber = BigInt(initialSeed);
            } catch (error) {
                console.error(`[Seed Generation] Invalid initial seed "${initialSeed}". Defaulting to 0n.`);
                seedNumber = 0n;
            }

            for (let i = 1; i < count; i++) {
                seedNumber += 1n;
                let newSeed = seedNumber.toString();
                if (newSeed.length < 16) {
                    newSeed = newSeed.padStart(16, '0');
                } else if (newSeed.length > 16) {
                    newSeed = newSeed.slice(-16); // Keep the last 16 digits
                }
                seeds.push(newSeed);
            }
            return seeds;
        }

      /**
 * Initializes the seedList based on user-provided seeds.
 * - If no seeds are provided, generate a random seed and create 100 sequential seeds.
 * - If one seed is provided, generate 99 additional sequential seeds from it.
 * - If multiple seeds are provided, use them as-is.
 */
function initializeSeedList() {
    if (window.globalData.seedList && window.globalData.seedList.length > 1) {
        // Multiple seeds provided; use as-is.
        console.log(`[Seed Initialization] Using user-provided seedList with ${window.globalData.seedList.length} seeds.`);
    } else if (window.globalData.seedList && window.globalData.seedList.length === 1) {
        // Single seed provided; generate 99 additional sequential seeds.
        const initialSeed = window.globalData.seedList[0];
        const additionalSeeds = generateSequentialSeeds(initialSeed, 100).slice(1); // Exclude the initial seed
        window.globalData.seedList = window.globalData.seedList.concat(additionalSeeds);
        console.log(`[Seed Initialization] Single seed provided. Generated 99 additional sequential seeds from "${initialSeed}". Total seeds: ${window.globalData.seedList.length}.`);
    } else {
        // No seeds provided; generate a random seed and 99 additional sequential seeds.
        const randomSeed = generateRandomSeed();
        window.globalData.seedList = generateSequentialSeeds(randomSeed, 100);
        // TEMPORARY: create 10 sequential seeds for testing
        // window.globalData.seedList = generateSequentialSeeds(randomSeed, 10);

        console.log(`[Seed Initialization] No user-provided seeds. Generated random seed "${randomSeed}" and created ${window.globalData.seedList.length} sequential seeds.`);
    }
}

// **Seed List Initialization (Moved Outside the 'if' Block)**
initializeSeedList();


/**
 * Checks if two BPMs are harmonically related by exact multiples or divisors.
 *
 * @param {number} loopBPM - The BPM of the looped sample.
 * @param {number} songBPM - The BPM of the song.
 * @param {number} [epsilon=0.01] - Tolerance for floating-point comparisons.
 * @returns {boolean} - True if harmonically related, else false.
 */
 const isHarmonic = (loopBPM, songBPM, epsilon = 0.01) => {
    return (
        Math.abs(loopBPM - songBPM) < epsilon ||                // Exact match
        Math.abs(loopBPM - songBPM * 2) < epsilon ||            // Exact double
        Math.abs(loopBPM - songBPM / 2) < epsilon               // Exact half
    );
};


async function generateMixBySeed(seedString, remixNumber) {
    // [loopedSamplesDebug] Starting mix generation
    console.log(`[loopedSamplesDebug] Generating mix #${remixNumber} with seed "${seedString}"`);
    
    const bpmOptions = [15, 30, 60, 70, 75, 80, 90, 92.5, 100, 105, 120, 140, 150, 160, 180, 185, 210, 225, 240, 280, 300, 320];
    const newSongs = [];

    // Initialize base seed with error handling
    let baseSeed;
    try {
        baseSeed = BigInt(seedString);
        console.log(`[loopedSamplesDebug] Parsed seed string "${seedString}" to BigInt: ${baseSeed}`);
    } catch (error) {
        console.error(`[loopedSamplesDebug] Invalid seed string: "${seedString}". Using base seed 0.`);
        baseSeed = 0n;
    }

    const currentSeed = baseSeed || 1n;

    // Function to derive BPM from a seed using PRNG
    const getBPMFromSeed = (seed) => {
        const prng = lcg64(seed);
        return bpmOptions[Math.floor(prng() * bpmOptions.length)];
    };

    const prng = lcg64(currentSeed);
    const selectedBPM = getBPMFromSeed(currentSeed);
    console.log(`[loopedSamplesDebug] Selected BPM based on seed ${currentSeed}: ${selectedBPM}`);

    // **Filter allChannels to exclude loops whose BPM doesn't match the selectedBPM or is not harmonic**
    const filteredChannels = allChannels.filter(channel => {
        // Extract the sample ID from the channel's URL
        const sampleId = channel.url.split('/').pop(); // Assumes URL is in the format "/content/{sampleId}"
        console.log(`[loopedSamplesDebug] Processing Channel ID ${channel.id} with Sample ID ${sampleId}`);
        
        const loopInfo = globalData.getLoopSampleInfo(sampleId);
        
        if (loopInfo) {
            // This channel is a loop with its own BPM
            if (isHarmonic(loopInfo.bpm, selectedBPM)) {
                console.log(`[loopedSamplesDebug] Including loop sample with Sample ID ${sampleId} and BPM ${loopInfo.bpm} as it is harmonically related to Song BPM ${selectedBPM}`);
                return true; // Include the loop
            } else {
                console.log(`[loopedSamplesDebug] Excluding loop sample with Sample ID ${sampleId} due to BPM mismatch (Loop BPM: ${loopInfo.bpm}, Song BPM: ${selectedBPM})`);
                return false; // Exclude the loop
            }
        } else {
            // Not a loop, include it
            console.log(`[loopedSamplesDebug] Including non-loop sample from Channel ID ${channel.id}`);
            return true;
        }
    });

    console.log(`[loopedSamplesDebug] Total channels after loop filtering: ${filteredChannels.length}`);

    // **Select random channels from filteredChannels**
    const randomChannels = getRandomChannels(filteredChannels, 24, prng);
    console.log(`[loopedSamplesDebug] Selected ${randomChannels.length} random channels for the mix.`);

    // Activation points and sequences (Now, all channels will be activated at sequence 1)
    const activationPoints = [
        { startSeq: 1, count: randomChannels.length } // Assigning all selected channels to sequence 1
    ];

    console.log(`[loopedSamplesDebug] Defined activation points:`, activationPoints);

    // Adjust counts proportionally to sum to the number of random channels
    const totalOriginalCounts = activationPoints.reduce((sum, { count }) => sum + count, 0);

    let totalAdjustedCounts = 0;
    const adjustedActivationPoints = activationPoints.map(({ startSeq, count }) => {
        const adjustedCount = Math.round((count / totalOriginalCounts) * randomChannels.length);
        totalAdjustedCounts += adjustedCount;
        return { startSeq, count: adjustedCount };
    });

    // Adjust counts to make total counts equal to randomChannels.length
    let difference = randomChannels.length - totalAdjustedCounts;
    if (difference !== 0) {
        // Adjust counts to compensate for rounding errors
        for (let i = 0; Math.abs(difference) > 0; i = (i + 1) % adjustedActivationPoints.length) {
            if (difference > 0) {
                adjustedActivationPoints[i].count++;
                difference--;
            } else if (adjustedActivationPoints[i].count > 0) {
                adjustedActivationPoints[i].count--;
                difference++;
            }
        }
    }

    console.log(`[loopedSamplesDebug] Adjusted activation points:`, adjustedActivationPoints);

    // Assign activation sequences to channels
    let channelIndex = 0;
    const channelsWithActivation = adjustedActivationPoints.flatMap(({ startSeq, count }) => {
        const activationChannels = [];
        for (let i = 0; i < count; i++) {
            const channel = randomChannels[channelIndex];
            channelIndex++;
            if (channel) {
                const clonedChannel = { ...channel };
                clonedChannel.activationSeq = startSeq;
                console.log(`[loopedSamplesDebug] Channel ID ${clonedChannel.id} assigned to activation sequence starting at ${startSeq}.`);
                activationChannels.push({ channel: clonedChannel, activationSeq: startSeq });
            }
        }
        return activationChannels;
    });

    console.log(`[loopedSamplesDebug] Total channels with activation: ${channelsWithActivation.length}`);

    // Collect unique sequence names from channels
    const sequenceSet = new Set(
        channelsWithActivation.flatMap(({ channel }) =>
            channel.metadata.channelSequence?.map(seq => seq.sequenceName) || []
        )
    );

    console.log(`[loopedSamplesDebug] Unique sequence names collected from channels:`, Array.from(sequenceSet));

    // Sort sequences numerically based on their suffix
    let sequences = [...sequenceSet].sort((a, b) =>
        (parseInt(a.replace('Sequence', '')) || 0) - (parseInt(b.replace('Sequence', '')) || 0)
    );

    console.log(`[loopedSamplesDebug] Sorted sequences:`, sequences);

    // SEQUENCE COUNT LIMIT: Limit the number of sequences here
    sequences = sequences.slice(0, 48);
    console.log(`[loopedSamplesDebug] Limited sequences to first 48:`, sequences);

    // Initialize the new song object with remix numbering
    const newSong = {
        id: `Remix ${remixNumber}`, // Assigning Remix number as ID
        projectName: `Remix ${remixNumber}`, // Assigning Remix number as Project Name
        artist: `melophonic`,
        bpm: selectedBPM,
        totalSequences: sequences.length,
        totalChannels: channelsWithActivation.length,
        channels: [],
        projectSequences: Object.fromEntries(sequences.map(seq => [seq, {}])),
        seed: seedString,
    };

    console.log(`[loopedSamplesDebug] Initialized new song object:`, newSong);

    // Initialize effects context for the song
    const effectsContext = {
        harmonyChannelsAdded: 0,
        maxHarmonyChannels: window.EffectsModule?.effectsConfig?.harmonize?.maxHarmonyChannels || 2,
        totalGain: 0,
        maxTotalGain: 1,
        channelLayers: {} // Track layers per channel
    };

    await Promise.all(channelsWithActivation.map(async ({ channel, activationSeq }, index) => {
        const chId = `ch${index}`;
        const newChannel = {
            id: chId,
            url: channel.url,
            metadata: {
                ...channel.metadata,
                originalBPM: newSong.bpm,
                activationSeq, // Track the activation sequence for this channel
            }
        };

        // Apply effects and other initializations for the channel
        await applyEffects(newChannel, index, newSong, activationSeq, newSong.bpm, effectsContext, prng);
        newSong.channels.push(newChannel);

        // Adjust and map sequences based on the activation sequence
        channel.metadata.channelSequence?.forEach(seqData => {
            if (newSong.projectSequences[seqData.sequenceName]) {
                // Calculate the offset to skip earlier sequences
                const offset = (activationSeq - 1) * 63; // 63 steps per sequence

                // Filter out the steps that are earlier than the activation sequence
                const validSteps = seqData.steps.filter(step => step >= offset);

                // Adjust the sequence steps so that the new start is at step 1
                const adjustedSteps = validSteps.map(step => step - offset);

                // Map the adjusted sequence to the channel in the new song
                newSong.projectSequences[seqData.sequenceName] = {
                    ...newSong.projectSequences[seqData.sequenceName],
                    [chId]: { steps: adjustedSteps }
                };
            }
        });
    }));

    // Log the final projectSequences mapping
    console.log(`[loopedSamplesDebug] Final projectSequences mapping:`, newSong.projectSequences);

    // Add the new song to the songs list
    newSongs.push(newSong);
    console.log(`[loopedSamplesDebug] New song added to the songs list.`);

    return newSongs;
}




/**
 * Generates song mixes based on a list of seeds and assigns sequential remix numbers.
 *
 * @param {string[]} seedList - The list of seed strings for PRNG.
 * @returns {Promise<Array>} - A promise that resolves to an array of generated songs.
 */
async function generateMixesForSeedList(seedList) {
    const newSongs = [];

    for (let i = 0; i < seedList.length; i++) {
        const seedString = seedList[i];
        const remixNumber = i + 1; // Remix numbers start at 1
        const songs = await generateMixBySeed(seedString, remixNumber);
        newSongs.push(...songs);
    }

    return newSongs;
}

// **Proceed with Mix Generation**
const generatedSongs = await generateMixesForSeedList(window.globalData.seedList);
console.log(`[Mix Generation] Generated ${generatedSongs.length} songs based on seedList.`);

// Assign songs to globalData once
if (!globalData.initialized) {
    Object.assign(globalData, {
        songsArray: generatedSongs,
        songsByBPM: globalData.songsByBPM || {},
        currentSongIndex: 0,
        currentSequenceIndex: 0,
        initialSampleOrder: generatedSongs.length ? prepareInitialSampleOrder(generatedSongs[0]) : null,
        isSingleSong: generatedSongs.length === 1,
        isMultipleSongs: generatedSongs.length > 1,
        initialized: true
    });
}

// Initialize GainNodes for all generated songs once
globalData.songsArray.forEach(song => {
    GainNodeHelper.createGainNodesForSong(song);
});

// Set artwork image if applicable
if (globalData.isArtworkCover && artworkUrl.length) setArtworkImage(artworkUrl[0]);

// Dispatch data loading completion event
document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
    detail: {
        success: true,
        totalSongs: globalData.songsArray.length,
        songs: globalData.songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
    }
}));

// Expose generateMixBySeed to the global scope if needed
window.generateMixBySeed = generateMixBySeed;
        }
        
    
    })();
    

</script>




<!-- audioProcessingAndManagement -->
<script>
    (async () => {
        // Initialize or retrieve the globalData object
        const globalData = window.globalData || (window.globalData = {});

        // Initialize or retrieve the AudioContext
        const audioContext = globalData.audioContext || (globalData.audioContext = new (window.AudioContext || window.webkitAudioContext)());

        /**
         * Converts a base64 string to an ArrayBuffer.
         *
         * @param {string} base64 - The base64 encoded string.
         * @returns {ArrayBuffer|null} - The resulting ArrayBuffer or null if conversion fails.
         */
        const base64ToArrayBuffer = (base64) => {
            try {
                // Validate base64 string before conversion
                if (!isValidBase64(base64)) {
                    throw new Error("Invalid base64 string.");
                }
                // Decode base64 to binary string
                const binaryString = atob(base64);
                // Create a Uint8Array from the binary string
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                return bytes.buffer;
            } catch (error) {
                console.error(`[base64ToArrayBuffer] Error converting base64 to ArrayBuffer: ${error.message}`);
                return null;
            }
        };

        /**
         * Pads a base64 string with '=' characters to make its length a multiple of 4.
         *
         * @param {string} str - The base64 string to pad.
         * @returns {string} - The padded base64 string.
         */
        const padBase64 = (str) => {
            const paddingNeeded = (4 - (str.length % 4)) % 4;
            return str + '='.repeat(paddingNeeded);
        };

        /**
         * Extracts base64 data from JSON or HTML content, including custom HTML tags.
         *
         * @param {string|Object} data - The input data (JSON object or HTML string).
         * @param {string} type - The type of data ("json" or "html").
         * @returns {string|null} - The extracted base64 string or null if not found.
         */
        const extractBase64 = (data, type) => {
            if (type === "json" && data.audioData) {
                const match = data.audioData.match(/base64,([A-Za-z0-9+/=]+)/);
                if (match) {
                    console.log(`[extractBase64] Found base64 data in JSON audioData. Length: ${match[1].length}`);
                    return match[1];
                }
                console.warn("[extractBase64] No base64 data found in JSON audioData.");
                return null;
            }

            if (type === "html") {
                try {
                    const parser = new DOMParser();
                    const doc = parser.parseFromString(data, "text/html");

                    // 1. Extract from all <source> tags with data:audio/
                    const sourceTags = doc.querySelectorAll('source[src^="data:audio/"]');
                    for (const source of sourceTags) {
                        const src = source.getAttribute('src');
                        if (!src || !src.includes('base64,')) continue;

                        // Split at 'base64,' and take the rest
                        let base64Str = src.split('base64,')[1];
                        if (!base64Str) continue;

                        // Remove all whitespace (including line breaks)
                        base64Str = base64Str.replace(/\s+/g, '');

                        // Pad the base64 string if necessary
                        base64Str = padBase64(base64Str);

                        console.log(`[extractBase64] Extracted base64 string from <source> tag. Length: ${base64Str.length}`);

                        if (isValidBase64(base64Str)) {
                            console.log(`[extractBase64] Valid base64 string found in <source> tag.`);
                            return base64Str;
                        } else {
                            console.warn(`[extractBase64] Invalid base64 string in <source> tag.`);
                            console.log(`[extractBase64] Base64 Data Snippet: "${base64Str.substring(0, 30)}..."`);
                        }
                    }

                    // 2. Extract from all <audio> tags with nested <source> tags
                    const audioTags = doc.querySelectorAll('audio');
                    for (const audio of audioTags) {
                        const source = audio.querySelector('source[src^="data:audio/"]');
                        if (source) {
                            const src = source.getAttribute('src');
                            if (!src || !src.includes('base64,')) continue;

                            let base64Str = src.split('base64,')[1];
                            if (!base64Str) continue;

                            base64Str = base64Str.replace(/\s+/g, '');
                            base64Str = padBase64(base64Str);

                            console.log(`[extractBase64] Extracted base64 string from <audio> tag's <source>. Length: ${base64Str.length}`);

                            if (isValidBase64(base64Str)) {
                                console.log(`[extractBase64] Valid base64 string found in <audio> tag's <source>.`);
                                return base64Str;
                            } else {
                                console.warn(`[extractBase64] Invalid base64 string in <audio> tag's <source>.`);
                                console.log(`[extractBase64] Base64 Data Snippet: "${base64Str.substring(0, 30)}..."`);
                            }
                        }
                    }

                    // 3. Extract from any element with src starting with data:audio/
                    const customAudioElements = doc.querySelectorAll('*[src^="data:audio/"]');
                    for (const elem of customAudioElements) {
                        const src = elem.getAttribute('src');
                        if (!src || !src.includes('base64,')) continue;

                        let base64Str = src.split('base64,')[1];
                        if (!base64Str) continue;

                        base64Str = base64Str.replace(/\s+/g, '');
                        base64Str = padBase64(base64Str);

                        console.log(`[extractBase64] Extracted base64 string from element with src. Length: ${base64Str.length}`);

                        if (isValidBase64(base64Str)) {
                            console.log(`[extractBase64] Valid base64 string found in element with src.`);
                            return base64Str;
                        } else {
                            console.warn(`[extractBase64] Invalid base64 string in element with src.`);
                            console.log(`[extractBase64] Base64 Data Snippet: "${base64Str.substring(0, 30)}..."`);
                        }
                    }

                    // 4. Extract from custom tags like <Audional_Base64_Sample_Text>
                    const customTags = doc.querySelectorAll('Audional_Base64_Sample_Text'); // Adjust if tag name differs
                    for (const customTag of customTags) {
                        const audioElements = customTag.querySelectorAll('audio, source');
                        for (const audioElem of audioElements) {
                            const src = audioElem.getAttribute('src');
                            if (!src || !src.includes('base64,')) continue;

                            let base64Str = src.split('base64,')[1];
                            if (!base64Str) continue;

                            base64Str = base64Str.replace(/\s+/g, '');
                            base64Str = padBase64(base64Str);

                            console.log(`[extractBase64] Extracted base64 string from audio element within custom tag. Length: ${base64Str.length}`);

                            if (isValidBase64(base64Str)) {
                                console.log(`[extractBase64] Valid base64 string found in audio element within custom tag.`);
                                return base64Str;
                            } else {
                                console.warn(`[extractBase64] Invalid base64 string in audio element within custom tag.`);
                                console.log(`[extractBase64] Base64 Data Snippet: "${base64Str.substring(0, 30)}..."`);
                            }
                        }
                    }

                    // 5. As a last resort, use regex to find any data:audio/ base64 strings
                    const htmlString = data.toString();
                    const regex = /data:audio\/[a-zA-Z0-9]+;base64,([A-Za-z0-9+/=]+)/g;
                    let match;
                    while ((match = regex.exec(htmlString)) !== null) {
                        let base64Str = match[1].replace(/\s+/g, '');
                        base64Str = padBase64(base64Str);

                        console.log(`[extractBase64] Extracted base64 string using regex. Length: ${base64Str.length}`);

                        if (isValidBase64(base64Str)) {
                            console.log(`[extractBase64] Valid base64 string found using regex.`);
                            return base64Str;
                        } else {
                            // console.warn(`[extractBase64] Invalid base64 string found using regex.`);
                            console.log(`[extractBase64] Base64 Data Snippet: "${base64Str.substring(0, 30)}..."`);
                        }
                    }

                    // console.warn("[extractBase64] No valid base64 data found in HTML.");
                    return null;
                } catch (error) {
                    // console.error(`[extractBase64] Failed to parse HTML: ${error.message}`);
                    return null;
                }
            }
        };

        /**
         * Validates whether a string is a valid base64 encoded string.
         *
         * @param {string} str - The string to validate.
         * @returns {boolean} - True if valid base64, false otherwise.
         */
        const isValidBase64 = (str) => {
            const cleaned = str.replace(/\s+/g, "");
            // Base64 strings should have a length that's a multiple of 4
            if (cleaned.length % 4 !== 0) {
                // console.warn(`[isValidBase64] Base64 string length is not a multiple of 4. Length: ${cleaned.length}`);
                return false;
            }
            // Check for valid base64 characters
            const isValid = /^[A-Za-z0-9+/]+={0,2}$/.test(cleaned);
            if (!isValid) {
                // console.warn(`[isValidBase64] Base64 string contains invalid characters.`);
            }
            return isValid;
        };

        /**
         * Decodes audio data based on content type.
         *
         * @param {Response} response - The fetch response object.
         * @param {string} contentType - The Content-Type of the response.
         * @param {string} url - The URL being fetched.
         * @param {string} songId - The ID of the song.
         * @param {string} channelId - The ID of the channel.
         * @returns {Promise<AudioBuffer|null>} - The decoded AudioBuffer or null if decoding failed.
         */
        const decodeAudioData = async (response, contentType, url, songId, channelId) => {
            const cache = globalData.audioFetchCache || (globalData.audioFetchCache = new Map());

            // Check if the audio data is already cached
            if (cache.has(url)) {
                // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Using cached AudioBuffer for URL: "${url}".`);
                return cache.get(url);
            }

            try {
                let decodedBuffer;

                // Handle data URI
                if (url.startsWith('data:audio/')) {
                    const base64Data = url.split(',')[1];
                    if (!base64Data) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] No base64 data found in data URI for URL: "${url}".`);
                        return null;
                    }

                    // console.log(`[decodeAudioData] Extracted base64 data from data URI. Length: ${base64Data.length}`);

                    // Remove all whitespace and pad the base64 string
                    let cleanedBase64 = base64Data.replace(/\s+/g, '');
                    cleanedBase64 = padBase64(cleanedBase64);

                    if (!isValidBase64(cleanedBase64)) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid base64 data in data URI for URL: "${url}".`);
                        // console.log(`[decodeAudioData] Base64 Data Snippet: "${cleanedBase64.substring(0, 30)}..."`);
                        return null;
                    }

                    const arrayBuffer = base64ToArrayBuffer(cleanedBase64);
                    if (!arrayBuffer) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Failed to convert base64 to ArrayBuffer for URL: "${url}".`);
                        return null;
                    }
                    decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                else if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                else if (/application\/json/.test(contentType)) {
                    const jsonData = await response.json();
                    const base64Data = extractBase64(jsonData, "json");
                    if (!base64Data || !isValidBase64(base64Data)) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid or missing base64 data in JSON for URL: "${url}".`);
                        if (base64Data) {
                            // console.log(`[decodeAudioData] Base64 Data Snippet: "${base64Data.substring(0, 30)}..." Length: ${base64Data.length}`);
                        }
                        return null;
                    }
                    // console.log(`[decodeAudioData] Extracted base64 data from JSON. Length: ${base64Data.length}`);
                    const arrayBuffer = base64ToArrayBuffer(base64Data);
                    if (!arrayBuffer) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Failed to convert base64 to ArrayBuffer for JSON URL: "${url}".`);
                        return null;
                    }
                    decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                else if (/text\/html/.test(contentType)) {
                    const htmlData = await response.text();
                    const base64Data = extractBase64(htmlData, "html");
                    if (!base64Data || !isValidBase64(base64Data)) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid or missing base64 data in HTML for URL: "${url}".`);
                        if (base64Data) {
                            // console.log(`[decodeAudioData] Base64 Data Snippet: "${base64Data.substring(0, 30)}..." Length: ${base64Data.length}`);
                        }
                        return null;
                    }
                    // console.log(`[decodeAudioData] Extracted base64 data from HTML. Length: ${base64Data.length}`);
                    const arrayBuffer = base64ToArrayBuffer(base64Data);
                    if (!arrayBuffer) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Failed to convert base64 to ArrayBuffer for HTML URL: "${url}".`);
                        return null;
                    }
                    decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                else {
                    if (!/audio\//.test(contentType)) {
                        // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Unsupported content type: "${contentType}" for URL: "${url}".`);
                        return null;
                    }
                    const arrayBuffer = await response.arrayBuffer();
                    decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }

                // Cache the decoded audio buffer
                cache.set(url, decodedBuffer);
                // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] AudioBuffer decoded and cached for URL: "${url}".`);

                return decodedBuffer;
            } catch (error) {
                // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoding error for URL: "${url}" - ${error.message}`);
                return null;
            }
        };

        /**
         * Normalizes an AudioBuffer to a specified maximum volume.
         *
         * @param {AudioBuffer} audioBuffer - The AudioBuffer to normalize.
         * @param {number} maxVolume - The target maximum volume (default is 0.5).
         * @returns {AudioBuffer} - The normalized AudioBuffer.
         */
        const normalizeAudioBuffer = (audioBuffer, maxVolume = 0.5) => {
            let maxAmplitude = 0;

            // Find the global maximum amplitude across all channels
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const channelData = audioBuffer.getChannelData(channel);
                for (const sample of channelData) {
                    const absSample = Math.abs(sample);
                    if (absSample > maxAmplitude) {
                        maxAmplitude = absSample;
                    }
                }
            }

            // Calculate the normalization factor
            const normalizationFactor = maxAmplitude > 0 ? maxVolume / maxAmplitude : 1;

            // Apply normalization if necessary
            if (normalizationFactor !== 1) {
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        channelData[i] *= normalizationFactor;
                    }
                }
                // Removed normalization log to reduce verbosity
            }

            return audioBuffer;
        };

        /**
         * Reverses the audio data in a Float32Array.
         *
         * @param {Float32Array} audioData - The audio data to reverse.
         * @returns {Float32Array} - The reversed audio data.
         */
        const reverseAudioData = (audioData) => {
            const reversedData = new Float32Array(audioData.length);
            for (let i = 0, len = audioData.length; i < len; i++) {
                reversedData[i] = audioData[len - i - 1];
            }
            return reversedData;
        };

        /**
         * Extracts the file name from a URL.
         *
         * @param {string} url - The URL string.
         * @returns {string} - The extracted file name or "Unknown" if not found.
         */
        const getFileNameFromURL = (url) => {
            return url.split("/").pop() || "Unknown";
        };

        /**
         * Processes an individual audio channel by fetching, decoding, trimming, and optionally reversing the audio data.
         *
         * @param {Object} song - The song object containing channel information.
         * @param {Object} channel - The channel object containing metadata and URL.
         * @param {Array} processedChannels - An array to store information about processed channels.
         */
        const processChannel = async (song, channel, processedChannels) => {
            const { id: songId } = song;
            const { id: channelId, url: channelURL, metadata: { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } } = channel;

            try {
                // Fetch the audio data from the channel URL
                const response = await fetch(channelURL);
                if (!response.ok) {
                    console.error(`[ProcessChannel][Song: "${songId}"] Fetch failed for URL: "${channelURL}" - Status: ${response.status} ${response.statusText}. Skipping Channel ID: "${channelId}".`);
                    return;
                }

                const contentType = response.headers.get("Content-Type") || "";

                // Decode the audio data based on the content type
                const audioBuffer = await decodeAudioData(response, contentType, channelURL, songId, channelId);
                if (!audioBuffer) {
                    console.error(`[ProcessChannel][Song: "${songId}"] Decoding failed for Channel ID: "${channelId}". Skipping.`);
                    return;
                }

                // Validate trim percentages
                if (trimEndTime_Percentage <= trimStartTime_Percentage) {
                    console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Invalid trim percentages - Start: ${trimStartTime_Percentage}%, End: ${trimEndTime_Percentage}%. Skipping.`);
                    return;
                }

                // Calculate sample indices for trimming
                const startSample = Math.floor(trimStartTime_Percentage / 100 * audioBuffer.duration * audioBuffer.sampleRate);
                const endSample = Math.floor(trimEndTime_Percentage / 100 * audioBuffer.duration * audioBuffer.sampleRate);
                const trimmedLength = endSample - startSample;

                if (trimmedLength <= 0) {
                    console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Non-positive trimmed length: ${trimmedLength} samples. Skipping.`);
                    return;
                }

                // Create a new AudioBuffer for the trimmed audio
                const trimmedBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
                for (let channelIndex = 0; channelIndex < audioBuffer.numberOfChannels; channelIndex++) {
                    trimmedBuffer.getChannelData(channelIndex).set(audioBuffer.getChannelData(channelIndex).subarray(startSample, endSample));
                }

                // Normalize the trimmed AudioBuffer
                const normalizedBuffer = normalizeAudioBuffer(trimmedBuffer, 0.5);

                // Initialize audioBuffers and reverseAudioBuffers in globalData if not present
                globalData.audioBuffers = globalData.audioBuffers || {};
                globalData.reverseAudioBuffers = globalData.reverseAudioBuffers || {};
                globalData.audioBuffers[songId] = globalData.audioBuffers[songId] || {};
                globalData.reverseAudioBuffers[songId] = globalData.reverseAudioBuffers[songId] || {};

                // Store the normalized AudioBuffer
                globalData.audioBuffers[songId][channelId] = normalizedBuffer;

                // If reversal is required, create and store the reversed AudioBuffer
                if (requiresReversal) {
                    try {
                        const reversedBuffer = createReversedAudioBuffer(normalizedBuffer);
                        globalData.reverseAudioBuffers[songId][channelId] = reversedBuffer;
                    } catch (reverseError) {
                        console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Error reversing AudioBuffer: ${reverseError.message}`);
                    }
                }

                /**
                 * Helper function to extract the sample ID from the channel URL.
                 * Assumes that the sample ID is the last segment of the URL path.
                 *
                 * @param {string} url - The channel URL.
                 * @returns {string} - The extracted sample ID.
                 */
                const getSampleIdFromURL = (url) => {
                    try {
                        const urlObj = new URL(url, window.location.origin);
                        const pathname = urlObj.pathname;
                        const lastSegment = pathname.split("/").pop() || "";
                        return lastSegment;
                    } catch (error) {
                        console.error(`[getSampleIdFromURL] Invalid URL: "${url}" - ${error.message}`);
                        return "";
                    }
                };

                // Extract sample ID from the channel URL
                const sampleId = getSampleIdFromURL(channelURL);

                // Check if the sample ID exists in the global loopSampleData array
                const isLoopedSample = window.globalData.loopSampleData.some(sample => sample.id === sampleId);

                if (isLoopedSample) {
                    console.log(`[LoopedSample] Processing looped audio sample ID: "${sampleId}" for Song: "${songId}", Channel: "${channelId}".`);
                }

                // Push processed channel information to the array, including looped sample status
                processedChannels.push({
                    "Song ID": songId,
                    "Channel ID": channelId,
                    "Audio File": getFileNameFromURL(channelURL),
                    "Full Duration (s)": audioBuffer.duration.toFixed(2),
                    "Trimmed Duration (s)": trimmedBuffer.duration.toFixed(2),
                    "Requires Reversal": requiresReversal,
                    "Is Looped Sample": isLoopedSample
                });
            } catch (error) {
                console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Unexpected error: ${error.message}`);
            }
        };

        /**
         * Creates a reversed AudioBuffer from a given AudioBuffer.
         *
         * @param {AudioBuffer} originalBuffer - The original AudioBuffer to reverse.
         * @returns {AudioBuffer} - The reversed AudioBuffer.
         */
        const createReversedAudioBuffer = (originalBuffer) => {
            const reversedBuffer = audioContext.createBuffer(originalBuffer.numberOfChannels, originalBuffer.length, originalBuffer.sampleRate);
            for (let channelIndex = 0; channelIndex < originalBuffer.numberOfChannels; channelIndex++) {
                const originalData = originalBuffer.getChannelData(channelIndex);
                const reversedData = reversedBuffer.getChannelData(channelIndex);
                for (let i = 0; i < originalData.length; i++) {
                    reversedData[i] = originalData[originalData.length - i - 1];
                }
            }
            return normalizeAudioBuffer(reversedBuffer, 0.5);
        };

        /**
         * Displays processed channel information in the console.
         *
         * @param {Array} processedChannels - An array of processed channel information.
         */
        const displayProcessedChannels = (processedChannels) => {
            if (processedChannels.length) {
                console.table(processedChannels);
            } else {
                // console.warn("No audio samples processed.");
            }
        };

        /**
         * Processes the initial sample order by fetching and decoding the necessary audio channels.
         */
        const processInitialSamples = async () => {
            const { songsArray, initialSampleOrder } = globalData;

            if (!songsArray || !songsArray.length) {
                console.error("No songs to process.");
                return;
            }

            if (!initialSampleOrder || !Array.isArray(initialSampleOrder)) {
                console.error("initialSampleOrder is not defined or not an array.");
                return;
            }

            const processedChannels = [];

            // Group initialSampleOrder by songId
            const songsMap = new Map();
            initialSampleOrder.forEach(sampleOrder => {
                if (!songsMap.has(sampleOrder.songId)) {
                    songsMap.set(sampleOrder.songId, []);
                }
                songsMap.get(sampleOrder.songId).push(sampleOrder.channelId);
            });

            // Iterate over each song and process its channels
            for (const [songId, channelIds] of songsMap.entries()) {
                const song = songsArray.find(song => song.id === songId);
                if (!song) {
                    // console.warn(`Song with ID ${songId} not found. Skipping.`);
                    continue;
                }

                const channelProcessingPromises = channelIds.map(channelId => {
                    const channel = song.channels.find(channel => channel.id === channelId);
                    if (channel) {
                        return processChannel(song, channel, processedChannels);
                    } else {
                        // console.warn(`Channel with ID ${channelId} not found in song ${songId}. Skipping.`);
                        return Promise.resolve(null);
                    }
                });

                // Await all channel processing for the current song
                await Promise.all(channelProcessingPromises);

                // Log once per song after all its channels have been processed
                // console.warn(`Processed Song: "${song.id}" with ${processedChannels.length} channels.`);
            }

            // Display all processed channels
            displayProcessedChannels(processedChannels);

            // console.warn("Initial audio buffers ready.");

            // Initialize Master Gain
            const masterGain = audioContext.createGain();
            masterGain.gain.value = 0.7;
            masterGain.connect(audioContext.destination);
            globalData.masterGain = masterGain;

            // console.warn("Master Gain initialized with gain:", masterGain.gain.value);

            // Dispatch event indicating initial audio buffers are ready
            document.dispatchEvent(new CustomEvent("initialAudioBuffersReady", {
                detail: { success: true }
            }));
        };

        /**
         * Initializes the audio processing by handling event listeners and processing sequences.
         */
        const initializeAudioProcessing = async () => {
            try {
                // Resume AudioContext if it is suspended
                if (audioContext.state === "suspended") {
                    await audioContext.resume();
                }

                // Process initial samples
                await processInitialSamples();

                // Background processing for additional audio buffers
                try {
                    const { songsArray, initialSampleOrder } = globalData;

                    if (!songsArray || !songsArray.length) {
                        console.error("No songs to process.");
                        return;
                    }

                    const additionalProcessedChannels = [];

                    // Flatten all channels from all songs
                    const allChannels = songsArray.flatMap(song => song.channels.map(channel => ({ song, channel })));

                    // Create a set of already processed songId-channelId combinations
                    const initialProcessedSet = new Set(initialSampleOrder.map(sample => `${sample.songId}-${sample.channelId}`));

                    // Filter out channels that have already been processed
                    const channelsToProcess = allChannels.filter(({ song, channel }) => !initialProcessedSet.has(`${song.id}-${channel.id}`));

                    const batches = [];

                    // Batch channels into groups of 4 for processing
                    while (channelsToProcess.length) {
                        batches.push(channelsToProcess.splice(0, 4));
                    }

                    // Process each batch sequentially
                    for (const batch of batches) {
                        const batchPromises = batch.map(({ song, channel }) => processChannel(song, channel, additionalProcessedChannels));
                        await Promise.all(batchPromises);
                    }

                    // Display additional processed channels
                    displayProcessedChannels(additionalProcessedChannels);

                    // console.warn("All background audio buffers processed.");

                    // Dispatch event indicating all audio buffers are ready
                    document.dispatchEvent(new CustomEvent("allAudioBuffersReady", {
                        detail: { success: true }
                    }));
                } catch (error) {
                    console.error("Background processing error:", error);
                }
            } catch (error) {
                console.error("Audio processing initialization error:", error);
            }
        };

        /**
         * Event listener for data loading completion to start audio processing.
         */
        document.addEventListener("dataLoadingComplete", initializeAudioProcessing);

        /**
         * Automatically initialize audio processing if songs are already loaded.
         */
        if (globalData.songsArray?.length) {
            initializeAudioProcessing();
        }

        /**
         * Event listener for initial audio buffers ready.
         */
        document.addEventListener("initialAudioBuffersReady", () => {
            // console.warn("Initial buffers ready. Press 'P' to play.");
        });
    })();
</script>


<!-- unifiedMetadataManagement -->
<script>
    // unifiedMetadataManagement.js
    (() => {
    /**
     * Extracts the project name from a song ID using a regular expression.
     *
     * @param {string} songId - The ID of the song.
     * @returns {string} - The extracted project name or "UNKNOWN PROJECT NAME" if not found.
     */
    const extractProjectName = (songId) => {
        const match = songId?.match(/Song\s+\d+:\s+(.+)/);
        return match?.[1]?.trim() || "UNKNOWN PROJECT NAME";
    };

    /**
     * Retrieves the artist name based on the project name from the artist map.
     *
     * @param {string} projectName - The name of the project.
     * @param {Object} artistMap - A mapping of project names to artist names.
     * @param {string} defaultArtist - The default artist name if not found in the map.
     * @returns {string} - The artist name associated with the project or a default value.
     */
    const getArtistName = (projectName, artistMap, defaultArtist) => {
        return artistMap?.[projectName] || defaultArtist || "Unknown Artist Name";
    };

    /**
     * Processes an array of songs to extract and display their metadata.
     *
     * @param {Array} songs - An array of song objects to process.
     */
    const processSongs = (songs) => {
        if (!Array.isArray(songs) || songs.length === 0) {
            // console.warn("No songs data available to process.");
            return;
        }

        // Extract project and artist information for each song
        const processedSongs = extractSongMetadata(songs);

        // Update the metadata content in the DOM
        updateMetadataContent(processedSongs);

        // Log the processed songs' metadata
        logProcessedSongs(processedSongs);
    };

    /**
     * Extracts metadata (track number, project name, artist name) from the songs array.
     *
     * @param {Array} songs - An array of song objects.
     * @returns {Array} - An array of processed song metadata.
     */
    const extractSongMetadata = (songs) => {
        // Retrieve the artist map from globalData or fallback to an empty object
        const artistMap = window.globalData?.projectArtistMap || window.projectArtistMap || {};

        // Map each song to its metadata
        return songs.map((song, index) => ({
            trackNumber: index + 1,
            projectName: extractProjectName(song.id),
            artistName: getArtistName(extractProjectName(song.id), artistMap, song.artist)
        }));
    };

    /**
     * Updates the metadata content in the DOM with the processed song information.
     *
     * @param {Array} processedSongs - An array of processed song metadata.
     */
    const updateMetadataContent = (processedSongs) => {
        const metadataContainer = document.getElementById("metadataContent");
        if (!metadataContainer) {
            // console.warn("Metadata content container (#metadataContent) not found.");
            return;
        }

        // Generate HTML for each song's metadata
        const metadataHTML = processedSongs.map(({ trackNumber, projectName, artistName }) => `
            <div class="metadataItem">
                <h2>${trackNumber}. ${projectName}</h2>
                <p>${artistName}</p>
            </div>
        `).join("");

        // Update the DOM with the generated HTML
        metadataContainer.innerHTML = metadataHTML;
    };

    /**
     * Logs the processed songs' metadata to the console.
     *
     * @param {Array} processedSongs - An array of processed song metadata.
     */
    const logProcessedSongs = (processedSongs) => {
        processedSongs.forEach(({ projectName, artistName }) => {
            // console.log(`Project Name: ${projectName}, Artist Name: ${artistName}`);
        });
    };

  
})();
</script>




<!-- Load Player Scripts AFTER data loading is complete -->
<script>
document.addEventListener("dataLoadingComplete",(e=>{const c=e=>{if(0===e.length)return;const d=e.shift(),t=document.createElement("script");t.src=d,t.async=!1,t.onload=()=>c(e),t.onerror=t=>{console.error(`[Script Loader] Error loading script: ${d}`,t),c(e)},document.body.appendChild(t)};c(["/content/5c03e882ab5a531271b2e93a80d8a9d72cb533c580bec1567020f5cd61595560i0","/content/7b305327f2951d219532ef0cb46b2039b23f2cfd0d8d0e827f3fe1b2b754b5a9i0","/content/8b5b09cfedbc0c6a187816181f8d33f90c5bbd15fc10af47008176effb866a47i0"]),updateSeedDisplay()}));
</script>




<!-- Playback -->
<script>
    /*
    <details>
        <summary> How to Access Global Timing Information</summary>
        <p>The playback engine exposes global timing information through the <code>window.globalData</code> object. Other modules can access the following properties and events to monitor and interact with playback:</p>
        <ul>
            <li><strong>Playback Status:</strong> <code>window.globalData.isPlaying</code> - <em>Boolean</em> indicating if playback is active.</li>
            <li><strong>Current Song Index:</strong> <code>window.globalData.currentSongIndex</code> - <em>Number</em> representing the index of the currently playing song.</li>
            <li><strong>Current Sequence:</strong> <code>window.globalData.currentSequence</code> - <em>Number</em> indicating the currently active sequence.</li>
            <li><strong>Playback Events:</strong>
                <ul>
                    <li><code>'playbackStarted'</code> - Dispatched when playback starts.</li>
                    <li><code>'playbackStopped'</code> - Dispatched when playback stops.</li>
                </ul>
                <em>Use <code>document.addEventListener</code> to listen for these events.</em>
            </li>
            <li><strong>Audio Context Current Time:</strong> <code>window.globalData.audioContext.currentTime</code> - <em>Number</em> representing the current time of the AudioContext for precise timing.</li>
            <li><strong>Playback Control Methods:</strong>
                <ul>
                    <li><code>window.globalData.startPlayback()</code> - Starts playback.</li>
                    <li><code>window.globalData.stopPlayback()</code> - Stops playback.</li>
                    <li><code>window.globalData.togglePlayback()</code> - Toggles playback state.</li>
                    <li><code>window.globalData.resetPlayback()</code> - Resets and restarts playback.</li>
                </ul>
            </li>
        </ul>
        <p><strong>Example Usage:</strong></p>
        <pre><code>

    */

 // playbackEngine.js
(() => {
    // Initialize global data or use existing globalData
    const globalData = window.globalData || (window.globalData = {
        isPlaying: false,
        currentSongIndex: 0,
        songsArray: [],
        audioBuffers: {},
        reverseAudioBuffers: {},
        audioContext: new (window.AudioContext || window.webkitAudioContext)(),
        masterGain: null,
        gainNodes: {},
        isArtworkCover: true,
        isVisualiserCover: false,
        compressor: null,      // Compressor Node
        lowShelfFilter: null,  // Low-Shelf Filter Node
        analyser: null,        // AnalyserNode
        isAudioProcessingInitialized: false, // Flag to prevent re-initialization
        currentSeed: 1n        // Initialize seed as BigInt
    });

    // Initialize the current sequence counter
    globalData.currentSequence = 0;

    const { audioContext } = globalData;
    const scheduleAheadTime = 0.1; // Time in seconds to schedule ahead
    const schedulerInterval = 25;   // Interval in milliseconds for the scheduler

    let playbackInterval = null;
    let sequenceStates = {};

    const missingAudioBuffers = new Set();
    const activeAudioSources = new Set();

    let countdownInterval = null;



/**
 * Function to start playback
 */
 function startPlayback() {
    const { songsArray, currentSongIndex } = globalData;

    // Prevent duplicate calls while playback is starting
    if (globalData.isPlaybackStarting) {
        // console.warn("startPlayback called while playback is already starting. Ignoring duplicate call.");
        return;
    }
    globalData.isPlaybackStarting = true;

    try {
        // Ensure there are songs available
        if (!songsArray.length) {
            console.error("No songs available for playback.");
            globalData.isPlaybackStarting = false;
            return;
        }

        // Get the current song and sequences
        const song = songsArray[currentSongIndex % songsArray.length];
        const projectSequences = song.projectSequences || {};

        const stepDuration = 60 / song.bpm / 4;       // Duration of a single step
        const sequenceDuration = 64 * stepDuration;   // Total duration of a sequence

        // Reset states and logs
        sequenceStates = {};
        missingAudioBuffers.clear();

        console.log(`Starting playback for Song: ${song.id} (${currentSongIndex + 1}/${songsArray.length}) with ${Object.keys(projectSequences).length} sequences.`);
        console.log(`Song BPM: ${song.bpm}`);

        // Initialize sequence states with ordered sequence numbers
        let sequenceStartTimeOffset = 0;
        let orderedSequenceNumber = 1; // Start from 1

        for (const [sequenceId, sequenceData] of Object.entries(projectSequences)) {
            sequenceStates[sequenceId] = {
                sequenceNumber: orderedSequenceNumber, // Assign ordered number
                nextStepIndex: 0,
                nextStepTime: globalData.audioContext.currentTime + sequenceStartTimeOffset,
                stepDuration: stepDuration,
                endTime: globalData.audioContext.currentTime + sequenceStartTimeOffset + sequenceDuration,
                completed: false,
                loggedStart: false // Initialize the loggedStart flag
            };
            sequenceStartTimeOffset += sequenceDuration;
            orderedSequenceNumber++;
        }

        globalData.currentSongId = song.id;

        // **Initialize Audio Processing Chain for the current song**
        initializeAudioProcessingChain();

        // **Prepare gain nodes for the song**
        GainNodeHelper.createGainNodesForSong(song);
        GainNodeHelper.prepareNextSongGainNodes(songsArray[(currentSongIndex + 1) % songsArray.length]);
        globalData.isPlaying = true;

        // Reset current sequence to 1 for the new song
        globalData.currentSequence = 1;

        // **Clear Existing playbackInterval Before Setting a New One**
        if (globalData.playbackInterval) {
            clearInterval(globalData.playbackInterval);
            globalData.playbackInterval = null;
            console.log("Existing playbackInterval cleared.");
        }

        // Reset flags
        globalData.hasCompletedSequences = false;
        globalData.hasProceededToNextSong = false;

        // **Start the playback scheduler**
        globalData.playbackInterval = setInterval(() => scheduleSequences(song), schedulerInterval);

        console.log("Sequences scheduled and playback started.");
        document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));

        // Update Now Playing information
        updateNowPlaying(song);
    } catch (error) {
        console.error("Error during startPlayback:", error);
    } finally {
        globalData.isPlaybackStarting = false;
    }
}

/**
 * Function to stop playback
 */
 function stopPlayback() {
    if (!globalData.isPlaying) {
        console.log("Playback is not in progress.");
        return;
    }

    // Stop and disconnect all active audio nodes
    resetPlayback();
    console.log("Playback stopped.");

    // Dispatch playback stopped event
    document.dispatchEvent(new CustomEvent("playbackStopped", { detail: { success: true } }));

    // Clear Now Playing information
    clearNowPlaying();

    // Clear countdown timer if active
    if (countdownInterval) {
        clearInterval(countdownInterval);
        countdownInterval = null;
        console.log("Countdown timer cleared.");
    }

    // Disconnect the BiquadFilter or any other active audio nodes if necessary
    if (globalData.lowShelfFilter) {
        globalData.compressor.disconnect(globalData.lowShelfFilter);
        globalData.lowShelfFilter.disconnect(globalData.analyser);
        globalData.analyser.disconnect(audioContext.destination);
        console.log("[PlaybackEngine] Disconnected audio nodes.");
    }
}

/**
 * Function to reset playback
 */
function resetPlayback(options = {}) {
    // Clear the playback interval if active
    if (globalData.playbackInterval) {
        clearInterval(globalData.playbackInterval);
        globalData.playbackInterval = null;
        console.log("Playback interval cleared in resetPlayback.");
    }

    // Set playback state to false
    globalData.isPlaying = false;

    // Reset sequence states and other necessary data
    sequenceStates = {};
    missingAudioBuffers.clear();

    // Stop and disconnect all active audio sources
    if (activeAudioSources.size > 0) {
        activeAudioSources.forEach(source => {
            try {
                source.stop();
                source.disconnect();
                console.log(`[PlaybackEngine] Stopped and disconnected audio source: ${source.id || 'unknown'}`);
            } catch (error) {
                console.error("[PlaybackEngine] Error stopping and disconnecting audio source:", error);
            }
        });
        activeAudioSources.clear();
    }

    // Clean up gain nodes if there is a current song
    if (globalData.currentSongId) {
        GainNodeHelper.cleanupGainNodesForSong(globalData.currentSongId);
        console.log("[PlaybackEngine] Cleaned up gain nodes for current song.");
        globalData.currentSongId = null;
    }

    // Clear countdown timer if active
    if (countdownInterval) {
        clearInterval(countdownInterval);
        countdownInterval = null;
        console.log("Countdown timer cleared in resetPlayback.");
    }

    // Execute callback if provided
    if (options.callback) {
        options.callback();
    }
}

    /**
     * Toggle playback function
     */
    globalData.togglePlayback = () => globalData.isPlaying ? stopPlayback() : startPlayback();
    globalData.startPlayback = startPlayback;
    globalData.stopPlayback = stopPlayback;
    globalData.resetPlayback = () => resetPlayback({ callback: startPlayback });

    /**
     * Function to schedule sequences
     */
     function scheduleSequences(song) {
    if (!globalData.isPlaying) {
        // Playback is stopped, do not schedule anything
        return;
    }

    // If sequences have already completed, return
    if (globalData.hasCompletedSequences) {
        return;
    }

    const currentTime = audioContext.currentTime;
    let allSequencesCompleted = true;
    const totalSequences = Object.keys(song.projectSequences).length;

    // Check for empty sequences
    if (totalSequences === 0) {
        // console.warn(`No sequences to schedule for song: ${song.id}. Proceeding to next song.`);
        globalData.hasCompletedSequences = true;
        proceedToNextSong();
        return;
    }

    for (const [sequenceId, sequenceData] of Object.entries(song.projectSequences || {})) {
        const sequenceState = sequenceStates[sequenceId];

        if (sequenceState && !sequenceState.completed) {
            if (currentTime >= sequenceState.endTime) {
                sequenceState.completed = true;
                console.log(`Sequence ${sequenceState.sequenceNumber} has completed.`);
            } else {
                allSequencesCompleted = false;

                // Check if a new sequence is starting
                if (currentTime >= sequenceState.nextStepTime && !sequenceState.loggedStart) {
                    globalData.currentSequence = sequenceState.sequenceNumber;
                    sequenceState.loggedStart = true; // Prevent logging again
                }

                // Schedule steps ahead of time
                while (sequenceState.nextStepTime < currentTime + scheduleAheadTime && globalData.isPlaying) {
                    const { nextStepIndex, nextStepTime, stepDuration } = sequenceState;

                    // Log when a new sequence starts
                    if (nextStepIndex === 0 && !sequenceState.loggedStart) {
                        console.log(`Starting Sequence ${sequenceState.sequenceNumber} at step ${nextStepIndex}.`);
                        sequenceState.loggedStart = true; // Prevent logging again
                    }

                    for (const [channelKey, noteData] of Object.entries(sequenceData)) {
                        const channelIndex = parseInt(channelKey.slice(2), 10);
                        const channel = song.channels[channelIndex];

                        if (!channel) {
                            continue;
                        }

                        const step = noteData.steps?.find(step => 
                            typeof step === 'number' ? step === nextStepIndex : step.index === nextStepIndex
                        );

                        if (step !== undefined) {
                            const reverse = typeof step === 'object' && step.reverse;
                            playNote(song, channel, nextStepTime, reverse);
                        }
                    }

                    // Move to the next step
                    sequenceState.nextStepIndex++;
                    if (sequenceState.nextStepIndex >= 64) {
                        sequenceState.completed = true;
                        console.log(`Sequence ${sequenceState.sequenceNumber} has completed all steps.`);
                        break;
                    }
                    sequenceState.nextStepTime += stepDuration;
                }
            }
        }
    }

    if (allSequencesCompleted) {
        console.log("All sequences have completed.");
        globalData.hasCompletedSequences = true;
        proceedToNextSong();
    }

}




    /**
     * Function to play a note on a specific channel at a given time with fade-in and fade-out to prevent clicks.
     *
     * @param {Object} song - The song object.
     * @param {Object} channel - The channel object.
     * @param {number} time - The scheduled time to play the note.
     * @param {boolean} reverse - Whether to play the note in reverse.
     */
    function playNote(song, channel, time, reverse) {
        // **Check if the channel corresponds to a loop sample**
        const loopInfo = globalData.getLoopSampleInfo(channel.id);
        if (loopInfo) {
            // **This is a loop sample, check if BPM matches**
            if (loopInfo.bpm !== song.bpm) {
                console.log(`Skipping loop sample with ID ${channel.id} due to BPM mismatch (Loop BPM: ${loopInfo.bpm}, Song BPM: ${song.bpm})`);
                // **BPM does not match, do not play this note**
                return;
            }
        }
        const bufferKey = `${song.id}_${channel.id}_${reverse ? "reverse" : "normal"}`;
        const buffer = reverse
            ? globalData.reverseAudioBuffers[song.id]?.[channel.id]
            : globalData.audioBuffers[song.id]?.[channel.id];

        if (!buffer) {
            if (!missingAudioBuffers.has(bufferKey)) {
                missingAudioBuffers.add(bufferKey);
                // console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
            }
            return;
        }

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.playbackRate.value = channel.metadata.playbackSpeed || 1;

        // Create a GainNode for this source to handle fade-in and fade-out
        const sourceGain = audioContext.createGain();
        sourceGain.gain.setValueAtTime(0, time); // Start with gain at 0 for fade-in

        // Connect source -> sourceGain -> channel's GainNode
        source.connect(sourceGain);
        const channelGainNode = globalData.gainNodes?.[song.id]?.[channel.id] || globalData.masterGain;
        sourceGain.connect(channelGainNode);

        // Define fade durations in seconds
        const fadeInDuration = 0.01;  // 10 ms
        const fadeOutDuration = 0.01; // 10 ms

        // Schedule fade-in
        sourceGain.gain.linearRampToValueAtTime(channel.metadata.volume || 1, time + fadeInDuration);

        // Calculate the stop time considering fade-out
        const stopTime = time + buffer.duration / source.playbackRate.value;
        const adjustedStopTime = stopTime - fadeOutDuration;

        // Schedule fade-out
        sourceGain.gain.setValueAtTime(channel.metadata.volume || 1, adjustedStopTime);
        sourceGain.gain.linearRampToValueAtTime(0, stopTime);

        // Start the source
        source.start(time);

        // Schedule stop
        source.stop(stopTime);

        // Track active sources for cleanup
        activeAudioSources.add(source);
        source.onended = () => activeAudioSources.delete(source);
    }


/**
 * Function to proceed to the next song
 */
 function proceedToNextSong() {
    if (!globalData.isPlaying) {
        if (!globalData.hasLoggedPlaybackNotActive) {
            console.log("Playback is not active. Cannot proceed to next song.");
            globalData.hasLoggedPlaybackNotActive = true;
        }
        return;
    }

    // Ensure this function runs only once per song
    if (globalData.hasProceededToNextSong) {
        console.log("Already proceeded to the next song. Exiting proceedToNextSong.");
        return;
    }
    globalData.hasProceededToNextSong = true;
    console.log("Initiating proceedToNextSong.");

    try {
        // Increment the seed
        const previousSeed = globalData.currentSeed;
        globalData.currentSeed = (globalData.currentSeed !== undefined ? BigInt(globalData.currentSeed) : 1n) + 1n;
        console.log(`Seed incremented from ${previousSeed} to ${globalData.currentSeed}.`);

        // Update the song index
        const previousSongIndex = globalData.currentSongIndex;
        globalData.currentSongIndex = (globalData.currentSongIndex + 1) % globalData.songsArray.length;
        console.log(`Song index updated from ${previousSongIndex} to ${globalData.currentSongIndex}.`);

        setTimeout(() => {
            console.log("Timeout reached. Attempting to proceed to the next song.");
            if (globalData.isPlaying) {
                // Retrieve the next song based on the updated index
                const nextSong = globalData.songsArray[globalData.currentSongIndex];
                if (nextSong) {
                    // Assign the updated seed to the next song
                    const previousSeedValue = nextSong.seed;
                    nextSong.seed = globalData.currentSeed.toString();
                    console.log(`Seed for next song updated from ${previousSeedValue} to ${nextSong.seed}.`);

                    // Reset playback and start the next song
                    resetPlayback({
                        callback: () => {
                            console.log("Resetting playback and starting next song.");
                            startPlayback();

                            // Dispatch 'songChanged' event with the new song's details
                            document.dispatchEvent(new CustomEvent("songChanged", { detail: { song: nextSong } }));
                            console.log(`'songChanged' event dispatched for song: ${nextSong.id}.`);
                        },
                    });
                } else {
                    console.error(`Next song not found at index ${globalData.currentSongIndex}.`);
                }
            }
        }, 200);
    } catch (error) {
        console.error(`Error in proceedToNextSong - ${error}`);
    } finally {
        // Do not reset hasProceededToNextSong here; we need to prevent re-entry
        // Reset flags for the next song will happen in startPlayback
        console.log("Finished processing next song.");
    }
}
 

  /**
 * Initializes the audio processing chain with Compressor, Low-Shelf Filter, and AnalyserNode.
 */
function initializeAudioProcessingChain() {
    // Prevent re-initialization if already done
    if (globalData.isAudioProcessingInitialized) {
        console.log("[PlaybackEngine] Audio processing chain already initialized.");
        return;
    }

    // **Initialize Compressor**
    if (!globalData.compressor) {
        globalData.compressor = audioContext.createDynamicsCompressor();
        globalData.compressor.threshold.setValueAtTime(-24, audioContext.currentTime);
        globalData.compressor.knee.setValueAtTime(30, audioContext.currentTime);
        globalData.compressor.ratio.setValueAtTime(12, audioContext.currentTime);
        globalData.compressor.attack.setValueAtTime(0.003, audioContext.currentTime);
        globalData.compressor.release.setValueAtTime(0.25, audioContext.currentTime);

        console.log("[PlaybackEngine] Compressor node initialized.");
    }

    // **Initialize Master Gain**
    if (!globalData.masterGain) {
        globalData.masterGain = audioContext.createGain();
        globalData.masterGain.gain.setValueAtTime(1, audioContext.currentTime); // Set default gain

        // Connect masterGain to compressor
        globalData.masterGain.connect(globalData.compressor);
        console.log("[PlaybackEngine] Master Gain node created and connected to Compressor.");
    }

    // **Initialize Low-Shelf Filter**
    if (!globalData.lowShelfFilter) {
        globalData.lowShelfFilter = audioContext.createBiquadFilter();
        globalData.lowShelfFilter.type = "lowshelf";

        // Clamp frequency and gain values to avoid out-of-range warnings
        const MIN_FREQUENCY = 20;      // Minimum frequency (20 Hz)
        const MAX_FREQUENCY = 22000;   // Maximum frequency (22 kHz)
        const MIN_GAIN = -40;          // Minimum gain in dB (-40 dB)
        const MAX_GAIN = 40;           // Maximum gain in dB (40 dB)

        // Clamp frequency and gain to valid ranges
        const clampedFrequency = Math.min(Math.max(50, MIN_FREQUENCY), MAX_FREQUENCY); // Default 50 Hz cutoff
        const clampedGain = Math.min(Math.max(-6, MIN_GAIN), MAX_GAIN);  // Default -6 dB attenuation

        // Apply clamped values
        globalData.lowShelfFilter.frequency.setValueAtTime(clampedFrequency, audioContext.currentTime);
        globalData.lowShelfFilter.gain.setValueAtTime(clampedGain, audioContext.currentTime);

        // Connect compressor to lowShelfFilter
        globalData.compressor.connect(globalData.lowShelfFilter);
        console.log("[PlaybackEngine] Low-shelf filter initialized and connected to Compressor.");
    }

    // **Initialize AnalyserNode**
    if (!globalData.analyser) {
        globalData.analyser = audioContext.createAnalyser();
        globalData.analyser.fftSize = 2048;
        globalData.analyser.smoothingTimeConstant = 0.8;

        // Connect lowShelfFilter to AnalyserNode
        globalData.lowShelfFilter.connect(globalData.analyser);
        console.log("[PlaybackEngine] Analyser node initialized and connected to Low-Shelf Filter.");

        // Connect AnalyserNode to audio destination
        globalData.analyser.connect(audioContext.destination);
        console.log("[PlaybackEngine] Analyser node connected to AudioContext destination.");
    }

    // **Mark Audio Processing as Initialized**
    globalData.isAudioProcessingInitialized = true;
    console.log("[PlaybackEngine] Audio processing chain fully initialized.");

    // **Set Up Bass Monitoring Loop**
    setupBassMonitoring();
}


    /**
     * Monitors low-frequency (bass) levels in real-time and adjusts the low-shelf filter accordingly.
     */
     function monitorLowFrequencies() {
         // Protective Checks
            if (!globalData.analyser) {
                console.error("[monitorLowFrequencies] AnalyserNode is not initialized in globalData.analyser.");
                return;
            }

            if (!globalData.lowShelfFilter) {
                console.error("[monitorLowFrequencies] lowShelfFilter is not initialized in globalData.lowShelfFilter.");
                return;
            }

            const bufferLength = globalData.analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            globalData.analyser.getByteFrequencyData(dataArray);

            // Calculate average bass level (e.g., frequencies below 250 Hz)
            const bassFrequency = 250;
            const nyquist = audioContext.sampleRate / 2;
            const bassBin = Math.floor(bassFrequency / nyquist * bufferLength);
            const bassLevels = dataArray.slice(0, bassBin);

            // Protective Check: Ensure there are bass levels to process
            if (bassLevels.length === 0) {
                // console.warn("[monitorLowFrequencies] No bass levels found in the current frequency data.");
                return;
            }

            const averageBass = bassLevels.reduce((sum, value) => sum + value, 0) / bassLevels.length;

            // console.log(`[Monitoring] Average Bass Level: ${averageBass.toFixed(2)}`);

            // Define a threshold (e.g., 100 out of 255)
            const bassThreshold = 100;

            if (averageBass > bassThreshold) {
                // Attenuate the low-shelf filter further
                const currentGain = globalData.lowShelfFilter.gain.value;
                const newGain = currentGain - 0.5;
                globalData.lowShelfFilter.gain.setValueAtTime(newGain, audioContext.currentTime);
                // console.log(`[Monitoring] Attenuated low-shelf filter to reduce bass. New Gain: ${newGain}`);
            } else if (averageBass < bassThreshold - 20) {
                // Restore the low-shelf filter gain
                const currentGain = globalData.lowShelfFilter.gain.value;
                const newGain = currentGain + 0.5;
                globalData.lowShelfFilter.gain.setValueAtTime(newGain, audioContext.currentTime);
                // console.log(`[Monitoring] Restored low-shelf filter gain. New Gain: ${newGain}`);
            }
        }

    /**
     * Sets up the monitoring loop using requestAnimationFrame for smoother updates.
     */
    function setupBassMonitoring() {
        // Ensure AnalyserNode is initialized
        if (!globalData.analyser) {
            console.error("[setupBassMonitoring] AnalyserNode is not available. Cannot set up bass monitoring.");
            return;
        }

        // Recursive function to continuously monitor bass frequencies
        function monitoringLoop() {
            monitorLowFrequencies();
            requestAnimationFrame(monitoringLoop);
        }

        // Start the monitoring loop
        monitoringLoop();
        console.log("[setupBassMonitoring] Bass monitoring loop initiated using requestAnimationFrame.");
    }




    /**
     * Function to update Now Playing information
     */
     function updateNowPlaying(song) {
            const nowPlayingContainer = document.getElementById("nowPlayingContainer");
            if (!nowPlayingContainer) {
                return;
            }

            const { projectName, artistName } = getProjectAndArtist(song);
            nowPlayingContainer.querySelector(".songTitle").textContent = projectName;
            nowPlayingContainer.querySelector(".artistName").textContent = artistName;
            nowPlayingContainer.querySelector(".songBPM").textContent = `BPM: ${song.bpm}`;

            // Add this line to update the seed and title
            displaySeedAndBPM(song.seed, song.bpm, song.id);

            initializeCountdown(song);
        }


    /**
     * Function to clear Now Playing information
     */
    function clearNowPlaying() {
        const nowPlayingContainer = document.getElementById("nowPlayingContainer");
        if (!nowPlayingContainer) {
            // console.warn("Now Playing Container not found.");
            return;
        }
        nowPlayingContainer.querySelector(".songTitle").textContent = "No song playing";
        nowPlayingContainer.querySelector(".artistName").textContent = "";
        nowPlayingContainer.querySelector(".songBPM").textContent = "BPM: N/A";
        nowPlayingContainer.querySelector(".timeLeft").textContent = "Time Left: N/A";
    }

    /**
     * Function to initialize countdown timer
     */
    function initializeCountdown(song) {
        // Clear any existing interval
        if (countdownInterval) {
            clearInterval(countdownInterval);
        }

        const nowPlayingContainer = document.getElementById("nowPlayingContainer");
        if (!nowPlayingContainer) return;

        const timeLeftElement = nowPlayingContainer.querySelector(".timeLeft");
        if (!timeLeftElement) return;

        // Calculate total duration in seconds
        const stepDuration = 60 / song.bpm / 4;
        const stepsPerSequence = 64;
        const totalSequences = Object.keys(song.projectSequences).length;
        const totalDuration = stepDuration * stepsPerSequence * totalSequences;

        let timeLeft = totalDuration;

        // Update the display immediately
        updateTimeLeftDisplay(timeLeftElement, timeLeft);

        // Update every second
        countdownInterval = setInterval(() => {
            if (globalData.isPlaying) {
                timeLeft -= 1;
                if (timeLeft <= 0) {
                    timeLeft = 0;
                    clearInterval(countdownInterval);
                }
                updateTimeLeftDisplay(timeLeftElement, timeLeft);
            } else {
                clearInterval(countdownInterval);
            }
        }, 1000);
    }

    /**
     * Function to update the Time Left display
     */
    function updateTimeLeftDisplay(element, timeLeftInSeconds) {
        const minutes = Math.floor(timeLeftInSeconds / 60);
        const seconds = Math.floor(timeLeftInSeconds % 60);
        element.textContent = `Time Left: ${minutes}:${seconds.toString().padStart(2, '0')}`;
    }


  /**
 * Function to proceed to the next song
 */
 // Log the seed list only once when the script initializes
if (!globalData.seedListLogged) {
    console.log("[DEBUGplayback] The initial seedList is: ", globalData.seedList);
    globalData.seedListLogged = true; // Set a flag to ensure this only logs once
}




    /**
     * Function to play an AudioBuffer through the audio processing chain.
     *
     * @param {AudioBuffer} audioBuffer - The audio buffer to play.
     */
    function playAudioBuffer(audioBuffer) {
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(globalData.masterGain); // Connect to Master Gain
        source.start();
        // console.log("[PlaybackEngine] AudioBufferSourceNode started.");

        // Track active sources for cleanup
        activeAudioSources.add(source);
        source.onended = () => activeAudioSources.delete(source);
    }


    /**
     * Function to get project name and artist name from song object
     */
    function getProjectAndArtist(song) {
        return {
            projectName: song.projectName || song.id || "Unknown Project",
            artistName: song.artist || "Unknown Artist"
        };
    }

   


    // Function to initialize playback engine
    globalData.initializePlaybackEngine = () => {
        if (!globalData.songsArray.length) {
            // console.error("No songs available for playback.");
            return;
        }
        // console.log("Playback Engine Initialization Complete.");
    };

    /**
     * Set up artwork cover for playback toggle
     */
    function setupArtworkCover() {
        document.addEventListener("DOMContentLoaded", () => {
            const artworkCover = document.getElementById("artworkCover");
            const artworkImage = document.getElementById("artworkImage");
            const loadingSpinner = document.getElementById("loadingSpinner");

            if (globalData.isArtworkCover && globalData.songsArray.length) {
                // Assuming artworkUrl is part of the first song
                const firstSong = globalData.songsArray[0];
                const artworkUrl = firstSong.artworkUrl || [];

                if (artworkUrl.length) {
                    artworkImage.src = artworkUrl[0];
                    artworkCover.classList.remove("hidden");
                    loadingSpinner.style.display = "none";
                    artworkImage.addEventListener("click", globalData.togglePlayback);
                    // console.log("Artwork cover is set up for playback toggle.");
                } else {
                    // console.warn("No artwork URL provided for the first song.");
                }
            } else {
                // console.warn("Artwork cover is not enabled or no songs available.");
            }
        });
    }

    /**
     * Event listener for initial audio buffers ready
     */
    document.addEventListener("initialAudioBuffersReady", (event) => {
        if (event.detail.success) {
            globalData.initializePlaybackEngine();
            console.log("Initial audio buffers are ready.");
        }
    });

    /**
     * Event listeners for playback started and stopped
     */
    ["playbackStarted", "playbackStopped"].forEach((eventType) => {
        document.addEventListener(eventType, (event) => {
            if (event.detail.success) {
                console.log(`Playback has been successfully ${eventType === "playbackStarted" ? "started" : "stopped"}.`);
            }
        });
    });

    // Initialize artwork cover setup
    setupArtworkCover();

    // Initialize playback engine if audio buffers are already loaded
    if (Object.keys(globalData.audioBuffers).length) {
        globalData.initializePlaybackEngine();
    }


    /**
     * Event listener for song changes.
     */
     document.addEventListener("songChanged", (event) => {
        const { song } = event.detail;
        if (song) {
            updateNowPlaying(song);
            console.log(`Now Playing: ${song.projectName} by ${song.artistName}`);
        }
    });

    /**
     * Initial setup on page load.
     */
    document.addEventListener("DOMContentLoaded", () => {
        // Optionally, initialize the Now Playing display if playback is already started
        if (window.globalData.isPlaying && window.globalData.songsArray.length) {
            const currentSong = window.globalData.songsArray[window.globalData.currentSongIndex];
            updateNowPlaying(currentSong);
        }
    });
})();
</script>

</body>
</html>