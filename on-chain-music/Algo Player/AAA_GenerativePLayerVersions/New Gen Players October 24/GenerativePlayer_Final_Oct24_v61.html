<!--Tracks are not progressing through seeds during normal playback -->
<!-- Could do with some more balances to help with repetitive loops -->


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audionals - Web3 Music Player</title>
    <link rel="stylesheet" href="/content/7a309a161e838ba93740684338b3d97f3c1226c046d8b1137afc2353b4bf16e1i0">

    <style>
        :root {
            --panel-bg-color: #333;
            --panel-text-color: #fff;
            --track-list-panel-bg-color: #444;
            --button-bg-color: #444;
            --button-hover-bg-color: #555;
            --button-active-bg-color: #777;
            --input-bg-color: #555;
            --border-radius: 8px;
            --padding: 10px;
            --box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
            --transition-duration: 0.3s;
            --text-color: #fff;
            --bpm-bg-color: orange;
            --seed-bg-color: green;
            --font-size: 16px;
        }
        /* Common Panel Styles */
        #seed-management-panel,
        #track-list-panel {
            position: fixed;
            background-color: var(--panel-bg-color);
            color: var(--panel-text-color);
            padding: var(--padding);
            border-radius: var(--border-radius);
            z-index: 10000;
            box-shadow: var(--box-shadow);
            transition: all var(--transition-duration) ease;
        }
        /* Specific Panel Positions and Sizes */
        #seed-management-panel {
            top: 10px;
            right: 10px;
            width: 320px;
        }
        #track-list-panel {
            bottom: 10px;
            left: 10px;
            width: 300px;
            background-color: var(--track-list-panel-bg-color);
        }
        .hidden {
            display: none;
        }
        @media (max-width: 600px) {
            #seed-management-panel,
            #track-list-panel {
                width: 90%;
                left: 5%;
                right: 5%;
            }
        }
        /* Canvas Styling */
        #seed-mgmt-canvas {
            width: 100%;
            height: 100px;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: #222;
        }
        /* Previous Seeds Container */
        #previous-seeds-container {
            margin-top: 15px;
        }
        #previous-seeds-container h3,
        #seed-input-section h3 {
            margin-bottom: 5px;
        }
        #previous-seeds-container ul {
            list-style: none;
            padding: 0;
            max-height: 150px;
            overflow-y: auto;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: #444;
        }
        #previous-seeds-container li {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 5px 10px;
            border-bottom: 1px solid #555;
        }
        #previous-seeds-container li:last-child {
            border-bottom: none;
        }
        #previous-seeds-container button {
            background-color: #666;
            color: #fff;
            border: none;
            border-radius: 4px;
            padding: 2px 6px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            margin-left: 10px;
        }
        #previous-seeds-container button:hover {
            background-color: #888;
        }
        /* Seed Input Section */
        #seed-input-section {
            margin-top: 15px;
        }
        #seed-input {
            width: 100%;
            padding: 8px;
            margin-bottom: 5px;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: var(--input-bg-color);
            color: var(--panel-text-color);
            transition: border 0.2s ease;
        }
        #seed-input:focus {
            border: 2px solid #00f;
            outline: none;
        }
        /* Clear Seeds Section */
        #clear-seeds-section {
            margin-top: 15px;
            text-align: center;
        }
        #clear-seeds-button {
            width: 100%;
            padding: 8px;
            background-color: #b22222;
            color: #fff;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            margin-top: 5px;
        }
        #clear-seeds-button:hover {
            background-color: #ff6347;
        }
        /* Button Styles */
        button {
            background-color: var(--button-bg-color);
            color: var(--panel-text-color);
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            padding: 10px 15px;
            margin: 5px;
        }
        button:hover {
            background-color: var(--button-hover-bg-color);
        }
        button:active {
            background-color: var(--button-active-bg-color);
        }
        button:focus {
            outline: 2px solid #00f;
        }
        /* Canvas and Now Playing */
        #loadingSpinner {
            z-index: 1000;
        }
        #artworkCover img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }
        #nowPlayingContainer {
            position: fixed;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(20, 20, 20, 0.95);
            color: #fff;
            padding: 10px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.5);
            z-index: 10000;
            text-align: center;
            border-radius: 8px;
            width: 90%;
            max-width: 600px;
            transition: background-color 0.3s ease;
        }
        #nowPlayingContainer:hover {
            background-color: rgba(20, 20, 20, 1);
        }
        #nowPlayingText {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 0;
            padding: 5px;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);
        }
        #nowPlayingContainer .current-seed {
            display: block;
            font-size: 0.9em;
            color: #ccc;
            margin-bottom: 5px;
        }
        #nowPlayingContainer .title {
            display: block;
            font-size: 1.2em;
            font-weight: bold;
            color: #fff;
        }
    </style>
</head>
<body>

    <HTMLsection>
        <span class="songTitle">The Infinite Ordinal Remix</span>
        <h1>Audionals</h1>
        
        <!-- Seed Management Panel -->
        <div id="seed-management-panel" class="hidden" role="dialog" aria-labelledby="seed-panel-title" aria-hidden="true">
            <h2 id="seed-panel-title">Seed Management</h2>
            
            <!-- Seed and BPM Display -->
            <canvas id="seed-mgmt-canvas" width="300" height="100" aria-label="Seed and BPM Information"></canvas>
            
            <!-- Previous Seeds List -->
            <div id="previous-seeds-container">
                <h3>Previous Seeds</h3>
                <ul></ul>
            </div>
            
            <!-- Seed Input Section -->
            <div id="seed-input-section">
                <h3>Load a Specific Seed</h3>
                <input type="text" id="seed-input" placeholder="Enter 16-digit Seed" aria-label="Enter Seed">
                <button id="load-seed-button" aria-label="Load Seed">Load Seed</button>
            </div>
            
            <!-- BPM Selection Section -->
            <div class="bpm-selection">
                <h3>Select BPM(s) to Filter</h3>
                <div class="bpm-options, hidden">
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-60" value="60" checked>
                        <label for="bpm-60">60 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-120" value="120" checked>
                        <label for="bpm-120">120 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-140" value="140" checked>
                        <label for="bpm-140">140 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-160" value="160" checked>
                        <label for="bpm-160">160 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-180" value="180" checked>
                        <label for="bpm-180">180 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-240" value="240" checked>
                        <label for="bpm-240">240 BPM</label>
                    </div>
                </div>
            </div>
            
            <!-- Clear Seeds Button -->
            <div id="clear-seeds-section">
                <button id="clear-seeds-button" aria-label="Clear Previous Seeds">Clear Previous Seeds</button>
            </div>
            
            <!-- Generate Mixes Button -->
            <div id="generate-mixes-section" style="margin-top: 15px; text-align: center;">
                <button id="generate-mixes-button" aria-label="Generate Mixes">Generate Mixes</button>
            </div>
        </div>
        
        <div id="loadingSpinner"></div>
        <div id="artworkCover"><img id="artworkImage" src="" alt="Artwork Cover"></div>
        <div id="trackListingPanel">
            <h2>Track Listings:</h2>
            <div id="metadataContent"></div>
        </div>
        
       <!-- Updated Now Playing Container -->
        <div id="nowPlayingContainer">
            <span class="current-seed">Seed: N/A</span>
            <span class="title">The Infinite Ordinal Remix</span>
            <span class="artistName">melophonic</span>
            <span class="songBPM">BPM: N/A</span> <!-- BPM Display -->
            <span class="timeLeft">Time Left: N/A</span> <!-- Countdown Display -->
            <!-- Hidden Elements for Playback Engine -->
            <span class="songTitle" style="display: none;"></span>
        </div>
        
        <div id="buttonContainer">
            <button id="playButton" onclick="globalData.togglePlayback()" aria-label="Play or Stop Music">Play / Stop</button>
            <button id="prevButton" onclick="handlePreviousSong()" aria-label="Previous Song">Previous</button>
            <button id="nextButton" onclick="handleNextSong()" aria-label="Next Song">Next</button>
            <button id="toggle-track-panel-button" onclick="toggleTrackListAndPopulate()" class = "hidden" aria-label="Toggle Track List Panel">Track List</button>
            <button id="toggle-seed-panel-button" onclick="togglePanel('seed-management-panel')" aria-label="Toggle Seed Management Panel">Seed Panel</button>
        </div>
        
        <!-- Track List Panel -->
        <div id="track-list-panel" class="hidden" role="dialog" aria-labelledby="track-list-title" aria-hidden="true">
            <h2 id="track-list-title" class="hidden">Track List</h2>
            <div id="track-list-container"></div>
        </div>
    </HTMLsection>

    <!-- Songs and Artwork -->
    <script src="/content/616ef4c1bef02cb6c0f785ef76b98df4e379e8f01e2b31e2ae9e68449485f2bci0"></script> 
    <!-- Global Data -->
    <script src="/content/e8496fa0bcb3cad6bc173cd1ef2564b9548b43b306634bdafce47083efd7619ai0"></script> 

    

<!-- Seed Management -->
<script>
    // Notes //
    /* 
#region Seed Management
**Purpose:**
Handles the generation, validation, storage, and display of unique seeds used within the application. Manages seed-related UI interactions and ensures seeds are persistently stored for user reference.

**Key Functionalities:**
- **Seed Generation & Validation:**
  - Generates a 16-digit numeric seed ensuring it doesn't exceed `Number.MAX_SAFE_INTEGER`.
  - Validates incoming seeds from URL parameters, generating a new one if invalid.
  
- **BPM Mapping:**
  - Converts the seed into a Beats Per Minute (BPM) value using a hashing mechanism to select from predefined BPM options.
  
- **UI Management:**
  - Toggles visibility of UI panels (e.g., track list).
  - Populates track lists dynamically based on global data.
  
- **Seed Persistence:**
  - Saves unique seeds to `localStorage` to maintain a history of previously used seeds.
  - Displays saved seeds with options to copy them to the clipboard.
  - Provides functionality to clear the seed history upon user confirmation.
  
- **Canvas Display:**
  - Visually represents the current seed and BPM on a canvas element for enhanced user clarity.
  
- **Event Listeners:**
  - Initializes seed display on DOM content loaded.
  - Handles user interactions such as loading a new seed or clearing seed history.
  - Ensures seamless user experience by managing input events and updating the UI accordingly.
  
**Overall Functionality:**
This script ensures robust management of seeds within the application, providing users with the ability to generate, view, and manage seeds effectively. It enhances user experience by maintaining a history of interactions and offering intuitive UI controls for seed-related operations.
#endregion
*/
        (() => {
            const log = (msg) => console.log(`[${new Date().toISOString()}] ${msg}`);
            const toggleClass = 'hidden';

            window.togglePanel = (panelId) => {
                const panel = document.getElementById(panelId);
                if (panel) {
                    panel.classList.toggle(toggleClass);
                    const isHidden = panel.classList.contains(toggleClass);
                    panel.setAttribute('aria-hidden', isHidden);
                } else {
                    console.error(`${panelId.replace(/-/g, ' ')} not found.`);
                }
            };

            window.populateTrackList = () => {
                const container = document.getElementById('track-list-container');
                container.innerHTML = '';
                const songs = globalData?.songsArray;
                if (songs?.length) {
                    songs.forEach(({ id, artist }) => {
                        const trackItem = document.createElement('div');
                        trackItem.className = 'track-item';
                        trackItem.innerHTML = `<div class="track-name">${id}</div><div class="track-artist">${artist}</div>`;
                        container.appendChild(trackItem);
                    });
                } else {
                    container.textContent = "No tracks available.";
                }
            };

            window.toggleTrackListAndPopulate = () => {
                togglePanel('track-list-panel');
                const panel = document.getElementById('track-list-panel');
                if (panel && !panel.classList.contains(toggleClass)) populateTrackList();
            };

            const generateSeed = () => {
                let seed = '';
                while (true) {
                    seed = Array.from({ length: 16 }, () => Math.floor(Math.random() * 10)).join('');
                    if (BigInt(seed) <= BigInt(Number.MAX_SAFE_INTEGER)) break;
                }
                return seed;
            };

            const mapSeedToBpm = (seed) => {
                const hash = seed.split("").reduce((acc, char) => {
                    const digit = parseInt(char, 10);
                    return (10 * acc + (isNaN(digit) ? 0 : digit)) % 1000000007;
                }, 0);
                const bpm = bpmOptions[hash % bpmOptions.length];
                log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${bpm}`);
                return bpm;
            };

            const getQueryParam = (param) => new URLSearchParams(window.location.search).get(param);
            const fixedProductionSeed = "";
            let initialSeed = getQueryParam('seed') || generateSeed();
                if (!/^\d{16}$/.test(initialSeed) || BigInt(initialSeed) > BigInt(Number.MAX_SAFE_INTEGER)) {
                    log(`Invalid seed provided: "${initialSeed}". Generating a new seed.`);
                    initialSeed = generateSeed();
                }
                window.seed = initialSeed;
                log(`Using seed: ${window.seed}`);

                // Remove the seed parameter from the URL to prevent reuse on reloads
                if (getQueryParam('seed')) {
                    const url = new URL(window.location);
                    url.searchParams.delete('seed');
                    history.replaceState(null, '', url.toString());
                }

            const prngSeedNumber = BigInt(window.seed);
            log(`Converted seed to BigInt: ${prngSeedNumber}`);

            const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
            const bpm = mapSeedToBpm(window.seed);

            const loadPreviousSeeds = () => {
                const seeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
                displayPreviousSeeds(seeds);
                return seeds;
            };

            const saveSeed = (seed) => {
                const seeds = loadPreviousSeeds();
                if (!seeds.includes(seed)) {
                    seeds.push(seed);
                    localStorage.setItem("previousSeeds", JSON.stringify(seeds));
                    displayPreviousSeeds(seeds);
                    log(`Seed saved: ${seed}`);
                }
            };

            const displayPreviousSeeds = (seeds) => {
                const container = document.getElementById("previous-seeds-container");
                if (!container) return;
                const ul = container.querySelector('ul');
                if (!ul) return;
                ul.innerHTML = seeds.length ? seeds.map(seed => `
                    <li>
                        <span>${seed}</span>
                        <button onclick="copyToClipboard('${seed}')">Copy</button>
                    </li>`).join('') : "<li>No previous seeds.</li>";
            };

            window.copyToClipboard = (seed) => {
                navigator.clipboard.writeText(seed)
                    .then(() => alert(`Seed copied to clipboard: ${seed}`))
                    .catch(err => console.error("Could not copy text:", err));
            };

            const clearPreviousSeeds = () => {
                if (confirm("Are you sure you want to clear all previous seeds?")) {
                    localStorage.removeItem("previousSeeds");
                    displayPreviousSeeds([]);
                    log("All previous seeds have been cleared.");
                }
            };

            const displaySeedAndBPM = (seed, bpm, title = "The Infinite Ordinal Remix") => {
                const canvas = document.getElementById("seed-mgmt-canvas");
                if (!canvas) return;
                const ctx = canvas.getContext("2d");
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--seed-bg-color') || 'green';
                ctx.fillRect(0, 0, canvas.width, canvas.height / 2);
                ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bpm-bg-color') || 'orange';
                ctx.fillRect(0, canvas.height / 2, canvas.width, canvas.height / 2);
                ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--text-color') || 'white';
                ctx.font = `${getComputedStyle(document.documentElement).getPropertyValue('--font-size') || '16px'} Arial`;
                ctx.textAlign = "center";
                ctx.textBaseline = "middle";
                ctx.fillText(`Seed: ${seed}`, canvas.width / 2, canvas.height / 4);
                ctx.fillText(`BPM: ${bpm}`, canvas.width / 2, (3 * canvas.height) / 4);
                saveSeed(seed);
                const seedDisplay = document.querySelector('#nowPlayingContainer .current-seed');
                if (seedDisplay) {
                    seedDisplay.textContent = `Seed: ${seed}`;
                    log(`Updated current seed display: ${seed}`);
                }
                const titleDisplay = document.querySelector('#nowPlayingContainer .title');
                if (titleDisplay && title) {
                    titleDisplay.textContent = title;
                    log(`Updated current song title: ${title}`);
                }
            };

            window.displaySeedAndBPM = displaySeedAndBPM;

            const validateSeedInput = (seed) => {
                if (!/^\d{16}$/.test(seed)) {
                    alert("Seed must be a 16-digit numeric string.");
                    return false;
                }
                if (BigInt(seed) > BigInt(Number.MAX_SAFE_INTEGER)) {
                    alert(`Seed must be a number up to ${Number.MAX_SAFE_INTEGER}.`);
                    return false;
                }
                return true;
            };

            const setupEventListeners = () => {
                document.addEventListener("DOMContentLoaded", () => {
                    // Ensure that songsArray has at least one song
                    if (globalData.songsArray.length > 0) {
                        const firstSong = globalData.songsArray[0];
                        displaySeedAndBPM(firstSong.seed, firstSong.bpm, firstSong.id);
                        // Set currentSongIndex to 0 to point to the first song
                        globalData.currentSongIndex = 0;
                    } else {
                        console.warn("No song mixes generated.");
                    }
                    loadPreviousSeeds();
                });
                document.getElementById("clear-seeds-button")?.addEventListener("click", clearPreviousSeeds);

                document.getElementById("load-seed-button")?.addEventListener("click", () => {
                    const seedInput = document.getElementById("seed-input").value.trim();
                    if (!seedInput) {
                        alert("Please enter a seed.");
                        return;
                    }
                    if (!validateSeedInput(seedInput)) return;
                    const url = new URL(window.location);
                    url.searchParams.set('seed', seedInput);
                    window.location.href = url.toString();
                });

                const seedInputField = document.getElementById("seed-input");
                if (seedInputField) {
                    seedInputField.addEventListener("keypress", (e) => {
                        if (e.key === "Enter") {
                            e.preventDefault();
                            document.getElementById("load-seed-button").click();
                        }
                    });
                }
            };




            setupEventListeners();
        })();
</script>

<!-- Effects Configuration Script (effects.js) -->
<script>
// Notes //
    /* 
#region Effects Configuration Script (effects.js)
**Purpose:**
Establishes a comprehensive framework for managing and configuring various audio effects within the application. Enables dynamic and randomized application of audio effects based on predefined configurations and probabilities.

**Key Functionalities:**
- **Effects Module Initialization:**
  - Initializes or utilizes an existing `EffectsModule` within the global `window` object to store and manage effects configurations.

- **Effects Configuration:**
  - Defines a variety of audio effects (e.g., pitchShift, harmonize, delay, chorus, leslie, synthBass, synth) with specific properties:
    - **enabled:** Boolean flag to activate or deactivate the effect.
    - **defaultProbability:** Determines the likelihood of the effect being applied.
    - **Parameter Ranges:** Specifies ranges or options for effect-specific parameters (e.g., rate, depth, feedback).

- **Parameter Generation (`getEffectParams`):**
  - Generates random parameters for each effect based on their configurations and a pseudo-random number generator (`prng`).
  - Ensures that effects are applied with varied and dynamic settings each time they are triggered.
  - Handles different parameter requirements for each effect type, allowing for extensibility and customization.

- **Event Dispatching:**
  - Emits an `effectsLoaded` event once the effects configurations are fully set up, signaling other parts of the application that the effects system is ready for use.

- **Extensibility:**
  - Designed to easily incorporate additional effects by adding new configurations and corresponding parameter generation logic.
  - Facilitates scalability, allowing the effects system to grow with application requirements.

**Overall Functionality:**
This script provides a flexible and scalable approach to audio effect management, enabling rich and randomized audio experiences tailored to user interactions or predefined conditions. By centralizing effect configurations and parameter generation, it ensures consistency and ease of maintenance across the application's audio processing components.
#endregion
*/
     (() => {
        window.EffectsModule = window.EffectsModule || {};


       window.EffectsModule.effectsConfig = { 
            pitchShift: { 
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                shifts: [0.25, 0.5, 1, 2, 4]
            },
            harmonize: { 
                enabled: false, 
                defaultProbability: 0.01, 
                intervals: [0.3, 0.5],
                maxHarmonyChannels: 1 
            },
            delay: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                noteValue: 'sixteenth',
                maxDelayRepeats: 8 // Reduced from 16
            },
            reverse: {
                enabled: true, 
                defaultProbability: 0.3 // Reduced from 1
            },
            pan: {
                enabled: true,
                defaultProbability: 1, // Safe to keep at 1
                positions: [-1, 1]
            },
            reverb: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                decayTimeRange: [1, 5], // Narrowed range
                mixRange: [0.2, 0.7] // Narrowed range
            },
            filter: {
                enabled: true, 
                defaultProbability: 0.7, 
                types: ['lowpass', 'highpass', 'bandpass'], 
                frequencyRange: [300, 8000], 
                QRange: [1, 8] // Narrowed range
            },
            tremolo: {
                enabled: true, 
                defaultProbability: 0.6, 
                rateRange: [4, 12],   
                depthRange: [0.6, 1]
            },
            distortion: {
                enabled: false, 
                defaultProbability: 0.3, // Reduced and kept disabled
                amountRange: [1, 10] // Adjusted range
            },
            bitcrusher: {
                enabled: true, 
                defaultProbability: 0.3, 
                bitDepthRange: [2, 6],    
                sampleRateRange: [8000, 22050]
            },
            chorus: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.5
                rateRange: [0.1, 5],       
                depthRange: [0.1, 1],      
                feedbackRange: [0, 0.3],   
                mixRange: [0, 0.8]         
            },
            leslie: {
                enabled: true,
                defaultProbability: 0.2, // Reduced from 0.3
                speedRange: [0.5, 1.5],    
                depthRange: [0.5, 1],      
                mixRange: [0, 1]            
            },
            delayBpmLinked: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.4
                delayTimes: ['quarter', 'eighth', 'sixteenth'], 
                feedbackRange: [0.3, 0.6], // Narrowed range
                mixRange: [0, 0.7]        // Narrowed range
            },
        };

        window.EffectsModule.getEffectParams = function(effectName, currentSequence, bpm, prng) {
            const effect = this.effectsConfig[effectName];
            if (!effect || !effect.enabled) return null;
            if (prng() < effect.defaultProbability) {
                // Generate random parameters within the specified ranges
                const params = {};
                switch(effectName) {
                    case 'pitchShift':
                        params.shifts = effect.shifts;
                        break;
                    case 'harmonize':
                        params.intervals = effect.intervals;
                        params.maxHarmonyChannels = effect.maxHarmonyChannels;
                        break;
                    case 'delay':
                        params.noteValue = effect.noteValue;
                        params.maxDelayRepeats = effect.maxDelayRepeats;
                        break;
                    case 'chorus':
                        params.rate = prng() * (effect.rateRange[1] - effect.rateRange[0]) + effect.rateRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'leslie':
                        params.speed = prng() * (effect.speedRange[1] - effect.speedRange[0]) + effect.speedRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'delayBpmLinked':
                        params.delayTime = effect.delayTimes[Math.floor(prng() * effect.delayTimes.length)];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
    
                    // Add cases for other effects as needed
                    default:
                        // For effects without additional parameters
                        break;
                }
                return { ...effect, ...params };
            }
            return null;
        };

        document.dispatchEvent(new Event('effectsLoaded'));
    })();
</script>



<!-- Main Script (main.js) -->
<script>
    /* 
#region Main Script
**Purpose:**
Initializes and manages audio effects, processes song data, handles sample caching, and generates dynamic song mixes based on user-defined parameters. Ensures seamless integration of various audio processing functionalities to create high-quality, customizable music tracks.

**Key Functionalities:**
- **Initialization and Dependencies:**
  - **Effects Module Loading:**
    - Waits for the `EffectsModule` to load and ensures its configuration is available before proceeding.
    - Listens for the `effectsLoaded` event if the module isn't immediately available.
  - **Dynamic Library Loading:**
    - Dynamically loads the `pako` library for data decompression if it's not already present in the global scope.

- **Audio Effects Application:**
  - **Effects Mapping:**
    - Defines an `effectsMap` that associates effect names with their corresponding application functions.
    - Supports a variety of effects including pitch shifting, chorus, harmonization, delay, reverse, filtering, tremolo, distortion, bitcrusher, Leslie effect, and BPM-linked delay.
  - **Effect Processing:**
    - Iterates through each effect in the `effectsMap`, retrieves relevant parameters from the `EffectsModule`, and applies the effect to the specified audio channel.
    - Ensures volume normalization to prevent exceeding maximum gain after applying effects.

- **Sample Management and Normalization:**
  - **Sample Caching:**
    - Implements a caching mechanism (`sampleCache`) to store processed audio samples, avoiding redundant processing and enhancing performance.
    - Generates unique cache keys based on sample URL and processing parameters like reversal and playback speed.
  - **Audio Normalization:**
    - Normalizes audio buffers to maintain consistent volume levels across all channels by adjusting amplitudes based on the maximum detected amplitude.

- **Song Data Fetching and Processing:**
  - **Data Retrieval:**
    - Fetches compressed song data from specified URLs using `fetch`.
    - Decompresses data using the `pako` library and parses the resulting JSON.
  - **Data Transformation:**
    - Processes and maps raw song data into a structured format, aligning keys based on predefined `keyNames` and `keyMap`.
    - Handles complex data structures, including sequences and channel-specific information, preparing them for mix generation.

- **Mute Schedule Generation:**
  - **Dynamic Scheduling:**
    - Generates schedules that dictate when to mute or unmute specific channels during the song's sequences.
    - Utilizes a pseudo-random number generator (`prng`) to determine mute/unmute actions and the number of channels affected per schedule event.

- **Mix Generation:**
  - **Seed-Based Randomness:**
    - Uses a Linear Congruential Generator (`lcg64`) seeded with a unique value to ensure reproducible and unique song mixes.
  - **Channel Selection and Activation:**
    - Randomly selects channels for each mix and assigns activation sequences based on predefined activation points.
  - **Effect and Mute Integration:**
    - Applies the defined audio effects to each selected channel.
    - Incorporates the generated mute schedules into each song mix, dynamically muting or unmuting channels as specified.
  - **BPM Categorization:**
    - Categorizes generated songs by their Beats Per Minute (BPM) for organized access and management.

- **Global Data Management:**
  - **Data Initialization:**
    - Initializes a global `globalData` object to store generated songs, current song and sequence indices, initial sample orders, and initialization status.
    - Ensures that global data structures are populated only once to maintain consistency across the application.
  - **Artwork Handling:**
    - Sets and displays artwork images based on provided URLs if the `isArtworkCover` flag is enabled.

- **Event Handling and UI Integration:**
  - **Event Dispatching:**
    - Dispatches a custom `dataLoadingComplete` event upon successful data loading and mix generation, allowing other components to respond accordingly.
  - **User Interface Updates:**
    - Updates UI elements such as artwork images and manages the visibility of various UI panels based on the initialization status and loaded data.

**Overall Functionality:**
The `main.js` script serves as the core module for audio processing within the application. It orchestrates the initialization of dependencies, applies complex audio effects, manages and normalizes audio samples, processes and structures song data, and generates dynamic, seed-based song mixes. By leveraging a systematic approach to effect application and sample management, the script ensures efficient performance and high-quality audio output, enhancing the user experience through customizable and reproducible music generation.

#endregion
*/

    (async () => {
        function waitForEffects() {
            return new Promise((resolve) => {
                if (window.EffectsModule && window.EffectsModule.effectsConfig) {
                    resolve();
                } else {
                    document.addEventListener('effectsLoaded', resolve, { once: true });
                }
            });
        }
        await waitForEffects();

     


      /**
     * Applies a series of audio effects to a given channel, ensuring volume consistency and balance.
     *
     * @param {Object} channel - The audio channel to apply effects to.
     * @param {number} index - The index of the channel.
     * @param {Object} newSong - The song object containing channel and sequence information.
     * @param {number} currentSequence - The current sequence number.
     * @param {number} bpm - Beats per minute of the song.
     * @param {Object} effectsContext - Context object to manage total gain and harmony channels.
     * @param {Function} prng - Pseudo-random number generator function.
     */
     function applyEffects(channel, index, newSong, currentSequence, bpm, effectsContext, prng) {
        const MAX_EFFECTS_PER_CHANNEL = 4; // Define a reasonable limit

        const effectsMap = [
            { name: 'pitchShift', applyFn: (ch, params) => applyRandomPitchShift(ch, params, prng) },
            { name: 'harmonize', applyFn: (ch, params) => addHarmony(ch, index, newSong, params, effectsContext, prng) },
            { name: 'delay', applyFn: (ch, params) => applyIntermittentDelay(ch, params, bpm) },
            { name: 'reverse', applyFn: (ch, params) => applyReverseEffect(ch) },
            { name: 'filter', applyFn: (ch, params) => applyFilterEffect(ch, params, prng) },
            { name: 'tremolo', applyFn: (ch, params) => applyTremoloEffect(ch, params, prng) },
            { name: 'distortion', applyFn: (ch, params) => applyDistortionEffect(ch, params, prng) },
            { name: 'bitcrusher', applyFn: (ch, params) => applyBitcrusherEffect(ch, params, prng) },
            { name: 'pan', applyFn: (ch, params) => applyPanEffect(ch, params, prng) },
            { name: 'reverb', applyFn: (ch, params) => applyReverbEffect(ch, params, prng) },
            { name: 'volumeChange', applyFn: (ch, params) => applyVolumeChange(ch, params, prng) },
            { name: 'chorus', applyFn: (ch, params) => applyChorusEffect(ch, params, prng) },
            { name: 'leslie', applyFn: (ch, params) => applyLeslieEffect(ch, params, bpm, prng) },
            { name: 'delayBpmLinked', applyFn: (ch, params) => applyBpmLinkedDelay(ch, params, bpm, prng) },
            { name: 'synthBassLine', applyFn: (ch, params) => applySynthBassLineEffect(ch, params, prng) },
        ];

        // Shuffle the effectsMap to randomize effect application order
        const shuffledEffects = effectsMap.sort(() => 0.5 - Math.random());

        let appliedEffectsCount = 0;

        // Iterate through each effect in the shuffledEffectsMap
        for (const effect of shuffledEffects) {
            if (appliedEffectsCount >= MAX_EFFECTS_PER_CHANNEL) break; // Stop if max effects reached

            const effectParams = window.EffectsModule.getEffectParams(effect.name, currentSequence, bpm, prng);
            if (effectParams) {
                // Apply the effect to the channel
                effect.applyFn(channel, effectParams);
                appliedEffectsCount++;

                // Logging the application of the effect
                console.log(`[Effects] Applied effect "${effect.name}" to Channel "${channel.id}" with parameters:`, effectParams);
            }
        }

        // Define volume clamping constants
        const MIN_CHANNEL_VOLUME = 0.5; // Minimum volume factor to prevent channels from being too quiet
        const MAX_CHANNEL_VOLUME = 1.5; // Maximum volume factor to prevent channels from being too loud
        const MAX_TOTAL_GAIN = 2;       // Maximum total gain across all channels to prevent overall mix from being too loud

        // Iterate through each effect in the effectsMap
        effectsMap.forEach(effect => {
            const effectParams = window.EffectsModule.getEffectParams(effect.name, currentSequence, bpm, prng);
            if (effectParams) {
                // Apply the effect to the channel
                effect.applyFn(channel, effectParams);

                // Logging the application of the effect
                console.log(`[Effects] Applied effect "${effect.name}" to Channel "${channel.id}" with parameters:`, effectParams);
            }
        });

        // After applying all effects, perform volume normalization and clamping

        // Ensure the total gain across all channels does not exceed MAX_TOTAL_GAIN
        if (effectsContext.totalGain > MAX_TOTAL_GAIN) {
            const reductionFactor = MAX_TOTAL_GAIN / effectsContext.totalGain;
            channel.metadata.volume = (channel.metadata.volume || 1) * reductionFactor;

            // Log the normalization action
            console.log(`[Normalization] Normalized Channel "${channel.id}" volume by factor ${reductionFactor.toFixed(2)} to maintain total gain within ${MAX_TOTAL_GAIN}.`);
        }

        // Update the total gain in the effects context
        effectsContext.totalGain += channel.metadata.volume || 1;

        // Clamp the channel's volume within defined bounds to maintain balance
        if (channel.metadata.volume < MIN_CHANNEL_VOLUME) {
            channel.metadata.volume = MIN_CHANNEL_VOLUME;
            console.log(`[Clamping] Clamped Channel "${channel.id}" volume to minimum ${MIN_CHANNEL_VOLUME}.`);
        } else if (channel.metadata.volume > MAX_CHANNEL_VOLUME) {
            channel.metadata.volume = MAX_CHANNEL_VOLUME;
            console.log(`[Clamping] Clamped Channel "${channel.id}" volume to maximum ${MAX_CHANNEL_VOLUME}.`);
        }

        // Optionally, adjust the GainNode's gain value if a GainNode is associated with the channel
        const gainNode = globalData.gainNodes?.[newSong.id]?.[channel.id];
        if (gainNode) {
            gainNode.gain.setValueAtTime(channel.metadata.volume, audioContext.currentTime);
            console.log(`[GainNode] Set gain for Channel "${channel.id}" to ${channel.metadata.volume.toFixed(2)}.`);
        } else {
            console.warn(`[GainNode] No GainNode found for Channel "${channel.id}".`);
        }
    }

        // **Chorus Effect Applied**
        const applyChorusEffect = (channel, { rate, depth, feedback, mix }, prng) => {
            channel.metadata.chorus = {
                rate,       // Modulation rate in Hz
                depth,      // Modulation depth (0 to 1)
                feedback,   // Feedback amount (0 to 0.5)
                mix         // Wet/Dry mix (0 to 1)
            };
        };

        // Reintroduce the applyRandomPitchShift function
        const applyRandomPitchShift = (channel, { shifts }, prng) => {
            const shift = shifts[Math.floor(prng() * shifts.length)];
            channel.metadata.playbackSpeed *= shift;
        };

        const addHarmony = (originalChannel, index, newSong, { intervals, maxHarmonyChannels }, context, prng) => {
            if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
            intervals.forEach(interval => {
                if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
                const harmony = JSON.parse(JSON.stringify(originalChannel));
                harmony.id = `${originalChannel.id}_harmony_${index}_${interval}`;
                harmony.metadata.playbackSpeed *= interval;
                harmony.metadata.volume = (harmony.metadata.volume || 1) * 0.8;
                newSong.channels.push(harmony);
                context.harmonyChannelsAdded++;
                context.totalGain += harmony.metadata.volume || 1; // Update totalGain
            });
        };


        const applyIntermittentDelay = (channel, { noteValue, maxDelayRepeats }, bpm) => {
            const beatDuration = 60000 / bpm;
            const delayMap = { 'quarter': beatDuration, 'eighth': beatDuration / 2, 'sixteenth': beatDuration / 4 };
            channel.metadata.delay = { time: delayMap[noteValue] || beatDuration, repeats: maxDelayRepeats };
        };

        const applyReverseEffect = channel => {
            channel.metadata.requiresReversal = true;
        };

        const applyVolumeChange = (channel, { range }, prng) => {
            const [min, max] = range;
            const randomFactor = prng() * (max - min) + min;
            const newVolume = (channel.metadata.volume || 1) * randomFactor;
            
            // Define acceptable volume bounds
            const MIN_VOLUME = 0.5; // Prevent channels from being too quiet
            const MAX_VOLUME = 1.5; // Prevent channels from being too loud
            
            // Clamp the new volume within the defined bounds
            channel.metadata.volume = Math.min(Math.max(newVolume, MIN_VOLUME), MAX_VOLUME);
            
            console.log(`[VolumeChange] Channel ${channel.id} volume set to ${channel.metadata.volume.toFixed(2)}`);
        };

        /**
         * Applies a pan effect to the channel, ensuring the pan value is within [-1, 1].
         *
         * @param {Object} channel - The audio channel to apply the pan effect to.
         * @param {Object} params - Parameters containing the 'positions' array.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        const applyPanEffect = (channel, { positions }, prng) => {
            if (!positions || !Array.isArray(positions) || positions.length === 0) {
                console.warn(`[PanEffect] Invalid or empty 'positions' array for Channel "${channel.id}". Assigning default pan value 0.`);
                channel.metadata.pan = 0; // Default center pan
                return;
            }

            const selectedPan = positions[Math.floor(prng() * positions.length)];

            // Clamp the pan value between -1 and 1
            channel.metadata.pan = Math.max(-1, Math.min(1, selectedPan));

            console.log(`[PanEffect] Channel "${channel.id}" pan set to ${channel.metadata.pan}`);
        };


    /**
     * Applies a reverb effect to the channel with controlled decay time and mix.
     *
     * @param {Object} channel - The audio channel to apply the reverb effect to.
     * @param {Object} params - Parameters containing 'decayTimeRange' and 'mixRange'.
     * @param {Function} prng - Pseudo-random number generator function.
     */
    const applyReverbEffect = (channel, { decayTimeRange, mixRange }, prng) => {
        // Define sensible default ranges if not provided
        const DEFAULT_DECAY_TIME_RANGE = [0.5, 3]; // in seconds
        const DEFAULT_MIX_RANGE = [0.2, 0.8];      // 0 to 1

        // Validate and assign ranges
        const validDecayTimeRange = Array.isArray(decayTimeRange) && decayTimeRange.length === 2
            ? decayTimeRange
            : DEFAULT_DECAY_TIME_RANGE;
        const validMixRange = Array.isArray(mixRange) && mixRange.length === 2
            ? mixRange
            : DEFAULT_MIX_RANGE;

        // Generate random decay time within range
        let decayTime = prng() * (validDecayTimeRange[1] - validDecayTimeRange[0]) + validDecayTimeRange[0];
        decayTime = Math.max(DEFAULT_DECAY_TIME_RANGE[0], Math.min(decayTime, DEFAULT_DECAY_TIME_RANGE[1]));

        // Generate random mix within range
        let mix = prng() * (validMixRange[1] - validMixRange[0]) + validMixRange[0];
        mix = Math.max(DEFAULT_MIX_RANGE[0], Math.min(mix, DEFAULT_MIX_RANGE[1]));

        channel.metadata.reverb = {
            decayTime: parseFloat(decayTime.toFixed(2)), // Rounded for consistency
            mix: parseFloat(mix.toFixed(2))
        };

        console.log(`[ReverbEffect] Channel "${channel.id}" reverb set with decayTime: ${channel.metadata.reverb.decayTime}s, mix: ${channel.metadata.reverb.mix}`);
    };



        /**
         * Applies a filter effect to the channel with controlled type, frequency, and Q factor.
         *
         * @param {Object} channel - The audio channel to apply the filter effect to.
         * @param {Object} params - Parameters containing 'types', 'frequencyRange', and 'QRange'.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        const applyFilterEffect = (channel, { types, frequencyRange, QRange }, prng) => {
            // Define sensible default parameters if not provided
            const DEFAULT_TYPES = ['lowpass', 'highpass', 'bandpass', 'lowshelf', 'highshelf', 'peaking'];
            const DEFAULT_FREQUENCY_RANGE = [20, 20000]; // in Hz
            const DEFAULT_Q_RANGE = [0.1, 10];          // Q factor

            // Validate and assign types
            const validTypes = Array.isArray(types) && types.length > 0
                ? types
                : DEFAULT_TYPES;

            // Validate and assign frequency range
            const validFrequencyRange = Array.isArray(frequencyRange) && frequencyRange.length === 2
                ? frequencyRange
                : DEFAULT_FREQUENCY_RANGE;

            // Validate and assign Q range
            const validQRange = Array.isArray(QRange) && QRange.length === 2
                ? QRange
                : DEFAULT_Q_RANGE;

            // Select a random filter type
            const selectedType = validTypes[Math.floor(prng() * validTypes.length)];

            // Generate random frequency within range
            let frequency = prng() * (validFrequencyRange[1] - validFrequencyRange[0]) + validFrequencyRange[0];
            frequency = Math.max(DEFAULT_FREQUENCY_RANGE[0], Math.min(frequency, DEFAULT_FREQUENCY_RANGE[1]));

            // Generate random Q within range
            let Q = prng() * (validQRange[1] - validQRange[0]) + validQRange[0];
            Q = Math.max(DEFAULT_Q_RANGE[0], Math.min(Q, DEFAULT_Q_RANGE[1]));

            channel.metadata.filter = {
                type: selectedType,
                frequency: parseFloat(frequency.toFixed(2)),
                Q: parseFloat(Q.toFixed(2))
            };

            console.log(`[FilterEffect] Channel "${channel.id}" filter set to type: ${channel.metadata.filter.type}, frequency: ${channel.metadata.filter.frequency}Hz, Q: ${channel.metadata.filter.Q}`);
        };

        /**
         * Applies a tremolo effect to the channel with controlled rate and depth.
         *
         * @param {Object} channel - The audio channel to apply the tremolo effect to.
         * @param {Object} params - Parameters containing 'rateRange' and 'depthRange'.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        const applyTremoloEffect = (channel, { rateRange, depthRange }, prng) => {
            // Define sensible default ranges if not provided
            const DEFAULT_RATE_RANGE = [0.1, 10];   // in Hz
            const DEFAULT_DEPTH_RANGE = [0.1, 0.9]; // 0 to 1

            // Validate and assign rate range
            const validRateRange = Array.isArray(rateRange) && rateRange.length === 2
                ? rateRange
                : DEFAULT_RATE_RANGE;

            // Validate and assign depth range
            const validDepthRange = Array.isArray(depthRange) && depthRange.length === 2
                ? depthRange
                : DEFAULT_DEPTH_RANGE;

            // Generate random rate within range
            let rate = prng() * (validRateRange[1] - validRateRange[0]) + validRateRange[0];
            rate = Math.max(DEFAULT_RATE_RANGE[0], Math.min(rate, DEFAULT_RATE_RANGE[1]));

            // Generate random depth within range
            let depth = prng() * (validDepthRange[1] - validDepthRange[0]) + validDepthRange[0];
            depth = Math.max(DEFAULT_DEPTH_RANGE[0], Math.min(depth, DEFAULT_DEPTH_RANGE[1]));

            channel.metadata.tremolo = {
                rate: parseFloat(rate.toFixed(2)),   // Rounded for consistency
                depth: parseFloat(depth.toFixed(2))
            };

            console.log(`[TremoloEffect] Channel "${channel.id}" tremolo set to rate: ${channel.metadata.tremolo.rate}Hz, depth: ${channel.metadata.tremolo.depth}`);
        };

        /**
         * Applies a distortion effect to the channel with controlled amount.
         *
         * @param {Object} channel - The audio channel to apply the distortion effect to.
         * @param {Object} params - Parameters containing 'amountRange'.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        const applyDistortionEffect = (channel, { amountRange }, prng) => {
            // Define sensible default range if not provided
            const DEFAULT_AMOUNT_RANGE = [0.1, 0.7]; // 0.1 to 0.7

            // Validate and assign amount range
            const validAmountRange = Array.isArray(amountRange) && amountRange.length === 2
                ? amountRange
                : DEFAULT_AMOUNT_RANGE;

            // Generate random amount within range
            let amount = prng() * (validAmountRange[1] - validAmountRange[0]) + validAmountRange[0];
            amount = Math.max(DEFAULT_AMOUNT_RANGE[0], Math.min(amount, DEFAULT_AMOUNT_RANGE[1]));

            channel.metadata.distortion = {
                amount: parseFloat(amount.toFixed(2)) // Rounded for consistency
            };

            console.log(`[DistortionEffect] Channel "${channel.id}" distortion set to amount: ${channel.metadata.distortion.amount}`);
        };

        /**
         * Applies a bitcrusher effect to the channel with controlled bit depth and sample rate.
         *
         * @param {Object} channel - The audio channel to apply the bitcrusher effect to.
         * @param {Object} params - Parameters containing 'bitDepthRange' and 'sampleRateRange'.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        const applyBitcrusherEffect = (channel, { bitDepthRange, sampleRateRange }, prng) => {
            // Define sensible default ranges if not provided
            const DEFAULT_BIT_DEPTH_RANGE = [8, 16];       // 8 to 16 bits
            const DEFAULT_SAMPLE_RATE_RANGE = [8000, 44100]; // 8000Hz to 44100Hz

            // Validate and assign bit depth range
            const validBitDepthRange = Array.isArray(bitDepthRange) && bitDepthRange.length === 2
                ? bitDepthRange
                : DEFAULT_BIT_DEPTH_RANGE;

            // Validate and assign sample rate range
            const validSampleRateRange = Array.isArray(sampleRateRange) && sampleRateRange.length === 2
                ? sampleRateRange
                : DEFAULT_SAMPLE_RATE_RANGE;

            // Generate random bit depth within range
            let bitDepth = Math.floor(prng() * (validBitDepthRange[1] - validBitDepthRange[0] + 1)) + validBitDepthRange[0];
            bitDepth = Math.max(DEFAULT_BIT_DEPTH_RANGE[0], Math.min(bitDepth, DEFAULT_BIT_DEPTH_RANGE[1]));

            // Generate random sample rate within range
            let sampleRate = prng() * (validSampleRateRange[1] - validSampleRateRange[0]) + validSampleRateRange[0];
            sampleRate = Math.max(DEFAULT_SAMPLE_RATE_RANGE[0], Math.min(sampleRate, DEFAULT_SAMPLE_RATE_RANGE[1]));
            sampleRate = parseFloat(sampleRate.toFixed(0)); // Rounded to nearest integer

            channel.metadata.bitcrusher = {
                bitDepth: bitDepth,
                sampleRate: sampleRate
            };

            console.log(`[BitcrusherEffect] Channel "${channel.id}" bitcrusher set to bitDepth: ${channel.metadata.bitcrusher.bitDepth}, sampleRate: ${channel.metadata.bitcrusher.sampleRate}Hz`);
        };

   

        // **Leslie Effect Function**
        const applyLeslieEffect = (channel, { rotationSpeed, depth, mix }, bpm) => {
            channel.metadata.leslie = {
                rotationSpeed, // Rotation speed in Hz
                depth,         // Depth of the effect
                mix            // Wet/Dry mix
            };
        };

        // **BPM-Linked Delay Function**
        const applyBpmLinkedDelay = (channel, { time, feedback, mix }, bpm) => {
            channel.metadata.delayBpmLinked = {
                time,       // Delay time in ms
                feedback,   // Feedback amount (0 to 1)
                mix         // Wet/Dry mix (0 to 1)
            };
        };



        const loopSampleIds = new Set([
            "7c42769c1763cc8f045aada7914e8158223e45e7a4f197b49f918b1c005d36fci0",
            "3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0",
        ]);

        const keyNames = [
            "projectName",
            "artistName",
            "projectBPM",
            "currentSequence",
            "channelURLs",
            "channelVolume",
            "channelPlaybackSpeed",
            "trimSettings",
            "projectChannelNames",
            "startSliderValue",
            "endSliderValue",
            "totalSampleDuration",
            "start",
            "end",
            "projectSequences",
            "steps"
        ];

        const keyMap = keyNames.reduce((map, key, index) => {
            map[key] = index;
            return map;
        }, {});

        const channelIds = Array.from({ length: 16 }, (_, index) => String.fromCharCode(65 + index)); // 'A' to 'P'
        const channelIdMap = channelIds.reduce((map, id, index) => {
            map[id] = index;
            return map;
        }, {});

        const fetchAndProcessSongData = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network error for ${url}`);
                const compressedData = new Uint8Array(await response.arrayBuffer());
                const inflatedData = window.pako.inflate(compressedData);
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                const parsedData = JSON.parse(jsonString);
                const processParsedData = (data) => {
                    const recurse = (obj) => {
                        if (Array.isArray(obj)) {
                            return obj.map(recurse);
                        } else if (obj && typeof obj === "object") {
                            return Object.entries(obj).reduce((accumulator, [key, value]) => {
                                const mappedKey = keyNames[key] || key;
                                accumulator[mappedKey] = mappedKey === "projectSequences"
                                    ? Object.fromEntries(
                                        Object.entries(value).map(([seqKey, seqValue]) => {
                                            const sequenceName = `Sequence${seqKey.replace(/^s/, "")}`;
                                            const channels = Object.fromEntries(
                                                Object.entries(seqValue).map(([channelKey, channelValue]) => {
                                                    const steps = channelValue[keyMap.steps] || [];
                                                    const processedSteps = steps.flatMap((step) => {
                                                        if (typeof step === "number") {
                                                            return step;
                                                        } else if (step?.r) {
                                                            const [start, end] = step.r;
                                                            return Array.from({ length: end - start + 1 }, (_, idx) => start + idx);
                                                        } else if (typeof step === "string" && step.endsWith("r")) {
                                                            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
                                                        } else {
                                                            return [];
                                                        }
                                                    });
                                                    return [`ch${channelIdMap[channelKey]}`, { steps: processedSteps }];
                                                })
                                            );
                                            return [sequenceName, channels];
                                        })
                                    )
                                    : recurse(value);
                                return accumulator;
                            }, {});
                        } else {
                            return obj;
                        }
                    };
                    return recurse(data);
                };
                return processParsedData(parsedData);
            } catch (error) {
                console.error(`[Initialization] Error fetching/deserializing ${url}:`, error);
                throw error;
            }
        };

        const prepareInitialSampleOrder = ({ projectSequences }) => {
            const sampleSet = new Set();
            const sampleOrder = [];
            Object.keys(projectSequences)
                .sort((a, b) => +a.slice(9) - +b.slice(9))
                .forEach(seqK => {
                    Object.entries(projectSequences[seqK]).forEach(([chId, { steps }]) => {
                        steps.forEach(step => {
                            if (typeof step === "number" || step?.index !== undefined) {
                                const id = `${chId}_${step.reverse ? 'r' : 'f'}`;
                                if (!sampleSet.has(id)) {
                                    sampleSet.add(id);
                                    sampleOrder.push({ channelId: chId, reverse: step.reverse || false });
                                }
                            }
                        });
                    });
                });
            return sampleOrder;
        };

        const setArtworkImage = url => {
            const el = document.getElementById("artworkImage");
            if (el) {
                el.src = url;
                el.parentElement.style.display = "flex";
            }
        };

        const normalizeAudioBuffer = (audioBuffer) => {
            const numChannels = audioBuffer.numberOfChannels;
            let globalMaxAmplitude = 0;

            // First pass: Find the global maximum amplitude across all channels
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                const channelMax = Math.max(...channelData.map(sample => Math.abs(sample)));
                if (channelMax > globalMaxAmplitude) {
                    globalMaxAmplitude = channelMax;
                }
            }

            // Define target peak amplitude to prevent clipping
            const TARGET_PEAK = 0.95; // 0.95 to leave some headroom

            // Calculate normalization factor
            const normalizationFactor = globalMaxAmplitude > 0 ? TARGET_PEAK / globalMaxAmplitude : 1;

            // Apply normalization
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                for (let j = 0; j < channelData.length; j++) {
                    channelData[j] *= normalizationFactor;
                }
            }

            console.log(`[Normalization] Applied normalization factor: ${normalizationFactor.toFixed(4)} to audio buffer.`);
            return audioBuffer;
        };
       
       
      // Define maximum cache size
const MAX_CACHE_SIZE = 100; // Adjust based on available memory and application needs

// Use a Map for sampleCache to maintain insertion order for LRU eviction
const sampleCache = new Map();

// Function to generate a unique key for each sample based on URL and processing parameters
const generateSampleKey = (url, params = {}) => {
    let key = url;
    if (params.reversed) key += '_reversed';
    if (params.playbackSpeed && params.playbackSpeed !== 1) key += `_speed_${params.playbackSpeed}`;
    // Include other parameters as needed
    return key;
};

const loadAndProcessSample = async (url, params = {}) => {
    const key = generateSampleKey(url, params);

    if (sampleCache.has(key)) {
        // Move the used sample to the end to mark it as recently used
        const value = sampleCache.get(key);
        sampleCache.delete(key);
        sampleCache.set(key, value);
        console.log(`[Cache] Reusing cached sample: ${key}`);
        return value;
    }

    try {
        const response = await fetch(url);
        if (!response.ok) {
            throw new Error(`Failed to fetch sample from ${url}: ${response.statusText}`);
        }

        const arrayBuffer = await response.arrayBuffer();

        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

        // Normalize the audio buffer
        audioBuffer = normalizeAudioBuffer(audioBuffer);

        // Apply processing if needed
        if (params.reversed) {
            for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                Array.prototype.reverse.call(audioBuffer.getChannelData(i));
            }
            console.log(`[Processing] Reversed audio buffer for key: ${key}`);
        }

        if (params.playbackSpeed && params.playbackSpeed !== 1) {
            // Implement time-stretching or pitch-shifting as needed
            // Placeholder: Log that playbackSpeed is being applied
            console.log(`[Processing] Applying playback speed ${params.playbackSpeed} for key: ${key}`);
            // Actual implementation would require more complex audio processing
        }

        // Add to cache
        sampleCache.set(key, audioBuffer);
        console.log(`[Cache] Added sample to cache: ${key}`);

        // Evict least recently used samples if cache size exceeds limit
        if (sampleCache.size > MAX_CACHE_SIZE) {
            const oldestKey = sampleCache.keys().next().value;
            sampleCache.delete(oldestKey);
            console.log(`[Cache] Evicted oldest sample from cache: ${oldestKey}`);
        }

        return audioBuffer;
    } catch (error) {
        console.error(`[LoadAndProcessSample] Error processing sample from ${url}:`, error);
        throw error; // Re-throw to allow higher-level handling
    }
};
            // **New Function: generateMuteSchedule**
            const generateMuteSchedule = (prng, totalSequences) => {
                const muteSchedule = [];
                const evenSequences = [];
                for (let seq = 2; seq <= totalSequences; seq += 2) {
                    evenSequences.push(seq);
                }

                evenSequences.forEach(seq => {
                    // Decide whether to mute or unmute at this sequence
                    const action = prng() < 0.5 ? 'mute' : 'unmute';
                    // Decide number of channels to affect (1 to 4)
                    const numChannels = Math.floor(prng() * 4) + 1;
                    // Placeholder: actual channel selection will be handled during mix generation
                    muteSchedule.push({ sequence: seq, action, numChannels });
                });

                return muteSchedule;
            };

            const validSongDataUrls = songDataUrls.filter((url) => url.trim() && !url.trim().startsWith("//"));

        if (validSongDataUrls.length) {
            if (!window.pako) {
                await (async function loadPako() {
                    try {
                        const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
                        const textContent = await response.text();
                        const scriptElement = new DOMParser().parseFromString(textContent, "text/html").querySelector("script");
                        if (!scriptElement || !scriptElement.textContent.includes("pako")) {
                            throw new Error("Pako library not found.");
                        }
                        document.head.append(
                            Object.assign(document.createElement("script"), { textContent: scriptElement.textContent })
                        );
                    } catch (error) {
                        console.error("[Initialization] Error loading Pako:", error);
                    }
                })();
            }
            const songDataArray = await Promise.all(
                validSongDataUrls.map(async (url, index) => {
                    try {
                        const data = await fetchAndProcessSongData(url);
                        return { data, index };
                    } catch (error) {
                        console.error(`[Initialization] Failed ${url}:`, error);
                        return null;
                    }
                })
            ).then(dataArray => {
                const validDataArray = dataArray.filter(Boolean);
                if (!validDataArray.length) throw new Error("[Initialization] No valid data.");
                return validDataArray;
            });

            const originalSongs = songDataArray
                .sort((a, b) => a.index - b.index)
                .map(({ data, index }) => {
                    const {
                        projectName = "The Infinite Ordinal",
                        artistName = "melophonic",
                        projectBPM = 120,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = data;

                    const channels = channelIds.map((id, idx) => {
                        const channelSequence = Object.entries(projectSequences).reduce((acc, [sequenceName, sequenceData]) => {
                            const channelData = sequenceData[`ch${idx}`];
                            if (channelData) acc.push({ sequenceName, steps: channelData.steps });
                            return acc;
                        }, []);
                        const metadata = {
                            volume: channelVolume[idx] ?? 1,
                            playbackSpeed: channelPlaybackSpeed[idx] ?? 1,
                            trimStartTime_Percentage: trimSettings[idx]?.start || 0,
                            trimEndTime_Percentage: trimSettings[idx]?.end || 100,
                            requiresReversal: channelSequence.some(seq => seq.steps.some(step => typeof step === "object" && step.reverse)),
                            channelSequence,
                            originalBPM: projectBPM
                        };
                        const sampleId = channelURLs[idx];
                        if (loopSampleIds.has(sampleId)) {
                            metadata.isLoop = true;
                        }
                        return { id, url: sampleId || "URL_not_found", metadata };
                    });
                    return {
                        id: `Song ${index + 1}: ${projectName}`,
                        artist: artistName,
                        bpm: projectBPM,
                        totalSequences: Object.keys(projectSequences).length,
                        totalChannels: channels.length,
                        channels,
                        projectSequences
                    };
                });

            const allChannels = originalSongs.flatMap(song => song.channels);

            function lcg64(seed) {
                let state = seed;
                const a = 6364136223846793005n;
                const c = 1442695040888963407n;
                const m = 18446744073709551616n; // 2^64
                return function() {
                    state = (a * state + c) % m;
                    return Number(state) / Number(m);
                }
            }

            const getRandomChannels = (channelsArray, num, prng) => {
                const shuffled = [...channelsArray];
                for (let i = shuffled.length - 1; i > 0; i--) {
                    const j = Math.floor(prng() * (i + 1));
                    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
                }
                return shuffled.slice(0, num);
            };

            // **New Function: selectChannelsForMuting**
            const selectChannelsForMuting = (channels, num, prng) => {
                const availableChannels = channels.filter(ch => !ch.isMuted); // Assuming channel object has 'isMuted' flag
                const shuffled = [...availableChannels];
                for (let i = shuffled.length - 1; i > 0; i--) {
                    const j = Math.floor(prng() * (i + 1));
                    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
                }
                return shuffled.slice(0, num).map(ch => ch.id);
            };

            // **New Function: selectChannelsForUnmuting**
            const selectChannelsForUnmuting = (channels, num, prng) => {
                const mutedChannels = channels.filter(ch => ch.isMuted);
                const shuffled = [...mutedChannels];
                for (let i = shuffled.length - 1; i > 0; i--) {
                    const j = Math.floor(prng() * (i + 1));
                    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
                }
                return shuffled.slice(0, num).map(ch => ch.id);
            };

            // Generate song mixes asynchronously and map them by BPM
            async function generateMixesBySeed(seedString, numMixes = 100, filteredBPMs = null) {
                const bpmOptions = [60, 120, 140, 160, 180, 240];
                const newSongs = [];
                const songsByBPM = {}; // Object to store songs categorized by BPM

                // Initialize base seed with error handling
                let baseSeed;
                try {
                    baseSeed = BigInt(seedString);
                } catch (error) {
                    console.error(`[seedDebug] Invalid seed string: "${seedString}". Using base seed 0.`);
                    baseSeed = 0n;
                }

                let currentSeed = baseSeed || 1n;

                // Function to derive BPM from a seed using PRNG
                const getBPMFromSeed = (seed) => {
                    const prng = lcg64(seed);
                    return bpmOptions[Math.floor(prng() * bpmOptions.length)];
                };

                // Function to find the next valid seed that matches the target BPM
                const findNextValidSeed = (startingSeed, targetBPM, maxAttempts = 1e6) => {
                    for (let seed = startingSeed, attempt = 0; attempt < maxAttempts; attempt++, seed += 1n) {
                        if (getBPMFromSeed(seed) === targetBPM) return seed;
                    }
                    throw new Error(`[seedDebug] Could not find seed producing BPM ${targetBPM} within ${maxAttempts} attempts.`);
                };

                // Main loop to generate each mix
                for (let mixIndex = 0; mixIndex < numMixes; mixIndex++) {
                    // If filtering by BPM, find the next seed that matches the desired BPM
                    if (filteredBPMs !== null) {
                        try {
                            currentSeed = findNextValidSeed(currentSeed, filteredBPMs);
                        } catch (error) {
                            console.error(error.message);
                            break; // Exit the loop if unable to find a valid seed
                        }
                    }

                    const prng = lcg64(currentSeed);
                    const selectedBPM = filteredBPMs !== null ? filteredBPMs : getBPMFromSeed(currentSeed);

                    // Select random channels for the mix
                    const randomChannels = getRandomChannels(allChannels, 16, prng);
                    const activationPoints = [
                        { startSeq: 1, count: 4 },
                        { startSeq: 5, count: 8 },
                        { startSeq: 17, count: 12 },
                        { startSeq: 25, count: 16 }
                    ];

                    // Assign activation sequences to channels
                    const channelsWithActivation = activationPoints.flatMap(({ startSeq, count }) =>
                        Array.from({ length: count }, (_, i) => {
                            const channel = randomChannels[i];
                            return channel ? { channel: JSON.parse(JSON.stringify(channel)), activationSeq: startSeq } : null;
                        }).filter(Boolean)
                    );

                    // Collect unique sequence names from channels
                    const sequenceSet = new Set(
                        channelsWithActivation.flatMap(({ channel }) => 
                            channel.metadata.channelSequence?.map(seq => seq.sequenceName) || []
                        )
                    );

                    // Sort sequences numerically based on their suffix
                    let sequences = [...sequenceSet].sort((a, b) =>
                        (parseInt(a.replace('Sequence', '')) || 0) - (parseInt(b.replace('Sequence', '')) || 0)
                    );

                    // Limit the number of sequences to 44
                    sequences = sequences.slice(0, 44);


                    // Initialize the new song object
                    const newSong = {
                        id: `The Infinite Ordinal Remix #${mixIndex + 1}`,
                        projectName: `The Infinite Ordinal`,
                        artist: `melophonic`,
                        bpm: selectedBPM,
                        totalSequences: sequences.length,
                        totalChannels: channelsWithActivation.length,
                        channels: [],
                        projectSequences: Object.fromEntries(sequences.map(seq => [seq, {}])),
                        seed: currentSeed.toString(),
                        // **New Property: muteSchedule**
                        muteSchedule: [] // To be populated
                    };

                    // Initialize effects context for the song
                    const effectsContext = {
                        harmonyChannelsAdded: 0,
                        maxHarmonyChannels: window.EffectsModule?.effectsConfig?.harmonize?.maxHarmonyChannels || 2,
                        totalGain: 0,
                        maxTotalGain: 10
                    };

                    // **Generate Mute Schedule for the Song**
                    const totalSequences = sequences.length;
                    const muteSchedule = generateMuteSchedule(prng, totalSequences);
                    newSong.muteSchedule = muteSchedule;

                    // Process each channel asynchronously and apply effects
                    await Promise.all(channelsWithActivation.map(async ({ channel, activationSeq }, index) => {
                        const chId = `ch${index}`;
                        const newChannel = {
                            id: chId,
                            url: channel.url,
                            metadata: { ...channel.metadata, originalBPM: newSong.bpm, activationSeq, isMuted: false } // Initialize isMuted flag
                        };
                        await applyEffects(newChannel, index, newSong, activationSeq, newSong.bpm, effectsContext, prng);
                        newSong.channels.push(newChannel);

                        // Map sequences to the new channel
                        channel.metadata.channelSequence?.forEach(seqData => {
                            if (newSong.projectSequences[seqData.sequenceName]) {
                                newSong.projectSequences[seqData.sequenceName] = {
                                    ...newSong.projectSequences[seqData.sequenceName],
                                    [chId]: { steps: seqData.steps }
                                };
                            }
                        });
                    }));

                    // **Assign Channels to Mute Schedule**
                    muteSchedule.forEach(actionItem => {
                        const { sequence, action, numChannels } = actionItem;
                        if (action === 'mute') {
                            const channelsToMute = selectChannelsForMuting(newSong.channels, numChannels, prng);
                            actionItem.channels = channelsToMute;
                            // Update channel metadata
                            channelsToMute.forEach(chId => {
                                const ch = newSong.channels.find(c => c.id === chId);
                                if (ch) ch.metadata.isMuted = true;
                            });
                        } else if (action === 'unmute') {
                            const channelsToUnmute = selectChannelsForUnmuting(newSong.channels, numChannels, prng);
                            actionItem.channels = channelsToUnmute;
                            // Update channel metadata
                            channelsToUnmute.forEach(chId => {
                                const ch = newSong.channels.find(c => c.id === chId);
                                if (ch) ch.metadata.isMuted = false;
                            });
                        }
                    });

                    // Log the generated song's seed and BPM
                    console.log(`[seedDebug] Generated Song with Seed: ${currentSeed} | BPM: ${selectedBPM}`);

                    // Add the new song to the songs list
                    newSongs.push(newSong);

                    // Add the new song to the songsByBPM map
                    if (!songsByBPM[selectedBPM]) {
                        songsByBPM[selectedBPM] = [];
                    }
                    songsByBPM[selectedBPM].push(newSong);

                    // Increment the seed for the next mix
                    currentSeed += 1n;
                }

                // Log the total number of generated mixes and the BPM map for debugging
                console.log(`[seedDebug] Generated ${newSongs.length} song mixes.`);
                console.log(`[seedDebug] Songs by BPM:`, songsByBPM);

                // Assign songsByBPM to globalData for access by other functions
                globalData.songsByBPM = songsByBPM;

                // Return the list of songs
                return newSongs;
            }

            // **New Function: applyChorusEffect** (Already defined above)

            // **New Functions for Channel Mute Scheduling**
            // selectChannelsForMuting and selectChannelsForUnmuting are defined above

            // **After generating the songs, ensure that samples are processed and cached**
            const generatedSongs = await generateMixesBySeed(window.seed);


            if (typeof globalData.initialized === 'undefined') {
                Object.assign(globalData, {
                    songsArray: generatedSongs,
                    currentSongIndex: 0,
                    currentSequenceIndex: 0,
                    initialSampleOrder: generatedSongs.length ? prepareInitialSampleOrder(generatedSongs[0]) : null,
                    isSingleSong: generatedSongs.length === 1,
                    isMultipleSongs: generatedSongs.length > 1,
                    initialized: true
                });
            }
            if (globalData.isArtworkCover && artworkUrl.length) setArtworkImage(artworkUrl[0]);
            document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
                detail: {
                    success: true,
                    totalSongs: globalData.songsArray.length,
                    songs: globalData.songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
                }
            }));
            window.generateMixesBySeed = generateMixesBySeed;
        } else {
            console.log("[Initialization] No valid song data URLs to process.");
        }
    })();
</script>




<!-- Load Player Scripts AFTER data loading is complete -->
<script>
         window.updateSeedDisplay = function() {
                const currentSong = globalData.songsArray[globalData.currentSongIndex];
                if (currentSong) {
                    const seed = currentSong.seed;
                    const bpm = currentSong.bpm;
                    const title = currentSong.id;
                    displaySeedAndBPM(seed, bpm, title);
                    globalData.currentSeed = seed; // Set the current seed
                } else {
                    console.warn("Current song index is out of bounds.");
                }
            };
        window.updateSeedDisplay = updateSeedDisplay;

        /**
         * Handles transitioning to the next song in the playlist.
         */
        window.handleNextSong = function() {
            globalData.nextSong();
            updateSeedDisplay();
        };

        /**
         * Handles transitioning to the previous song in the playlist.
         */
        window.handlePreviousSong = function() {
            globalData.previousSong();
            updateSeedDisplay();
        };

        document.addEventListener("dataLoadingComplete", (event) => {
            const remainingScriptUrls = [
                "/content/5c03e882ab5a531271b2e93a80d8a9d72cb533c580bec1567020f5cd61595560i0", // projectArtistMapping
                "/content/016f153f011f6a23b8fccd0efcc7945913ee97f241c7a2df7c71c4fa7c9a5fb3i0", // unifiedMetadataManagement
                "/content/ef622be8aeeac45fdbdc291dd0db739d24c2c667c5c3ce7662f2b8c7f2c3de58i0", // GainNodeHelpers
                "/content/f4cc99813b43f71b3e781d3c99f24a6a7a5b1004ea0efce3b225011e347b8df0i0", // audioProcessingAndManagement
                "/content/7b305327f2951d219532ef0cb46b2039b23f2cfd0d8d0e827f3fe1b2b754b5a9i0", // DynamicGainBalancing
                "/content/8b5b09cfedbc0c6a187816181f8d33f90c5bbd15fc10af47008176effb866a47i0", // keyboardControlsAndEventListeners

                ];

            const loadScriptsSequentially = (urls) => {
                if (urls.length === 0) return;
                const src = urls.shift();
                const script = document.createElement("script");
                script.src = src;
                script.async = false;
                script.onload = () => loadScriptsSequentially(urls);
                script.onerror = (e) => {
                    console.error(`[Script Loader] Error loading script: ${src}`, e);
                    loadScriptsSequentially(urls);
                };
                document.body.appendChild(script);
            };

            loadScriptsSequentially([...remainingScriptUrls]);
            updateSeedDisplay(); // Update seed display after loading is complete
        });
</script>







<!-- Playback -->
<script>
    /*
    <details>
        <summary>🔍 How to Access Global Timing Information</summary>
        <p>The playback engine exposes global timing information through the <code>window.globalData</code> object. Other modules can access the following properties and events to monitor and interact with playback:</p>
        <ul>
            <li><strong>Playback Status:</strong> <code>window.globalData.isPlaying</code> - <em>Boolean</em> indicating if playback is active.</li>
            <li><strong>Current Song Index:</strong> <code>window.globalData.currentSongIndex</code> - <em>Number</em> representing the index of the currently playing song.</li>
            <li><strong>Current Sequence:</strong> <code>window.globalData.currentSequence</code> - <em>Number</em> indicating the currently active sequence.</li>
            <li><strong>Playback Events:</strong>
                <ul>
                    <li><code>'playbackStarted'</code> - Dispatched when playback starts.</li>
                    <li><code>'playbackStopped'</code> - Dispatched when playback stops.</li>
                </ul>
                <em>Use <code>document.addEventListener</code> to listen for these events.</em>
            </li>
            <li><strong>Audio Context Current Time:</strong> <code>window.globalData.audioContext.currentTime</code> - <em>Number</em> representing the current time of the AudioContext for precise timing.</li>
            <li><strong>Playback Control Methods:</strong>
                <ul>
                    <li><code>window.globalData.startPlayback()</code> - Starts playback.</li>
                    <li><code>window.globalData.stopPlayback()</code> - Stops playback.</li>
                    <li><code>window.globalData.togglePlayback()</code> - Toggles playback state.</li>
                    <li><code>window.globalData.resetPlayback()</code> - Resets and restarts playback.</li>
                </ul>
            </li>
        </ul>
        <p><strong>Example Usage:</strong></p>
        <pre><code>
// Check if playback is active
if (window.globalData.isPlaying) {
    console.log("Playback is currently active.");
}

// Listen for playback start
document.addEventListener("playbackStarted", (event) => {
    console.log("Playback has started.");
});

// Start playback
window.globalData.startPlayback();
        </code></pre>
    </details>
    */

    // playbackEngine.js
(() => {
    // Initialize global data or use existing globalData
    const globalData = window.globalData || (window.globalData = {
        isPlaying: false,
        currentSongIndex: 0,
        songsArray: [],
        audioBuffers: {},
        reverseAudioBuffers: {},
        audioContext: new (window.AudioContext || window.webkitAudioContext)(),
        masterGain: null,
        gainNodes: {},
        isArtworkCover: true,
        isVisualiserCover: false,
        compressor: null,      // Added Compressor
        lowShelfFilter: null,  // Added Low-Shelf Filter
        analyser: null         // Optional: Added AnalyserNode
    });

    // Initialize the current sequence counter
    globalData.currentSequence = 0;

    const { audioContext } = globalData;
    const scheduleAheadTime = 0.1; // Time in seconds to schedule ahead
    const schedulerInterval = 25;   // Interval in milliseconds for the scheduler

    let playbackInterval = null;
    let sequenceStates = {};

    const missingAudioBuffers = new Set();
    const activeAudioSources = new Set();

    let countdownInterval = null;

    function initializeCountdown(song) {
        // Clear any existing interval
        if (countdownInterval) {
            clearInterval(countdownInterval);
        }

        const nowPlayingContainer = document.getElementById("nowPlayingContainer");
        if (!nowPlayingContainer) return;

        const timeLeftElement = nowPlayingContainer.querySelector(".timeLeft");
        if (!timeLeftElement) return;

        // Calculate total duration in seconds
        const stepDuration = 60 / song.bpm / 4;
        const stepsPerSequence = 64;
        const totalSequences = Object.keys(song.projectSequences).length;
        const totalDuration = stepDuration * stepsPerSequence * totalSequences;

        let timeLeft = totalDuration;

        // Update the display immediately
        updateTimeLeftDisplay(timeLeftElement, timeLeft);

        // Update every second
        countdownInterval = setInterval(() => {
            if (globalData.isPlaying) {
                timeLeft -= 1;
                if (timeLeft <= 0) {
                    timeLeft = 0;
                    clearInterval(countdownInterval);
                }
                updateTimeLeftDisplay(timeLeftElement, timeLeft);
            } else {
                clearInterval(countdownInterval);
            }
        }, 1000);
    }

    function updateTimeLeftDisplay(element, timeLeftInSeconds) {
        const minutes = Math.floor(timeLeftInSeconds / 60);
        const seconds = Math.floor(timeLeftInSeconds % 60);
        element.textContent = `Time Left: ${minutes}:${seconds.toString().padStart(2, '0')}`;
    }

    // Function to start playback
    function startPlayback() {
        const { songsArray, currentSongIndex } = globalData;

        if (!songsArray.length) {
            console.error("No songs available for playback.");
            return;
        }

        // Get the current song and its sequences
        const song = songsArray[currentSongIndex % songsArray.length];
        const projectSequences = song.projectSequences || {};

        const stepDuration = 60 / song.bpm / 4;       // Duration of a single step
        const sequenceDuration = 64 * stepDuration;   // Total duration of a sequence

        // Reset states and logs
        globalData.currentSongIndex %= songsArray.length;
        sequenceStates = {};
        missingAudioBuffers.clear();

        console.log(`Starting playback for Song: ${song.id} (${globalData.currentSongIndex + 1}/${songsArray.length}) with ${Object.keys(projectSequences).length} sequences.`);
        console.log(`Song BPM: ${song.bpm}`);

        // **Update Synth's BPM Here**
        if (window.synth && typeof window.synth.updateBPM === 'function') {
            window.synth.updateBPM(song.bpm);
            console.log(`Synth BPM updated to ${song.bpm} BPM.`);
        } else {
            console.warn("Synth instance not found or updateBPM method unavailable.");
        }

        let sequenceStartTimeOffset = 0;
        let orderedSequenceNumber = 1; // Start from 1

        // Initialize sequence states with ordered sequence numbers
        for (const [sequenceId, sequenceData] of Object.entries(projectSequences)) {
            sequenceStates[sequenceId] = {
                sequenceNumber: orderedSequenceNumber, // Assign ordered number
                nextStepIndex: 0,
                nextStepTime: audioContext.currentTime + sequenceStartTimeOffset,
                stepDuration: stepDuration,
                endTime: audioContext.currentTime + sequenceStartTimeOffset + sequenceDuration,
                completed: false,
                loggedStart: false // Initialize the loggedStart flag
            };
            sequenceStartTimeOffset += sequenceDuration;
            orderedSequenceNumber++;
        }

        globalData.currentSongId = song.id;

        // **Initialize Compressor and Low-Shelf Filter if not already done**
        initializeAudioProcessingChain();

        // Prepare gain nodes for the song
        GainNodeHelper.createGainNodesForSong(song);
        GainNodeHelper.prepareNextSong(songsArray[(globalData.currentSongIndex + 1) % songsArray.length]);
        globalData.isPlaying = true;

        // Reset currentSequence to 1 for the new song
        globalData.currentSequence = 1;

        // Start the playback scheduler
        playbackInterval = setInterval(() => scheduleSequences(song), schedulerInterval);

        console.log("Sequences scheduled and playback started.");
        document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));

        // Update Now Playing information
        updateNowPlaying(song);
    }

    // Function to initialize the audio processing chain with Compressor and Low-Shelf Filter
    function initializeAudioProcessingChain() {
        if (!globalData.compressor) {
            // Create Compressor
            globalData.compressor = audioContext.createDynamicsCompressor();
            globalData.compressor.threshold.setValueAtTime(-24, audioContext.currentTime);
            globalData.compressor.knee.setValueAtTime(30, audioContext.currentTime);
            globalData.compressor.ratio.setValueAtTime(12, audioContext.currentTime);
            globalData.compressor.attack.setValueAtTime(0.003, audioContext.currentTime);
            globalData.compressor.release.setValueAtTime(0.25, audioContext.currentTime);

            // Connect masterGain to compressor
            globalData.masterGain = audioContext.createGain();
            globalData.masterGain.gain.setValueAtTime(1, audioContext.currentTime); // Set default gain
            globalData.masterGain.connect(globalData.compressor);
            globalData.compressor.connect(audioContext.destination);

            console.log("[PlaybackEngine] Compressor node initialized and connected.");
        }

        if (!globalData.lowShelfFilter) {
            // Create Low-Shelf Filter
            globalData.lowShelfFilter = audioContext.createBiquadFilter();
            globalData.lowShelfFilter.type = "lowshelf";
            globalData.lowShelfFilter.frequency.setValueAtTime(50, audioContext.currentTime); // 200 Hz
            globalData.lowShelfFilter.gain.setValueAtTime(-6, audioContext.currentTime); // -6 dB attenuation

            // Insert Low-Shelf Filter after Compressor
            globalData.compressor.disconnect();
            globalData.compressor.connect(globalData.lowShelfFilter);
            globalData.lowShelfFilter.connect(audioContext.destination);

            console.log("[PlaybackEngine] Low-shelf filter node initialized and connected.");
        }

        // Optional: Initialize AnalyserNode for real-time monitoring
        if (!globalData.analyser) {
            globalData.analyser = audioContext.createAnalyser();
            globalData.analyser.fftSize = 2048;
            globalData.analyser.smoothingTimeConstant = 0.8;

            // Connect lowShelfFilter to analyser and then to destination
            globalData.lowShelfFilter.disconnect();
            globalData.lowShelfFilter.connect(globalData.analyser);
            globalData.analyser.connect(audioContext.destination);

            console.log("[PlaybackEngine] Analyser node initialized for real-time monitoring.");
        }

        // Start real-time monitoring (Optional)
        // setInterval(monitorLowFrequencies, 1000); // Uncomment if implementing monitoring
    }

    // Function to stop playback
    function stopPlayback() {
        if (!globalData.isPlaying) {
            console.log("Playback is not in progress.");
            return;
        }

        resetPlayback();
        console.log("Playback stopped.");
        document.dispatchEvent(new CustomEvent("playbackStopped", { detail: { success: true } }));

        // Clear Now Playing information
        clearNowPlaying();

        // Clear countdown timer
        if (countdownInterval) {
            clearInterval(countdownInterval);
            countdownInterval = null;
        }
    }

    // Function to reset playback
    function resetPlayback(options = {}) {
        clearInterval(playbackInterval);
        if (!options.preserveIsPlaying) {
            globalData.isPlaying = false;
        }

        sequenceStates = {};
        missingAudioBuffers.clear();

        // Stop and disconnect all active audio sources
        activeAudioSources.forEach(source => {
            try {
                source.stop();
                source.disconnect();
            } catch (error) {
                console.error("Error stopping/disconnecting an audio source:", error);
            }
        });
        activeAudioSources.clear();

        // Clean up gain nodes
        if (globalData.currentSongId) {
            GainNodeHelper.cleanupGainNodesForSong(globalData.currentSongId);
            globalData.currentSongId = null;
        }

        // Clear countdown timer
        if (countdownInterval) {
            clearInterval(countdownInterval);
            countdownInterval = null;
        }

        // Execute callback if provided
        if (options.callback) {
            options.callback();
        }
    }

    // Toggle playback function
    globalData.togglePlayback = () => globalData.isPlaying ? stopPlayback() : startPlayback();
    globalData.startPlayback = startPlayback;
    globalData.stopPlayback = stopPlayback;
    globalData.resetPlayback = () => resetPlayback({ callback: startPlayback });

    // Updated Function to schedule sequences
    function scheduleSequences(song) {
        const currentTime = audioContext.currentTime;
        let allSequencesCompleted = true;
        const totalSequences = Object.keys(song.projectSequences).length;

        for (const [sequenceId, sequenceData] of Object.entries(song.projectSequences || {})) {
            const sequenceState = sequenceStates[sequenceId];

            if (sequenceState && !sequenceState.completed) {
                if (currentTime >= sequenceState.endTime) {
                    sequenceState.completed = true;
                    console.log(`Sequence ${sequenceState.sequenceNumber} has completed.`);
                } else {
                    allSequencesCompleted = false;

                    // Check if a new sequence is starting
                    if (currentTime >= sequenceState.nextStepTime && !sequenceState.loggedStart) {
                        globalData.currentSequence = sequenceState.sequenceNumber;
                        console.log(`Updating current sequence display: Sequence ${globalData.currentSequence} out of ${totalSequences}`);
                        sequenceState.loggedStart = true; // Prevent logging again
                    }

                    // Schedule steps ahead of time
                    while (sequenceState.nextStepTime < currentTime + scheduleAheadTime && globalData.isPlaying) {
                        const { nextStepIndex, nextStepTime, stepDuration } = sequenceState;

                        // **Log when a new sequence starts**
                        if (nextStepIndex === 0 && !sequenceState.loggedStart) {
                            console.log(`Starting Sequence ${sequenceState.sequenceNumber} at step ${nextStepIndex}.`);
                            sequenceState.loggedStart = true;
                        }

                        for (const [channelKey, noteData] of Object.entries(sequenceData)) {
                            const channelIndex = parseInt(channelKey.slice(2), 10);
                            const channel = song.channels[channelIndex];

                            if (!channel) {
                                console.warn(`Channel index ${channelIndex} not found in song ${song.id}.`);
                                continue;
                            }

                            const step = noteData.steps?.find(step => 
                                typeof step === 'number' ? step === nextStepIndex : step.index === nextStepIndex
                            );

                            if (step !== undefined) {
                                const reverse = typeof step === 'object' && step.reverse;
                                playNote(song, channel, nextStepTime, reverse);
                            }
                        }

                        // Move to the next step
                        sequenceState.nextStepIndex++;
                        if (sequenceState.nextStepIndex >= 64) {
                            sequenceState.completed = true;
                            console.log(`Sequence ${sequenceState.sequenceNumber} has completed all steps.`);
                            break;
                        }
                        sequenceState.nextStepTime += stepDuration;
                    }
                }
            }
        }

        if (allSequencesCompleted) {
            console.log("All sequences have completed.");
            proceedToNextSong();
        }

        applyMuteSchedule(song, globalData.currentSequence);
    }

    // Updated Function to update Now Playing information
    const updateNowPlaying = (song) => {
        const nowPlayingContainer = document.getElementById("nowPlayingContainer");
        if (!nowPlayingContainer) {
            console.warn("Now Playing Container not found.");
            return;
        }

        const { projectName, artistName } = getProjectAndArtist(song);
        nowPlayingContainer.querySelector(".songTitle").textContent = projectName;
        nowPlayingContainer.querySelector(".artistName").textContent = artistName;
        nowPlayingContainer.querySelector(".songBPM").textContent = `BPM: ${song.bpm}`;

        initializeCountdown(song);
    };

    // Function to clear Now Playing information
    const clearNowPlaying = () => {
        const nowPlayingContainer = document.getElementById("nowPlayingContainer");
        if (!nowPlayingContainer) {
            console.warn("Now Playing Container not found.");
            return;
        }
        nowPlayingContainer.querySelector(".songTitle").textContent = "No song playing";
        nowPlayingContainer.querySelector(".artistName").textContent = "";
        nowPlayingContainer.querySelector(".songBPM").textContent = "BPM: N/A";
        nowPlayingContainer.querySelector(".timeLeft").textContent = "Time Left: N/A";
    };

    // In playbackEngine.js

    const MAX_ACTIVE_CHANNELS = 8; // Set a reasonable limit

    function applyMuteSchedule(song, currentSequence) {
        const { muteSchedule } = song;
        if (!muteSchedule || !Array.isArray(muteSchedule)) return;

        // Find actions scheduled for the current sequence
        const actions = muteSchedule.filter(actionItem => actionItem.sequence === currentSequence);

        actions.forEach(actionItem => {
            const { action, channels } = actionItem;
            channels.forEach(channelId => {
                const channel = song.channels.find(ch => ch.id === channelId);
                if (channel) {
                    if (action === 'mute') {
                        muteChannel(channel);
                    } else if (action === 'unmute') {
                        if (getActiveChannelCount(song) < MAX_ACTIVE_CHANNELS) {
                            unmuteChannel(channel);
                        }
                    }
                }
            });
        });
    }

    function getActiveChannelCount(song) {
        return song.channels.filter(ch => !ch.metadata.isMuted).length;
    }

    function muteChannel(channel) {
        if (!channel.metadata.isMuted) {
            channel.metadata.isMuted = true;
            const gainNode = globalData.gainNodes[song.id]?.[channel.id];
            if (gainNode) {
                gainNode.gain.cancelScheduledValues(audioContext.currentTime);
                gainNode.gain.setValueAtTime(gainNode.gain.value, audioContext.currentTime);
                gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + 0.5); // 0.5 second fade-out
                console.log(`Channel ${channel.id} muted with fade-out.`);
            }
        }
    }

    function unmuteChannel(channel) {
        if (channel.metadata.isMuted) {
            channel.metadata.isMuted = false;
            const gainNode = globalData.gainNodes[song.id]?.[channel.id];
            if (gainNode) {
                gainNode.gain.cancelScheduledValues(audioContext.currentTime);
                gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                gainNode.gain.linearRampToValueAtTime(1, audioContext.currentTime + 0.5); // 0.5 second fade-in
                console.log(`Channel ${channel.id} unmuted with fade-in.`);
            }
        }
    }

    // Function to proceed to the next song
    function proceedToNextSong() {
        if (!globalData.isPlaying) return;

        // Increment the seed here
        globalData.currentSeed = (globalData.currentSeed !== undefined ? BigInt(globalData.currentSeed) : 1n) + 1n;
        console.log(`Seed progressed to: ${globalData.currentSeed}`);

        // Update the song index
        globalData.currentSongIndex = (globalData.currentSongIndex + 1) % globalData.songsArray.length;

        setTimeout(() => {
            if (globalData.isPlaying) {
                resetPlayback({ preserveIsPlaying: true, callback: startPlayback });
            }
        }, 200);
    }

    // Function to play a note
    const playNote = (song, channel, time, reverse) => {
        const bufferKey = `${song.id}_${channel.id}_${reverse ? "reverse" : "normal"}`;
        const buffer = reverse
            ? globalData.reverseAudioBuffers[song.id]?.[channel.id]
            : globalData.audioBuffers[song.id]?.[channel.id];

        if (!buffer) {
            if (!missingAudioBuffers.has(bufferKey)) {
                missingAudioBuffers.add(bufferKey);
                console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
            }
            return;
        }

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.playbackRate.value = channel.metadata.playbackSpeed || 1;

        const gainNode = globalData.gainNodes?.[song.id]?.[channel.id] || globalData.masterGain;
        source.connect(gainNode);
        source.start(time);
        activeAudioSources.add(source);
        source.onended = () => activeAudioSources.delete(source);
    };

    // Function to initialize playback engine
    globalData.initializePlaybackEngine = () => {
        if (!globalData.songsArray.length) {
            console.error("No songs available for playback.");
            return;
        }
        console.log("Playback Engine Initialization Complete.");
        console.log("Playback is ready. Click the artwork to start.");
    };

    // Function to get project name and artist name from song object
    function getProjectAndArtist(song) {
        return {
            projectName: song.projectName || song.id || "Unknown Project",
            artistName: song.artist || "Unknown Artist"
        };
    }

    // Set up artwork cover for playback toggle
    const setupArtworkCover = () => {
        document.addEventListener("DOMContentLoaded", () => {
            const artworkCover = document.getElementById("artworkCover");
            const artworkImage = document.getElementById("artworkImage");
            const loadingSpinner = document.getElementById("loadingSpinner");

            if (globalData.isArtworkCover && artworkUrl.length) {
                artworkImage.src = artworkUrl[0];
                artworkCover.classList.remove("hidden");
                loadingSpinner.style.display = "none";
                artworkImage.addEventListener("click", globalData.togglePlayback);
                console.log("Artwork cover is set up for playback toggle.");
            } else {
                console.warn("Artwork cover is not enabled or no artwork URL provided.");
            }
        });
    };

    // Event listener for initial audio buffers ready
    document.addEventListener("initialAudioBuffersReady", (event) => {
        if (event.detail.success) {
            globalData.initializePlaybackEngine();
            console.log("Initial audio buffers are ready.");
        }
    });

    // Event listeners for playback started and stopped
    ["playbackStarted", "playbackStopped"].forEach((eventType) => {
        document.addEventListener(eventType, (event) => {
            if (event.detail.success) {
                console.log(`Playback has been successfully ${eventType === "playbackStarted" ? "started" : "stopped"}.`);
            }
        });
    });

    // Initialize artwork cover setup
    setupArtworkCover();

    // Initialize playback engine if audio buffers are already loaded
    if (Object.keys(globalData.audioBuffers).length) {
        globalData.initializePlaybackEngine();
    }

    // Optional: Implement Real-Time Bass Monitoring
    
    function monitorLowFrequencies() {
        const bufferLength = globalData.analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        globalData.analyser.getByteFrequencyData(dataArray);

        // Calculate average bass level (e.g., frequencies below 250 Hz)
        const bassFrequency = 250;
        const nyquist = audioContext.sampleRate / 2;
        const bassBin = Math.floor(bassFrequency / nyquist * bufferLength);
        const bassLevels = dataArray.slice(0, bassBin);
        const averageBass = bassLevels.reduce((sum, value) => sum + value, 0) / bassLevels.length;

        console.log(`[Monitoring] Average Bass Level: ${averageBass.toFixed(2)}`);

        // Define a threshold (e.g., 100 out of 255)
        const bassThreshold = 100;

        if (averageBass > bassThreshold) {
            // Attenuate the low-shelf filter further
            const currentGain = globalData.lowShelfFilter.gain.value;
            globalData.lowShelfFilter.gain.setValueAtTime(currentGain - 0.5, audioContext.currentTime);
            console.log(`[Monitoring] Attenuated low-shelf filter to reduce bass.`);
        } else if (averageBass < bassThreshold - 20) {
            // Restore the low-shelf filter gain
            const currentGain = globalData.lowShelfFilter.gain.value;
            globalData.lowShelfFilter.gain.setValueAtTime(currentGain + 0.5, audioContext.currentTime);
            console.log(`[Monitoring] Restored low-shelf filter gain.`);
        }
    }

    // Set up the monitoring interval
    setInterval(monitorLowFrequencies, 1000); // Every second
    
})();
</script>








<!-- Synth Script (Comment out to mute module) -->
<!-- <script>
    /*******************************************************
     *                                                     *
     *                     PRNG Class                      *
     *                                                     *
     *******************************************************/

    /**
     * PRNG: Pseudo-Random Number Generator using Linear Congruential Generator (LCG).
     * Provides deterministic random numbers based on an internal seed.
     */
    class PRNG {
        constructor(seed) {
            // Ensure the seed is a BigInt
            if (typeof seed === 'bigint') {
                this.seed = seed % 2147483647n; // Use BigInt literal
                if (this.seed <= 0n) this.seed += 2147483646n;
            } else if (typeof seed === 'number') {
                this.seed = BigInt(seed) % 2147483647n;
                if (this.seed <= 0n) this.seed += 2147483646n;
            } else {
                throw new TypeError('Seed must be a Number or BigInt');
            }
        }

        /**
         * Generates the next random number in the sequence.
         * @returns {number} Next integer in the sequence as a Number.
         */
        next() {
            this.seed = (this.seed * 16807n) % 2147483647n;
            return Number(this.seed);
        }

        /**
         * Returns a floating-point number between 0 (inclusive) and 1 (exclusive).
         * @returns {number} Pseudo-random number.
         */
        random() {
            return (this.next() - 1) / 2147483646;
        }
    }

    /*******************************************************
     *                                                     *
     *                  NoteShaper Class                   *
     *                                                     *
     *******************************************************/

    /**
     * NoteShaper: Class to define different note styles by setting length and envelope settings.
     */
    class NoteShaper {
        /**
         * @param {object} envelope - Envelope settings for the note.
         * @param {number} duration - Duration of the note in seconds.
         */
        constructor(envelope, duration) {
            this.envelope = envelope; // { attack, decay, sustain, release }
            this.duration = duration; // Duration in seconds
        }
    }

    /*******************************************************
     *                                                     *
     *                RhythmPattern Class                  *
     *                                                     *
     *******************************************************/

    /**
     * RhythmPattern: Class to define patterns of notes for creating unique rhythms.
     */
    class RhythmPattern {
        /**
         * @param {number[]} pattern - Array representing the rhythm pattern in beats.
         */
        constructor(pattern) {
            this.pattern = pattern; // e.g., [1, 0.5, 0.5, 1]
        }
    }

    /*******************************************************
     *                                                     *
     *                    Synth Class                      *
     *                                                     *
     *******************************************************/

    /**
     * Synth: Enhanced class for synthesizing audio with advanced controls.
     */
    class Synth {
        /**
         * @param {AudioContext} audioContext - The AudioContext instance.
         * @param {number|BigInt} seed - The initial seed for the PRNG.
         * @param {object} [config] - Optional configuration object for initial settings.
         */
        constructor(audioContext, seed = 123456, config = {}) {
            // Validate audioContext
            if (!(audioContext instanceof (window.AudioContext || window.webkitAudioContext))) {
                throw new TypeError('audioContext must be an instance of AudioContext');
            }

            // Assign AudioContext
            this.context = audioContext;

            // Create Master GainNode and connect to destination
            this.masterGain = this.context.createGain();
            this.masterGain.gain.setValueAtTime(config.volume !== undefined ? config.volume : 0.5, this.context.currentTime); // Set default volume
            this.masterGain.connect(this.context.destination);

            // Initialize PRNG with the seed
            this.seed = seed;
            this.prng = new PRNG(this.seed);

            // Initialize Synth Parameters with configuration or default values
            this.setWaveform(config.waveform || 'sine');
            this.setVolume(config.volume !== undefined ? config.volume : 0.3);             // Default volume
            this.setOctaveShift(config.octaveShift || 0);          // No octave shift
            this.setPolyphony(config.isPolyphonic || false);        // Monophonic mode

            // Initialize Filter Parameters
            this.setFilterType(config.filterType || 'lowpass'); // Default filter type
            this.setFilterCutoff(config.filterCutoff || 1000);   // Default cutoff frequency in Hz
            this.setFilterResonance(config.filterResonance || 1); // Default Q factor

            // Initialize Modulation Parameters
            this.setModulationDepth(config.modulationDepth || 0);       // Default modulation depth
            this.setModulationFrequency(config.modulationFrequency || 5); // Default modulation frequency in Hz

            // Create Filter Node
            this.filter = this.context.createBiquadFilter();
            this.filter.type = this.filterType;
            this.filter.frequency.setValueAtTime(this.filterCutoff, this.context.currentTime);
            this.filter.Q.setValueAtTime(this.filterResonance, this.context.currentTime);
            this.filter.connect(this.masterGain);

            // Create LFO for Modulation
            this.lfo = this.context.createOscillator();
            this.lfo.type = 'sine';
            this.lfo.frequency.setValueAtTime(this.modulationFrequency, this.context.currentTime);

            this.lfoGain = this.context.createGain();
            this.lfoGain.gain.setValueAtTime(this.modulationDepth, this.context.currentTime);

            // Connect LFO to Filter's cutoff frequency for modulation
            this.lfo.connect(this.lfoGain);
            this.lfoGain.connect(this.filter.frequency);
            this.lfo.start();

            // Note Parameters
            this.rootFrequency = 92.50; // F♯2 as the root note
            this.scale = this.generateMinorScale(this.rootFrequency);

            // Initialize allowedNotes
            this.allowedNotes = [this.scale[0]]; // Use the root note

            // BPM and Loop Settings
            this.BPM = config.BPM || 120; // Beats per minute
            this.loopLengthInBars = config.loopLengthInBars || 1; // One bar loop

            // Initialize NoteShapers
            this.noteShapers = this.createNoteShapers();

            // Initialize RhythmPatterns
            this.rhythmPatterns = this.createRhythmPatterns();

            // Decide which note shaper and rhythm pattern to use
            this.currentNoteShaper = this.noteShapers[0]; // Default to the first note shaper
            this.currentRhythmPattern = this.rhythmPatterns[0]; // Default to the first rhythm pattern

            // Prepare the initial loop
            this.currentNoteList = []; // Holds notes and timings for the current loop
            this.prepareLoop();

            // Playback control flags and trackers
            this.isPlaying = false;
            this.currentOscillator = null; // Track active oscillator
            this.schedulerInterval = 25; // Scheduler runs every 25ms
            this.scheduleAheadTime = 0.1; // Schedule notes 100ms ahead
            this.schedulerTimerID = null; // Reference to the scheduler timer
            this.noteIndex = 0;
            this.loopStartTime = null; // Absolute start time of the current loop

            console.log(`[synth] Synth initialized with seed ${this.seed}.`);
        }

        /*******************************************************
         *               Synth Parameter Methods               *
         *******************************************************/

        setWaveform(waveform) {
            const validWaveforms = ['sine', 'square', 'triangle', 'sawtooth'];
            this.waveform = validWaveforms.includes(waveform) ? waveform : 'sawtooth';
        }

        setVolume(volume) {
            this.volume = volume;
            this.masterGain.gain.setValueAtTime(this.volume, this.context.currentTime);
        }

        setOctaveShift(shift) {
            this.octaveShift = shift;
        }

        setPolyphony(isPolyphonic) {
            this.isPolyphonic = isPolyphonic;
        }

        setFilterType(type) {
            const validFilterTypes = ['lowpass', 'highpass', 'bandpass', 'lowshelf', 'highshelf', 'peaking', 'notch', 'allpass'];
            this.filterType = validFilterTypes.includes(type) ? type : 'lowpass';
            if (this.filter) {
                this.filter.type = this.filterType;
            }
        }

        setFilterCutoff(cutoffFrequency) {
            this.filterCutoff = cutoffFrequency;
            if (this.filter) {
                this.filter.frequency.setValueAtTime(this.filterCutoff, this.context.currentTime);
            }
        }

        setFilterResonance(Q) {
            this.filterResonance = Q;
            if (this.filter) {
                this.filter.Q.setValueAtTime(this.filterResonance, this.context.currentTime);
            }
        }

        setModulationDepth(depth) {
            this.modulationDepth = depth;
            if (this.lfoGain) {
                this.lfoGain.gain.setValueAtTime(this.modulationDepth, this.context.currentTime);
            }
        }

        setModulationFrequency(freq) {
            this.modulationFrequency = freq;
            if (this.lfo) {
                this.lfo.frequency.setValueAtTime(this.modulationFrequency, this.context.currentTime);
            }
        }

        /*******************************************************
         *                Note Shaping Methods                 *
         *******************************************************/

        /**
         * Creates a set of NoteShaper instances for different note styles.
         * @returns {NoteShaper[]}
         */
        createNoteShapers() {
            return [
                // Short staccato note
                new NoteShaper({ attack: 0.01, decay: 0.05, sustain: 0.0, release: 0.1 }, 0.2),
                // Medium-length note
                new NoteShaper({ attack: 0.02, decay: 0.1, sustain: 0.7, release: 0.2 }, 0.5),
                // Long sustained note
                new NoteShaper({ attack: 0.05, decay: 0.2, sustain: 0.8, release: 0.5 }, 1.0),
            ];
        }

        /**
         * Selects a NoteShaper by index.
         * @param {number} index
         */
        selectNoteShaper(index) {
            if (index >= 0 && index < this.noteShapers.length) {
                this.currentNoteShaper = this.noteShapers[index];
                console.log(`[synth] NoteShaper set to index ${index}.`);
                // Re-prepare the loop with the new NoteShaper
                this.prepareLoop();
            } else {
                console.warn(`[synth] Invalid NoteShaper index: ${index}.`);
            }
        }

        /*******************************************************
         *                Rhythm Pattern Methods               *
         *******************************************************/

        /**
         * Creates a set of RhythmPattern instances for different rhythms.
         * @returns {RhythmPattern[]}
         */
        createRhythmPatterns() {
            return [
                // Simple quarter notes
                new RhythmPattern([1, 1, 1, 1]),
                // Syncopated rhythm
                new RhythmPattern([0.5, 0.5, 1, 1]),
                // Triplet feel
                new RhythmPattern([0.66, 0.66, 0.66, 1]),
                // Sparse rhythm
                new RhythmPattern([2, 2]),
            ];
        }

        /**
         * Selects a RhythmPattern by index.
         * @param {number} index
         */
        selectRhythmPattern(index) {
            if (index >= 0 && index < this.rhythmPatterns.length) {
                this.currentRhythmPattern = this.rhythmPatterns[index];
                console.log(`[synth] RhythmPattern set to index ${index}.`);
                // Re-prepare the loop with the new RhythmPattern
                this.prepareLoop();
            } else {
                console.warn(`[synth] Invalid RhythmPattern index: ${index}.`);
            }
        }

        /*******************************************************
         *                Note Generation Methods              *
         *******************************************************/

        /**
         * Generates a natural minor scale based on the root frequency.
         * @param {number} rootFrequency 
         * @returns {number[]} Array of frequencies for the minor scale.
         */
        generateMinorScale(rootFrequency) {
            const semitoneRatio = 2 ** (1 / 12);
            const minorScaleIntervals = [0, 2, 3, 5, 7, 8, 10]; // Semitones for natural minor scale
            return minorScaleIntervals.map(interval => rootFrequency * (semitoneRatio ** interval));
        }

        /**
         * Prepares the loop of notes using the current NoteShaper and RhythmPattern.
         */
        prepareLoop() {
            const totalBeats = this.loopLengthInBars * 4; // 4 beats per bar
            const beatDuration = 60 / this.BPM; // Duration of one beat in seconds

            this.currentNoteList = [];
            const pattern = this.currentRhythmPattern.pattern;
            let currentBeat = 0;

            while (currentBeat < totalBeats) {
                for (let i = 0; i < pattern.length && currentBeat < totalBeats; i++) {
                    const beatLength = pattern[i];
                    const startTimeInBeats = currentBeat;
                    const frequency = this.allowedNotes[0]; // Use the root note
                    const durationInSeconds = this.currentNoteShaper.duration;

                    this.currentNoteList.push({
                        frequency: frequency,
                        startTime: startTimeInBeats * beatDuration,
                        duration: durationInSeconds,
                        envelope: this.currentNoteShaper.envelope
                    });

                    currentBeat += beatLength;
                }
            }

            console.log(`[synth] Loop prepared with ${this.currentNoteList.length} notes.`);
        }

        /*******************************************************
         *                  Playback Methods                   *
         *******************************************************/

        /**
         * Starts the Synth's playback loop.
         */
        startPlaying() {
            if (this.isPlaying) return;
            this.isPlaying = true;

            // Resume AudioContext if suspended
            this.resumeAudioContext();

            // Start the scheduler
            this.startScheduler();

            console.log('[synth] Synth started playing.');
        }

        /**
         * Stops the Synth's playback loop and all active notes.
         */
        stopPlaying() {
            if (!this.isPlaying) return;
            this.isPlaying = false;

            // Stop all active oscillators
            this.stopAllOscillators();

            // Stop the scheduler
            this.stopScheduler();

            console.log('[synth] Synth stopped playing.');
        }

        /**
         * Resumes the AudioContext if it is suspended.
         */
        resumeAudioContext() {
            if (this.context.state === 'suspended') {
                this.context.resume();
            }
        }

        /**
         * Starts the internal scheduler loop.
         */
        startScheduler() {
            if (this.schedulerTimerID) return;
            this.schedulerTimerID = setInterval(() => this.scheduler(), this.schedulerInterval);
        }

        /**
         * Stops the internal scheduler loop.
         */
        stopScheduler() {
            if (this.schedulerTimerID) {
                clearInterval(this.schedulerTimerID);
                this.schedulerTimerID = null;
            }
        }

        /**
         * Scheduler function that dispatches timing events to schedule notes.
         */
        scheduler() {
            if (!this.isPlaying) return;

            const currentTime = this.context.currentTime;

            if (!this.loopStartTime) {
                this.loopStartTime = currentTime + 0.1; // Start after 100ms
            }

            const lookahead = this.scheduleAheadTime;
            const loopDurationInSeconds = (60 / this.BPM) * 4 * this.loopLengthInBars; // 4 beats per bar
            const loopEndTime = this.loopStartTime + loopDurationInSeconds;

            // Schedule notes
            while (this.noteIndex < this.currentNoteList.length &&
                this.loopStartTime + this.currentNoteList[this.noteIndex].startTime < currentTime + lookahead) {
                const note = this.currentNoteList[this.noteIndex];
                const noteStartTime = this.loopStartTime + note.startTime;
                this.scheduleNote(note, noteStartTime);
                this.noteIndex++;
            }

            // Loop reset
            if (currentTime >= loopEndTime) {
                this.noteIndex = 0;
                this.loopStartTime += loopDurationInSeconds;
            }
        }

        /**
         * Schedules a single note.
         * @param {object} note - { frequency, startTime, duration, envelope }
         * @param {number} absoluteStartTime - Absolute start time in AudioContext's timeline.
         */
        scheduleNote(note, absoluteStartTime) {
            const { frequency, duration, envelope } = note;
            const adjustedFrequency = frequency * Math.pow(2, this.octaveShift);

            const oscillator = this.context.createOscillator();
            const gainNode = this.context.createGain();

            oscillator.type = this.waveform;
            oscillator.frequency.setValueAtTime(adjustedFrequency, absoluteStartTime);

            // Configure gain envelope using the note's envelope settings
            gainNode.gain.setValueAtTime(0, absoluteStartTime);
            gainNode.gain.linearRampToValueAtTime(this.volume, absoluteStartTime + envelope.attack);
            gainNode.gain.setValueAtTime(this.volume * envelope.sustain, absoluteStartTime + envelope.attack + envelope.decay);
            gainNode.gain.linearRampToValueAtTime(0, absoluteStartTime + duration - envelope.release);

            oscillator.connect(gainNode);
            gainNode.connect(this.filter); // Connect to filter instead of masterGain

            oscillator.start(absoluteStartTime);
            oscillator.stop(absoluteStartTime + duration);

            oscillator.onended = () => {
                oscillator.disconnect();
                gainNode.disconnect();
            };

            if (this.isPolyphonic) {
                // Handle polyphony if needed
            } else {
                // Monophonic: stop previous oscillator
                if (this.currentOscillator) {
                    this.currentOscillator.stop();
                }
                this.currentOscillator = oscillator;
            }
        }

        /**
         * Stops and disconnects the current oscillator.
         */
        stopAllOscillators() {
            if (this.currentOscillator) {
                this.currentOscillator.stop();
                this.currentOscillator.disconnect();
                this.currentOscillator = null;
            }
        }

        /*******************************************************
         *               Seed Updating Method                  *
         *******************************************************/

        /**
         * Updates the internal seed and reinitializes the PRNG and loop.
         * @param {number|BigInt} newSeed - The new seed value.
         */
        updateSeed(newSeed) {
            console.log(`[synth] Updating seed from ${this.seed} to ${newSeed}.`);
            this.seed = newSeed;
            this.prng = new PRNG(this.seed);

            // Optionally, you can randomize the selection of NoteShaper and RhythmPattern based on the new seed
            const noteShaperIndex = this.prng.next() % this.noteShapers.length;
            this.selectNoteShaper(noteShaperIndex);

            const rhythmPatternIndex = this.prng.next() % this.rhythmPatterns.length;
            this.selectRhythmPattern(rhythmPatternIndex);

            // Prepare the loop with the new settings
            this.prepareLoop();

            console.log(`[synth] Seed updated to ${this.seed}.`);
        }

        /*******************************************************
         *                 BPM Updating Method                 *
         *******************************************************/

        /**
         * Updates the BPM (Beats Per Minute) of the rhythm.
         * @param {number} newBPM 
         */
        updateBPM(newBPM) {
            if (typeof newBPM !== 'number' || newBPM <= 0) {
                console.warn(`[synth] Invalid BPM value: ${newBPM}. BPM must be a positive number.`);
                return;
            }
            this.BPM = newBPM;
            console.log(`[synth] BPM updated to ${this.BPM}.`);
            // Re-prepare the loop with the new BPM
            this.prepareLoop();
        }
    }

    /*******************************************************
     *                                                     *
     *                  Global Synth Instance              *
     *                                                     *
     *******************************************************/

    // Reference to the Synth instance
    let synth;

    // Ensure globalData.audioContext is defined before this script runs
    document.addEventListener("dataLoadingComplete", () => {
        if (globalData.songsArray && globalData.songsArray.length > 0) {
            const firstSong = globalData.songsArray[0];
            try {
                // Initialize Synth with configuration
                synth = new Synth(globalData.audioContext, BigInt(firstSong.seed), {
                    waveform: 'sawtooth',
                    volume: 0.75,
                    octaveShift: -1,
                    isPolyphonic: false,
                    filterType: 'lowpass',
                    filterCutoff: 800,
                    filterResonance: 2,
                    modulationDepth: 200,
                    modulationFrequency: 10,
                    BPM: 120,
                    loopLengthInBars: 1
                });
                window.synth = synth; // Make Synth globally accessible

                // Initial Log
                console.log(`Synth initialized with seed ${firstSong.seed} at ${synth.BPM} BPM with enhanced settings.`);
            } catch (error) {
                console.error('Error initializing Synth:', error);
            }
        } else {
            console.error('No songs available to initialize Synth.');
        }
    });

    /*******************************************************
     *                                                     *
     *            Event Listeners and Controls             *
     *                                                     *
     *******************************************************/

    /**
     * Event Listener: Playback Started
     * Triggers Synth to start playing.
     */
    document.addEventListener("playbackStarted", () => {
        if (synth) {
            synth.startPlaying();
        } else {
            console.warn('Synth instance is not initialized.');
        }
    });

    /**
     * Event Listener: Playback Stopped
     * Triggers Synth to stop playing.
     */
    document.addEventListener("playbackStopped", () => {
        if (synth) {
            synth.stopPlaying();
        } else {
            console.warn('Synth instance is not initialized.');
        }
    });

    /**
     * Update Synth seed when the song changes.
     * This should be called in handleNextSong and handlePreviousSong.
     */
    window.updateSynthSeed = function() {
        if (synth && globalData.currentSeed !== undefined) {
            synth.updateSeed(BigInt(globalData.currentSeed));
            console.log(`Synth seed updated to ${globalData.currentSeed}.`);

            // Restart Synth playback to apply the new seed loop
            if (globalData.isPlaying) {
                synth.stopPlaying();
                synth.startPlaying();
            }
        } else {
            console.error('Cannot update Synth seed. Synth or globalData.currentSeed is undefined.');
        }
    };

    /**
     * Modifications to handleNextSong and handlePreviousSong to update the Synth seed.
     */
    window.handleNextSong = function() {
        globalData.nextSong();
        updateSeedDisplay();
        updateSynthSeed(); // Update the Synth with the new seed
    };

    window.handlePreviousSong = function() {
        globalData.previousSong();
        updateSeedDisplay();
        updateSynthSeed(); // Update the Synth with the new seed
    };

    /**
     * Optional: Add Keyboard Controls for Playback
     * Pressing the spacebar toggles playback.
     */
    document.addEventListener('keydown', (event) => {
        if (event.code === 'Space') {
            event.preventDefault();
            if (synth) {
                if (synth.isPlaying) {
                    synth.stopPlaying();
                } else {
                    synth.startPlaying();
                }
            } else {
                console.warn('Synth instance is not initialized.');
            }
        }
    });

    /**
     * Optional: Add Loop Length Controls
     * Provides functions to set loop length dynamically.
     */
    window.setLoopLength = function(loopLengthInBars) {
        if (typeof loopLengthInBars !== 'number' || loopLengthInBars < 1) {
            console.warn('Loop length must be a positive integer.');
            return;
        }
        if (synth) {
            synth.loopLengthInBars = loopLengthInBars;
            synth.prepareLoop(); // Re-prepare the loop with the new length
            console.log(`[synth] Loop length set to ${loopLengthInBars} bar(s).`);
        } else {
            console.warn('Synth instance is not initialized.');
        }
    };
</script> -->






</body>
</html>


