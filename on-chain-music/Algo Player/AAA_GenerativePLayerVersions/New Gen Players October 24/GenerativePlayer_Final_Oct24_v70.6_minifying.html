<!--Tracks are not progressing through seeds during normal playback -->
<!-- Could do with some more balances to help with repetitive loops -->


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Audionals - Web3 Music Player</title>
    <link rel="stylesheet" href="/content/7a309a161e838ba93740684338b3d97f3c1226c046d8b1137afc2353b4bf16e1i0">

    <style>
        :root {
            --panel-bg-color: #333;
            --panel-text-color: #fff;
            --track-list-panel-bg-color: #444;
            --button-bg-color: #444;
            --button-hover-bg-color: #555;
            --button-active-bg-color: #777;
            --input-bg-color: #555;
            --border-radius: 8px;
            --padding: 10px;
            --box-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
            --transition-duration: 0.3s;
            --text-color: #fff;
            --bpm-bg-color: orange;
            --seed-bg-color: green;
            --font-size: 16px;
        }
        /* Common Panel Styles */
        #seed-management-panel,
        #track-list-panel {
            position: fixed;
            background-color: var(--panel-bg-color);
            color: var(--panel-text-color);
            padding: var(--padding);
            border-radius: var(--border-radius);
            z-index: 10000;
            box-shadow: var(--box-shadow);
            transition: all var(--transition-duration) ease;
        }
        /* Specific Panel Positions and Sizes */
        #seed-management-panel {
            top: 10px;
            right: 10px;
            width: 320px;
        }
        #track-list-panel {
            bottom: 10px;
            left: 10px;
            width: 300px;
            background-color: var(--track-list-panel-bg-color);
        }
        .hidden {
            display: none;
        }
        @media (max-width: 600px) {
            #seed-management-panel,
            #track-list-panel {
                width: 90%;
                left: 5%;
                right: 5%;
            }
        }
        /* Canvas Styling */
        #seed-mgmt-canvas {
            width: 100%;
            height: 100px;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: #222;
        }
        /* Previous Seeds Container */
        #previous-seeds-container {
            margin-top: 15px;
        }
        #previous-seeds-container h3,
        #seed-input-section h3 {
            margin-bottom: 5px;
        }
        #previous-seeds-container ul {
            list-style: none;
            padding: 0;
            max-height: 150px;
            overflow-y: auto;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: #444;
        }
        #previous-seeds-container li {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 5px 10px;
            border-bottom: 1px solid #555;
        }
        #previous-seeds-container li:last-child {
            border-bottom: none;
        }
        #previous-seeds-container button {
            background-color: #666;
            color: #fff;
            border: none;
            border-radius: 4px;
            padding: 2px 6px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            margin-left: 10px;
        }
        #previous-seeds-container button:hover {
            background-color: #888;
        }
        /* Seed Input Section */
        #seed-input-section {
            margin-top: 15px;
        }
        #seed-input {
            width: 100%;
            padding: 8px;
            margin-bottom: 5px;
            border: 1px solid #555;
            border-radius: 4px;
            background-color: var(--input-bg-color);
            color: var(--panel-text-color);
            transition: border 0.2s ease;
        }
        #seed-input:focus {
            border: 2px solid #00f;
            outline: none;
        }
        /* Clear Seeds Section */
        #clear-seeds-section {
            margin-top: 15px;
            text-align: center;
        }
        #clear-seeds-button {
            width: 100%;
            padding: 8px;
            background-color: #b22222;
            color: #fff;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            margin-top: 5px;
        }
        #clear-seeds-button:hover {
            background-color: #ff6347;
        }
        /* Button Styles */
        button {
            background-color: var(--button-bg-color);
            color: var(--panel-text-color);
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color var(--transition-duration) ease;
            padding: 10px 15px;
            margin: 5px;
        }
        button:hover {
            background-color: var(--button-hover-bg-color);
        }
        button:active {
            background-color: var(--button-active-bg-color);
        }
        button:focus {
            outline: 2px solid #00f;
        }
        /* Canvas and Now Playing */
        #loadingSpinner {
            z-index: 1000;
        }
        #artworkCover img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }
        #nowPlayingContainer {
            position: fixed;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(20, 20, 20, 0.95);
            color: #fff;
            padding: 10px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.5);
            z-index: 10000;
            text-align: center;
            border-radius: 8px;
            width: 90%;
            max-width: 600px;
            transition: background-color 0.3s ease;
        }
        #nowPlayingContainer:hover {
            background-color: rgba(20, 20, 20, 1);
        }
        #nowPlayingText {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 0;
            padding: 5px;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.5);
        }
        #nowPlayingContainer .current-seed {
            display: block;
            font-size: 0.9em;
            color: #ccc;
            margin-bottom: 5px;
        }
        #nowPlayingContainer .title {
            display: block;
            font-size: 1.2em;
            font-weight: bold;
            color: #fff;
        }
    </style>
</head>
<body>

    <HTMLsection>
        <span class="songTitle">The Infinite Ordinal Remix</span>
        <h1>Audionals</h1>
        
        <!-- Seed Management Panel -->
        <div id="seed-management-panel" class="hidden" role="dialog" aria-labelledby="seed-panel-title" aria-hidden="true">
            <h2 id="seed-panel-title">Seed Management</h2>
            
            <!-- Seed and BPM Display -->
            <canvas id="seed-mgmt-canvas" width="300" height="100" aria-label="Seed and BPM Information"></canvas>
            
            <!-- Previous Seeds List -->
            <div id="previous-seeds-container">
                <h3>Previous Seeds</h3>
                <ul></ul>
            </div>
            
            <!-- Seed Input Section -->
            <div id="seed-input-section">
                <h3>Load a Specific Seed</h3>
                <input type="text" id="seed-input" placeholder="Enter 16-digit Seed" aria-label="Enter Seed">
                <button id="load-seed-button" aria-label="Load Seed">Load Seed</button>
            </div>
            
            <!-- BPM Selection Section -->
            <div class="bpm-selection">
                <h3>Select BPM(s) to Filter</h3>
                <div class="bpm-options, hidden">
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-60" value="60" checked>
                        <label for="bpm-60">60 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-120" value="120" checked>
                        <label for="bpm-120">120 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-140" value="140" checked>
                        <label for="bpm-140">140 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-160" value="160" checked>
                        <label for="bpm-160">160 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-180" value="180" checked>
                        <label for="bpm-180">180 BPM</label>
                    </div>
                    <div class="bpm-option">
                        <input type="checkbox" id="bpm-240" value="240" checked>
                        <label for="bpm-240">240 BPM</label>
                    </div>
                </div>
            </div>
            
            <!-- Clear Seeds Button -->
            <div id="clear-seeds-section">
                <button id="clear-seeds-button" aria-label="Clear Previous Seeds">Clear Previous Seeds</button>
            </div>
            
            <!-- Generate Mixes Button -->
            <div id="generate-mixes-section" style="margin-top: 15px; text-align: center;">
                <button id="generate-mixes-button" aria-label="Generate Mixes">Generate Mixes</button>
            </div>
        </div>
        
        <div id="loadingSpinner"></div>
        <div id="artworkCover"><img id="artworkImage" src="" alt="Artwork Cover"></div>
        <div id="trackListingPanel">
            <h2>Track Listings:</h2>
            <div id="metadataContent"></div>
        </div>
        
       <!-- Updated Now Playing Container -->
        <div id="nowPlayingContainer">
            <span class="current-seed">Seed: N/A</span>
            <span class="title">The Infinite Ordinal Remix</span>
            <span class="artistName">melophonic</span>
            <span class="songBPM">BPM: N/A</span> <!-- BPM Display -->
            <span class="timeLeft">Time Left: N/A</span> <!-- Countdown Display -->
            <!-- Hidden Elements for Playback Engine -->
            <span class="songTitle" style="display: none;"></span>
        </div>
        
        <div id="buttonContainer">
            <button id="playButton" onclick="globalData.togglePlayback()" aria-label="Play or Stop Music">Play / Stop</button>
            <button id="prevButton" onclick="handlePreviousSong()" aria-label="Previous Song">Previous</button>
            <button id="nextButton" onclick="handleNextSong()" aria-label="Next Song">Next</button>
            <button id="toggle-track-panel-button" onclick="toggleTrackListAndPopulate()" class = "hidden" aria-label="Toggle Track List Panel">Track List</button>
            <button id="toggle-seed-panel-button" onclick="togglePanel('seed-management-panel')" aria-label="Toggle Seed Management Panel">Seed Panel</button>
        </div>
        
        <!-- Track List Panel -->
        <div id="track-list-panel" class="hidden" role="dialog" aria-labelledby="track-list-title" aria-hidden="true">
            <h2 id="track-list-title" class="hidden">Track List</h2>
            <div id="track-list-container"></div>
        </div>
    </HTMLsection>

    <!-- Songs and Artwork -->
    <script src="/content/616ef4c1bef02cb6c0f785ef76b98df4e379e8f01e2b31e2ae9e68449485f2bci0"></script> 
    <!-- Global Data -->
    <!-- <script src="/content/e8496fa0bcb3cad6bc173cd1ef2564b9548b43b306634bdafce47083efd7619ai0"></script>  -->


    
<!--Global Data -->
<script>
        // globalData.js
        const globalData = window.globalData = {
            isPlaying: false,
            currentSongIndex: 0,
            songsArray: [], // This will be populated based on seedList
            audioBuffers: {},
            reverseAudioBuffers: {},
            audioContext: new (window.AudioContext || window.webkitAudioContext)(),
            masterGain: null,
            gainNodes: {},
            startPlayback: null,
            stopPlayback: null,
            togglePlayback: null,
            resetPlayback: null,
            isArtworkCover: true,
            isVisualiserCover: false,
        };
    
        globalData.masterGain = globalData.audioContext.createGain();
        globalData.masterGain.connect(globalData.audioContext.destination);
    
        // Implement nextSong and previousSong methods
        globalData.nextSong = function() {
            this.currentSongIndex = (this.currentSongIndex + 1) % this.songsArray.length;
            log(`Switched to next song: Index ${this.currentSongIndex}`);
        };
    
        globalData.previousSong = function() {
            this.currentSongIndex = (this.currentSongIndex - 1 + this.songsArray.length) % this.songsArray.length;
            log(`Switched to previous song: Index ${this.currentSongIndex}`);
        };
</script>
    
<!-- Seed Management -->
<script>
    // Notes //
    /* 
#region Seed Management
[... existing comments ...]
#endregion
*/
    (() => {
        const log = (msg) => console.log(`[${new Date().toISOString()}] ${msg}`);
        const toggleClass = 'hidden';

        window.togglePanel = (panelId) => {
            const panel = document.getElementById(panelId);
            if (panel) {
                panel.classList.toggle(toggleClass);
                const isHidden = panel.classList.contains(toggleClass);
                panel.setAttribute('aria-hidden', isHidden);
            } else {
                console.error(`${panelId.replace(/-/g, ' ')} not found.`);
            }
        };

        window.populateTrackList = () => {
            const container = document.getElementById('track-list-container');
            container.innerHTML = '';
            const songs = globalData?.songsArray;
            if (songs?.length) {
                songs.forEach(({ id, artist }) => {
                    const trackItem = document.createElement('div');
                    trackItem.className = 'track-item';
                    trackItem.innerHTML = `<div class="track-name">${id}</div><div class="track-artist">${artist}</div>`;
                    container.appendChild(trackItem);
                });
            } else {
                container.textContent = "No tracks available.";
            }
        };

        window.toggleTrackListAndPopulate = () => {
            togglePanel('track-list-panel');
            const panel = document.getElementById('track-list-panel');
            if (panel && !panel.classList.contains(toggleClass)) populateTrackList();
        };

        const generateSeed = () => {
            let seed = '';
            while (true) {
                seed = Array.from({ length: 16 }, () => Math.floor(Math.random() * 10)).join('');
                if (BigInt(seed) <= BigInt(Number.MAX_SAFE_INTEGER)) break;
            }
            return seed;
        };

        const mapSeedToBpm = (seed) => {
            const hash = seed.split("").reduce((acc, char) => {
                const digit = parseInt(char, 10);
                return (10 * acc + (isNaN(digit) ? 0 : digit)) % 1000000007;
            }, 0);
            const bpm = bpmOptions[hash % bpmOptions.length];
            log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${bpm}`);
            return bpm;
        };

        const getQueryParam = (param) => new URLSearchParams(window.location.search).get(param);
        const fixedProductionSeed = "";

        // Updated code to handle multiple seeds
        const seedParam = getQueryParam('seed');
        let seedList = [];

        if (seedParam) {
            seedList = seedParam.split(/[\s,]+/).map(s => s.trim()).filter(s => s !== '');
            for (let i = 0; i < seedList.length; i++) {
                const seed = seedList[i];
                if (!/^\d{16}$/.test(seed) || BigInt(seed) > BigInt(Number.MAX_SAFE_INTEGER)) {
                    log(`Invalid seed provided: "${seed}". Generating a new seed.`);
                    seedList[i] = generateSeed();
                }
            }
        } else {
            seedList = [generateSeed()];
        }

        window.seedList = seedList;
        window.seed = seedList[0]; // For backward compatibility
        log(`Using seed(s): ${window.seedList.join(', ')}`);

        // Remove the seed parameter from the URL to prevent reuse on reloads
        if (getQueryParam('seed')) {
            const url = new URL(window.location);
            url.searchParams.delete('seed');
            history.replaceState(null, '', url.toString());
        }

        const bpmOptions = [80, 100, 120, 140, 160, 180, 240];

        // Populate globalData.songsArray with seeds from seedList
        if (!window.globalData) {
            window.globalData = {};
        }
        window.globalData.songsArray = seedList.map((seed, index) => {
            const bpm = mapSeedToBpm(seed);
            return {
                seed,
                bpm,
                id: `Song ${index + 1}`,
                artist: 'Unknown Artist',
                // Additional song properties if needed
            };
        });

        // Initialize currentSongIndex if not already set
        if (window.globalData.currentSongIndex === undefined) {
            window.globalData.currentSongIndex = 0;
        }

        const loadPreviousSeeds = () => {
            const seeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
            displayPreviousSeeds(seeds);
            return seeds;
        };

        const saveSeed = (seed) => {
            const seeds = loadPreviousSeeds();
            if (!seeds.includes(seed)) {
                seeds.push(seed);
                localStorage.setItem("previousSeeds", JSON.stringify(seeds));
                displayPreviousSeeds(seeds);
                log(`Seed saved: ${seed}`);
            }
        };

        const displayPreviousSeeds = (seeds) => {
            const container = document.getElementById("previous-seeds-container");
            if (!container) return;
            const ul = container.querySelector('ul');
            if (!ul) return;
            ul.innerHTML = seeds.length ? seeds.map(seed => `
                <li>
                    <span>${seed}</span>
                    <button onclick="copyToClipboard('${seed}')">Copy</button>
                </li>`).join('') : "<li>No previous seeds.</li>";
        };

        window.copyToClipboard = (seed) => {
            navigator.clipboard.writeText(seed)
                .then(() => alert(`Seed copied to clipboard: ${seed}`))
                .catch(err => console.error("Could not copy text:", err));
        };

        const clearPreviousSeeds = () => {
            if (confirm("Are you sure you want to clear all previous seeds?")) {
                localStorage.removeItem("previousSeeds");
                displayPreviousSeeds([]);
                log("All previous seeds have been cleared.");
            }
        };

        const displaySeedAndBPM = (seed, bpm, title = "The Infinite Ordinal Remix") => {
            const canvas = document.getElementById("seed-mgmt-canvas");
            if (!canvas) return;
            const ctx = canvas.getContext("2d");
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--seed-bg-color') || 'green';
            ctx.fillRect(0, 0, canvas.width, canvas.height / 2);
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bpm-bg-color') || 'orange';
            ctx.fillRect(0, canvas.height / 2, canvas.width, canvas.height / 2);
            ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--text-color') || 'white';
            ctx.font = `${getComputedStyle(document.documentElement).getPropertyValue('--font-size') || '16px'} Arial`;
            ctx.textAlign = "center";
            ctx.textBaseline = "middle";
            ctx.fillText(`Seed: ${seed}`, canvas.width / 2, canvas.height / 4);
            ctx.fillText(`BPM: ${bpm}`, canvas.width / 2, (3 * canvas.height) / 4);
            saveSeed(seed);
            const seedDisplay = document.querySelector('#nowPlayingContainer .current-seed');
            if (seedDisplay) {
                seedDisplay.textContent = `Seed: ${seed}`;
                log(`Updated current seed display: ${seed}`);
            }
            const titleDisplay = document.querySelector('#nowPlayingContainer .title');
            if (titleDisplay && title) {
                titleDisplay.textContent = title;
                log(`Updated current song title: ${title}`);
            }
        };

        window.displaySeedAndBPM = displaySeedAndBPM;

        const validateSeedInput = (seed) => {
            if (!/^\d{16}$/.test(seed)) {
                alert("Seed must be a 16-digit numeric string.");
                return false;
            }
            if (BigInt(seed) > BigInt(Number.MAX_SAFE_INTEGER)) {
                alert(`Seed must be a number up to ${Number.MAX_SAFE_INTEGER}.`);
                return false;
            }
            return true;
        };

        const setupEventListeners = () => {
            document.addEventListener("DOMContentLoaded", () => {
                // Ensure that songsArray has at least one song
                if (globalData.songsArray.length > 0) {
                    const firstSong = globalData.songsArray[globalData.currentSongIndex];
                    displaySeedAndBPM(firstSong.seed, firstSong.bpm, firstSong.id);
                    // Set currentSongIndex to 0 to point to the first song
                    globalData.currentSongIndex = 0;
                } else {
                    console.warn("No song mixes generated.");
                }
                loadPreviousSeeds();
            });
            document.getElementById("clear-seeds-button")?.addEventListener("click", clearPreviousSeeds);

            // Updated event listener for load-seed-button
            document.getElementById("load-seed-button")?.addEventListener("click", () => {
                const seedInput = document.getElementById("seed-input").value.trim();
                if (!seedInput) {
                    alert("Please enter a seed or seeds.");
                    return;
                }
                // Split the input into seeds, by commas or newlines
                const seeds = seedInput.split(/[\s,]+/).map(s => s.trim()).filter(s => s !== '');
                // Validate each seed
                for (const seed of seeds) {
                    if (!validateSeedInput(seed)) {
                        return;
                    }
                }
                // Set the 'seed' parameter in the URL
                const url = new URL(window.location);
                url.searchParams.set('seed', seeds.join(','));
                window.location.href = url.toString();
            });

            const seedInputField = document.getElementById("seed-input");
            if (seedInputField) {
                seedInputField.addEventListener("keypress", (e) => {
                    if (e.key === "Enter") {
                        e.preventDefault();
                        document.getElementById("load-seed-button").click();
                    }
                });
            }
        };

        setupEventListeners();
    })();
</script>

<!-- Seed Display -->
<script>
   // Playback Control Functions
   window.updateSeedDisplay = function() {
                const currentSong = globalData.songsArray[globalData.currentSongIndex];
                if (currentSong) {
                    const seed = currentSong.seed;
                    const bpm = currentSong.bpm;
                    const title = currentSong.id;
                    displaySeedAndBPM(seed, bpm, title);
                    globalData.currentSeed = seed; // Set the current seed
                } else {
                    console.warn("Current song index is out of bounds.");
                }
            };
            window.updateSeedDisplay = updateSeedDisplay;

        /**
         * Handles transitioning to the next song in the playlist.
         */
        window.handleNextSong = function() {
            // Update the current song index
            globalData.currentSongIndex = (globalData.currentSongIndex + 1) % globalData.songsArray.length;
            // Update the seed display
            updateSeedDisplay();
            
            // If a song is currently playing, restart playback
            if (globalData.isPlaying) {
                globalData.resetPlayback({ callback: globalData.startPlayback });
            }
        };

        /**
         * Handles transitioning to the previous song in the playlist.
         */
        window.handlePreviousSong = function() {
            // Update the current song index
            globalData.currentSongIndex = (globalData.currentSongIndex - 1 + globalData.songsArray.length) % globalData.songsArray.length;
            // Update the seed display
            updateSeedDisplay();
            
            // If a song is currently playing, restart playback
            if (globalData.isPlaying) {
                globalData.resetPlayback({ callback: globalData.startPlayback });
            }
        };

            // Call updateSeedDisplay to initialize the display
            document.addEventListener("DOMContentLoaded", () => {
                updateSeedDisplay();
                // Load and start playback of the first song if desired
            });

            
</script>




<!-- Combined Effects Configuration, Audio Effects Module, and GainNode Management -->
 <script>
    /*
    #region Combined Effects Configuration, Audio Effects Module, and GainNode Management

    ## Purpose:
    - **Effects Configuration:**
      Establishes a comprehensive framework for managing and configuring various audio effects within the application. Enables dynamic and randomized application of audio effects based on predefined configurations and probabilities.
    - **Audio Effects Module:**
      Defines and exports various audio effect application functions used for processing audio channels within the application.
    - **GainNode Management:**
      Ensures that GainNodes are correctly created and mapped for each channel, allowing for volume control and audio effects management.

    ## Key Functionalities:

    ### Effects Configuration:
    - **Effects Module Initialization:**
      - Initializes or utilizes an existing `EffectsModule` within the global `window` object to store and manage effects configurations.
    - **Effects Configuration:**
      - Defines a variety of audio effects (e.g., pitchShift, harmonize, delay, chorus, leslie, synthBass, synth) with specific properties:
        - **enabled:** Boolean flag to activate or deactivate the effect.
        - **defaultProbability:** Determines the likelihood of the effect being applied.
        - **Parameter Ranges:** Specifies ranges or options for effect-specific parameters (e.g., rate, depth, feedback).
    - **Parameter Generation (`getEffectParams`):**
      - Generates random parameters for each effect based on their configurations and a pseudo-random number generator (`prng`).
      - Ensures that effects are applied with varied and dynamic settings each time they are triggered.
      - Handles different parameter requirements for each effect type, allowing for extensibility and customization.
    - **Event Dispatching:**
      - Emits an `effectsLoaded` event once the effects configurations are fully set up, signaling other parts of the application that the effects system is ready for use.
    - **Extensibility:**
      - Designed to easily incorporate additional effects by adding new configurations and corresponding parameter generation logic.
      - Facilitates scalability, allowing the effects system to grow with application requirements.

    ### Audio Effects Module:
    - **Effect Application Functions:**
      - `applyChorusEffect`
      - `applyRandomPitchShift`
      - `addHarmony`
      - `applyIntermittentDelay`
      - `applyReverseEffect`
      - `applyVolumeChange`
      - `applyPanEffect`
      - `applyReverbEffect`
      - `applyFilterEffect`
      - `applyTremoloEffect`
      - `applyDistortionEffect`
      - `applyBitcrusherEffect`
      - `applyLeslieEffect`
      - `applyBpmLinkedDelay`
      - Each function is responsible for applying specific audio effects to audio channels based on provided parameters.

    ### GainNode Management:
    - **GainNode Creation and Mapping:**
      - Ensures that each channel has an associated GainNode for volume control.
      - Maps GainNodes to their corresponding channels within each song.
    - **GainNode Initialization Functions:**
      - `createGainNodesForSong`: Creates GainNodes for all channels in a given song.
      - `prepareNextSong`: Prepares GainNodes for the next song (if applicable).
      - `cleanupGainNodesForSong`: Cleans up GainNodes for a song when it's no longer needed.
    - **Global Data Structure:**
      - Maintains a global `gainNodes` map within `globalData` to manage GainNodes for all songs and channels.
      - Ensures that GainNodes are correctly connected to the audio context's master gain node.

    ## Overall Functionality:
    This combined script provides a flexible and scalable approach to audio effect management and GainNode handling. By centralizing effect configurations, parameter generation, dedicated effect application functions, and GainNode management, it ensures consistency, ease of maintenance, and rich, randomized audio experiences tailored to user interactions or predefined conditions across the application's audio processing components.

    #endregion
    */

    (() => {
        // ================================
        // Effects Configuration Section
        // ================================
        window.EffectsModule = window.EffectsModule || {};

        window.EffectsModule.effectsConfig = { 
            pitchShift: { 
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                shifts: [0.25, 0.5, 1, 2, 4]
            },
            harmonize: { 
                enabled: true, 
                defaultProbability: 0.0025, // needs to range from 0.0025 to 0.1 - More stable mixes in general at 0.01 but interesting mixes around 0.1
                intervals: [0.25, 0.5, 1, 1.5, 2, 4],
                maxHarmonyChannels: 1 
            },
            delay: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                noteValue: 'sixteenth',
                maxDelayRepeats: 8 // Reduced from 16
            },
            reverse: {
                enabled: true, 
                defaultProbability: 0.3 // Reduced from 1
            },
            pan: {
                enabled: true,
                defaultProbability: 1, // Safe to keep at 1
                positions: [-1, 1]
            },
            reverb: {
                enabled: true, 
                defaultProbability: 0.5, // Reduced from 1
                decayTimeRange: [1, 5], // Narrowed range
                mixRange: [0.2, 0.7] // Narrowed range
            },
            filter: {
                enabled: true, 
                defaultProbability: 0.7, 
                types: ['lowpass', 'highpass', 'bandpass'], 
                frequencyRange: [300, 8000], 
                QRange: [1, 8] // Narrowed range
            },
            tremolo: {
                enabled: true, 
                defaultProbability: 0.6, 
                rateRange: [4, 12],   
                depthRange: [0.6, 1]
            },
            distortion: {
                enabled: false, 
                defaultProbability: 0.3, // Reduced and kept disabled
                amountRange: [1, 10] // Adjusted range
            },
            bitcrusher: {
                enabled: true, 
                defaultProbability: 0.3, 
                bitDepthRange: [2, 6],    
                sampleRateRange: [8000, 22050]
            },
            chorus: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.5
                rateRange: [0.1, 5],       
                depthRange: [0.1, 1],      
                feedbackRange: [0, 0.3],   
                mixRange: [0, 0.8]         
            },
            leslie: {
                enabled: true,
                defaultProbability: 0.2, // Reduced from 0.3
                speedRange: [0.5, 1.5],    
                depthRange: [0.5, 1],      
                mixRange: [0, 1]            
            },
            delayBpmLinked: {
                enabled: true,
                defaultProbability: 0.3, // Reduced from 0.4
                delayTimes: ['quarter', 'eighth', 'sixteenth'], 
                feedbackRange: [0.3, 0.6], // Narrowed range
                mixRange: [0, 0.7]        // Narrowed range
            },
            // Removed 'synthBassLine' as it's undefined
        };

        window.EffectsModule.getEffectParams = function(effectName, currentSequence, bpm, prng) {
            const effect = this.effectsConfig[effectName];
            if (!effect || !effect.enabled) return null;
            if (prng() < effect.defaultProbability) {
                // Generate random parameters within the specified ranges
                const params = {};
                switch(effectName) {
                    case 'pitchShift':
                        params.shifts = effect.shifts;
                        break;
                    case 'harmonize':
                        params.intervals = effect.intervals;
                        params.maxHarmonyChannels = effect.maxHarmonyChannels;
                        break;
                    case 'delay':
                        params.noteValue = effect.noteValue;
                        params.maxDelayRepeats = effect.maxDelayRepeats;
                        break;
                    case 'chorus':
                        params.rate = prng() * (effect.rateRange[1] - effect.rateRange[0]) + effect.rateRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'leslie':
                        params.rotationSpeed = prng() * (effect.speedRange[1] - effect.speedRange[0]) + effect.speedRange[0];
                        params.depth = prng() * (effect.depthRange[1] - effect.depthRange[0]) + effect.depthRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;
                    case 'delayBpmLinked':
                        params.time = effect.delayTimes[Math.floor(prng() * effect.delayTimes.length)];
                        params.feedback = prng() * (effect.feedbackRange[1] - effect.feedbackRange[0]) + effect.feedbackRange[0];
                        params.mix = prng() * (effect.mixRange[1] - effect.mixRange[0]) + effect.mixRange[0];
                        break;

                    // Add cases for other effects as needed
                    default:
                        // For effects without additional parameters
                        break;
                }
                return { ...effect, ...params };
            }
            return null;
        };

        // ================================
        // Audio Effects Module Section
        // ================================

        // Helper function to clamp values
        const clamp = (value, min, max) => Math.min(Math.max(value, min), max);

        // Apply Chorus Effect
        window.applyChorusEffect = (channel, { rate, depth, feedback, mix }, prng) => {
            channel.metadata.chorus = {
                rate,       // Modulation rate in Hz
                depth,      // Modulation depth (0 to 1)
                feedback,   // Feedback amount (0 to 0.5)
                mix         // Wet/Dry mix (0 to 1)
            };
            // console.log(`[ChorusEffect] Channel "${channel.id}" chorus set with rate: ${rate}Hz, depth: ${depth}, feedback: ${feedback}, mix: ${mix}`);
        };

        // Apply Random Pitch Shift
        window.applyRandomPitchShift = (channel, { shifts }, prng) => {
            const shift = shifts[Math.floor(prng() * shifts.length)];
            channel.metadata.playbackSpeed *= shift;
            // console.log(`[PitchShift] Channel "${channel.id}" playback speed shifted by factor ${shift}`);
        };

        // Add Harmony
        window.addHarmony = (originalChannel, index, newSong, { intervals, maxHarmonyChannels }, context, prng) => {
            if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
            intervals.forEach(interval => {
                if (context.harmonyChannelsAdded >= maxHarmonyChannels) return;
                const harmony = JSON.parse(JSON.stringify(originalChannel));
                harmony.id = `${originalChannel.id}_harmony_${index}_${interval}`;
                harmony.metadata.playbackSpeed *= interval;
                harmony.metadata.volume = clamp((harmony.metadata.volume || 1) * 0.5, 1);
                newSong.channels.push(harmony);
                context.harmonyChannelsAdded++;
                context.totalGain += harmony.metadata.volume || 1; // Update totalGain
                // console.log(`[Harmony] Added harmony channel "${harmony.id}" with interval ${interval}`);
            });
        };

        // Apply Intermittent Delay
        window.applyIntermittentDelay = (channel, { noteValue, maxDelayRepeats }, bpm) => {
            const beatDuration = 60000 / bpm;
            const delayMap = { 'quarter': beatDuration, 'eighth': beatDuration / 2, 'sixteenth': beatDuration / 4 };
            channel.metadata.delay = { time: delayMap[noteValue] || beatDuration, repeats: maxDelayRepeats };
            // console.log(`[IntermittentDelay] Channel "${channel.id}" delay set with time: ${channel.metadata.delay.time}ms, repeats: ${channel.metadata.delay.repeats}`);
        };

        // Apply Reverse Effect
        window.applyReverseEffect = channel => {
            channel.metadata.requiresReversal = true;
            // console.log(`[ReverseEffect] Channel "${channel.id}" reversal enabled`);
        };

        // Apply Volume Change
        window.applyVolumeChange = (channel, { range }, prng) => {
            const [min, max] = range;
            const randomFactor = prng() * (max - min) + min;
            const newVolume = clamp((channel.metadata.volume || 1) * randomFactor, 0.5, 1);
            channel.metadata.volume = parseFloat(newVolume.toFixed(2));
            // console.log(`[VolumeChange] Channel "${channel.id}" volume set to ${channel.metadata.volume}`);
        };

        // Apply Pan Effect
        window.applyPanEffect = (channel, { positions }, prng) => {
            if (!positions || !Array.isArray(positions) || positions.length === 0) {
                console.warn(`[PanEffect] Invalid or empty 'positions' array for Channel "${channel.id}". Assigning default pan value 0.`);
                channel.metadata.pan = 0; // Default center pan
                return;
            }

            const selectedPan = clamp(positions[Math.floor(prng() * positions.length)], -1, 1);
            channel.metadata.pan = parseFloat(selectedPan.toFixed(2));
            // console.log(`[PanEffect] Channel "${channel.id}" pan set to ${channel.metadata.pan}`);
        };

        // Apply Reverb Effect
        window.applyReverbEffect = (channel, { decayTimeRange, mixRange }, prng) => {
            // Generate random decay time within range
            let decayTime = prng() * (decayTimeRange[1] - decayTimeRange[0]) + decayTimeRange[0];
            decayTime = clamp(decayTime, decayTimeRange[0], decayTimeRange[1]);

            // Generate random mix within range
            let mix = prng() * (mixRange[1] - mixRange[0]) + mixRange[0];
            mix = clamp(mix, mixRange[0], mixRange[1]);

            channel.metadata.reverb = {
                decayTime: parseFloat(decayTime.toFixed(2)), // Rounded for consistency
                mix: parseFloat(mix.toFixed(2))
            };

            // console.log(`[ReverbEffect] Channel "${channel.id}" reverb set with decayTime: ${channel.metadata.reverb.decayTime}s, mix: ${channel.metadata.reverb.mix}`);
        };

        // Apply Filter Effect
        window.applyFilterEffect = (channel, { types, frequencyRange, QRange }, prng) => {
            // Select a random filter type
            const selectedType = types[Math.floor(prng() * types.length)];

            // Generate random frequency within range
            let frequency = prng() * (frequencyRange[1] - frequencyRange[0]) + frequencyRange[0];
            frequency = clamp(frequency, frequencyRange[0], frequencyRange[1]);

            // Generate random Q within range
            let Q = prng() * (QRange[1] - QRange[0]) + QRange[0];
            Q = clamp(Q, QRange[0], QRange[1]);

            channel.metadata.filter = {
                type: selectedType,
                frequency: parseFloat(frequency.toFixed(2)),
                Q: parseFloat(Q.toFixed(2))
            };

            // console.log(`[FilterEffect] Channel "${channel.id}" filter set to type: ${channel.metadata.filter.type}, frequency: ${channel.metadata.filter.frequency}Hz, Q: ${channel.metadata.filter.Q}`);
        };

        // Apply Tremolo Effect
        window.applyTremoloEffect = (channel, { rateRange, depthRange }, prng) => {
            // Generate random rate within range
            let rate = prng() * (rateRange[1] - rateRange[0]) + rateRange[0];
            rate = clamp(rate, rateRange[0], rateRange[1]);

            // Generate random depth within range
            let depth = prng() * (depthRange[1] - depthRange[0]) + depthRange[0];
            depth = clamp(depth, depthRange[0], depthRange[1]);

            channel.metadata.tremolo = {
                rate: parseFloat(rate.toFixed(2)),   // Rounded for consistency
                depth: parseFloat(depth.toFixed(2))
            };

            // console.log(`[TremoloEffect] Channel "${channel.id}" tremolo set to rate: ${channel.metadata.tremolo.rate}Hz, depth: ${channel.metadata.tremolo.depth}`);
        };

        // Apply Distortion Effect
        window.applyDistortionEffect = (channel, { amountRange }, prng) => {
            // Generate random amount within range
            let amount = prng() * (amountRange[1] - amountRange[0]) + amountRange[0];
            amount = clamp(amount, amountRange[0], amountRange[1]);

            channel.metadata.distortion = {
                amount: parseFloat(amount.toFixed(2)) // Rounded for consistency
            };

            // console.log(`[DistortionEffect] Channel "${channel.id}" distortion set to amount: ${channel.metadata.distortion.amount}`);
        };

        // Apply Bitcrusher Effect
        window.applyBitcrusherEffect = (channel, { bitDepthRange, sampleRateRange }, prng) => {
            // Generate random bit depth within range
            let bitDepth = Math.floor(prng() * (bitDepthRange[1] - bitDepthRange[0] + 1)) + bitDepthRange[0];
            bitDepth = clamp(bitDepth, bitDepthRange[0], bitDepthRange[1]);

            // Generate random sample rate within range
            let sampleRate = prng() * (sampleRateRange[1] - sampleRateRange[0]) + sampleRateRange[0];
            sampleRate = clamp(sampleRate, sampleRateRange[0], sampleRateRange[1]);
            sampleRate = parseFloat(sampleRate.toFixed(0)); // Rounded to nearest integer

            channel.metadata.bitcrusher = {
                bitDepth: bitDepth,
                sampleRate: sampleRate
            };

            // console.log(`[BitcrusherEffect] Channel "${channel.id}" bitcrusher set to bitDepth: ${channel.metadata.bitcrusher.bitDepth}, sampleRate: ${channel.metadata.bitcrusher.sampleRate}Hz`);
        };

        // Apply Leslie Effect
        window.applyLeslieEffect = (channel, { rotationSpeed, depth, mix }, bpm) => {
            channel.metadata.leslie = {
                rotationSpeed, // Rotation speed in Hz
                depth,         // Depth of the effect
                mix            // Wet/Dry mix
            };
            // console.log(`[LeslieEffect] Channel "${channel.id}" Leslie effect set with rotationSpeed: ${rotationSpeed}Hz, depth: ${depth}, mix: ${mix}`);
        };

        // Apply BPM-Linked Delay
        window.applyBpmLinkedDelay = (channel, { time, feedback, mix }, bpm) => {
            channel.metadata.delayBpmLinked = {
                time,       // Delay time in ms
                feedback,   // Feedback amount (0 to 1)
                mix         // Wet/Dry mix (0 to 1)
            };
            // console.log(`[BpmLinkedDelay] Channel "${channel.id}" BPM-linked delay set with time: ${time}ms, feedback: ${feedback}, mix: ${mix}`);
        };

        // ================================
        // GainNode Management Section
        // ================================

        window.GainNodeHelper = (() => {
            // Initialize globalData if not present
            const globalData = window.globalData || (window.globalData = { 
                gainNodes: {}, 
                audioContext: new (window.AudioContext || window.webkitAudioContext)(), 
                masterGain: null 
            });

            // Initialize masterGain if not already set
            if (!globalData.masterGain) {
                globalData.masterGain = globalData.audioContext.createGain();
                globalData.masterGain.connect(globalData.audioContext.destination);
                // console.log(`[GainNodeHelper] Master GainNode initialized and connected to destination.`);
            }

            /**
             * Initializes GainNodes for all channels in a given song.
             *
             * @param {Object} song - The song object containing channels.
             */
            const createGainNodesForSong = (song) => {
                const songId = song.id;
                if (!song.channels || song.channels.length === 0) {
                    console.warn(`[GainNodeHelper] No channels found for Song "${songId}".`);
                    return;
                }

                globalData.gainNodes[songId] = globalData.gainNodes[songId] || {};

                song.channels.forEach(channel => {
                    if (!globalData.gainNodes[songId][channel.id]) {
                        const gainNode = globalData.audioContext.createGain();
                        gainNode.gain.value = channel.metadata.volume || 1;
                        gainNode.connect(globalData.masterGain);
                        globalData.gainNodes[songId][channel.id] = gainNode;
                        // console.log(`[GainNodeHelper] GainNode created for Channel "${channel.id}" in Song "${songId}".`);
                    }
                });
            };

            /**
             * Prepares GainNodes for the next song.
             *
             * @param {Object} song - The next song object.
             */
            const prepareNextSongGainNodes = (song) => {
                createGainNodesForSong(song);
                // console.log(`[GainNodeHelper] Prepared GainNodes for next Song "${song.id}".`);
            };

            /**
             * Cleans up GainNodes for a specific song.
             *
             * @param {string} songId - The ID of the song to clean up.
             */
            const cleanupGainNodesForSong = (songId) => {
                const songGainNodes = globalData.gainNodes[songId];
                if (songGainNodes) {
                    Object.values(songGainNodes).forEach(gainNode => gainNode.disconnect());
                    delete globalData.gainNodes[songId];
                    // console.log(`[GainNodeHelper] Cleaned up GainNodes for Song "${songId}".`);
                } else {
                    console.warn(`[GainNodeHelper] No GainNodes found to clean up for Song "${songId}".`);
                }
            };

            // Expose public methods
            return {
                createGainNodesForSong,
                prepareNextSongGainNodes,
                cleanupGainNodesForSong
            };
        })();

        // ================================
        // Finalize Configuration
        // ================================

        // Dispatch 'effectsLoaded' event to signal that the effects system is ready
        document.dispatchEvent(new Event('effectsLoaded'));
    })();
</script>

<!-- GainNode Helpers (gainNodeHelpers.js) -->
<script>
    window.GainNodeHelper = (() => {
        // Ensure a single globalData instance
        const globalData = window.globalData || (window.globalData = { 
            gainNodes: {}, 
            audioContext: new (window.AudioContext || window.webkitAudioContext)(), 
            masterGain: null 
        });

        if (!globalData.masterGain) {
            globalData.masterGain = globalData.audioContext.createGain();
            globalData.masterGain.connect(globalData.audioContext.destination);
            console.log("[GainNodeHelper] Master Gain node created and connected to AudioContext destination.");
        }

        // Adjustable controls
        const masteringControls = {
            targetLoudness: 0.8, // Target volume for normalization (0.0 to 1.0)
            transientThreshold: 1.2, // Maximum transient gain multiplier
            smoothingFactor: 0.7 // Smoothing factor for transient control (0-1, higher is smoother)
        };

        /**
         * Normalize gain levels for a song's channels based on their metadata or peak loudness.
         *
         * @param {Object} song - The song object containing channels.
         */
        const normalizeChannelVolumes = (song) => {
            if (!song.channels || song.channels.length === 0) {
                console.warn(`[GainNodeHelper] No channels to normalize for Song "${song.id}".`);
                return;
            }

            const volumes = song.channels.map(channel => channel.metadata.volume || 1);
            const maxVolume = Math.max(...volumes);

            song.channels.forEach(channel => {
                const normalizedVolume = (channel.metadata.volume || 1) / maxVolume * masteringControls.targetLoudness;
                updateChannelGain(song.id, channel.id, normalizedVolume);
                console.log(`[GainNodeHelper] Normalized volume for Channel "${channel.id}" to ${normalizedVolume.toFixed(2)}.`);
            });
        };

        /**
         * Apply transient control to smooth out peaks in a song's channels.
         *
         * @param {Object} song - The song object containing channels.
         */
        const applyTransientControl = (song) => {
            if (!song.channels || song.channels.length === 0) {
                console.warn(`[GainNodeHelper] No channels for transient control for Song "${song.id}".`);
                return;
            }

            song.channels.forEach(channel => {
                const gainNode = globalData.gainNodes?.[song.id]?.[channel.id];
                if (gainNode) {
                    const adjustedGain = Math.min(
                        gainNode.gain.value * masteringControls.transientThreshold, 
                        masteringControls.targetLoudness
                    );
                    gainNode.gain.setTargetAtTime(
                        adjustedGain, 
                        globalData.audioContext.currentTime, 
                        masteringControls.smoothingFactor
                    );
                    console.log(`[GainNodeHelper] Applied transient control for Channel "${channel.id}", adjusted to ${adjustedGain.toFixed(2)}.`);
                }
            });
        };

        /**
         * Initializes GainNodes for a given song.
         *
         * @param {Object} song - The song object containing channels.
         * @param {boolean} isNextSong - Flag indicating if the song is the next in the queue.
         */
        const initializeGainNodes = (song, isNextSong = false) => {
            const songId = song.id;
            console.log(`[GainNodeHelper] Initializing GainNodes for Song ID: ${songId}`);

            if (isNextSong) {
                console.log(`[GainNodeHelper] Preparing next song: ${songId}`);
            } else {
                console.log(`[GainNodeHelper] Setting current song: ${songId}`);
            }

            if (song.channels && song.channels.length > 0) {
                if (!globalData.gainNodes[songId]) {
                    globalData.gainNodes[songId] = {};
                }
                song.channels.forEach(channel => {
                    if (!globalData.gainNodes[songId][channel.id]) {
                        const gainNode = globalData.audioContext.createGain();
                        gainNode.gain.value = channel.metadata.volume || 1;
                        gainNode.connect(globalData.masterGain);
                        globalData.gainNodes[songId][channel.id] = gainNode;
                        console.log(`[GainNodeHelper] GainNode created for Channel "${channel.id}" of Song "${songId}".`);
                    }
                });
                normalizeChannelVolumes(song);
                applyTransientControl(song);
                console.log(`[GainNodeHelper] All GainNodes initialized for Song ID: ${songId}`);
            } else {
                console.warn(`[GainNodeHelper] No channels found for Song "${songId}".`);
            }
        };

        /**
         * Updates the gain value for a specific channel.
         *
         * @param {string} songId - The ID of the song.
         * @param {string} channelId - The ID of the channel.
         * @param {number} volume - The new volume value.
         */
        const updateChannelGain = (songId, channelId, volume) => {
            const gainNode = globalData.gainNodes?.[songId]?.[channelId];
            if (gainNode) {
                gainNode.gain.setValueAtTime(volume, globalData.audioContext.currentTime);
                console.log(`[GainNodeHelper] Updated gain for Channel "${channelId}" of Song "${songId}" to ${volume.toFixed(2)}.`);
            } else {
                console.warn(`[GainNodeHelper] No GainNode found for Channel "${channelId}" of Song "${songId}".`);
            }
        };

        /**
         * Cleans up GainNodes for a specific song.
         *
         * @param {string} songId - The ID of the song to clean up.
         */
        const cleanupGainNodes = (songId) => {
            const songGainNodes = globalData.gainNodes[songId];
            if (songGainNodes) {
                Object.values(songGainNodes).forEach(gainNode => gainNode.disconnect());
                delete globalData.gainNodes[songId];
                console.log(`[GainNodeHelper] Cleaned up GainNodes for Song ID: ${songId}`);
            } else {
                console.warn(`[GainNodeHelper] No GainNodes found to clean up for Song ID: ${songId}.`);
            }
        };

        return {
            createGainNodesForSong: (song) => initializeGainNodes(song, false),
            prepareNextSongGainNodes: (song) => initializeGainNodes(song, true),
            cleanupGainNodesForSong: (songId) => cleanupGainNodes(songId),
            setChannelGain: (songId, channelId, volume) => updateChannelGain(songId, channelId, volume),
            setMasteringControls: (controls) => Object.assign(masteringControls, controls)
        };
    })();
</script>

<!-- Main Script (main.js) -->
<script>
    /* 
    #region Main Script
    **Purpose:**
    [Unchanged: Comprehensive documentation as provided by the user]
    #endregion
    */
    
    (async () => {
        const globalData = window.globalData; // Ensure consistent access
        const audioContext = globalData.audioContext; // Standardize AudioContext access

        // // Embed the seed list directly
        // window.seedList = [
        //         '1378012087872054',
        //         '8577097119065499',
        //         '8651019588475341',
        //         '8651019588475378'
        //     ];
            

        function waitForEffects() {
            return new Promise((resolve) => {
                if (window.EffectsModule && window.EffectsModule.effectsConfig) {
                    resolve();
                } else {
                    document.addEventListener('effectsLoaded', resolve, { once: true });
                }
            });
        }
        await waitForEffects();
    

        // Adjustable controls for gain reduction when layering
        const layeringControls = {
            gainReductionPerLayer: 0.7, // Gain multiplier per additional layer (e.g., 0.7 reduces gain by 30% per layer)
            maxLayers: 4 // Maximum number of layers per channel to prevent excessive gain reduction
        };

        /**
         * Applies a series of audio effects to a given channel, ensuring volume consistency and balance.
         *
         * @param {Object} channel - The audio channel to apply effects to.
         * @param {number} index - The index of the channel.
         * @param {Object} newSong - The song object containing channel and sequence information.
         * @param {number} currentSequence - The current sequence number.
         * @param {number} bpm - Beats per minute of the song.
         * @param {Object} effectsContext - Context object to manage total gain and harmony channels.
         * @param {Function} prng - Pseudo-random number generator function.
         */
        function applyEffects(channel, index, newSong, currentSequence, bpm, effectsContext, prng) {
            const MAX_EFFECTS_PER_CHANNEL = 3; // Define a reasonable limit

            const duplicationEffects = new Set(['harmonize', 'delay', 'delayBpmLinked']); // Effects that duplicate layers

            const effectsMap = [
                { name: 'pitchShift', applyFn: (ch, params) => applyRandomPitchShift(ch, params, prng) },
                { name: 'harmonize', applyFn: (ch, params) => addHarmony(ch, index, newSong, params, effectsContext, prng) },
                { name: 'delay', applyFn: (ch, params) => applyIntermittentDelay(ch, params, bpm) },
                { name: 'reverse', applyFn: (ch, params) => applyReverseEffect(ch) },
                { name: 'filter', applyFn: (ch, params) => applyFilterEffect(ch, params, prng) },
                { name: 'tremolo', applyFn: (ch, params) => applyTremoloEffect(ch, params, prng) },
                { name: 'distortion', applyFn: (ch, params) => applyDistortionEffect(ch, params, prng) },
                { name: 'bitcrusher', applyFn: (ch, params) => applyBitcrusherEffect(ch, params, prng) },
                { name: 'pan', applyFn: (ch, params) => applyPanEffect(ch, params, prng) },
                { name: 'reverb', applyFn: (ch, params) => applyReverbEffect(ch, params, prng) },
                { name: 'volumeChange', applyFn: (ch, params) => applyVolumeChange(ch, params, prng) },
                { name: 'chorus', applyFn: (ch, params) => applyChorusEffect(ch, params, prng) },
                { name: 'leslie', applyFn: (ch, params) => applyLeslieEffect(ch, params, bpm, prng) },
                { name: 'delayBpmLinked', applyFn: (ch, params) => applyBpmLinkedDelay(ch, params, bpm, prng) },
            ];

            // Shuffle the effectsMap to randomize effect application order
            const shuffledEffects = effectsMap.sort(() => 0.5 - Math.random());

            let appliedEffectsCount = 0;

            // Iterate through each effect in the shuffledEffectsMap
            for (const effect of shuffledEffects) {
                if (appliedEffectsCount >= MAX_EFFECTS_PER_CHANNEL) break; // Stop if max effects reached

                const effectParams = window.EffectsModule.getEffectParams(effect.name, currentSequence, bpm, prng);
                if (effectParams) {
                    // Apply the effect to the channel
                    effect.applyFn(channel, effectParams);
                    appliedEffectsCount++;

                    // If the effect is a duplication effect, adjust gain accordingly
                    if (duplicationEffects.has(effect.name)) {
                        // Initialize layer count if not present
                        if (!effectsContext.channelLayers[channel.id]) {
                            effectsContext.channelLayers[channel.id] = 1; // Original layer
                        }

                        // Increment layer count
                        if (effectsContext.channelLayers[channel.id] < layeringControls.maxLayers) {
                            effectsContext.channelLayers[channel.id]++;
                        }

                        // Calculate the new gain based on the number of layers
                        const layers = effectsContext.channelLayers[channel.id];
                        const newGain = (1 / layers) * layeringControls.gainReductionPerLayer ** (layers - 1);

                        // Update the channel's metadata volume
                        channel.metadata.volume = newGain;

                        // Apply the new gain using GainNodeHelper
                        GainNodeHelper.setChannelGain(newSong.id, channel.id, newGain);

                        console.log(`[Effects][Song: "${newSong.id}"] Applied duplication effect "${effect.name}" to Channel "${channel.id}". Layers: ${layers}, New Gain: ${newGain.toFixed(2)}`);
                    }

                    // Logging the application of the effect with song and channel information
                    // console.log(`[Effects][Song: "${newSong.id}"] Applied effect "${effect.name}" to Channel "${channel.id}" with parameters:`, effectParams);
                }
            }

            // Define volume clamping constants
            const MIN_CHANNEL_VOLUME = 0.5; // Minimum volume factor to prevent channels from being too quiet
            const MAX_CHANNEL_VOLUME = 1.5; // Maximum volume factor to prevent channels from being too loud
            const MAX_TOTAL_GAIN = 1;       // Maximum total gain across all channels to prevent overall mix from being too loud

            // After applying all effects, perform volume normalization and clamping

            // Ensure the total gain across all channels does not exceed MAX_TOTAL_GAIN
            if (effectsContext.totalGain > MAX_TOTAL_GAIN) {
                const reductionFactor = MAX_TOTAL_GAIN / effectsContext.totalGain;
                channel.metadata.volume = (channel.metadata.volume || 1) * reductionFactor;

                // Log the normalization action with song and channel information
                console.log(`[Normalization][Song: "${newSong.id}"] Normalized Channel "${channel.id}" volume by factor ${reductionFactor.toFixed(2)} to maintain total gain within ${MAX_TOTAL_GAIN}.`);
            }

            // Update the total gain in the effects context
            effectsContext.totalGain += channel.metadata.volume || 1;

            // Clamp the channel's volume within defined bounds to maintain balance
            if (channel.metadata.volume < MIN_CHANNEL_VOLUME) {
                channel.metadata.volume = MIN_CHANNEL_VOLUME;
                console.log(`[Clamping][Song: "${newSong.id}"] Clamped Channel "${channel.id}" volume to minimum ${MIN_CHANNEL_VOLUME}.`);
            } else if (channel.metadata.volume > MAX_CHANNEL_VOLUME) {
                channel.metadata.volume = MAX_CHANNEL_VOLUME;
                // console.log(`[Clamping][Song: "${newSong.id}"] Clamped Channel "${channel.id}" volume to maximum ${MAX_CHANNEL_VOLUME}.`);
            }

            // Update the GainNode's gain value using GainNodeHelper
            GainNodeHelper.setChannelGain(newSong.id, channel.id, channel.metadata.volume || 1);
        }
            
                
        const loopSampleIds = new Set([
            "7c42769c1763cc8f045aada7914e8158223e45e7a4f197b49f918b1c005d36fci0",
            "3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0",
        ]);
    
        const keyNames = [
            "projectName",
            "artistName",
            "projectBPM",
            "currentSequence",
            "channelURLs",
            "channelVolume",
            "channelPlaybackSpeed",
            "trimSettings",
            "projectChannelNames",
            "startSliderValue",
            "endSliderValue",
            "totalSampleDuration",
            "start",
            "end",
            "projectSequences",
            "steps"
        ];
    
        const keyMap = keyNames.reduce((map, key, index) => {
            map[key] = index;
            return map;
        }, {});
    
        const channelIds = Array.from({ length: 16 }, (_, index) => String.fromCharCode(65 + index)); // 'A' to 'P'
        const channelIdMap = channelIds.reduce((map, id, index) => {
            map[id] = index;
            return map;
        }, {});
    
        const fetchAndProcessSongData = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network error for ${url}`);
                const compressedData = new Uint8Array(await response.arrayBuffer());
                const inflatedData = window.pako.inflate(compressedData);
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                const parsedData = JSON.parse(jsonString);
                const processParsedData = (data) => {
                    const recurse = (obj) => {
                        if (Array.isArray(obj)) {
                            return obj.map(recurse);
                        } else if (obj && typeof obj === "object") {
                            return Object.entries(obj).reduce((accumulator, [key, value]) => {
                                const mappedKey = keyNames[key] || key;
                                accumulator[mappedKey] = mappedKey === "projectSequences"
                                    ? Object.fromEntries(
                                        Object.entries(value).map(([seqKey, seqValue]) => {
                                            const sequenceName = `Sequence${seqKey.replace(/^s/, "")}`;
                                            const channels = Object.fromEntries(
                                                Object.entries(seqValue).map(([channelKey, channelValue]) => {
                                                    const steps = channelValue[keyMap.steps] || [];
                                                    const processedSteps = steps.flatMap((step) => {
                                                        if (typeof step === "number") {
                                                            return step;
                                                        } else if (step?.r) {
                                                            const [start, end] = step.r;
                                                            return Array.from({ length: end - start + 1 }, (_, idx) => start + idx);
                                                        } else if (typeof step === "string" && step.endsWith("r")) {
                                                            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
                                                        } else {
                                                            return [];
                                                        }
                                                    });
                                                    return [`ch${channelIdMap[channelKey]}`, { steps: processedSteps }];
                                                })
                                            );
                                            return [sequenceName, channels];
                                        })
                                    )
                                    : recurse(value);
                                return accumulator;
                            }, {});
                        } else {
                            return obj;
                        }
                    };
                    return recurse(data);
                };
                return processParsedData(parsedData);
            } catch (error) {
                console.error(`[Initialization] Error fetching/deserializing ${url}:`, error);
                throw error;
            }
        };
    
        const prepareInitialSampleOrder = ({ projectSequences }) => {
            const sampleSet = new Set();
            const sampleOrder = [];
            Object.keys(projectSequences)
                .sort((a, b) => +a.slice(9) - +b.slice(9))
                .forEach(seqK => {
                    Object.entries(projectSequences[seqK]).forEach(([chId, { steps }]) => {
                        steps.forEach(step => {
                            if (typeof step === "number" || step?.index !== undefined) {
                                const id = `${chId}_${step.reverse ? 'r' : 'f'}`;
                                if (!sampleSet.has(id)) {
                                    sampleSet.add(id);
                                    sampleOrder.push({ channelId: chId, reverse: step.reverse || false });
                                }
                            }
                        });
                    });
                });
            return sampleOrder;
        };
    
        const setArtworkImage = url => {
            const el = document.getElementById("artworkImage");
            if (el) {
                el.src = url;
                el.parentElement.style.display = "flex";
            }
        };
    
        const normalizeAudioBuffer = (audioBuffer) => {
            const numChannels = audioBuffer.numberOfChannels;
            let globalMaxAmplitude = 0;
    
            // First pass: Find the global maximum amplitude across all channels
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                const channelMax = Math.max(...channelData.map(sample => Math.abs(sample)));
                if (channelMax > globalMaxAmplitude) {
                    globalMaxAmplitude = channelMax;
                }
            }
    
            // Define target peak amplitude to prevent clipping
            const TARGET_PEAK = 0.95; // 0.95 to leave some headroom
    
            // Calculate normalization factor
            const normalizationFactor = globalMaxAmplitude > 0 ? TARGET_PEAK / globalMaxAmplitude : 1;
    
            // Apply normalization
            for (let i = 0; i < numChannels; i++) {
                const channelData = audioBuffer.getChannelData(i);
                for (let j = 0; j < channelData.length; j++) {
                    channelData[j] *= normalizationFactor;
                }
            }
    
            // console.log(`[Normalization] Applied normalization factor: ${normalizationFactor.toFixed(4)} to audio buffer.`);
            return audioBuffer;
        };
       
       
        // Define maximum cache size
        const MAX_CACHE_SIZE = 100; // Adjust based on available memory and application needs
    
        // Use a Map for sampleCache to maintain insertion order for LRU eviction
        const sampleCache = new Map();
    
        // Function to generate a unique key for each sample based on URL and processing parameters
        const generateSampleKey = (url, params = {}) => {
            let key = url;
            if (params.reversed) key += '_reversed';
            if (params.playbackSpeed && params.playbackSpeed !== 1) key += `_speed_${params.playbackSpeed}`;
            // Include other parameters as needed
            return key;
        };
    
        const loadAndProcessSample = async (url, params = {}) => {
            const key = generateSampleKey(url, params);
    
            if (sampleCache.has(key)) {
                // Move the used sample to the end to mark it as recently used
                const value = sampleCache.get(key);
                sampleCache.delete(key);
                sampleCache.set(key, value);
                console.log(`[Cache] Reusing cached sample: ${key}`);
                return value;
            }
    
            try {
                const response = await fetch(url);
                if (!response.ok) {
                    throw new Error(`Failed to fetch sample from ${url}: ${response.statusText}`);
                }
    
                const arrayBuffer = await response.arrayBuffer();
    
                let audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    
                // Normalize the audio buffer
                audioBuffer = normalizeAudioBuffer(audioBuffer);
    
                // Apply processing if needed
                if (params.reversed) {
                    for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                        Array.prototype.reverse.call(audioBuffer.getChannelData(i));
                    }
                    // console.log(`[Processing] Reversed audio buffer for key: ${key}`);
                }
    
                if (params.playbackSpeed && params.playbackSpeed !== 1) {
                    // Implement time-stretching or pitch-shifting as needed
                    // Placeholder: Log that playbackSpeed is being applied
                    // console.log(`[Processing] Applying playback speed ${params.playbackSpeed} for key: ${key}`);
                    // Actual implementation would require more complex audio processing
                }
    
                // Add to cache
                sampleCache.set(key, audioBuffer);
                // console.log(`[Cache] Added sample to cache: ${key}`);
    
                // Evict least recently used samples if cache size exceeds limit
                if (sampleCache.size > MAX_CACHE_SIZE) {
                    const oldestKey = sampleCache.keys().next().value;
                    sampleCache.delete(oldestKey);
                    console.log(`[Cache] Evicted oldest sample from cache: ${oldestKey}`);
                }
    
                return audioBuffer;
            } catch (error) {
                console.error(`[LoadAndProcessSample] Error processing sample from ${url}:`, error);
                throw error; // Re-throw to allow higher-level handling
            }
        };
    
        // **New Function: generateMuteSchedule**
        const generateMuteSchedule = (prng, totalSequences) => {
            const muteSchedule = [];
            const evenSequences = [];
            for (let seq = 2; seq <= totalSequences; seq += 2) {
                evenSequences.push(seq);
            }
    
            evenSequences.forEach(seq => {
                // Decide whether to mute or unmute at this sequence
                const action = prng() < 0.5 ? 'mute' : 'unmute';
                // Decide number of channels to affect (1 to 4)
                const numChannels = Math.floor(prng() * 4) + 1;
                // Placeholder: actual channel selection will be handled during mix generation
                muteSchedule.push({ sequence: seq, action, numChannels });
            });
    
            return muteSchedule;
        };
    
        const validSongDataUrls = songDataUrls.filter((url) => url.trim() && !url.trim().startsWith("//"));
    
        if (validSongDataUrls.length) {
            if (!window.pako) {
                await (async function loadPako() {
                    try {
                        const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
                        const textContent = await response.text();
                        const scriptElement = new DOMParser().parseFromString(textContent, "text/html").querySelector("script");
                        if (!scriptElement || !scriptElement.textContent.includes("pako")) {
                            throw new Error("Pako library not found.");
                        }
                        document.head.append(
                            Object.assign(document.createElement("script"), { textContent: scriptElement.textContent })
                        );
                        console.log("[Initialization] Pako library loaded successfully.");
                    } catch (error) {
                        console.error("[Initialization] Error loading Pako:", error);
                    }
                })();
            }
            const songDataArray = await Promise.all(
                validSongDataUrls.map(async (url, index) => {
                    try {
                        const data = await fetchAndProcessSongData(url);
                        return { data, index };
                    } catch (error) {
                        console.error(`[Initialization] Failed to fetch/process ${url}:`, error);
                        return null;
                    }
                })
            ).then(dataArray => {
                const validDataArray = dataArray.filter(Boolean);
                if (!validDataArray.length) throw new Error("[Initialization] No valid data.");
                return validDataArray;
            });
    
            const originalSongs = songDataArray
                .sort((a, b) => a.index - b.index)
                .map(({ data, index }) => {
                    const {
                        projectName = "The Infinite Ordinal",
                        artistName = "melophonic",
                        projectBPM = 120,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = data;
    
                    const channels = channelIds.map((id, idx) => {
                        const channelSequence = Object.entries(projectSequences).reduce((acc, [sequenceName, sequenceData]) => {
                            const channelData = sequenceData[`ch${idx}`];
                            if (channelData) acc.push({ sequenceName, steps: channelData.steps });
                            return acc;
                        }, []);
                        const metadata = {
                            volume: channelVolume[idx] ?? 1,
                            playbackSpeed: channelPlaybackSpeed[idx] ?? 1,
                            trimStartTime_Percentage: trimSettings[idx]?.start || 0,
                            trimEndTime_Percentage: trimSettings[idx]?.end || 100,
                            requiresReversal: channelSequence.some(seq => seq.steps.some(step => typeof step === "object" && step.reverse)),
                            channelSequence,
                            originalBPM: projectBPM
                        };
                        const sampleId = channelURLs[idx];
                        if (loopSampleIds.has(sampleId)) {
                            metadata.isLoop = true;
                        }
                        return { id, url: sampleId || "URL_not_found", metadata };
                    });
                    return {
                        id: `Song ${index + 1}: ${projectName}`,
                        artist: artistName,
                        bpm: projectBPM,
                        totalSequences: Object.keys(projectSequences).length,
                        totalChannels: channels.length,
                        channels,
                        projectSequences
                    };
                });
    
            const allChannels = originalSongs.flatMap(song => song.channels);
    
            function lcg64(seed) {
                let state = seed;
                const a = 6364136223846793005n;
                const c = 1442695040888963407n;
                const m = 18446744073709551616n; // 2^64
                return function() {
                    state = (a * state + c) % m;
                    return Number(state) / Number(m);
                }
            }
    
            const getRandomChannels = (channelsArray, num, prng) => {
                const shuffled = [...channelsArray];
                for (let i = shuffled.length - 1; i > 0; i--) {
                    const j = Math.floor(prng() * (i + 1));
                    [shuffled[i], shuffled[j]] = [shuffled[j], shuffled[i]];
                }
                return shuffled.slice(0, num);
            };
    
           
     /**
         * Generates a random 16-digit seed string.
         *
         * @returns {string} - A 16-digit random seed.
         */
         function generateRandomSeed() {
            let seed = '';
            for (let i = 0; i < 16; i++) {
                seed += Math.floor(Math.random() * 10).toString();
            }
            return seed;
        }

        /**
         * Generates a list of sequential seeds starting from the initial seed.
         *
         * @param {string} initialSeed - The starting 16-digit seed.
         * @param {number} count - Number of sequential seeds to generate.
         * @returns {string[]} - An array of 16-digit sequential seeds.
         */
        function generateSequentialSeeds(initialSeed, count = 100) {
            const seeds = [initialSeed];
            let seedNumber;
            try {
                seedNumber = BigInt(initialSeed);
            } catch (error) {
                console.error(`[Seed Generation] Invalid initial seed "${initialSeed}". Defaulting to 0n.`);
                seedNumber = 0n;
            }

            for (let i = 1; i < count; i++) {
                seedNumber += 1n;
                let newSeed = seedNumber.toString();
                if (newSeed.length < 16) {
                    newSeed = newSeed.padStart(16, '0');
                } else if (newSeed.length > 16) {
                    newSeed = newSeed.slice(-16); // Keep the last 16 digits
                }
                seeds.push(newSeed);
            }
            return seeds;
        }

        /**
         * Initializes the seedList based on user-provided seeds.
         * - If no seeds are provided, generate a random seed and create 100 sequential seeds.
         * - If one seed is provided, generate 99 additional sequential seeds from it.
         * - If multiple seeds are provided, use them as-is.
         */
        function initializeSeedList() {
            if (window.seedList && window.seedList.length > 1) {
                // Multiple seeds provided; use as-is.
                console.log(`[Seed Initialization] Using user-provided seedList with ${window.seedList.length} seeds.`);
            } else if (window.seedList && window.seedList.length === 1) {
                // Single seed provided; generate 99 additional sequential seeds.
                const initialSeed = window.seedList[0];
                const additionalSeeds = generateSequentialSeeds(initialSeed, 100).slice(1); // Exclude the initial seed
                window.seedList = window.seedList.concat(additionalSeeds);
                console.log(`[Seed Initialization] Single seed provided. Generated 99 additional sequential seeds from "${initialSeed}". Total seeds: ${window.seedList.length}.`);
            } else {
                // No seeds provided; generate a random seed and 99 additional sequential seeds.
                const randomSeed = generateRandomSeed();
                window.seedList = generateSequentialSeeds(randomSeed, 100);
                console.log(`[Seed Initialization] No user-provided seeds. Generated random seed "${randomSeed}" and created ${window.seedList.length} sequential seeds.`);
            }
        }

        // **Seed List Initialization (Moved Outside the 'if' Block)**
        initializeSeedList();

        // **Proceed with Mix Generation**
        async function generateMixBySeed(seedString) {
            console.log(`[debugSeed][generateMixBySeed] Generating mix with seed "${seedString}"`);
            const bpmOptions = [60, 120, 140, 160, 180, 240];
            const newSongs = [];

            // Initialize base seed with error handling
            let baseSeed;
            try {
                baseSeed = BigInt(seedString);
            } catch (error) {
                console.error(`[seedDebug] Invalid seed string: "${seedString}". Using base seed 0.`);
                baseSeed = 0n;
            }

            const currentSeed = baseSeed || 1n;

            // Function to derive BPM from a seed using PRNG
            const getBPMFromSeed = (seed) => {
                const prng = lcg64(seed);
                return bpmOptions[Math.floor(prng() * bpmOptions.length)];
            };

            const prng = lcg64(currentSeed);
            const selectedBPM = getBPMFromSeed(currentSeed);

            // Select random channels for the mix
            const randomChannels = getRandomChannels(allChannels, 24, prng);

            // Activation points and sequences
            const activationPoints = [
                { startSeq: 1, count: 4 },
                { startSeq: 5, count: 8 },
                { startSeq: 9, count: 12 },
                { startSeq: 13, count: 16 }
            ];

            // Assign activation sequences to channels
            const channelsWithActivation = activationPoints.flatMap(({ startSeq, count }) =>
                Array.from({ length: count }, (_, i) => {
                    const channel = randomChannels[i];
                    return channel ? { channel: JSON.parse(JSON.stringify(channel)), activationSeq: startSeq } : null;
                }).filter(Boolean)
            );

            // Collect unique sequence names from channels
            const sequenceSet = new Set(
                channelsWithActivation.flatMap(({ channel }) =>
                    channel.metadata.channelSequence?.map(seq => seq.sequenceName) || []
                )
            );

            // Sort sequences numerically based on their suffix
            let sequences = [...sequenceSet].sort((a, b) =>
                (parseInt(a.replace('Sequence', '')) || 0) - (parseInt(b.replace('Sequence', '')) || 0)
            );

            // Limit the number of sequences to 44
            sequences = sequences.slice(0, 44);

            // Initialize the new song object
            const newSong = {
                id: `The Infinite Ordinal Remix #${seedString}`,
                projectName: `The Infinite Ordinal`,
                artist: `melophonic`,
                bpm: selectedBPM,
                totalSequences: sequences.length,
                totalChannels: channelsWithActivation.length,
                channels: [],
                projectSequences: Object.fromEntries(sequences.map(seq => [seq, {}])),
                seed: seedString,
                muteSchedule: [] // Retain for other dynamic muting purposes if needed
            };

        // Initialize effects context for the song
        const effectsContext = {
            harmonyChannelsAdded: 0,
            maxHarmonyChannels: window.EffectsModule?.effectsConfig?.harmonize?.maxHarmonyChannels || 2,
            totalGain: 0,
            maxTotalGain: 1,
            channelLayers: {} // Track layers per channel
        };

            // Assign activationSeq to channels and set isMuted=true
            await Promise.all(channelsWithActivation.map(async ({ channel, activationSeq }, index) => {
                const chId = `ch${index}`; // Ensure unique channel IDs within the song
                const newChannel = {
                    id: chId,
                    url: channel.url,
                    metadata: {
                        ...channel.metadata,
                        originalBPM: newSong.bpm,
                        activationSeq,
                        isMuted: true // Initialize as muted
                    }
                };
                await applyEffects(newChannel, index, newSong, activationSeq, newSong.bpm, effectsContext, prng);
                newSong.channels.push(newChannel);

                // Map sequences to the new channel
                channel.metadata.channelSequence?.forEach(seqData => {
                    if (newSong.projectSequences[seqData.sequenceName]) {
                        newSong.projectSequences[seqData.sequenceName] = {
                            ...newSong.projectSequences[seqData.sequenceName],
                            [chId]: { steps: seqData.steps }
                        };
                    }
                });
            }));

            // Add the new song to the songs list
            newSongs.push(newSong);

            return newSongs;
        }

        /**
         * Generates song mixes based on a list of seeds.
         *
         * @param {string[]} seedList - The list of seed strings for PRNG.
         * @returns {Promise<Array>} - A promise that resolves to an array of generated songs.
         */
        async function generateMixesForSeedList(seedList) {
            const newSongs = [];

            for (const seedString of seedList) {
                const songs = await generateMixBySeed(seedString);
                newSongs.push(...songs);
            }

            return newSongs;
        }

        // **Proceed with Mix Generation**
        const generatedSongs = await generateMixesForSeedList(window.seedList);
        console.log(`[Mix Generation] Generated ${generatedSongs.length} songs based on seedList.`);

        // Assign songs to globalData once
        if (!globalData.initialized) {
            Object.assign(globalData, {
                songsArray: generatedSongs,
                songsByBPM: globalData.songsByBPM || {},
                currentSongIndex: 0,
                currentSequenceIndex: 0,
                initialSampleOrder: generatedSongs.length ? prepareInitialSampleOrder(generatedSongs[0]) : null,
                isSingleSong: generatedSongs.length === 1,
                isMultipleSongs: generatedSongs.length > 1,
                initialized: true
            });
        }

        // Initialize GainNodes for all generated songs once
        globalData.songsArray.forEach(song => {
            GainNodeHelper.createGainNodesForSong(song);
        });

        // Set artwork image if applicable
        if (globalData.isArtworkCover && artworkUrl.length) setArtworkImage(artworkUrl[0]);

        // Dispatch data loading completion event
        document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
            detail: {
                success: true,
                totalSongs: globalData.songsArray.length,
                songs: globalData.songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
            }
        }));

        // Expose generateMixBySeed to the global scope if needed
        window.generateMixBySeed = generateMixBySeed;
        }
        
    
    })();
    

</script>



<!-- audioProcessingAndManagement -->
<script>
    (async () => {
    // Initialize or retrieve the globalData object
    const globalData = window.globalData || (window.globalData = {});

    // Initialize or retrieve the AudioContext
    const audioContext = globalData.audioContext || (globalData.audioContext = new (window.AudioContext || window.webkitAudioContext)());

  
    /**
     * Converts a base64 string to an ArrayBuffer.
     *
     * @param {string} base64 - The base64 encoded string.
     * @returns {ArrayBuffer} - The resulting ArrayBuffer.
     */
    const base64ToArrayBuffer = (base64) => {
        return Uint8Array.from(atob(base64), (char) => char.charCodeAt(0)).buffer;
    };

    /**
         * Extracts base64 data from JSON or HTML content.
         *
         * @param {string|Object} data - The input data (JSON object or HTML string).
         * @param {string} type - The type of data ("json" or "html").
         * @returns {string|null} - The extracted base64 string or null if not found.
         */
        const extractBase64 = (data, type) => {
            if (type === "json" && data.audioData) {
                const match = data.audioData.match(/base64,([A-Za-z0-9+/=]+)/);
                return match ? match[1] : null;
            }
            if (type === "html") {
                try {
                    const parser = new DOMParser();
                    const doc = parser.parseFromString(data, "text/html");
                    const source = doc.querySelector('source[src^="data:audio/"]');
                    if (source && source.src) {
                        const src = source.src;
                        const base64Match = src.match(/base64,([^"]+)/);
                        return base64Match ? base64Match[1] : null;
                    }
                    return null;
                } catch (error) {
                    console.error(`[extractBase64][Error] Failed to parse HTML: ${error.message}`);
                    return null;
                }
            }
            return null;
        };

    /**
     * Validates whether a string is a valid base64 encoded string.
     *
     * @param {string} str - The string to validate.
     * @returns {boolean} - True if valid base64, false otherwise.
     */
    const isValidBase64 = (str) => {
        const cleaned = str.replace(/\s+/g, "");
        return cleaned.length % 4 === 0 && /^[A-Za-z0-9+/]+={0,2}$/.test(cleaned);
    };

    /**
     * Normalizes an AudioBuffer to a specified maximum volume.
     *
     * @param {AudioBuffer} audioBuffer - The AudioBuffer to normalize.
     * @param {number} maxVolume - The target maximum volume (default is 0.5).
     * @returns {AudioBuffer} - The normalized AudioBuffer.
     */
    const normalizeAudioBuffer = (audioBuffer, maxVolume = 0.5) => {
        let maxAmplitude = 0;

        // Find the global maximum amplitude across all channels
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
            const channelData = audioBuffer.getChannelData(channel);
            for (const sample of channelData) {
                const absSample = Math.abs(sample);
                if (absSample > maxAmplitude) {
                    maxAmplitude = absSample;
                }
            }
        }

        // Calculate the normalization factor
        const normalizationFactor = maxAmplitude > 0 ? maxVolume / maxAmplitude : 1;

        // Apply normalization if necessary
        if (normalizationFactor !== 1) {
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const channelData = audioBuffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    channelData[i] *= normalizationFactor;
                }
            }
            // console.log(`Normalized AudioBuffer to ${maxVolume} with factor ${normalizationFactor.toFixed(4)}`);
        }

        return audioBuffer;
    };

    /**
     * Reverses the audio data in a Float32Array.
     *
     * @param {Float32Array} audioData - The audio data to reverse.
     * @returns {Float32Array} - The reversed audio data.
     */
    const reverseAudioData = (audioData) => {
        const reversedData = new Float32Array(audioData.length);
        for (let i = 0, len = audioData.length; i < len; i++) {
            reversedData[i] = audioData[len - i - 1];
        }
        return reversedData;
    };

    /**
     * Extracts the file name from a URL.
     *
     * @param {string} url - The URL string.
     * @returns {string} - The extracted file name or "Unknown" if not found.
     */
    const getFileNameFromURL = (url) => {
        return url.split("/").pop() || "Unknown";
    };

    /**
 * Processes an individual audio channel by fetching, decoding, trimming, and optionally reversing the audio data.
 *
 * @param {Object} song - The song object containing channel information.
 * @param {Object} channel - The channel object containing metadata and URL.
 * @param {Array} processedChannels - An array to store information about processed channels.
 */
const processChannel = async (song, channel, processedChannels) => {
    const { id: songId, channels } = song;
    const { id: channelId, url: channelURL, metadata: { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } } = channel;

    try {
        // console.log(`\n[ProcessChannel] Starting processing for Song ID: "${songId}", Channel ID: "${channelId}", URL: "${channelURL}"`);

        // Fetch the audio data from the channel URL
        const response = await fetch(channelURL);
        if (!response.ok) {
            console.error(`[ProcessChannel][Song: "${songId}"] Fetch failed for URL: "${channelURL}" - Status: ${response.status} ${response.statusText}. Skipping Channel ID: "${channelId}".`);
            return;
        }
        // console.log(`[ProcessChannel][Song: "${songId}"] Successfully fetched data from URL: "${channelURL}".`);

        const contentType = response.headers.get("Content-Type") || "";
        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Content-Type: "${contentType}".`);

        // Decode the audio data based on the content type
        const audioBuffer = await decodeAudioData(response, contentType, channelURL, songId, channelId);
        if (!audioBuffer) {
            console.error(`[ProcessChannel][Song: "${songId}"] Decoding failed for Channel ID: "${channelId}". Skipping.`);
            return;
        }

        // Validate trim percentages
        if (trimEndTime_Percentage <= trimStartTime_Percentage) {
            console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Invalid trim percentages - Start: ${trimStartTime_Percentage}%, End: ${trimEndTime_Percentage}%. Skipping.`);
            return;
        }

        // Calculate sample indices for trimming
        const startSample = Math.floor(trimStartTime_Percentage / 100 * audioBuffer.duration * audioBuffer.sampleRate);
        const endSample = Math.floor(trimEndTime_Percentage / 100 * audioBuffer.duration * audioBuffer.sampleRate);
        const trimmedLength = endSample - startSample;

        if (trimmedLength <= 0) {
            console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Non-positive trimmed length: ${trimmedLength} samples. Skipping.`);
            return;
        }

        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Trimming audio - Start Sample: ${startSample}, End Sample: ${endSample}, Trimmed Length: ${trimmedLength} samples.`);

        // Create a new AudioBuffer for the trimmed audio
        const trimmedBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
        for (let channelIndex = 0; channelIndex < audioBuffer.numberOfChannels; channelIndex++) {
            trimmedBuffer.getChannelData(channelIndex).set(audioBuffer.getChannelData(channelIndex).subarray(startSample, endSample));
        }
        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Trimmed AudioBuffer created.`);

        // Normalize the trimmed AudioBuffer
        const normalizedBuffer = normalizeAudioBuffer(trimmedBuffer, 0.5);
        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Normalized AudioBuffer.`);

        // Initialize audioBuffers and reverseAudioBuffers in globalData if not present
        globalData.audioBuffers = globalData.audioBuffers || {};
        globalData.reverseAudioBuffers = globalData.reverseAudioBuffers || {};
        globalData.audioBuffers[songId] = globalData.audioBuffers[songId] || {};
        globalData.reverseAudioBuffers[songId] = globalData.reverseAudioBuffers[songId] || {};

        // Store the normalized AudioBuffer
        globalData.audioBuffers[songId][channelId] = normalizedBuffer;
        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Normalized AudioBuffer stored.`);

        // If reversal is required, create and store the reversed AudioBuffer
        if (requiresReversal) {
            try {
                const reversedBuffer = createReversedAudioBuffer(normalizedBuffer);
                globalData.reverseAudioBuffers[songId][channelId] = reversedBuffer;
                // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Reversed AudioBuffer created and stored.`);
            } catch (reverseError) {
                console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Error reversing AudioBuffer: ${reverseError.message}`);
            }
        }

        // Push processed channel information to the array
        processedChannels.push({
            "Song ID": songId,
            "Channel ID": channelId,
            "Audio File": getFileNameFromURL(channelURL),
            "Full Duration (s)": audioBuffer.duration.toFixed(2),
            "Trimmed Duration (s)": trimmedBuffer.duration.toFixed(2),
            "Requires Reversal": requiresReversal
        });

        // console.log(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Processing completed successfully.`);
    } catch (error) {
        console.error(`[ProcessChannel][Song: "${songId}", Channel: "${channelId}"] Unexpected error: ${error.message}`);
    }
};

/**
 * Decodes audio data based on content type.
 *
 * @param {Response} response - The fetch response object.
 * @param {string} contentType - The Content-Type of the response.
 * @param {string} url - The URL being fetched.
 * @param {string} songId - The ID of the song.
 * @param {string} channelId - The ID of the channel.
 * @returns {Promise<AudioBuffer|null>} - The decoded AudioBuffer or null if decoding failed.
 */
 const decodeAudioData = async (response, contentType, url, songId, channelId) => {
    const cache = globalData.audioFetchCache || (globalData.audioFetchCache = new Map());

    // Check if the audio data is already cached
    if (cache.has(url)) {
        // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Retrieved AudioBuffer from cache for URL: "${url}".`);
        return cache.get(url);
    }

    try {
        let decodedBuffer;

        // Handle data URI
        if (url.startsWith('data:audio/')) {
            const base64Data = url.split(',')[1];
            if (!isValidBase64(base64Data)) {
                console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid base64 data in data URI for URL: "${url}".`);
                return null;
            }
            const arrayBuffer = base64ToArrayBuffer(base64Data);
            decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoded audio from data URI: "${url}".`);
        }
        else if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
            const arrayBuffer = await response.arrayBuffer();
            decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoded audio from URL: "${url}".`);
        }
        else if (/application\/json/.test(contentType)) {
            const jsonData = await response.json();
            const base64Data = extractBase64(jsonData, "json");
            if (!base64Data || !isValidBase64(base64Data)) {
                // console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid or missing base64 data in JSON for URL: "${url}".`);
                return null;
            }
            const arrayBuffer = base64ToArrayBuffer(base64Data);
            decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoded JSON audio from URL: "${url}".`);
        }
        else if (/text\/html/.test(contentType)) {
            const htmlData = await response.text();
            const base64Data = extractBase64(htmlData, "html");
            if (!base64Data || !isValidBase64(base64Data)) {
                console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Invalid or missing base64 data in HTML for URL: "${url}".`);
                return null;
            }
            const arrayBuffer = base64ToArrayBuffer(base64Data);
            decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoded HTML audio from URL: "${url}".`);
        }
        else {
            if (!/audio\//.test(contentType)) {
                console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Unsupported content type: "${contentType}" for URL: "${url}".`);
                return null;
            }
            const arrayBuffer = await response.arrayBuffer();
            decodedBuffer = await audioContext.decodeAudioData(arrayBuffer);
            // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoded audio from URL: "${url}".`);
        }

        // Cache the decoded audio buffer
        cache.set(url, decodedBuffer);
        // console.log(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Cached AudioBuffer for URL: "${url}".`);

        return decodedBuffer;
    } catch (error) {
        console.error(`[decodeAudioData][Song: "${songId}", Channel: "${channelId}"] Decoding error for URL: "${url}" - ${error.message}`);
        return null;
    }
};

/**
 * Creates a reversed AudioBuffer from a given AudioBuffer.
 *
 * @param {AudioBuffer} originalBuffer - The original AudioBuffer to reverse.
 * @returns {AudioBuffer} - The reversed AudioBuffer.
 */
const createReversedAudioBuffer = (originalBuffer) => {
    const reversedBuffer = audioContext.createBuffer(originalBuffer.numberOfChannels, originalBuffer.length, originalBuffer.sampleRate);
    for (let channelIndex = 0; channelIndex < originalBuffer.numberOfChannels; channelIndex++) {
        const originalData = originalBuffer.getChannelData(channelIndex);
        const reversedData = reversedBuffer.getChannelData(channelIndex);
        for (let i = 0; i < originalData.length; i++) {
            reversedData[i] = originalData[originalData.length - i - 1];
        }
    }
    // console.log(`[createReversedAudioBuffer] Reversed AudioBuffer created.`);
    return normalizeAudioBuffer(reversedBuffer, 0.5);
};

    /**
     * Displays processed channel information in the console.
     *
     * @param {Array} processedChannels - An array of processed channel information.
     */
    const displayProcessedChannels = (processedChannels) => {
        if (processedChannels.length) {
            console.table(processedChannels);
        } else {
            console.warn("No audio samples processed.");
        }
    };

     /**
         * Processes the initial sample order by fetching and decoding the necessary audio channels.
         */
         const processInitialSamples = async () => {
            const { songsArray, initialSampleOrder } = globalData;

            if (!songsArray.length) {
                console.error("No songs to process.");
                return;
            }

            const processedChannels = [];

            // Group initialSampleOrder by songId
            const songsMap = new Map();
            initialSampleOrder.forEach(sampleOrder => {
                if (!songsMap.has(sampleOrder.songId)) {
                    songsMap.set(sampleOrder.songId, []);
                }
                songsMap.get(sampleOrder.songId).push(sampleOrder.channelId);
            });

            // Iterate over each song and process its channels
            for (const [songId, channelIds] of songsMap.entries()) {
                const song = songsArray.find(song => song.id === songId);
                if (!song) {
                    console.warn(`Song with ID ${songId} not found. Skipping.`);
                    continue;
                }

                const channelProcessingPromises = channelIds.map(channelId => {
                    const channel = song.channels.find(channel => channel.id === channelId);
                    if (channel) {
                        return processChannel(song, channel);
                    } else {
                        console.warn(`Channel with ID ${channelId} not found in song ${songId}. Skipping.`);
                        return null;
                    }
                });

                // Await all channel processing for the current song
                const results = await Promise.all(channelProcessingPromises);

                // Filter out any null results
                const validResults = results.filter(result => result !== null);
                processedChannels.push(...validResults);

                // Log once per song after all its channels have been processed
                console.log(`Processed Song: "${song.id}" with ${validResults.length} channels.`);
            }

            // Display all processed channels
            displayProcessedChannels(processedChannels);

            console.log("Initial audio buffers ready.");

            // Initialize Master Gain
            const masterGain = audioContext.createGain();
            masterGain.gain.value = 0.7;
            masterGain.connect(audioContext.destination);
            globalData.masterGain = masterGain;

            console.log("Master Gain initialized with gain:", masterGain.gain.value);

            // Dispatch event indicating initial audio buffers are ready
            document.dispatchEvent(new CustomEvent("initialAudioBuffersReady", {
                detail: { success: true }
            }));
        };


    /**
     * Initializes the audio processing by handling event listeners and processing sequences.
     */
    const initializeAudioProcessing = async () => {
        try {
            // Resume AudioContext if it is suspended
            if (audioContext.state === "suspended") {
                await audioContext.resume();
            }

            // Process initial samples
            await processInitialSamples();

            // Background processing for additional audio buffers
            try {
                const { songsArray, initialSampleOrder } = globalData;

                if (!songsArray.length) {
                    console.error("No songs to process.");
                    return;
                }

                const additionalProcessedChannels = [];

                // Flatten all channels from all songs
                const allChannels = songsArray.flatMap(song => song.channels.map(channel => ({ song, channel })));

                // Create a set of already processed songId-channelId combinations
                const initialProcessedSet = new Set(initialSampleOrder.map(sample => `${sample.songId}-${sample.channelId}`));

                // Filter out channels that have already been processed
                const channelsToProcess = allChannels.filter(({ song, channel }) => !initialProcessedSet.has(`${song.id}-${channel.id}`));

                const batches = [];

                // Batch channels into groups of 4 for processing
                while (channelsToProcess.length) {
                    batches.push(channelsToProcess.splice(0, 4));
                }

                // Process each batch sequentially
                for (const batch of batches) {
                    await Promise.all(batch.map(({ song, channel }) => processChannel(song, channel, additionalProcessedChannels)));
                }

                // Display additional processed channels
                displayProcessedChannels(additionalProcessedChannels);

                console.log("All background audio buffers processed.");

                // Dispatch event indicating all audio buffers are ready
                document.dispatchEvent(new CustomEvent("allAudioBuffersReady", {
                    detail: { success: true }
                }));
            } catch (error) {
                console.error("Background processing error:", error);
            }
        } catch (error) {
            console.error("Audio processing initialization error:", error);
        }
    };

    // Event listener for data loading completion to start audio processing
    document.addEventListener("dataLoadingComplete", initializeAudioProcessing);

    // Automatically initialize audio processing if songs are already loaded
    if (globalData.songsArray?.length) {
        initializeAudioProcessing();
    }

    // Event listener for initial audio buffers ready
    document.addEventListener("initialAudioBuffersReady", () => {
        console.log("Initial buffers ready. Press 'P' to play.");
    });
})();
</script>


<!-- unifiedMetadataManagement -->
<script>
    // unifiedMetadataManagement.js
    (() => {
    /**
     * Extracts the project name from a song ID using a regular expression.
     *
     * @param {string} songId - The ID of the song.
     * @returns {string} - The extracted project name or "UNKNOWN PROJECT NAME" if not found.
     */
    const extractProjectName = (songId) => {
        const match = songId?.match(/Song\s+\d+:\s+(.+)/);
        return match?.[1]?.trim() || "UNKNOWN PROJECT NAME";
    };

    /**
     * Retrieves the artist name based on the project name from the artist map.
     *
     * @param {string} projectName - The name of the project.
     * @param {Object} artistMap - A mapping of project names to artist names.
     * @param {string} defaultArtist - The default artist name if not found in the map.
     * @returns {string} - The artist name associated with the project or a default value.
     */
    const getArtistName = (projectName, artistMap, defaultArtist) => {
        return artistMap?.[projectName] || defaultArtist || "Unknown Artist Name";
    };

    /**
     * Processes an array of songs to extract and display their metadata.
     *
     * @param {Array} songs - An array of song objects to process.
     */
    const processSongs = (songs) => {
        if (!Array.isArray(songs) || songs.length === 0) {
            console.warn("No songs data available to process.");
            return;
        }

        // Extract project and artist information for each song
        const processedSongs = extractSongMetadata(songs);

        // Update the metadata content in the DOM
        updateMetadataContent(processedSongs);

        // Log the processed songs' metadata
        logProcessedSongs(processedSongs);
    };

    /**
     * Extracts metadata (track number, project name, artist name) from the songs array.
     *
     * @param {Array} songs - An array of song objects.
     * @returns {Array} - An array of processed song metadata.
     */
    const extractSongMetadata = (songs) => {
        // Retrieve the artist map from globalData or fallback to an empty object
        const artistMap = window.globalData?.projectArtistMap || window.projectArtistMap || {};

        // Map each song to its metadata
        return songs.map((song, index) => ({
            trackNumber: index + 1,
            projectName: extractProjectName(song.id),
            artistName: getArtistName(extractProjectName(song.id), artistMap, song.artist)
        }));
    };

    /**
     * Updates the metadata content in the DOM with the processed song information.
     *
     * @param {Array} processedSongs - An array of processed song metadata.
     */
    const updateMetadataContent = (processedSongs) => {
        const metadataContainer = document.getElementById("metadataContent");
        if (!metadataContainer) {
            console.warn("Metadata content container (#metadataContent) not found.");
            return;
        }

        // Generate HTML for each song's metadata
        const metadataHTML = processedSongs.map(({ trackNumber, projectName, artistName }) => `
            <div class="metadataItem">
                <h2>${trackNumber}. ${projectName}</h2>
                <p>${artistName}</p>
            </div>
        `).join("");

        // Update the DOM with the generated HTML
        metadataContainer.innerHTML = metadataHTML;
    };

    /**
     * Logs the processed songs' metadata to the console.
     *
     * @param {Array} processedSongs - An array of processed song metadata.
     */
    const logProcessedSongs = (processedSongs) => {
        processedSongs.forEach(({ projectName, artistName }) => {
            // console.log(`Project Name: ${projectName}, Artist Name: ${artistName}`);
        });
    };

    /**
     * Initializes metadata management and logging by processing songs and setting up event listeners.
     */
    const initializeMetadataManagement = () => {
        // Check if songsArray is already available in globalData
        if (window.globalData?.songsArray?.length) {
            processSongs(window.globalData.songsArray);
        } else {
            // Listen for the 'dataLoadingComplete' event to process songs when data is available
            document.addEventListener("dataLoadingComplete", ({ detail: { songs } = {} }) => {
                processSongs(songs);
            });

            // Listen for keydown events to toggle the visibility of the track listing panel
            document.addEventListener("keydown", ({ key }) => {
                if (key.toLowerCase() === "t") {
                    toggleTrackListingPanel();
                }
            });
        }
    };

    /**
     * Toggles the visibility of the track listing panel in the DOM.
     */
    const toggleTrackListingPanel = () => {
        const trackListingPanel = document.getElementById("trackListingPanel");
        if (trackListingPanel) {
            trackListingPanel.classList.toggle("visible");
        } else {
            console.warn("Metadata panel container (#trackListingPanel) not found.");
        }
    };

    /**
     * Executes the initialization of metadata management and logging.
     */
    const executeInitialization = () => {
        try {
            initializeMetadataManagement();
        } catch (error) {
            console.error("Error initializing Metadata Management and Logging:", error);
        }
    };

    // Start the initialization process
    executeInitialization();
})();</script>



<!-- Load Player Scripts AFTER data loading is complete -->
<script>
      

        document.addEventListener("dataLoadingComplete", (event) => {
            const remainingScriptUrls = [


                "/content/5c03e882ab5a531271b2e93a80d8a9d72cb533c580bec1567020f5cd61595560i0", // projectArtistMapping
                "/content/7b305327f2951d219532ef0cb46b2039b23f2cfd0d8d0e827f3fe1b2b754b5a9i0", // DynamicGainBalancing
                "/content/8b5b09cfedbc0c6a187816181f8d33f90c5bbd15fc10af47008176effb866a47i0", // keyboardControlsAndEventListeners

                ];

            const loadScriptsSequentially = (urls) => {
                if (urls.length === 0) return;
                const src = urls.shift();
                const script = document.createElement("script");
                script.src = src;
                script.async = false;
                script.onload = () => loadScriptsSequentially(urls);
                script.onerror = (e) => {
                    console.error(`[Script Loader] Error loading script: ${src}`, e);
                    loadScriptsSequentially(urls);
                };
                document.body.appendChild(script);
            };

            loadScriptsSequentially([...remainingScriptUrls]);
            updateSeedDisplay(); // Update seed display after loading is complete
        });
</script>





<!-- Playback -->
<script>
    /*
    <details>
        <summary> How to Access Global Timing Information</summary>
        <p>The playback engine exposes global timing information through the <code>window.globalData</code> object. Other modules can access the following properties and events to monitor and interact with playback:</p>
        <ul>
            <li><strong>Playback Status:</strong> <code>window.globalData.isPlaying</code> - <em>Boolean</em> indicating if playback is active.</li>
            <li><strong>Current Song Index:</strong> <code>window.globalData.currentSongIndex</code> - <em>Number</em> representing the index of the currently playing song.</li>
            <li><strong>Current Sequence:</strong> <code>window.globalData.currentSequence</code> - <em>Number</em> indicating the currently active sequence.</li>
            <li><strong>Playback Events:</strong>
                <ul>
                    <li><code>'playbackStarted'</code> - Dispatched when playback starts.</li>
                    <li><code>'playbackStopped'</code> - Dispatched when playback stops.</li>
                </ul>
                <em>Use <code>document.addEventListener</code> to listen for these events.</em>
            </li>
            <li><strong>Audio Context Current Time:</strong> <code>window.globalData.audioContext.currentTime</code> - <em>Number</em> representing the current time of the AudioContext for precise timing.</li>
            <li><strong>Playback Control Methods:</strong>
                <ul>
                    <li><code>window.globalData.startPlayback()</code> - Starts playback.</li>
                    <li><code>window.globalData.stopPlayback()</code> - Stops playback.</li>
                    <li><code>window.globalData.togglePlayback()</code> - Toggles playback state.</li>
                    <li><code>window.globalData.resetPlayback()</code> - Resets and restarts playback.</li>
                </ul>
            </li>
        </ul>
        <p><strong>Example Usage:</strong></p>
        <pre><code>
// Check if playback is active
if (window.globalData.isPlaying) {
    console.log("Playback is currently active.");
}

// Listen for playback start
document.addEventListener("playbackStarted", (event) => {
    console.log("Playback has started.");
});

// Start playback
window.globalData.startPlayback();
        </code></pre>
    </details>
    */

    // playbackEngine.js
    (() => {
        // Initialize global data or use existing globalData
        const globalData = window.globalData || (window.globalData = {
            isPlaying: false,
            currentSongIndex: 0,
            songsArray: [],
            audioBuffers: {},
            reverseAudioBuffers: {},
            audioContext: new (window.AudioContext || window.webkitAudioContext)(),
            masterGain: null,
            gainNodes: {},
            isArtworkCover: true,
            isVisualiserCover: false,
            compressor: null,      // Compressor Node
            lowShelfFilter: null,  // Low-Shelf Filter Node
            analyser: null,        // AnalyserNode
            isAudioProcessingInitialized: false, // Flag to prevent re-initialization
            currentSeed: 1n        // Initialize seed as BigInt
        });

        // Initialize the current sequence counter
        globalData.currentSequence = 0;

        const { audioContext } = globalData;
        const scheduleAheadTime = 0.1; // Time in seconds to schedule ahead
        const schedulerInterval = 25;   // Interval in milliseconds for the scheduler

        let playbackInterval = null;
        let sequenceStates = {};

        const missingAudioBuffers = new Set();
        const activeAudioSources = new Set();

        let countdownInterval = null;

        /**
         * Initializes the audio processing chain with Compressor, Low-Shelf Filter, and AnalyserNode.
         */
        function initializeAudioProcessingChain() {
            if (globalData.isAudioProcessingInitialized) {
                console.log("[PlaybackEngine] Audio processing chain already initialized.");
                return;
            }

            // Initialize Compressor
            if (!globalData.compressor) {
                globalData.compressor = audioContext.createDynamicsCompressor();
                globalData.compressor.threshold.setValueAtTime(-24, audioContext.currentTime);
                globalData.compressor.knee.setValueAtTime(30, audioContext.currentTime);
                globalData.compressor.ratio.setValueAtTime(12, audioContext.currentTime);
                globalData.compressor.attack.setValueAtTime(0.003, audioContext.currentTime);
                globalData.compressor.release.setValueAtTime(0.25, audioContext.currentTime);
                console.log("[PlaybackEngine] Compressor node initialized.");
            }

            // Initialize Master Gain
            if (!globalData.masterGain) {
                globalData.masterGain = audioContext.createGain();
                globalData.masterGain.gain.setValueAtTime(1, audioContext.currentTime);
                globalData.masterGain.connect(globalData.compressor);
                console.log("[PlaybackEngine] Master Gain node created and connected to Compressor.");
            }

            // Initialize Low-Shelf Filter
            if (!globalData.lowShelfFilter) {
                globalData.lowShelfFilter = audioContext.createBiquadFilter();
                globalData.lowShelfFilter.type = "lowshelf";
                globalData.lowShelfFilter.frequency.setValueAtTime(50, audioContext.currentTime);
                globalData.lowShelfFilter.gain.setValueAtTime(-6, audioContext.currentTime);
                globalData.compressor.connect(globalData.lowShelfFilter);
                console.log("[PlaybackEngine] Low-shelf filter initialized and connected to Compressor.");
            }

            // Initialize AnalyserNode
            if (!globalData.analyser) {
                globalData.analyser = audioContext.createAnalyser();
                globalData.analyser.fftSize = 2048;
                globalData.analyser.smoothingTimeConstant = 0.8;
                globalData.lowShelfFilter.connect(globalData.analyser);
                console.log("[PlaybackEngine] Analyser node initialized and connected to Low-Shelf Filter.");
                globalData.analyser.connect(audioContext.destination);
                console.log("[PlaybackEngine] Analyser node connected to AudioContext destination.");
            }

            globalData.isAudioProcessingInitialized = true;
            console.log("[PlaybackEngine] Audio processing chain fully initialized.");

            setupBassMonitoring();
        }

        /**
         * Monitors low-frequency (bass) levels in real-time and adjusts the low-shelf filter accordingly.
         */
        function monitorLowFrequencies() {
            if (!globalData.analyser) {
                console.error("[monitorLowFrequencies] AnalyserNode is not initialized.");
                return;
            }

            if (!globalData.lowShelfFilter) {
                console.error("[monitorLowFrequencies] lowShelfFilter is not initialized.");
                return;
            }

            const bufferLength = globalData.analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            globalData.analyser.getByteFrequencyData(dataArray);

            const bassFrequency = 250;
            const nyquist = audioContext.sampleRate / 2;
            const bassBin = Math.floor(bassFrequency / nyquist * bufferLength);
            const bassLevels = dataArray.slice(0, bassBin);

            if (bassLevels.length === 0) {
                console.warn("[monitorLowFrequencies] No bass levels found.");
                return;
            }

            const averageBass = bassLevels.reduce((sum, value) => sum + value, 0) / bassLevels.length;
            const bassThreshold = 100;

            if (averageBass > bassThreshold) {
                const newGain = globalData.lowShelfFilter.gain.value - 0.5;
                globalData.lowShelfFilter.gain.setValueAtTime(newGain, audioContext.currentTime);
            } else if (averageBass < bassThreshold - 20) {
                const newGain = globalData.lowShelfFilter.gain.value + 0.5;
                globalData.lowShelfFilter.gain.setValueAtTime(newGain, audioContext.currentTime);
            }
        }

        /**
         * Sets up the monitoring loop using requestAnimationFrame for smoother updates.
         */
        function setupBassMonitoring() {
            if (!globalData.analyser) {
                console.error("[setupBassMonitoring] AnalyserNode is not available.");
                return;
            }

            function monitoringLoop() {
                monitorLowFrequencies();
                requestAnimationFrame(monitoringLoop);
            }

            monitoringLoop();
            console.log("[setupBassMonitoring] Bass monitoring loop initiated.");
        }

        /**
         * Function to start playback
         */
        function startPlayback() {
            const { songsArray, currentSongIndex } = globalData;

            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }

            const song = songsArray[currentSongIndex % songsArray.length];
            const projectSequences = song.projectSequences || {};
            const stepDuration = 60 / song.bpm / 4;
            const sequenceDuration = 64 * stepDuration;

            globalData.currentSongIndex %= songsArray.length;
            sequenceStates = {};
            missingAudioBuffers.clear();

            console.log(`Starting playback for Song: ${song.id} (${globalData.currentSongIndex + 1}/${songsArray.length}) with ${Object.keys(projectSequences).length} sequences.`);
            console.log(`Song BPM: ${song.bpm}`);

            if (window.synth && typeof window.synth.updateBPM === 'function') {
                window.synth.updateBPM(song.bpm);
                console.log(`Synth BPM updated to ${song.bpm} BPM.`);
            } else {
                console.warn("Synth instance not found or updateBPM method unavailable.");
            }

            let sequenceStartTimeOffset = 0;
            let orderedSequenceNumber = 1;

            for (const [sequenceId, sequenceData] of Object.entries(projectSequences)) {
                sequenceStates[sequenceId] = {
                    sequenceNumber: orderedSequenceNumber,
                    nextStepIndex: 0,
                    nextStepTime: globalData.audioContext.currentTime + sequenceStartTimeOffset,
                    stepDuration: stepDuration,
                    endTime: globalData.audioContext.currentTime + sequenceStartTimeOffset + sequenceDuration,
                    completed: false,
                    loggedStart: false
                };
                sequenceStartTimeOffset += sequenceDuration;
                orderedSequenceNumber++;
            }

            globalData.currentSongId = song.id;
            initializeAudioProcessingChain();
            GainNodeHelper.createGainNodesForSong(song);
            GainNodeHelper.prepareNextSongGainNodes(songsArray[(globalData.currentSongIndex + 1) % songsArray.length]);
            globalData.isPlaying = true;
            globalData.currentSequence = 1;

            playbackInterval = setInterval(() => scheduleSequences(song), schedulerInterval);
            console.log("Sequences scheduled and playback started.");
            document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
            updateNowPlaying(song);
        }

        /**
         * Function to stop playback
         */
        function stopPlayback() {
            if (!globalData.isPlaying) {
                console.log("Playback is not in progress.");
                return;
            }

            resetPlayback();
            console.log("Playback stopped.");
            document.dispatchEvent(new CustomEvent("playbackStopped", { detail: { success: true } }));
            clearNowPlaying();

            if (countdownInterval) {
                clearInterval(countdownInterval);
                countdownInterval = null;
            }
        }

        /**
         * Function to reset playback
         */
        function resetPlayback(options = {}) {
            clearInterval(playbackInterval);
            if (!options.preserveIsPlaying) {
                globalData.isPlaying = false;
            }

            sequenceStates = {};
            missingAudioBuffers.clear();

            activeAudioSources.forEach(source => {
                try {
                    source.stop();
                    source.disconnect();
                } catch (error) {
                    console.error("Error stopping/disconnecting an audio source:", error);
                }
            });
            activeAudioSources.clear();

            if (globalData.currentSongId) {
                GainNodeHelper.cleanupGainNodesForSong(globalData.currentSongId);
                globalData.currentSongId = null;
            }

            if (countdownInterval) {
                clearInterval(countdownInterval);
                countdownInterval = null;
            }

            if (options.callback) {
                options.callback();
            }
        }

        /**
         * Toggle playback function
         */
        globalData.togglePlayback = () => globalData.isPlaying ? stopPlayback() : startPlayback();
        globalData.startPlayback = startPlayback;
        globalData.stopPlayback = stopPlayback;
        globalData.resetPlayback = () => resetPlayback({ callback: startPlayback });

        /**
         * Function to schedule sequences
         */
        function scheduleSequences(song) {
            const currentTime = audioContext.currentTime;
            let allSequencesCompleted = true;
            const totalSequences = Object.keys(song.projectSequences).length;

            for (const [sequenceId, sequenceData] of Object.entries(song.projectSequences || {})) {
                const sequenceState = sequenceStates[sequenceId];

                if (sequenceState && !sequenceState.completed) {
                    if (currentTime >= sequenceState.endTime) {
                        sequenceState.completed = true;
                        console.log(`Sequence ${sequenceState.sequenceNumber} has completed.`);
                    } else {
                        allSequencesCompleted = false;

                        if (currentTime >= sequenceState.nextStepTime && !sequenceState.loggedStart) {
                            globalData.currentSequence = sequenceState.sequenceNumber;
                            console.log(`Updating current sequence display: Sequence ${globalData.currentSequence} out of ${totalSequences}`);
                            sequenceState.loggedStart = true;
                        }

                        while (sequenceState.nextStepTime < currentTime + scheduleAheadTime && globalData.isPlaying) {
                            const { nextStepIndex, nextStepTime, stepDuration } = sequenceState;

                            if (nextStepIndex === 0 && !sequenceState.loggedStart) {
                                console.log(`Starting Sequence ${sequenceState.sequenceNumber} at step ${nextStepIndex}.`);
                                sequenceState.loggedStart = true;
                            }

                            for (const [channelKey, noteData] of Object.entries(sequenceData)) {
                                const channelIndex = parseInt(channelKey.slice(2), 10);
                                const channel = song.channels[channelIndex];

                                if (!channel) {
                                    console.warn(`Channel index ${channelIndex} not found in song ${song.id}.`);
                                    continue;
                                }

                                const step = noteData.steps?.find(step => 
                                    typeof step === 'number' ? step === nextStepIndex : step.index === nextStepIndex
                                );

                                if (step !== undefined) {
                                    const reverse = typeof step === 'object' && step.reverse;
                                    playNote(song, channel, nextStepTime, reverse);
                                }
                            }

                            sequenceState.nextStepIndex++;
                            if (sequenceState.nextStepIndex >= 64) {
                                sequenceState.completed = true;
                                console.log(`Sequence ${sequenceState.sequenceNumber} has completed all steps.`);
                                break;
                            }
                            sequenceState.nextStepTime += stepDuration;
                        }
                    }
                }
            }

            if (allSequencesCompleted) {
                console.log("All sequences have completed.");
                proceedToNextSong();
            }

            applyMuteSchedule(song, globalData.currentSequence);
        }

        /**
         * Function to play a note on a specific channel at a given time with fade-in and fade-out to prevent clicks.
         *
         * @param {Object} song - The song object.
         * @param {Object} channel - The channel object.
         * @param {number} time - The scheduled time to play the note.
         * @param {boolean} reverse - Whether to play the note in reverse.
         */
        function playNote(song, channel, time, reverse) {
            const bufferKey = `${song.id}_${channel.id}_${reverse ? "reverse" : "normal"}`;
            const buffer = reverse
                ? globalData.reverseAudioBuffers[song.id]?.[channel.id]
                : globalData.audioBuffers[song.id]?.[channel.id];

            if (!buffer) {
                if (!missingAudioBuffers.has(bufferKey)) {
                    missingAudioBuffers.add(bufferKey);
                    console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
                }
                return;
            }

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.playbackRate.value = channel.metadata.playbackSpeed || 1;

            const sourceGain = audioContext.createGain();
            sourceGain.gain.setValueAtTime(0, time);

            source.connect(sourceGain);
            const channelGainNode = globalData.gainNodes?.[song.id]?.[channel.id] || globalData.masterGain;
            sourceGain.connect(channelGainNode);

            const fadeInDuration = 0.01;  // 10 ms
            const fadeOutDuration = 0.01; // 10 ms

            sourceGain.gain.linearRampToValueAtTime(channel.metadata.volume || 1, time + fadeInDuration);

            const stopTime = time + buffer.duration / source.playbackRate.value;
            const adjustedStopTime = stopTime - fadeOutDuration;

            sourceGain.gain.setValueAtTime(channel.metadata.volume || 1, adjustedStopTime);
            sourceGain.gain.linearRampToValueAtTime(0, stopTime);

            source.start(time);
            source.stop(stopTime);

            activeAudioSources.add(source);
            source.onended = () => activeAudioSources.delete(source);
        }

        /**
         * Function to apply mute/unmute based on muteSchedule
         */
        function applyMuteSchedule(song, currentSequence) {
            const { muteSchedule } = song;
            if (!muteSchedule || !Array.isArray(muteSchedule)) return;

            const actions = muteSchedule.filter(actionItem => actionItem.sequence === currentSequence);

            actions.forEach(actionItem => {
                const { action, channels } = actionItem;
                channels.forEach(channelId => {
                    const channel = song.channels.find(ch => ch.id === channelId);
                    if (channel) {
                        if (action === 'mute') {
                            muteChannel(channel);
                        } else if (action === 'unmute') {
                            if (getActiveChannelCount(song) < MAX_ACTIVE_CHANNELS) {
                                unmuteChannel(channel);
                            }
                        }
                    }
                });
            });
        }

        function getActiveChannelCount(song) {
            return song.channels.filter(ch => !ch.metadata.isMuted).length;
        }

        function muteChannel(channel) {
            if (!channel.metadata.isMuted) {
                channel.metadata.isMuted = true;
                const gainNode = globalData.gainNodes[song.id]?.[channel.id];
                if (gainNode) {
                    gainNode.gain.cancelScheduledValues(audioContext.currentTime);
                    gainNode.gain.setValueAtTime(gainNode.gain.value, audioContext.currentTime);
                    gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + 0.5);
                    console.log(`Channel ${channel.id} muted with fade-out.`);
                }
            }
        }

        function unmuteChannel(channel) {
            if (channel.metadata.isMuted) {
                channel.metadata.isMuted = false;
                const gainNode = globalData.gainNodes[song.id]?.[channel.id];
                if (gainNode) {
                    gainNode.gain.cancelScheduledValues(audioContext.currentTime);
                    gainNode.gain.setValueAtTime(0, audioContext.currentTime);
                    gainNode.gain.linearRampToValueAtTime(1, audioContext.currentTime + 0.5);
                    console.log(`Channel ${channel.id} unmuted with fade-in.`);
                }
            }
        }

        /**
         * Function to update Now Playing information
         */
        function updateNowPlaying(song) {
            const nowPlayingContainer = document.getElementById("nowPlayingContainer");
            if (!nowPlayingContainer) {
                console.warn("Now Playing Container not found.");
                return;
            }

            const { projectName, artistName } = getProjectAndArtist(song);
            nowPlayingContainer.querySelector(".songTitle").textContent = projectName;
            nowPlayingContainer.querySelector(".artistName").textContent = artistName;
            nowPlayingContainer.querySelector(".songBPM").textContent = `BPM: ${song.bpm}`;

            initializeCountdown(song);
        }

        /**
         * Function to clear Now Playing information
         */
        function clearNowPlaying() {
            const nowPlayingContainer = document.getElementById("nowPlayingContainer");
            if (!nowPlayingContainer) {
                console.warn("Now Playing Container not found.");
                return;
            }
            nowPlayingContainer.querySelector(".songTitle").textContent = "No song playing";
            nowPlayingContainer.querySelector(".artistName").textContent = "";
            nowPlayingContainer.querySelector(".songBPM").textContent = "BPM: N/A";
            nowPlayingContainer.querySelector(".timeLeft").textContent = "Time Left: N/A";
        }

        /**
         * Function to initialize countdown timer
         */
        function initializeCountdown(song) {
            if (countdownInterval) {
                clearInterval(countdownInterval);
            }

            const nowPlayingContainer = document.getElementById("nowPlayingContainer");
            if (!nowPlayingContainer) return;

            const timeLeftElement = nowPlayingContainer.querySelector(".timeLeft");
            if (!timeLeftElement) return;

            const stepDuration = 60 / song.bpm / 4;
            const stepsPerSequence = 64;
            const totalSequences = Object.keys(song.projectSequences).length;
            const totalDuration = stepDuration * stepsPerSequence * totalSequences;

            let timeLeft = totalDuration;
            updateTimeLeftDisplay(timeLeftElement, timeLeft);

            countdownInterval = setInterval(() => {
                if (globalData.isPlaying) {
                    timeLeft -= 1;
                    if (timeLeft <= 0) {
                        timeLeft = 0;
                        clearInterval(countdownInterval);
                    }
                    updateTimeLeftDisplay(timeLeftElement, timeLeft);
                } else {
                    clearInterval(countdownInterval);
                }
            }, 1000);
        }

        /**
         * Function to update the Time Left display
         */
        function updateTimeLeftDisplay(element, timeLeftInSeconds) {
            const minutes = Math.floor(timeLeftInSeconds / 60);
            const seconds = Math.floor(timeLeftInSeconds % 60);
            element.textContent = `Time Left: ${minutes}:${seconds.toString().padStart(2, '0')}`;
        }

        /**
         * Function to proceed to the next song
         */
        function proceedToNextSong() {
            if (!globalData.isPlaying) return;

            globalData.currentSeed = (globalData.currentSeed !== undefined ? BigInt(globalData.currentSeed) : 1n) + 1n;
            console.log(`Seed progressed to: ${globalData.currentSeed}`);

            globalData.currentSongIndex = (globalData.currentSongIndex + 1) % globalData.songsArray.length;

            setTimeout(() => {
                if (globalData.isPlaying) {
                    const nextSong = globalData.songsArray[globalData.currentSongIndex];
                    if (nextSong) {
                        nextSong.seed = globalData.currentSeed.toString();
                        console.log(`Assigned new seed to song: ${nextSong.id} -> Seed: ${nextSong.seed}`);

                        resetPlayback({ preserveIsPlaying: true, callback: () => {
                            startPlayback();
                            document.dispatchEvent(new CustomEvent("songChanged", { detail: { song: nextSong } }));
                        }});
                    } else {
                        console.warn("Next song not found in songsArray.");
                    }
                }
            }, 200);
        }

        /**
         * Function to play an AudioBuffer through the audio processing chain.
         *
         * @param {AudioBuffer} audioBuffer - The audio buffer to play.
         */
        function playAudioBuffer(audioBuffer) {
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(globalData.masterGain);
            source.start();
            console.log("[PlaybackEngine] AudioBufferSourceNode started.");

            activeAudioSources.add(source);
            source.onended = () => activeAudioSources.delete(source);
        }

        /**
         * Function to get project name and artist name from song object
         */
        function getProjectAndArtist(song) {
            return {
                projectName: song.projectName || song.id || "Unknown Project",
                artistName: song.artist || "Unknown Artist"
            };
        }

        /**
         * Function to initialize playback engine
         */
        globalData.initializePlaybackEngine = () => {
            if (!globalData.songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }
            console.log("Playback Engine Initialization Complete.");
            console.log("Playback is ready. Click the artwork to start.");
        };

        /**
         * Set up artwork cover for playback toggle
         */
        function setupArtworkCover() {
            document.addEventListener("DOMContentLoaded", () => {
                const artworkCover = document.getElementById("artworkCover");
                const artworkImage = document.getElementById("artworkImage");
                const loadingSpinner = document.getElementById("loadingSpinner");

                if (globalData.isArtworkCover && globalData.songsArray.length) {
                    const firstSong = globalData.songsArray[0];
                    const artworkUrl = firstSong.artworkUrl || [];

                    if (artworkUrl.length) {
                        artworkImage.src = artworkUrl[0];
                        artworkCover.classList.remove("hidden");
                        loadingSpinner.style.display = "none";
                        artworkImage.addEventListener("click", globalData.togglePlayback);
                        console.log("Artwork cover is set up for playback toggle.");
                    } else {
                        console.warn("No artwork URL provided for the first song.");
                    }
                } else {
                    console.warn("Artwork cover is not enabled or no songs available.");
                }
            });
        }

        /**
         * Event listener for initial audio buffers ready
         */
        document.addEventListener("initialAudioBuffersReady", (event) => {
            if (event.detail.success) {
                globalData.initializePlaybackEngine();
                console.log("Initial audio buffers are ready.");
            }
        });

        /**
         * Event listeners for playback started and stopped
         */
        ["playbackStarted", "playbackStopped"].forEach((eventType) => {
            document.addEventListener(eventType, (event) => {
                if (event.detail.success) {
                    console.log(`Playback has been successfully ${eventType === "playbackStarted" ? "started" : "stopped"}.`);
                }
            });
        });

        setupArtworkCover();

        if (Object.keys(globalData.audioBuffers).length) {
            globalData.initializePlaybackEngine();
        }
    })();
</script>












</body>
</html>


