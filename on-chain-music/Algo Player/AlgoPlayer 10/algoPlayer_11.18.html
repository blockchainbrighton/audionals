<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Optimized</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0; padding: 0;
            display: flex; flex-direction: column;
            align-items: center; justify-content: center;
            height: 100vh; background-color: #000;
        }
        #artworkCover {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex; justify-content: center; align-items: center;
            z-index: 1000; cursor: pointer; transition: opacity 0.3s ease;
        }
        #artworkCover.hidden { opacity: 0; pointer-events: none; }
        #artworkImage {
            max-width: 80%; max-height: 80%; object-fit: contain;
            border: 4px solid #fff; border-radius: 10px;
            box-shadow: 0 0 20px rgba(255, 255, 255, 0.5);
            cursor: pointer;
        }
        #loadingSpinner {
            position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);
            border: 8px solid #f3f3f3; border-top: 8px solid #3498db;
            border-radius: 50%; width: 60px; height: 60px;
            animation: spin 2s linear infinite; z-index: 1001; display: none;
        }
        @keyframes spin {
            0% { transform: rotate(0deg) translate(-50%, -50%); }
            100% { transform: rotate(360deg) translate(-50%, -50%); }
        }
    </style>
    <script>
        const artworkUrl = ["/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0"];
        const songDataUrls = [
            "/content/a4fb0b49181975450a6710f20128eb0b3acc51f4aa1ce87ebdbc9607562013a2i0",
            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0",
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0",
            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0",
            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0",
            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0",
        ];
        const globalData = window.globalData = {
            isSingleSong: false,
            isMultipleSongs: true,
            isNormalPlayer: true,
            isLoopedPlayback: false,
            isSequentialPlayback: true,
            isRemixPlayer: false,
            songsArray: [],
            audioBuffers: {},
            reverseAudioBuffers: {},
            audioFetchCache: new Map(),
            isArtworkCover: true,
            isVisualiserCover: false,
            initialSampleOrder: [],
            isPlaying: false,
            audioContext: new (window.AudioContext || window.webkitAudioContext)(),
        };
        function startPlayback() {
            document.dispatchEvent(new CustomEvent("startPlaybackRequested"));
        }
        function stopPlayback() {
            document.dispatchEvent(new CustomEvent("stopPlaybackRequested"));
        }
        document.addEventListener("playbackStarted", () => {
            globalData.isPlaying = true;
            console.log("Playback has started.");
        });
        document.addEventListener("playbackStopped", () => {
            globalData.isPlaying = false;
            console.log("Playback has stopped.");
        });
    </script>
</head>
<body>
    <h1>Audionals</h1>
    <div id="loadingSpinner"></div>
    <div id="artworkCover">
        <img id="artworkImage" src="" alt="Artwork Cover">
    </div>
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const artworkCover = document.getElementById('artworkCover');
            const artworkImage = document.getElementById('artworkImage');
            const displayArtworkCover = () => {
                artworkCover.classList.remove('hidden');
                loadingSpinner.style.display = 'none';
            };
            if (globalData.isArtworkCover && artworkUrl.length > 0) {
                artworkImage.src = artworkUrl[0];
                displayArtworkCover();
                artworkImage.addEventListener('click', () => {
                    globalData.isPlaying ? stopPlayback() : startPlayback();
                });
            }
        });
    </script>

 <!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->
<section>
    <script>
    (async () => {
        // Configuration
        const keyMap = [
            "projectName",
            "artistName",
            "projectBPM",
            "currentSequence",
            "channelURLs",
            "channelVolume",
            "channelPlaybackSpeed",
            "trimSettings",
            "projectChannelNames",
            "startSliderValue",
            "endSliderValue",
            "totalSampleDuration",
            "start",
            "end",
            "projectSequences",
            "steps"
        ];
        const reverseKeyMap = keyMap.reduce((acc, key, idx) => ({ ...acc, [key]: idx }), {});
        const channelMap = Array.from({ length: 16 }, (_, i) => String.fromCharCode(65 + i)); // A-P
        const reverseChannelMap = channelMap.reduce((acc, ch, idx) => ({ ...acc, [ch]: idx }), {});

        // Utility Functions
        const loadPako = async () => {
            try {
                const { default: pako } = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
                window.pako = pako;
            } catch (error) {
                console.error("Error loading Pako library:", error);
                throw error;
            }
        };

        const decompressSteps = steps => steps.flatMap(step => {
            if (typeof step === "number") return step;
            if (step?.r) return Array.from({ length: step.r[1] - step.r[0] + 1 }, (_, i) => step.r[0] + i);
            if (typeof step === "string" && step.endsWith("r")) return { index: parseInt(step.slice(0, -1), 10), reverse: true };
            return [];
        });

        const deserialize = data => {
            const recurse = obj => Array.isArray(obj) ? obj.map(recurse) :
                obj && typeof obj === "object" ? Object.entries(obj).reduce((acc, [k, v]) => {
                    const key = keyMap[k] || k;
                    acc[key] = key === "projectSequences" ? Object.fromEntries(
                        Object.entries(v).map(([seqK, seqV]) => [
                            `Sequence${seqK.replace(/^s/, "")}`,
                            Object.fromEntries(
                                Object.entries(seqV).map(([trackK, trackV]) => [
                                    `ch${reverseChannelMap[trackK]}`,
                                    { steps: decompressSteps(trackV[reverseKeyMap.steps] || []) }
                                ])
                            )
                        ])
                    ) : recurse(v);
                    return acc;
                }, {}) : obj;
            return recurse(data);
        };

        const fetchAndDeserialize = async url => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                const inflatedData = window.pako.inflate(new Uint8Array(await response.arrayBuffer()));
                return deserialize(JSON.parse(new TextDecoder("utf-8").decode(inflatedData)));
            } catch (error) {
                console.error(`Error fetching/deserializing URL ${url}:`, error);
                throw error;
            }
        };

        const fetchAndProcessData = async urls => {
            const results = await Promise.all(urls.map((url, idx) => fetchAndDeserialize(url)
                .then(data => ({ data, idx }))
                .catch(error => {
                    console.error(`Failed to process URL ${url}:`, error);
                    return null;
                })
            ));
            const validResults = results.filter(Boolean);
            if (!validResults.length) throw new Error("No valid data was processed.");
            return validResults;
        };

        const processSongsAndChannels = dataWithIndices => {
            const songsArray = dataWithIndices
                .sort((a, b) => a.idx - b.idx)
                .map(({ data, idx }) => {
                    const {
                        projectName = `Song_${idx + 1}`,
                        artistName = "Unknown Artist",
                        projectBPM = 120,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = data;

                    const channels = channelMap.map((ch, i) => ({
                        id: ch,
                        url: channelURLs[i] || `URL_not_found`,
                        metadata: {
                            volume: channelVolume[i] ?? 1.0,
                            playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                            trimStartTime_Percentage: trimSettings[i]?.start || 0,
                            trimEndTime_Percentage: trimSettings[i]?.end || 100,
                            requiresReversal: Object.values(projectSequences).some(seq =>
                                Object.values(seq).some(track => track.steps.some(s => typeof s === 'object' && s.reverse))
                            )
                        }
                    }));

                    return {
                        id: `Song ${idx + 1}: ${projectName}`,
                        artist: artistName,
                        bpm: projectBPM,
                        totalSequences: Object.keys(projectSequences).length,
                        channels,
                        projectSequences
                    };
                });

            globalData.songsArray = songsArray;
            if (songsArray.length) globalData.initialSampleOrder = getInitialSampleOrder(songsArray[0]);
            return songsArray;
        };

        const getInitialSampleOrder = song => {
            const { projectSequences } = song;
            const sampleOrder = [];
            const sequences = Object.keys(projectSequences).sort().slice(0, 2);

            sequences.forEach(seqName => {
                const sequence = projectSequences[seqName];
                Object.values(sequence).slice(0, 16).forEach(({ steps }, chIdx) => {
                    steps.slice(0, 16).forEach(step => {
                        if (typeof step === "number" || (typeof step === "object" && step.index !== undefined)) {
                            const key = `${chIdx}_${step.reverse ? "r" : "f"}`;
                            if (!sampleOrder.some(item => `${item.channelId}_${item.reverse ? "r" : "f"}` === key)) {
                                sampleOrder.push({ channelId: `ch${chIdx}`, reverse: step.reverse || false });
                            }
                        }
                    });
                });
            });

            return sampleOrder;
        };

        const logSongsArray = songsArray => {
            console.log(`Total Songs: ${songsArray.length}`);
            songsArray.forEach(({ id, artist, bpm, totalSequences, channels, projectSequences }, idx) => {
                console.log(`\n${id} by ${artist} - BPM: ${bpm} - Total Sequences: ${totalSequences}`);
                channels.forEach(({ id: chId, metadata }, chIdx) => {
                    const { volume, playbackSpeed, trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = metadata;
                    console.log(`\tChannel ${chIdx + 1} - ${chId}, Volume: ${volume}, Speed: ${playbackSpeed}, Trim: ${trimStartTime_Percentage}% - ${trimEndTime_Percentage}%, Reversal: ${requiresReversal}`);
                });
                console.log(`\tProject Sequences:\n${JSON.stringify(projectSequences, null, 2)}`);
            });

            if (globalData.initialSampleOrder.length) {
                console.log(`\nInitial Sample Order for ${songsArray[0].id}:`);
                globalData.initialSampleOrder.forEach(({ channelId, reverse }, idx) => {
                    console.log(`\t${idx + 1}. Channel: ${channelId}, Reverse: ${reverse}`);
                });
            }

            if (globalData.isArtworkCover && artworkUrl.length) {
                console.log(`\nArtwork URL(s):`, artworkUrl);
                displayArtworkCover(artworkUrl[0]);
            }

            globalData.isSingleSong = songsArray.length === 1;
            globalData.isMultipleSongs = songsArray.length > 1;
            console.log(`\nFlags - Single Song: ${globalData.isSingleSong}, Multiple Songs: ${globalData.isMultipleSongs}`);

            document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
                detail: {
                    success: true,
                    totalSongs: songsArray.length,
                    songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
                }
            }));
        };

        const displayArtworkCover = url => {
            const artworkImage = document.getElementById('artworkImage');
            if (artworkImage) {
                artworkImage.src = url;
                artworkImage.parentElement.style.display = 'flex';
            } else {
                console.warn("Artwork cover elements not found.");
            }
        };

        // Initialization
        try {
            const validUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
            if (validUrls.length) {
                await loadPako();
                const deserializedDataWithIndices = await fetchAndProcessData(validUrls);
                const songsArray = processSongsAndChannels(deserializedDataWithIndices);
                logSongsArray(songsArray);
            } else {
                console.log('No valid song data URLs to process.');
            }
        } catch (error) {
            console.error('Initialization error:', error);
        }
    })();
    </script>
</section>

<!-- Section 2 - Audio Buffering and Mapping (Optimized for Lazy Loading) -->

<section2>
    <script>
    (async () => {
        const globalData = window.globalData || (window.globalData = {});
        const audioContext = globalData.audioContext = globalData.audioContext || new (window.AudioContext || window.webkitAudioContext)();

        // Utility Functions (unchanged)
        const base64ToArrayBuffer = (base64) => Uint8Array.from(atob(base64), c => c.charCodeAt(0)).buffer;

        const extractBase64FromHTML = (html) => {
            const match = html.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="([^"]+)"/i);
            if (match && match[1].includes("base64")) {
                const base64Index = match[1].indexOf("base64,");
                if (base64Index !== -1) return match[1].substring(base64Index + 7);
            }
            return null;
        };

        const extractBase64FromJSON = (jsonData) => {
            try {
                const parsed = JSON.parse(jsonData);
                if (parsed.audioData) {
                    const base64Index = parsed.audioData.indexOf("base64,");
                    if (base64Index !== -1) return parsed.audioData.substring(base64Index + 7);
                }
            } catch (e) {}
            return null;
        };

        const isValidBase64 = (str) => {
            const cleanedStr = str.replace(/\s+/g, '');
            if (cleanedStr.length % 4 !== 0) return false;
            try { atob(cleanedStr); return true; } catch (e) { return false; }
        };

        /**
         * Normalizes an AudioBuffer to a target peak amplitude.
         * @param {AudioBuffer} audioBuffer - The AudioBuffer to normalize.
         * @param {number} targetPeak - The desired peak amplitude (e.g., 0.5).
         * @returns {AudioBuffer} - The normalized AudioBuffer.
         */
        const normalizeAudioBuffer = (audioBuffer, targetPeak = 0.5) => {
            let maxAmplitude = 0;

            // Find the maximum amplitude across all channels
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const channelData = audioBuffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    const absSample = Math.abs(channelData[i]);
                    if (absSample > maxAmplitude) {
                        maxAmplitude = absSample;
                    }
                }
            }

            // Calculate the scaling factor
            const scalingFactor = maxAmplitude > 0 ? targetPeak / maxAmplitude : 1;

            // Apply the scaling factor to all channels
            if (scalingFactor !== 1) {
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        channelData[i] *= scalingFactor;
                    }
                }
                console.log(`Normalized AudioBuffer to target peak of ${targetPeak}. Scaling factor: ${scalingFactor.toFixed(4)}`);
            }

            return audioBuffer;
        };

        /**
         * Fetches and decodes audio data from a given URL based on its content type.
         * @param {Response} response - The fetch response object.
         * @param {string} contentType - The content type of the response.
         * @param {string} url - The URL of the audio resource.
         * @returns {Promise<AudioBuffer|null>} - The decoded AudioBuffer or null if decoding fails.
         */
        const fetchAndDecodeAudio = async (response, contentType, url) => {
            const cache = globalData.audioFetchCache = globalData.audioFetchCache || new Map();
            if (cache.has(url)) return cache.get(url);

            let audioBuffer;
            try {
                if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    console.log(`Successfully decoded audio from URL ${url}`);
                } else if (/application\/json/.test(contentType)) {
                    const textData = await response.text();
                    const base64Data = extractBase64FromJSON(textData);
                    if (base64Data && isValidBase64(base64Data)) {
                        const arrayBuffer = base64ToArrayBuffer(base64Data);
                        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        console.log(`Successfully decoded JSON audio from URL ${url}`);
                    } else {
                        console.warn(`Invalid or missing base64 audio data in JSON for URL ${url}. Skipping this channel.`);
                        return null; // Gracefully handle invalid base64
                    }
                } else if (/text\/html/.test(contentType)) {
                    const textData = await response.text();
                    const base64Data = extractBase64FromHTML(textData);
                    if (base64Data && isValidBase64(base64Data)) {
                        const arrayBuffer = base64ToArrayBuffer(base64Data);
                        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        console.log(`Successfully decoded HTML audio from URL ${url}`);
                    } else {
                        console.warn(`Invalid or missing base64 audio data in HTML for URL ${url}. Skipping this channel.`);
                        return null; // Gracefully handle invalid base64
                    }
                } else if (/audio\//.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    console.log(`Successfully decoded audio from URL ${url}`);
                } else {
                    console.warn(`Unsupported content type (${contentType}) or missing audio data for URL ${url}. Skipping this channel.`);
                    return null; // Gracefully handle unsupported content types
                }

                cache.set(url, audioBuffer);
                return audioBuffer;
            } catch (error) {
                console.warn(`Error decoding audio from URL ${url}:`, error.message);
                return null; // Gracefully handle decoding errors
            }
        };

        const reverseArray = (array) => {
            const reversed = new Float32Array(array.length);
            for (let i = 0, len = array.length; i < len; i++) {
                reversed[i] = array[len - i - 1];
            }
            return reversed;
        };

        const createReverseAudioBuffer = (audioBuffer) => {
            const reverseBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const data = audioBuffer.getChannelData(channel);
                reverseBuffer.getChannelData(channel).set(reverseArray(data));
            }
            return reverseBuffer;
        };

        const extractFileName = (url) => url.split('/').pop() || "Unknown";

        /**
         * Processes an individual audio channel for a song.
         * @param {Object} song - The song object.
         * @param {Object} channel - The channel object.
         * @param {Array} logEntries - The array to store log entries.
         */
        const processChannel = async (song, channel, logEntries) => {
            try {
                const response = await fetch(channel.url);
                if (!response.ok) {
                    console.warn(`Network response was not ok for URL: ${channel.url}. Skipping this channel.`);
                    return; // Gracefully skip this channel
                }

                const contentType = response.headers.get("Content-Type") || "";
                console.log(`Fetching URL: ${channel.url} with Content-Type: ${contentType}`);

                const audioBuffer = await fetchAndDecodeAudio(response, contentType, channel.url);

                // Check if audioBuffer is null (decoding failed)
                if (!audioBuffer) {
                    console.warn(`Failed to decode audio for Song: ${song.id}, Channel: ${channel.id}. Skipping this channel.`);
                    return; // Gracefully skip this channel
                }

                const { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = channel.metadata;
                if (trimEndTime_Percentage <= trimStartTime_Percentage) {
                    console.warn(`Trim end percentage (${trimEndTime_Percentage}%) is <= start percentage (${trimStartTime_Percentage}%) for Song: ${song.id}, Channel: ${channel.id}`);
                    return; // Skip processing this channel
                }

                const trimStartTime = (trimStartTime_Percentage / 100) * audioBuffer.duration;
                const trimEndTime = (trimEndTime_Percentage / 100) * audioBuffer.duration;

                const startSample = Math.floor(trimStartTime * audioBuffer.sampleRate);
                const endSample = Math.floor(trimEndTime * audioBuffer.sampleRate);
                const trimmedLength = endSample - startSample;

                if (trimmedLength <= 0) {
                    console.warn(`Trimmed length (${trimmedLength} samples) is non-positive for Song: ${song.id}, Channel: ${channel.id}`);
                    return; // Skip processing this channel
                }

                const trimmedAudioBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    trimmedAudioBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(startSample, endSample));
                }

                // Normalize the trimmed audio buffer
                const normalizedAudioBuffer = normalizeAudioBuffer(trimmedAudioBuffer, 0.5); // Lower target peak amplitude

                // Store the normalized buffer in globalData
                globalData.audioBuffers = globalData.audioBuffers || {};
                globalData.reverseAudioBuffers = globalData.reverseAudioBuffers || {};
                globalData.audioBuffers[song.id] = globalData.audioBuffers[song.id] || {};
                globalData.reverseAudioBuffers[song.id] = globalData.reverseAudioBuffers[song.id] || {};
                globalData.audioBuffers[song.id][channel.id] = normalizedAudioBuffer;

                if (requiresReversal) {
                    const reversedBuffer = createReverseAudioBuffer(normalizedAudioBuffer);
                    // Normalize the reversed buffer as well
                    const normalizedReversedBuffer = normalizeAudioBuffer(reversedBuffer, 0.5);
                    globalData.reverseAudioBuffers[song.id][channel.id] = normalizedReversedBuffer;
                }

                logEntries.push({
                    songId: song.id,
                    channelId: channel.id,
                    audioFileName: extractFileName(channel.url),
                    fullDuration: audioBuffer.duration.toFixed(2),
                    durationAfterTrimming: normalizedAudioBuffer.duration.toFixed(2),
                    requiresReversal
                });

                console.log(`Processed and normalized audio for Song: ${song.id}, Channel: ${channel.id}${requiresReversal ? " (Reversed)" : ""}`);
            } catch (error) {
                console.warn(`Failed to process audio for Song: ${song.id}, Channel: ${channel.id}: ${error.message}`);
                // Optionally, implement fallback mechanisms here, such as assigning a silent buffer
            }
        };

        const logDetailedInfo = (logEntries) => {
            if (logEntries.length > 0) {
                console.table(logEntries.map(entry => ({
                    "Song ID": entry.songId,
                    "Channel ID": entry.channelId,
                    "Audio File Name": entry.audioFileName,
                    "Full Duration (s)": entry.fullDuration,
                    "Duration After Trimming (s)": entry.durationAfterTrimming,
                    "Requires Reversal": entry.requiresReversal
                })));
            } else {
                console.warn("Audio samples not processed yet.");
            }
        };

        /**
         * Initializes a Master Gain Node to control overall output volume.
         * Ensures that the main audio bus does not get overloaded when multiple channels are played simultaneously.
         */
        const initializeMasterGain = () => {
            const masterGain = audioContext.createGain();
            masterGain.gain.value = 0.7; // Adjust this value as needed (0.0 to 1.0)
            masterGain.connect(audioContext.destination);
            globalData.masterGain = masterGain;
            console.log("Master Gain Node initialized with gain:", masterGain.gain.value);
        };

        const ensureAudioContextRunning = async () => {
            if (audioContext.state === 'suspended') await audioContext.resume();
        };

        /**
         * Starts playback by triggering the playback logic.
         */
        const startPlayback = () => {
            // Implement your playback logic here.
            console.log("Playback started.");
            // Example: Dispatch an event to signal playback start
            document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
        };

        /**
         * Processes audio channels for initial playback.
         * Loads only the necessary channels to buffer the first two bars (e.g., 4 seconds).
         * Activates the P-key listener once initial buffering is complete.
         */
        const processInitialAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs available to process.");
                return;
            }

            const logEntries = [];
            const initialPromises = [];

            // Iterate through the initialSampleOrder to prioritize loading
            for (const sample of initialSampleOrder) {
                const song = songsArray.find(s => s.id === sample.songId);
                if (!song) continue;
                const channel = song.channels.find(c => c.id === sample.channelId);
                if (!channel) continue;
                initialPromises.push(processChannel(song, channel, logEntries));
            }

            // Await all initial samples to be processed
            await Promise.all(initialPromises);
            logDetailedInfo(logEntries);
            console.log("Initial audio buffers for playback are ready.");

            // Initialize Master Gain Node
            initializeMasterGain();

            // Dispatch an event indicating that initial audio buffers are ready
            document.dispatchEvent(new CustomEvent("initialAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Processes remaining audio channels in the background.
         */
        const processRemainingAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs available to process.");
                return;
            }

            const logEntries = [];
            const backgroundPromises = [];

            // Collect all channels not in the initialSampleOrder
            for (const song of songsArray) {
                for (const channel of song.channels) {
                    // Check if this channel is already processed as part of initialSampleOrder
                    const isInitial = initialSampleOrder.some(sample => sample.songId === song.id && sample.channelId === channel.id);
                    if (!isInitial) {
                        backgroundPromises.push(processChannel(song, channel, logEntries));
                    }
                }
            }

            // Process remaining channels with limited concurrency to optimize performance
            const CONCURRENT_LIMIT = 4; // Adjust based on performance needs
            const batches = [];
            while (backgroundPromises.length) {
                batches.push(backgroundPromises.splice(0, CONCURRENT_LIMIT));
            }

            for (const batch of batches) {
                await Promise.all(batch);
                // Optionally, add progress updates here
            }

            logDetailedInfo(logEntries);
            console.log("All background audio buffers have been processed.");

            // Dispatch an event indicating that all audio buffers are ready
            document.dispatchEvent(new CustomEvent("allAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Initializes the entire audio processing workflow with lazy loading.
         */
        const initAudioProcessing = async () => {
            try {
                await ensureAudioContextRunning();

                // Phase 1: Process initial audio channels for immediate playback
                await processInitialAudioChannels();

                // Phase 2: Process remaining audio channels in the background
                processRemainingAudioChannels().catch(error => {
                    console.error("Error during background audio processing:", error);
                });
            } catch (error) {
                console.error("Error during audio processing initialization:", error);
            }
        };

        /**
         * Sets up the initial audio processing when data loading is complete.
         */
        const setupAudioProcessing = () => {
            document.addEventListener("dataLoadingComplete", initAudioProcessing);
            if (globalData.songsArray && globalData.songsArray.length) {
                initAudioProcessing();
            }
        };

        /**
         * Listens for the 'initialAudioBuffersReady' event to notify the user or perform additional actions.
         */
        const setupInitialBufferListener = () => {
            document.addEventListener("initialAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    console.log("Initial audio buffers are ready. You can now press 'P' to start playback.");
                    // Optionally, display a UI prompt or enable playback controls here
                }
            });
        };

        /**
         * Starts the entire setup process.
         */
        const startSetup = () => {
            setupAudioProcessing();
            setupInitialBufferListener();
        };

        // Initialization
        startSetup();
    })();
    </script>
</section2>


<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) -->
<section>
    <script>
    (() => {
        const globalData = window.globalData || (window.globalData = {});
        const audioContext = globalData.audioContext;

        // Initialize playback state
        globalData.isPlaying = false;

        /**
         * Listen for startPlaybackRequested and stopPlaybackRequested events
         */
        document.addEventListener("startPlaybackRequested", () => {
            if (!globalData.isPlaying) {
                startPlayback();
            }
        });

        document.addEventListener("stopPlaybackRequested", () => {
            if (globalData.isPlaying) {
                stopPlayback();
            }
        });

        /**
         * Override the existing startPlayback and stopPlayback functions from Section 3
         */
        const originalStartPlayback = window.startPlayback || function() {};
        const originalStopPlayback = window.stopPlayback || function() {};

        // Redefine startPlayback to include setting globalData.isPlaying
        window.startPlayback = () => {
            originalStartPlayback();
            globalData.isPlaying = true;
            document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
        };

        // Redefine stopPlayback to include setting globalData.isPlaying
        window.stopPlayback = () => {
            originalStopPlayback();
            globalData.isPlaying = false;
            document.dispatchEvent(new CustomEvent("playbackStopped", { detail: { success: true } }));
        };

        const lookahead = 0.1; // Time in seconds to look ahead for scheduling
        const schedulerInterval = 25; // Scheduler loop interval in milliseconds
        let isPlaying = false;
        let schedulerTimerID = null;
        let sequenceStates = {}; // Tracks the state of each sequence

        // Variables for Handling Multiple Songs and Looping
        let currentSongIndex = 0; // Tracks the index of the current song

        // Set to keep track of missing audio buffers to prevent multiple warnings
        const missingBuffers = new Set();

        /**
         * Initializes the Playback Engine.
         * Ensures that songs are available and sets up necessary components.
         */
        const initPlaybackEngine = () => {
            const { songsArray } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }
            console.log("Playback Engine Initialization Complete.");
            console.log("Playback is ready. Click the artwork to start.");
        };

        /**
         * Starts playback for the current song.
         * Initializes sequence states and starts the scheduler loop.
         */
        const startPlayback = () => {
            const { songsArray, audioBuffers, reverseAudioBuffers } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }

            // Update totalSongs dynamically
            const totalSongs = songsArray.length;

            // Ensure currentSongIndex is within bounds
            if (currentSongIndex >= totalSongs) {
                currentSongIndex = 0;
            }

            const song = songsArray[currentSongIndex];
            const sequences = song.projectSequences || {};
            console.log(`Starting playback for Song: ${song.id} (${currentSongIndex + 1}/${totalSongs}) with ${Object.keys(sequences).length} sequences.`);
            console.log(`Song BPM: ${song.bpm}`);

            const stepsPerBeat = 4;
            const stepDuration = (60 / song.bpm) / stepsPerBeat;
            const sequenceDuration = 64 * stepDuration;

            // Reset sequenceStates and missingBuffers for the new song
            sequenceStates = {};
            missingBuffers.clear(); // Clear missing buffers set

            let sequenceStartOffset = 0;
            for (const [sequenceName, sequence] of Object.entries(sequences)) {
                const startTime = audioContext.currentTime + sequenceStartOffset;
                sequenceStates[sequenceName] = {
                    nextStepIndex: 0,
                    nextStepTime: startTime,
                    stepDuration,
                    startTime,
                    endTime: startTime + sequenceDuration,
                    completed: false
                };
                console.log(`Initialized scheduler for sequence: ${sequenceName} starting at +${sequenceStartOffset.toFixed(2)}s`);
                sequenceStartOffset += sequenceDuration;
            }

            isPlaying = true;
            schedulerTimerID = setInterval(() => schedulerLoop(song, audioBuffers, reverseAudioBuffers), schedulerInterval);
            console.log('Playback started.');
        };

        /**
         * Stops playback and resets the Playback Engine state.
         */
        const stopPlayback = () => {
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback stopped and sequence states reset.');
        };

        /**
         * The main scheduler loop that schedules audio playback.
         * @param {Object} song - The current song object.
         * @param {Object} audioBuffers - The loaded audio buffers.
         * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
         */
        const schedulerLoop = (song, audioBuffers, reverseAudioBuffers) => {
            const currentTime = audioContext.currentTime;
            let allSequencesCompleted = true;

            for (const [sequenceName, sequence] of Object.entries(song.projectSequences || {})) {
                const state = sequenceStates[sequenceName];
                if (!state || state.completed) continue;

                // Check if the sequence has ended
                if (currentTime >= state.endTime) {
                    state.completed = true;
                    console.log(`Sequence ${sequenceName} has completed.`);
                    continue;
                }

                allSequencesCompleted = false;

                // Schedule steps within the lookahead window
                while (state.nextStepTime < currentTime + lookahead && isPlaying) {
                    const stepIndex = state.nextStepIndex;
                    const stepTime = state.nextStepTime;

                    for (const [trackName, trackData] of Object.entries(sequence)) {
                        const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                        const channel = song.channels[channelIndex];
                        
                        if (!channel) {
                            console.warn(`Channel index ${channelIndex} not found in song ${song.id}.`);
                            continue;
                        }

                        const steps = trackData.steps || [];
                        const step = steps.find(s => (typeof s === "number" && s === stepIndex) || (s.index === stepIndex));

                        if (step !== undefined) {
                            const reverse = typeof step === "object" && step.reverse;
                            schedulePlayback(song, channel, stepTime, reverse, audioBuffers, reverseAudioBuffers, state.stepDuration);
                        }
                    }

                    state.nextStepIndex += 1;
                    if (state.nextStepIndex >= 64) {
                        state.completed = true;
                        console.log(`Sequence ${sequenceName} has completed all steps.`);
                        break;
                    }
                    state.nextStepTime += state.stepDuration;
                }
            }

            if (allSequencesCompleted) {
                console.log("All sequences have completed.");

                const totalSongs = globalData.songsArray.length; // Update totalSongs

                // Handle looping and sequential playback based on flags
                if (globalData.isLoopedPlayback) {
                    if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                        // Move to the next song in the list
                        currentSongIndex += 1;
                        if (currentSongIndex >= totalSongs) {
                            currentSongIndex = 0; // Loop back to the first song
                            console.log("Reached the end of the playlist. Looping back to the first song.");
                        } else {
                            console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        }
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Loop the current song
                        console.log(`Looping the current song: ${song.id}`);
                        resetPlayback();
                        startPlayback();
                    }
                } else if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                    // Move to the next song without looping
                    currentSongIndex += 1;
                    if (currentSongIndex < totalSongs) {
                        console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Reached the end of the playlist
                        console.log("Reached the end of the playlist. Stopping playback.");
                        stopPlayback();
                    }
                } else {
                    // Single song playback without looping
                    console.log("Playback has completed the single song.");
                    stopPlayback();
                }
            }
        };

        /**
         * Schedules playback of an individual audio buffer.
         * @param {Object} song - The current song object.
         * @param {Object} channel - The current channel object.
         * @param {number} time - The scheduled start time in seconds.
         * @param {boolean} reverse - Indicates if the audio should be played in reverse.
         * @param {Object} audioBuffers - The loaded audio buffers.
         * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
         * @param {number} stepDuration - Duration of each step in seconds.
         */
        const schedulePlayback = (song, channel, time, reverse, audioBuffers, reverseAudioBuffers, stepDuration) => {
            const bufferKey = `${song.id}_${channel.id}_${reverse ? 'reverse' : 'normal'}`;
            const buffer = reverse ? reverseAudioBuffers[song.id]?.[channel.id] : audioBuffers[song.id]?.[channel.id];

            if (!buffer) {
                if (!missingBuffers.has(bufferKey)) {
                    missingBuffers.add(bufferKey);
                    console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
                }
                return;
            }

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.playbackRate.value = channel.metadata.playbackSpeed || 1;
            source.connect(globalData.masterGain || audioContext.destination);
            source.start(time);
            // Uncomment the following line for detailed scheduling logs
            // console.log(`Scheduled playback for Channel: ${channel.id} at ${time.toFixed(2)}s${reverse ? " (Reverse)" : ""}`);
        };

        /**
         * Resets the Playback Engine for the next song.
         */
        const resetPlayback = () => {
            // Stop current playback and reset states without completely stopping the engine
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback reset for the next song.');
        };

        /**
         * Initializes playback after audio buffers are ready.
         */
        const initializePlayback = () => {
            console.log("Audio buffers are ready. Playback can begin.");
            initPlaybackEngine();
        };

        /**
         * Sets up event listeners for custom events dispatched by Section 2.
         */
        const setupEventListeners = () => {
            // Listen for the initialAudioBuffersReady event to initialize the playback engine
            document.addEventListener("initialAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    initializePlayback();
                    console.log("Initial audio buffers are ready.");
                    // Optionally, you can display the artwork cover here if it's not already visible
                }
            });

            // Listen for the allAudioBuffersReady event to log completion
            document.addEventListener("allAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    console.log("All audio buffers have been loaded and are ready.");
                    // Optionally, perform additional actions here, such as updating the UI
                }
            });

            // Listen for the playbackStarted event if needed elsewhere
            document.addEventListener("playbackStarted", (event) => {
                if (event.detail.success) {
                    console.log("Playback has been successfully started.");
                    // Optionally, perform additional actions here
                }
            });

            // Listen for the playbackStopped event if needed elsewhere
            document.addEventListener("playbackStopped", (event) => {
                if (event.detail.success) {
                    console.log("Playback has been successfully stopped.");
                    // Optionally, perform additional actions here
                }
            });
        };

        /**
         * Initializes the Playback Engine and sets up event listeners.
         */
        const setupPlaybackEngine = () => {
            setupEventListeners();
            // Note: The click listener is handled in the DOMElements script
            console.log('Playback Engine setup complete.');
        };

        /**
         * Starts the entire setup process.
         * If audio buffers are already loaded, initialize immediately.
         * Otherwise, wait for the initialAudioBuffersReady event.
         */
        const startSetup = () => {
            if (Object.keys(globalData.audioBuffers || {}).length) {
                // If audioBuffers are already loaded, initialize playback
                setupPlaybackEngine();
            } else {
                // Otherwise, wait for the initialAudioBuffersReady event
                document.addEventListener("initialAudioBuffersReady", setupPlaybackEngine);
            }
        };

        // Initialization
        startSetup();

    })();
    </script>
</section>


</body>
</html>