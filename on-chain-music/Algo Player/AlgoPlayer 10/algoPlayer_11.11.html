<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Optimized</title>
</head>
<body>
    <h1>Web3 Audio Sequencer Playback Engine Optimized</h1>
    <p>Check the console for the 2D array of songs and channels with metadata.</p>

<!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->
<section>
<script>
(async () => {
    // Initialize globalData
    const globalData = window.globalData = window.globalData || {
        isSingleSong: false,
        isMultipleSongs: false,
        songsArray: [],
        audioBuffers: {},
        reverseAudioBuffers: {},
        audioFetchCache: new Map()
    };

    // Configuration
    const keyMap = {
        0: "projectName",
        1: "artistName",
        2: "projectBPM",
        3: "currentSequence",
        4: "channelURLs",
        5: "channelVolume",
        6: "channelPlaybackSpeed",
        7: "trimSettings",
        8: "projectChannelNames",
        9: "startSliderValue",
        10: "endSliderValue",
        11: "totalSampleDuration",
        12: "start",
        13: "end",
        14: "projectSequences",
        15: "steps"
    };

    const reverseKeyMap = {};
    for (const [k, v] of Object.entries(keyMap)) {
        reverseKeyMap[v] = +k;
    }

    const channelMap = Array.from({ length: 26 }, (_, i) => String.fromCharCode(65 + i));
    const reverseChannelMap = {};
    channelMap.forEach((letter, i) => { reverseChannelMap[letter] = i; });

    // Utility Functions
    const loadPako = async () => {
        try {
            const { default: pako } = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
            window.pako = pako;
        } catch (error) {
            console.error("Error loading Pako library:", error);
            throw error;
        }
    };

    const decompressSteps = (steps) => steps.flatMap(step => {
        if (typeof step === "number") return step;
        if (step?.r) {
            const [start, end] = step.r;
            return Array.from({ length: end - start + 1 }, (_, i) => start + i);
        }
        if (typeof step === "string" && step.endsWith("r")) {
            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
        }
        return [];
    });

    const deserialize = (data) => {
        const recurse = (obj) => {
            if (Array.isArray(obj)) return obj.map(recurse);
            if (obj && typeof obj === "object") {
                return Object.entries(obj).reduce((acc, [k, v]) => {
                    const key = keyMap[k] || k;
                    if (key === "projectSequences") {
                        acc[key] = Object.entries(v).reduce((seqAcc, [seqK, seqV]) => {
                            const seqName = `Sequence${seqK.replace(/^s/, "")}`;
                            seqAcc[seqName] = Object.entries(seqV).reduce((trackAcc, [trackK, trackV]) => {
                                const chName = `ch${reverseChannelMap[trackK]}`;
                                const steps = trackV[reverseKeyMap.steps] || [];
                                trackAcc[chName] = { steps: decompressSteps(steps) };
                                return trackAcc;
                            }, {});
                            return seqAcc;
                        }, {});
                    } else {
                        acc[key] = recurse(v);
                    }
                    return acc;
                }, {});
            }
            return obj;
        };
        return recurse(data);
    };

    const fetchAndDeserialize = async (url) => {
        try {
            const response = await fetch(url);
            if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
            const arrayBuffer = await response.arrayBuffer();
            const inflatedData = window.pako.inflate(new Uint8Array(arrayBuffer));
            const jsonString = new TextDecoder("utf-8").decode(inflatedData);
            return deserialize(JSON.parse(jsonString));
        } catch (error) {
            console.error(`Error fetching/deserializing URL ${url}:`, error);
            throw error;
        }
    };

    const fetchAndProcessData = async (urls) => {
        const results = await Promise.all(urls.map(url => fetchAndDeserialize(url).catch(error => {
            console.error(`Failed to process URL ${url}:`, error);
            return null;
        })));
        const validResults = results.filter(Boolean);
        if (!validResults.length) throw new Error("No valid data was processed.");
        return validResults;
    };

    const processSongsAndChannels = (deserializedData) => {
        const songsArray = deserializedData.map((songData, songIndex) => {
            const {
                projectName = `Song_${songIndex + 1}`,
                artistName = "Unknown Artist",
                projectBPM = 120,
                projectSequences = {},
                channelURLs = [],
                channelVolume = [],
                channelPlaybackSpeed = [],
                trimSettings = {}
            } = songData;

            const channels = Array.from({ length: 16 }, (_, i) => ({
                id: channelMap[i] || `Channel_${i + 1}`,
                url: channelURLs[i] || `URL_not_found`,
                metadata: {
                    volume: channelVolume[i] ?? 1.0,
                    playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                    trimStartTime_Percentage: trimSettings[i]?.start || 0,
                    trimEndTime_Percentage: trimSettings[i]?.end || 100,
                    requiresReversal: false
                }
            }));

            Object.values(projectSequences).forEach(sequence => {
                Object.entries(sequence).forEach(([channelSequenceId, channelSequence]) => {
                    const steps = channelSequence.steps || [];
                    const hasReverseStep = steps.some(step => typeof step === 'object' && step.reverse);
                    if (hasReverseStep) {
                        const match = channelSequenceId.match(/^ch(\d+)$/);
                        if (match) {
                            const channelIndex = parseInt(match[1], 10);
                            if (!isNaN(channelIndex) && channelIndex >= 0 && channelIndex < channels.length) {
                                channels[channelIndex].metadata.requiresReversal = true;
                            }
                        }
                    }
                });
            });

            return {
                id: projectName,
                artist: artistName,
                bpm: projectBPM,
                totalSequences: Object.keys(projectSequences).length,
                channels,
                projectSequences
            };
        });

        globalData.songsArray = songsArray;
        return songsArray;
    };

    const logSongsArray = (songsArray) => {
        console.log(`Total Songs: ${songsArray.length}`);
        songsArray.forEach((song, songIndex) => {
            console.log(`\nSong #${songIndex + 1}: ${song.id} by ${song.artist} - BPM: ${song.bpm} - Total Sequences: ${song.totalSequences}`);
            song.channels.forEach((channel, channelIndex) => {
                const meta = channel.metadata;
                console.log(`\tChannel ${channelIndex + 1} - ${channel.id}, Volume: ${meta.volume}, Playback Speed: ${meta.playbackSpeed}, Trim Start: ${meta.trimStartTime_Percentage}%, Trim End: ${meta.trimEndTime_Percentage}%, Requires Reversal: ${meta.requiresReversal}`);
            });
            console.log(`\tProject Sequences for ${song.id}:\n${JSON.stringify(song.projectSequences, null, 2)}`);
        });

        globalData.isSingleSong = songsArray.length === 1;
        globalData.isMultipleSongs = songsArray.length > 1;
        console.log(`\nFlags set - isSingleSong: ${globalData.isSingleSong}, isMultipleSongs: ${globalData.isMultipleSongs}`);

        document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
            detail: {
                success: true,
                totalSongs: songsArray.length,
                songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
            }
        }));
    };

    // Initialization
    try {
        const songDataUrls = [
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0"
        ];

        const validUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
        if (validUrls.length) {
            await loadPako();
            const deserializedData = await fetchAndProcessData(validUrls);
            const songsArray = processSongsAndChannels(deserializedData);
            logSongsArray(songsArray);
        } else {
            console.log('No valid song data URLs to process.');
        }
    } catch (error) {
        console.error('Error during initialization:', error);
    }
})();
</script>
</section>

<!-- Section 2 - Audio Buffering and Mapping -->
<section>
<script>
(async () => {
    const globalData = window.globalData;
    const audioContext = globalData.audioContext = globalData.audioContext || new (window.AudioContext || window.webkitAudioContext)();

    const base64ToArrayBuffer = (base64) => Uint8Array.from(atob(base64), c => c.charCodeAt(0)).buffer;

    const extractBase64FromHTML = (html) => {
        const match = html.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="([^"]+)"/i);
        if (match && match[1].includes("base64")) {
            const base64Index = match[1].indexOf("base64,");
            if (base64Index !== -1) return match[1].substring(base64Index + 7);
        }
        return null;
    };

    const extractBase64FromJSON = (jsonData) => {
        try {
            const parsed = JSON.parse(jsonData);
            if (parsed.audioData) {
                const base64Index = parsed.audioData.indexOf("base64,");
                if (base64Index !== -1) return parsed.audioData.substring(base64Index + 7);
            }
        } catch (e) {}
        return null;
    };

    const isValidBase64 = (str) => {
        const cleanedStr = str.replace(/\s+/g, '');
        if (cleanedStr.length % 4 !== 0) return false;
        try { atob(cleanedStr); return true; } catch (e) { return false; }
    };

    const fetchAndDecodeAudio = async (response, contentType, url) => {
        const cache = globalData.audioFetchCache;
        if (cache.has(url)) return cache.get(url);

        let audioBuffer;
        try {
            if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            } else if (/application\/json/.test(contentType)) {
                const textData = await response.text();
                const base64Data = extractBase64FromJSON(textData);
                if (base64Data && isValidBase64(base64Data)) {
                    const arrayBuffer = base64ToArrayBuffer(base64Data);
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                } else throw new Error("Invalid or missing base64 audio data in JSON.");
            } else if (/text\/html/.test(contentType)) {
                const textData = await response.text();
                const base64Data = extractBase64FromHTML(textData);
                if (base64Data && isValidBase64(base64Data)) {
                    const arrayBuffer = base64ToArrayBuffer(base64Data);
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                } else throw new Error("Invalid or missing base64 audio data in HTML.");
            } else if (/audio\//.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            } else throw new Error("Unsupported content type or missing audio data.");

            cache.set(url, audioBuffer);
            return audioBuffer;
        } catch (error) {
            console.error(`Error decoding audio from URL ${url}:`, error);
            throw error;
        }
    };

    const reverseArray = (array) => {
        const reversed = new Float32Array(array.length);
        for (let i = 0, len = array.length; i < len; i++) {
            reversed[i] = array[len - i - 1];
        }
        return reversed;
    };

    const createReverseAudioBuffer = (audioBuffer) => {
        const reverseBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
            const data = audioBuffer.getChannelData(channel);
            reverseBuffer.getChannelData(channel).set(reverseArray(data));
        }
        return reverseBuffer;
    };

    const extractFileName = (url) => url.split('/').pop() || "Unknown";

    const processChannel = async (song, channel, logEntries) => {
        try {
            const response = await fetch(channel.url);
            if (!response.ok) throw new Error(`Network response was not ok for URL: ${channel.url}`);

            const audioBuffer = await fetchAndDecodeAudio(response, response.headers.get("Content-Type"), channel.url);

            const { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = channel.metadata;
            if (trimEndTime_Percentage <= trimStartTime_Percentage) {
                console.warn(`Trim end percentage is less than or equal to start percentage for Song: ${song.id}, Channel: ${channel.id}`);
                return;
            }

            const trimStartTime = (trimStartTime_Percentage / 100) * audioBuffer.duration;
            const trimEndTime = (trimEndTime_Percentage / 100) * audioBuffer.duration;

            const startSample = Math.floor(trimStartTime * audioBuffer.sampleRate);
            const endSample = Math.floor(trimEndTime * audioBuffer.sampleRate);
            const trimmedLength = endSample - startSample;

            if (trimmedLength <= 0) {
                console.warn(`Trimmed length is non-positive for Song: ${song.id}, Channel: ${channel.id}`);
                return;
            }

            const trimmedAudioBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
            for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                trimmedAudioBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(startSample, endSample));
            }

            globalData.audioBuffers[song.id] = globalData.audioBuffers[song.id] || {};
            globalData.reverseAudioBuffers[song.id] = globalData.reverseAudioBuffers[song.id] || {};
            globalData.audioBuffers[song.id][channel.id] = trimmedAudioBuffer;

            if (requiresReversal) {
                const reversedBuffer = createReverseAudioBuffer(trimmedAudioBuffer);
                globalData.reverseAudioBuffers[song.id][channel.id] = reversedBuffer;
            }

            logEntries.push({
                songId: song.id,
                channelId: channel.id,
                audioFileName: extractFileName(channel.url),
                fullDuration: audioBuffer.duration.toFixed(2),
                durationAfterTrimming: trimmedAudioBuffer.duration.toFixed(2),
                requiresReversal
            });

            console.log(`Processed audio for Song: ${song.id}, Channel: ${channel.id}${requiresReversal ? " (Reversed)" : ""}`);
        } catch (error) {
            console.error(`Failed to process audio for Song: ${song.id}, Channel: ${channel.id}`, error);
        }
    };

    const logDetailedInfo = (logEntries) => {
        if (logEntries.length > 0) {
            console.table(logEntries.map(entry => ({
                "Song ID": entry.songId,
                "Channel ID": entry.channelId,
                "Audio File Name": entry.audioFileName,
                "Full Duration (s)": entry.fullDuration,
                "Duration After Trimming (s)": entry.durationAfterTrimming,
                "Requires Reversal": entry.requiresReversal
            })));
        } else {
            console.warn("No audio samples were processed successfully.");
        }
    };

    const processAllAudioChannels = async () => {
        const { songsArray } = globalData;
        if (!songsArray.length) {
            console.error("No songs available to process.");
            return;
        }

        const logEntries = [];
        const promises = songsArray.flatMap(song => song.channels.map(channel => processChannel(song, channel, logEntries)));
        const results = await Promise.allSettled(promises);

        results.forEach((result, index) => {
            if (result.status === 'rejected') {
                console.warn(`Processing failed for Channel ${index + 1}:`, result.reason);
            }
        });

        logDetailedInfo(logEntries);
        console.log("All trimmed audio buffers and reverse audio buffers have been created and mapped.");
        document.dispatchEvent(new CustomEvent("audioBuffersReady", { detail: { success: true } }));
    };

    const ensureAudioContextRunning = async () => {
        if (audioContext.state === 'suspended') await audioContext.resume();
    };

    const initAudioProcessing = async () => {
        try {
            await ensureAudioContextRunning();
            await processAllAudioChannels();
        } catch (error) {
            console.error("Error during audio processing initialization:", error);
        }
    };

    document.addEventListener("dataLoadingComplete", initAudioProcessing);
    if (globalData.songsArray.length) initAudioProcessing();
})();
</script>
</section>

<!-- Section 3 - Playback Engine -->
<section>
<script>
(() => {
    const globalData = window.globalData;
    const audioContext = globalData.audioContext;

    const lookahead = 0.1;
    const schedulerInterval = 25;
    let isPlaying = false;
    let schedulerTimerID = null;
    const sequenceStates = {};

    const initPlaybackEngine = () => {
        const { songsArray } = globalData;
        if (!songsArray.length) {
            console.error("No songs available for playback.");
            return;
        }
        console.log("Playback Engine Initialization Complete.");
        console.log("Playback is ready. Press 'p' to start.");
    };

    const startPlayback = () => {
        const { songsArray, audioBuffers, reverseAudioBuffers } = globalData;
        if (!songsArray.length) {
            console.error("No songs available for playback.");
            return;
        }

        const song = songsArray[0];
        const sequences = song.projectSequences || {};
        console.log(`Starting playback for Song: ${song.id} with ${Object.keys(sequences).length} sequences.`);
        console.log(`Song BPM: ${song.bpm}`);

        const stepsPerBeat = 4;
        const stepDuration = (60 / song.bpm) / stepsPerBeat;
        const sequenceDuration = 64 * stepDuration;

        let sequenceStartOffset = 0;
        for (const [sequenceName, sequence] of Object.entries(sequences)) {
            const startTime = audioContext.currentTime + sequenceStartOffset;
            sequenceStates[sequenceName] = {
                nextStepIndex: 0,
                nextStepTime: startTime,
                stepDuration,
                startTime,
                endTime: startTime + sequenceDuration,
                completed: false
            };
            console.log(`Initialized scheduler for sequence: ${sequenceName} starting at +${sequenceStartOffset.toFixed(2)}s`);
            sequenceStartOffset += sequenceDuration;
        }

        isPlaying = true;
        schedulerTimerID = setInterval(() => schedulerLoop(song, audioBuffers, reverseAudioBuffers), schedulerInterval);
        console.log('Playback started.');
    };

    const stopPlayback = () => {
        if (schedulerTimerID) clearInterval(schedulerTimerID);
        isPlaying = false;
        for (const state of Object.values(sequenceStates)) {
            state.nextStepIndex = 0;
            state.nextStepTime = 0;
            state.completed = false;
        }
        console.log('Playback stopped and sequence states reset.');
    };

    const schedulerLoop = (song, audioBuffers, reverseAudioBuffers) => {
        const currentTime = audioContext.currentTime;
        let allSequencesCompleted = true;

        for (const [sequenceName, sequence] of Object.entries(song.projectSequences || {})) {
            const state = sequenceStates[sequenceName];
            if (!state || state.completed) continue;

            // Check if the sequence has ended
            if (currentTime >= state.endTime) {
                state.completed = true;
                console.log(`Sequence ${sequenceName} has completed.`);
                continue;
            }

            allSequencesCompleted = false;

            // Schedule steps within the lookahead window
            while (state.nextStepTime < currentTime + lookahead && isPlaying) {
                const stepIndex = state.nextStepIndex;
                const stepTime = state.nextStepTime;

                for (const [trackName, trackData] of Object.entries(sequence)) {
                    const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                    const channel = song.channels[channelIndex];

                    if (!channel) continue;

                    const steps = trackData.steps || [];
                    const step = steps.find(s => (typeof s === "number" && s === stepIndex) || (s.index === stepIndex));

                    if (step !== undefined) {
                        const reverse = typeof step === "object" && step.reverse;
                        schedulePlayback(song, channel, stepTime, reverse, audioBuffers, reverseAudioBuffers, state.stepDuration);
                    }
                }

                state.nextStepIndex += 1;
                if (state.nextStepIndex >= 64) {
                    state.completed = true;
                    console.log(`Sequence ${sequenceName} has completed all steps.`);
                    break;
                }
                state.nextStepTime += state.stepDuration;
            }
        }

        if (allSequencesCompleted) {
            console.log("All sequences have completed.");
            stopPlayback();
            // Optionally, handle looping or moving to the next song here
        }
    };

    const schedulePlayback = (song, channel, time, reverse, audioBuffers, reverseAudioBuffers, stepDuration) => {
        const buffer = reverse ? reverseAudioBuffers[song.id][channel.id] : audioBuffers[song.id][channel.id];
        if (!buffer) return;

        if (buffer.duration > stepDuration) {
            console.warn(`Buffer duration (${buffer.duration.toFixed(2)}s) exceeds stepDuration (${stepDuration.toFixed(2)}s).`);
        }

        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.playbackRate.value = channel.metadata.playbackSpeed;
        source.connect(audioContext.destination);
        source.start(time);
    };

    const onKeyPress = (event) => {
        if (event.key.toLowerCase() === 'p') {
            if (!isPlaying) {
                startPlayback();
            } else {
                stopPlayback();
            }
        }
    };

    const initializePlayback = () => {
        console.log("Audio buffers are ready. Playback can begin.");
        initPlaybackEngine();
    };

    document.addEventListener("audioBuffersReady", () => {
        initializePlayback();
        console.log('Press "p" to start playback.');
        document.addEventListener('keydown', onKeyPress);
    });

    if (Object.keys(globalData.audioBuffers).length) {
        initializePlayback();
        console.log('Press "p" to start playback.');
        document.addEventListener('keydown', onKeyPress);
    }
})();
</script>
</section>

</body>
</html>