<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Optimized</title>
    <style>
        /* Artwork Cover Styling */
        #artworkCover {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: black;
            display: none; /* Hidden by default */
            justify-content: center;
            align-items: center;
            z-index: 1000; /* Ensure it's on top */
        }

        #artworkImage {
            max-width: 80%;
            max-height: 80%;
            object-fit: contain;
        }
    </style>
    
<customElements>
    <script>
            const artworkUrl = [
            "/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0",
        ];

        const songDataUrls = [
            // Uncomment or add more song URLs as needed
            // "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH
            // "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM
            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE ** MIGHT BE THIS ONE THAT IS OUT OF SYNC??
            // "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress
            // "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP
            // "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY
            // "/content/a4fb0b49181975450a6710f20128eb0b3acc51f4aa1ce87ebdbc9607562013a2i0", // MintyFresh Vibes
            // "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE
            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240
            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch
            // "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60
            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // ON-CHAIN IN THE MEMBRANE        
        ];

        // Initialize globalData
        const globalData = window.globalData = window.globalData || {
            isSingleSong: false,
            isMultipleSongs: true,
            isNormalPlayer: true,
            isLoopedPlayback: false,
            isSequentialPlayback: true,
            isRemixPlayer: false,
            songsArray: [],
            audioBuffers: {},
            reverseAudioBuffers: {},
            audioFetchCache: new Map(),
            isArtworkCover: true, // Flag to control artwork display
            isVisualiserCover: false,
            initialSampleOrder: [], // To store the order of initial samples
        };
    </script>
</customElements>

</head>

<body>

    <h1>Web3 Audio Sequencer Playback Engine Optimized</h1>
    <p>Check the console for the 2D array of songs and channels with metadata.</p>

    <!-- Artwork Cover Container -->
    <div id="artworkCover">
        <img id="artworkImage" src="" alt="Artwork Cover">
    </div>


<DOMElements>
    <script>
        // Ensure the DOM is fully loaded before adding event listeners
        document.addEventListener('DOMContentLoaded', () => {
            const artworkCover = document.getElementById('artworkCover');
        
            if (globalData.isArtworkCover && artworkUrl.length > 0) {
                // Listen for a click on the artwork cover to hide it
                artworkCover.addEventListener('click', () => {
                    artworkCover.style.display = 'none';
                    console.log('Artwork cover dismissed. Ready for playback.');
                });
        
                // Optionally, listen for a key press (e.g., 'Enter') to hide the artwork cover
                document.addEventListener('keydown', (event) => {
                    if (event.key === 'Enter') {
                        artworkCover.style.display = 'none';
                        console.log('Artwork cover dismissed via Enter key. Ready for playback.');
                    }
                });
            }
        });
        </script>
</DOMElements>

    <!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->
<section>
    <script>
    (async () => {
        


        

        // Configuration
        const keyMap = {
            0: "projectName",
            1: "artistName",
            2: "projectBPM",
            3: "currentSequence",
            4: "channelURLs",
            5: "channelVolume",
            6: "channelPlaybackSpeed",
            7: "trimSettings",
            8: "projectChannelNames",
            9: "startSliderValue",
            10: "endSliderValue",
            11: "totalSampleDuration",
            12: "start",
            13: "end",
            14: "projectSequences",
            15: "steps"
        };

        const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([k, v]) => [v, +k]));
        const channelMap = Array.from({ length: 26 }, (_, i) => String.fromCharCode(65 + i)); // A-Z
        const reverseChannelMap = Object.fromEntries(channelMap.map((letter, i) => [letter, i]));

        // Utility Functions
        const loadPako = async () => {
            try {
                const { default: pako } = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
                window.pako = pako;
            } catch (error) {
                console.error("Error loading Pako library:", error);
                throw error;
            }
        };

        const decompressSteps = (steps) => steps.flatMap(step => {
            if (typeof step === "number") return step;
            if (step?.r) {
                const [start, end] = step.r;
                return Array.from({ length: end - start + 1 }, (_, i) => start + i);
            }
            if (typeof step === "string" && step.endsWith("r")) {
                return { index: parseInt(step.slice(0, -1), 10), reverse: true };
            }
            return [];
        });

        const deserialize = (data) => {
            const recurse = (obj) => {
                if (Array.isArray(obj)) return obj.map(recurse);
                if (obj && typeof obj === "object") {
                    return Object.entries(obj).reduce((acc, [k, v]) => {
                        const key = keyMap[k] || k;
                        if (key === "projectSequences") {
                            acc[key] = Object.entries(v).reduce((seqAcc, [seqK, seqV]) => {
                                const seqName = `Sequence${seqK.replace(/^s/, "")}`;
                                seqAcc[seqName] = Object.entries(seqV).reduce((trackAcc, [trackK, trackV]) => {
                                    const chName = `ch${reverseChannelMap[trackK]}`;
                                    const steps = trackV[reverseKeyMap.steps] || [];
                                    trackAcc[chName] = { steps: decompressSteps(steps) };
                                    return trackAcc;
                                }, {});
                                return seqAcc;
                            }, {});
                        } else {
                            acc[key] = recurse(v);
                        }
                        return acc;
                    }, {});
                }
                return obj;
            };
            return recurse(data);
        };

        const fetchAndDeserialize = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                const arrayBuffer = await response.arrayBuffer();
                const inflatedData = window.pako.inflate(new Uint8Array(arrayBuffer));
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                return deserialize(JSON.parse(jsonString));
            } catch (error) {
                console.error(`Error fetching/deserializing URL ${url}:`, error);
                throw error;
            }
        };

        const fetchAndProcessData = async (urls) => {
            const fetchPromises = urls.map((url, index) => fetchAndDeserialize(url)
                .then(data => ({ data, index })) // Attach original index
                .catch(error => {
                    console.error(`Failed to process URL ${url}:`, error);
                    return null;
                })
            );
            const results = await Promise.all(fetchPromises);
            const validResults = results.filter(Boolean);
            if (!validResults.length) throw new Error("No valid data was processed.");
            return validResults;
        };

        const processSongsAndChannels = (deserializedDataWithIndices) => {
            const songsArray = deserializedDataWithIndices
                .sort((a, b) => a.index - b.index) // Ensure order based on original URLs array
                .map(({ data: songData, index: songIndex }) => {
                    const {
                        projectName = `Song_${songIndex + 1}`,
                        artistName = "Unknown Artist",
                        projectBPM = 120,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = songData;

                    const channels = Array.from({ length: 16 }, (_, i) => ({
                        id: channelMap[i] || `Channel_${i + 1}`,
                        url: channelURLs[i] || `URL_not_found`,
                        metadata: {
                            volume: channelVolume[i] ?? 1.0,
                            playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                            trimStartTime_Percentage: trimSettings[i]?.start || 0,
                            trimEndTime_Percentage: trimSettings[i]?.end || 100,
                            requiresReversal: false
                        }
                    }));

                    // Update requiresReversal flag based on projectSequences
                    Object.values(projectSequences).forEach(sequence => {
                        Object.entries(sequence).forEach(([channelSequenceId, channelSequence]) => {
                            const steps = channelSequence.steps || [];
                            const hasReverseStep = steps.some(step => typeof step === 'object' && step.reverse);
                            if (hasReverseStep) {
                                const match = channelSequenceId.match(/^ch(\d+)$/);
                                if (match) {
                                    const channelIndex = parseInt(match[1], 10);
                                    if (!isNaN(channelIndex) && channelIndex >= 0 && channelIndex < channels.length) {
                                        channels[channelIndex].metadata.requiresReversal = true;
                                    }
                                }
                            }
                        });
                    });

                    return {
                        id: `Song ${songIndex + 1}: ${projectName}`, // Prefix with song number
                        artist: artistName,
                        bpm: projectBPM,
                        totalSequences: Object.keys(projectSequences).length,
                        channels,
                        projectSequences
                    };
                });

            globalData.songsArray = songsArray;

            // For the first song, extract the initial sample order
            if (songsArray.length > 0) {
                globalData.initialSampleOrder = getInitialSampleOrder(songsArray[0]);
            }

            return songsArray;
        };

        /**
         * Determines the initial sample order for a song.
         * Prioritizes samples in the first few sequences and early steps.
         * @param {Object} song - The song object.
         * @returns {Array} - Array of sample objects with channelId and reverse flag.
         */
        const getInitialSampleOrder = (song) => {
            const sampleOrder = [];
            const sequences = song.projectSequences;
            const sequenceNames = Object.keys(sequences).sort(); // Ensure sequences are processed in order

            // Define how many sequences and steps to prioritize
            const prioritySequences = 2; // Number of initial sequences to prioritize
            const prioritySteps = 16; // Number of initial steps per sequence

            for (const sequenceName of sequenceNames.slice(0, prioritySequences)) {
                const sequence = sequences[sequenceName];

                // Process only the first 'prioritySteps' steps
                for (let stepIndex = 0; stepIndex < prioritySteps; stepIndex++) {
                    for (const [channelName, channelData] of Object.entries(sequence)) {
                        const steps = channelData.steps || [];
                        const step = steps.find(s => {
                            if (typeof s === "number") {
                                return s === stepIndex;
                            } else if (typeof s === "object" && s.index !== undefined) {
                                return s.index === stepIndex;
                            }
                            return false;
                        });
                        if (step !== undefined) {
                            const reverse = (typeof step === "object" && step.reverse) || false;
                            sampleOrder.push({ channelId: channelName, reverse });
                        }
                    }
                }
            }

            // Remove duplicates while preserving order
            const uniqueSampleOrder = [];
            const seen = new Set();
            for (const item of sampleOrder) {
                const key = item.channelId + (item.reverse ? "_reverse" : "");
                if (!seen.has(key)) {
                    seen.add(key);
                    uniqueSampleOrder.push(item);
                }
            }

            return uniqueSampleOrder;
        };

        const logSongsArray = (songsArray) => {
            console.log(`Total Songs: ${songsArray.length}`);
            songsArray.forEach((song, songIndex) => {
                console.log(`\n${song.id} by ${song.artist} - BPM: ${song.bpm} - Total Sequences: ${song.totalSequences}`);
                song.channels.forEach((channel, channelIndex) => {
                    const meta = channel.metadata;
                    console.log(`\tChannel ${channelIndex + 1} - ${channel.id}, Volume: ${meta.volume}, Playback Speed: ${meta.playbackSpeed}, Trim Start: ${meta.trimStartTime_Percentage}%, Trim End: ${meta.trimEndTime_Percentage}%, Requires Reversal: ${meta.requiresReversal}`);
                });
                console.log(`\tProject Sequences for ${song.id}:\n${JSON.stringify(song.projectSequences, null, 2)}`);
            });

            // Log initial sample order for the first song
            if (globalData.initialSampleOrder.length > 0) {
                console.log(`\nInitial Sample Order for ${globalData.songsArray[0].id}:`);
                globalData.initialSampleOrder.forEach((item, index) => {
                    console.log(`\t${index + 1}. Channel: ${item.channelId}, Reverse: ${item.reverse}`);
                });
            }

            // Log artwork URLs if isArtworkCover is true
            if (globalData.isArtworkCover && artworkUrl.length > 0) {
                console.log(`\nArtwork URL(s):`);
                artworkUrl.forEach((url, index) => {
                    console.log(`\tArtwork ${index + 1}: ${url}`);
                });
                displayArtworkCover(artworkUrl[0]); // Display the first artwork URL
            }

            globalData.isSingleSong = songsArray.length === 1;
            globalData.isMultipleSongs = songsArray.length > 1;
            console.log(`\nFlags set - isSingleSong: ${globalData.isSingleSong}, isMultipleSongs: ${globalData.isMultipleSongs}`);

            document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
                detail: {
                    success: true,
                    totalSongs: songsArray.length,
                    songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
                }
            }));
        };

        /**
         * Displays the artwork cover by setting the image source and showing the container.
         * @param {string} url - The URL of the artwork image.
         */
        const displayArtworkCover = (url) => {
            const artworkCover = document.getElementById('artworkCover');
            const artworkImage = document.getElementById('artworkImage');
            if (artworkCover && artworkImage) {
                artworkImage.src = url;
                artworkCover.style.display = 'flex';
            } else {
                console.warn("Artwork cover elements not found in the DOM.");
            }
        };

        // Initialization
        try {
            const validUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
            if (validUrls.length) {
                await loadPako();
                const deserializedDataWithIndices = await fetchAndProcessData(validUrls);
                const songsArray = processSongsAndChannels(deserializedDataWithIndices);
                logSongsArray(songsArray);
            } else {
                console.log('No valid song data URLs to process.');
            }
        } catch (error) {
            console.error('Error during initialization:', error);
        }
    })();
</script>
</section>

<!-- Section 2 - Audio Buffering and Mapping (Optimized for Lazy Loading) -->

<section2>
    <script>
    (async () => {
        const globalData = window.globalData || (window.globalData = {});
        const audioContext = globalData.audioContext = globalData.audioContext || new (window.AudioContext || window.webkitAudioContext)();

        // Utility Functions (unchanged)
        const base64ToArrayBuffer = (base64) => Uint8Array.from(atob(base64), c => c.charCodeAt(0)).buffer;

        const extractBase64FromHTML = (html) => {
            const match = html.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="([^"]+)"/i);
            if (match && match[1].includes("base64")) {
                const base64Index = match[1].indexOf("base64,");
                if (base64Index !== -1) return match[1].substring(base64Index + 7);
            }
            return null;
        };

        const extractBase64FromJSON = (jsonData) => {
            try {
                const parsed = JSON.parse(jsonData);
                if (parsed.audioData) {
                    const base64Index = parsed.audioData.indexOf("base64,");
                    if (base64Index !== -1) return parsed.audioData.substring(base64Index + 7);
                }
            } catch (e) {}
            return null;
        };

        const isValidBase64 = (str) => {
            const cleanedStr = str.replace(/\s+/g, '');
            if (cleanedStr.length % 4 !== 0) return false;
            try { atob(cleanedStr); return true; } catch (e) { return false; }
        };

        /**
         * Normalizes an AudioBuffer to a target peak amplitude.
         * @param {AudioBuffer} audioBuffer - The AudioBuffer to normalize.
         * @param {number} targetPeak - The desired peak amplitude (e.g., 0.5).
         * @returns {AudioBuffer} - The normalized AudioBuffer.
         */
        const normalizeAudioBuffer = (audioBuffer, targetPeak = 0.5) => {
            let maxAmplitude = 0;

            // Find the maximum amplitude across all channels
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const channelData = audioBuffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    const absSample = Math.abs(channelData[i]);
                    if (absSample > maxAmplitude) {
                        maxAmplitude = absSample;
                    }
                }
            }

            // Calculate the scaling factor
            const scalingFactor = maxAmplitude > 0 ? targetPeak / maxAmplitude : 1;

            // Apply the scaling factor to all channels
            if (scalingFactor !== 1) {
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        channelData[i] *= scalingFactor;
                    }
                }
                console.log(`Normalized AudioBuffer to target peak of ${targetPeak}. Scaling factor: ${scalingFactor.toFixed(4)}`);
            }

            return audioBuffer;
        };

        /**
         * Fetches and decodes audio data from a given URL based on its content type.
         * @param {Response} response - The fetch response object.
         * @param {string} contentType - The content type of the response.
         * @param {string} url - The URL of the audio resource.
         * @returns {Promise<AudioBuffer|null>} - The decoded AudioBuffer or null if decoding fails.
         */
        const fetchAndDecodeAudio = async (response, contentType, url) => {
            const cache = globalData.audioFetchCache = globalData.audioFetchCache || new Map();
            if (cache.has(url)) return cache.get(url);

            let audioBuffer;
            try {
                if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    console.log(`Successfully decoded audio from URL ${url}`);
                } else if (/application\/json/.test(contentType)) {
                    const textData = await response.text();
                    const base64Data = extractBase64FromJSON(textData);
                    if (base64Data && isValidBase64(base64Data)) {
                        const arrayBuffer = base64ToArrayBuffer(base64Data);
                        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        console.log(`Successfully decoded JSON audio from URL ${url}`);
                    } else {
                        console.warn(`Invalid or missing base64 audio data in JSON for URL ${url}. Skipping this channel.`);
                        return null; // Gracefully handle invalid base64
                    }
                } else if (/text\/html/.test(contentType)) {
                    const textData = await response.text();
                    const base64Data = extractBase64FromHTML(textData);
                    if (base64Data && isValidBase64(base64Data)) {
                        const arrayBuffer = base64ToArrayBuffer(base64Data);
                        audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                        console.log(`Successfully decoded HTML audio from URL ${url}`);
                    } else {
                        console.warn(`Invalid or missing base64 audio data in HTML for URL ${url}. Skipping this channel.`);
                        return null; // Gracefully handle invalid base64
                    }
                } else if (/audio\//.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    console.log(`Successfully decoded audio from URL ${url}`);
                } else {
                    console.warn(`Unsupported content type (${contentType}) or missing audio data for URL ${url}. Skipping this channel.`);
                    return null; // Gracefully handle unsupported content types
                }

                cache.set(url, audioBuffer);
                return audioBuffer;
            } catch (error) {
                console.warn(`Error decoding audio from URL ${url}:`, error.message);
                return null; // Gracefully handle decoding errors
            }
        };

        const reverseArray = (array) => {
            const reversed = new Float32Array(array.length);
            for (let i = 0, len = array.length; i < len; i++) {
                reversed[i] = array[len - i - 1];
            }
            return reversed;
        };

        const createReverseAudioBuffer = (audioBuffer) => {
            const reverseBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
            for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                const data = audioBuffer.getChannelData(channel);
                reverseBuffer.getChannelData(channel).set(reverseArray(data));
            }
            return reverseBuffer;
        };

        const extractFileName = (url) => url.split('/').pop() || "Unknown";

        /**
         * Processes an individual audio channel for a song.
         * @param {Object} song - The song object.
         * @param {Object} channel - The channel object.
         * @param {Array} logEntries - The array to store log entries.
         */
        const processChannel = async (song, channel, logEntries) => {
            try {
                const response = await fetch(channel.url);
                if (!response.ok) {
                    console.warn(`Network response was not ok for URL: ${channel.url}. Skipping this channel.`);
                    return; // Gracefully skip this channel
                }

                const contentType = response.headers.get("Content-Type") || "";
                console.log(`Fetching URL: ${channel.url} with Content-Type: ${contentType}`);

                const audioBuffer = await fetchAndDecodeAudio(response, contentType, channel.url);

                // Check if audioBuffer is null (decoding failed)
                if (!audioBuffer) {
                    console.warn(`Failed to decode audio for Song: ${song.id}, Channel: ${channel.id}. Skipping this channel.`);
                    return; // Gracefully skip this channel
                }

                const { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = channel.metadata;
                if (trimEndTime_Percentage <= trimStartTime_Percentage) {
                    console.warn(`Trim end percentage (${trimEndTime_Percentage}%) is <= start percentage (${trimStartTime_Percentage}%) for Song: ${song.id}, Channel: ${channel.id}`);
                    return; // Skip processing this channel
                }

                const trimStartTime = (trimStartTime_Percentage / 100) * audioBuffer.duration;
                const trimEndTime = (trimEndTime_Percentage / 100) * audioBuffer.duration;

                const startSample = Math.floor(trimStartTime * audioBuffer.sampleRate);
                const endSample = Math.floor(trimEndTime * audioBuffer.sampleRate);
                const trimmedLength = endSample - startSample;

                if (trimmedLength <= 0) {
                    console.warn(`Trimmed length (${trimmedLength} samples) is non-positive for Song: ${song.id}, Channel: ${channel.id}`);
                    return; // Skip processing this channel
                }

                const trimmedAudioBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    trimmedAudioBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(startSample, endSample));
                }

                // Normalize the trimmed audio buffer
                const normalizedAudioBuffer = normalizeAudioBuffer(trimmedAudioBuffer, 0.5); // Lower target peak amplitude

                // Store the normalized buffer in globalData
                globalData.audioBuffers = globalData.audioBuffers || {};
                globalData.reverseAudioBuffers = globalData.reverseAudioBuffers || {};
                globalData.audioBuffers[song.id] = globalData.audioBuffers[song.id] || {};
                globalData.reverseAudioBuffers[song.id] = globalData.reverseAudioBuffers[song.id] || {};
                globalData.audioBuffers[song.id][channel.id] = normalizedAudioBuffer;

                if (requiresReversal) {
                    const reversedBuffer = createReverseAudioBuffer(normalizedAudioBuffer);
                    // Normalize the reversed buffer as well
                    const normalizedReversedBuffer = normalizeAudioBuffer(reversedBuffer, 0.5);
                    globalData.reverseAudioBuffers[song.id][channel.id] = normalizedReversedBuffer;
                }

                logEntries.push({
                    songId: song.id,
                    channelId: channel.id,
                    audioFileName: extractFileName(channel.url),
                    fullDuration: audioBuffer.duration.toFixed(2),
                    durationAfterTrimming: normalizedAudioBuffer.duration.toFixed(2),
                    requiresReversal
                });

                console.log(`Processed and normalized audio for Song: ${song.id}, Channel: ${channel.id}${requiresReversal ? " (Reversed)" : ""}`);
            } catch (error) {
                console.warn(`Failed to process audio for Song: ${song.id}, Channel: ${channel.id}: ${error.message}`);
                // Optionally, implement fallback mechanisms here, such as assigning a silent buffer
            }
        };

        const logDetailedInfo = (logEntries) => {
            if (logEntries.length > 0) {
                console.table(logEntries.map(entry => ({
                    "Song ID": entry.songId,
                    "Channel ID": entry.channelId,
                    "Audio File Name": entry.audioFileName,
                    "Full Duration (s)": entry.fullDuration,
                    "Duration After Trimming (s)": entry.durationAfterTrimming,
                    "Requires Reversal": entry.requiresReversal
                })));
            } else {
                console.warn("No audio samples were processed successfully.");
            }
        };

        /**
         * Initializes a Master Gain Node to control overall output volume.
         * Ensures that the main audio bus does not get overloaded when multiple channels are played simultaneously.
         */
        const initializeMasterGain = () => {
            const masterGain = audioContext.createGain();
            masterGain.gain.value = 0.7; // Adjust this value as needed (0.0 to 1.0)
            masterGain.connect(audioContext.destination);
            globalData.masterGain = masterGain;
            console.log("Master Gain Node initialized with gain:", masterGain.gain.value);
        };

        const ensureAudioContextRunning = async () => {
            if (audioContext.state === 'suspended') await audioContext.resume();
        };

        /**
         * Activates the P-key listener to start playback.
         */
        const activatePKeyListener = () => {
            const onKeyPress = (event) => {
                if (event.key.toLowerCase() === 'p') {
                    startPlayback();
                }
            };
            window.addEventListener('keydown', onKeyPress);
            console.log("P-key listener activated. Press 'P' to start playback.");
        };

        /**
         * Starts playback by triggering the playback logic.
         */
        const startPlayback = () => {
            // Implement your playback logic here.
            console.log("Playback started.");
            // Example: Dispatch an event to signal playback start
            document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
        };

        /**
         * Processes audio channels for initial playback.
         * Loads only the necessary channels to buffer the first two bars (e.g., 4 seconds).
         * Activates the P-key listener once initial buffering is complete.
         */
        const processInitialAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs available to process.");
                return;
            }

            const logEntries = [];
            const initialPromises = [];

            // Iterate through the initialSampleOrder to prioritize loading
            for (const sample of initialSampleOrder) {
                const song = songsArray.find(s => s.id === sample.songId);
                if (!song) continue;
                const channel = song.channels.find(c => c.id === sample.channelId);
                if (!channel) continue;
                initialPromises.push(processChannel(song, channel, logEntries));
            }

            // Await all initial samples to be processed
            await Promise.all(initialPromises);
            logDetailedInfo(logEntries);
            console.log("Initial audio buffers for playback are ready.");

            // Initialize Master Gain Node
            initializeMasterGain();

            // Activate P-key listener
            activatePKeyListener();

            // Dispatch an event indicating that initial audio buffers are ready
            document.dispatchEvent(new CustomEvent("initialAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Processes remaining audio channels in the background.
         */
        const processRemainingAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs available to process.");
                return;
            }

            const logEntries = [];
            const backgroundPromises = [];

            // Collect all channels not in the initialSampleOrder
            for (const song of songsArray) {
                for (const channel of song.channels) {
                    // Check if this channel is already processed as part of initialSampleOrder
                    const isInitial = initialSampleOrder.some(sample => sample.songId === song.id && sample.channelId === channel.id);
                    if (!isInitial) {
                        backgroundPromises.push(processChannel(song, channel, logEntries));
                    }
                }
            }

            // Process remaining channels with limited concurrency to optimize performance
            const CONCURRENT_LIMIT = 4; // Adjust based on performance needs
            const batches = [];
            while (backgroundPromises.length) {
                batches.push(backgroundPromises.splice(0, CONCURRENT_LIMIT));
            }

            for (const batch of batches) {
                await Promise.all(batch);
                // Optionally, add progress updates here
            }

            logDetailedInfo(logEntries);
            console.log("All background audio buffers have been processed.");

            // Dispatch an event indicating that all audio buffers are ready
            document.dispatchEvent(new CustomEvent("allAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Initializes the entire audio processing workflow with lazy loading.
         */
        const initAudioProcessing = async () => {
            try {
                await ensureAudioContextRunning();

                // Phase 1: Process initial audio channels for immediate playback
                await processInitialAudioChannels();

                // Phase 2: Process remaining audio channels in the background
                processRemainingAudioChannels().catch(error => {
                    console.error("Error during background audio processing:", error);
                });
            } catch (error) {
                console.error("Error during audio processing initialization:", error);
            }
        };

        /**
         * Sets up the initial audio processing when data loading is complete.
         */
        const setupAudioProcessing = () => {
            document.addEventListener("dataLoadingComplete", initAudioProcessing);
            if (globalData.songsArray && globalData.songsArray.length) {
                initAudioProcessing();
            }
        };

        /**
         * Listens for the 'initialAudioBuffersReady' event to notify the user or perform additional actions.
         */
        const setupInitialBufferListener = () => {
            document.addEventListener("initialAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    console.log("Initial audio buffers are ready. You can now press 'P' to start playback.");
                    // Optionally, display a UI prompt or enable playback controls here
                }
            });
        };

        /**
         * Starts the entire setup process.
         */
        const startSetup = () => {
            setupAudioProcessing();
            setupInitialBufferListener();
        };

        // Initialization
        startSetup();
    })();
    </script>
<s/ection2>

<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) -->
<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) -->
<section>
    <script>
    (() => {
        const globalData = window.globalData || (window.globalData = {});
        const audioContext = globalData.audioContext;

        const lookahead = 0.1; // Time in seconds to look ahead for scheduling
        const schedulerInterval = 25; // Scheduler loop interval in milliseconds
        let isPlaying = false;
        let schedulerTimerID = null;
        let sequenceStates = {}; // Tracks the state of each sequence

        // Variables for Handling Multiple Songs and Looping
        let currentSongIndex = 0; // Tracks the index of the current song

        // Set to keep track of missing audio buffers to prevent multiple warnings
        const missingBuffers = new Set();

        /**
         * Initializes the Playback Engine.
         * Ensures that songs are available and sets up necessary components.
         */
        const initPlaybackEngine = () => {
            const { songsArray } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }
            console.log("Playback Engine Initialization Complete.");
            console.log("Playback is ready. Press 'P' to start.");
        };

        /**
         * Starts playback for the current song.
         * Initializes sequence states and starts the scheduler loop.
         */
        const startPlayback = () => {
            const { songsArray, audioBuffers, reverseAudioBuffers } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }

            // Update totalSongs dynamically
            const totalSongs = songsArray.length;

            // Ensure currentSongIndex is within bounds
            if (currentSongIndex >= totalSongs) {
                currentSongIndex = 0;
            }

            const song = songsArray[currentSongIndex];
            const sequences = song.projectSequences || {};
            console.log(`Starting playback for Song: ${song.id} (${currentSongIndex + 1}/${totalSongs}) with ${Object.keys(sequences).length} sequences.`);
            console.log(`Song BPM: ${song.bpm}`);

            const stepsPerBeat = 4;
            const stepDuration = (60 / song.bpm) / stepsPerBeat;
            const sequenceDuration = 64 * stepDuration;

            // Reset sequenceStates and missingBuffers for the new song
            sequenceStates = {};
            missingBuffers.clear(); // Clear missing buffers set

            let sequenceStartOffset = 0;
            for (const [sequenceName, sequence] of Object.entries(sequences)) {
                const startTime = audioContext.currentTime + sequenceStartOffset;
                sequenceStates[sequenceName] = {
                    nextStepIndex: 0,
                    nextStepTime: startTime,
                    stepDuration,
                    startTime,
                    endTime: startTime + sequenceDuration,
                    completed: false
                };
                console.log(`Initialized scheduler for sequence: ${sequenceName} starting at +${sequenceStartOffset.toFixed(2)}s`);
                sequenceStartOffset += sequenceDuration;
            }

            isPlaying = true;
            schedulerTimerID = setInterval(() => schedulerLoop(song, audioBuffers, reverseAudioBuffers), schedulerInterval);
            console.log('Playback started.');
        };

        /**
         * Stops playback and resets the Playback Engine state.
         */
        const stopPlayback = () => {
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback stopped and sequence states reset.');
        };

        /**
         * The main scheduler loop that schedules audio playback.
         * @param {Object} song - The current song object.
         * @param {Object} audioBuffers - The loaded audio buffers.
         * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
         */
        const schedulerLoop = (song, audioBuffers, reverseAudioBuffers) => {
            const currentTime = audioContext.currentTime;
            let allSequencesCompleted = true;

            for (const [sequenceName, sequence] of Object.entries(song.projectSequences || {})) {
                const state = sequenceStates[sequenceName];
                if (!state || state.completed) continue;

                // Check if the sequence has ended
                if (currentTime >= state.endTime) {
                    state.completed = true;
                    console.log(`Sequence ${sequenceName} has completed.`);
                    continue;
                }

                allSequencesCompleted = false;

                // Schedule steps within the lookahead window
                while (state.nextStepTime < currentTime + lookahead && isPlaying) {
                    const stepIndex = state.nextStepIndex;
                    const stepTime = state.nextStepTime;

                    for (const [trackName, trackData] of Object.entries(sequence)) {
                        const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                        const channel = song.channels[channelIndex];
                        
                        if (!channel) {
                            console.warn(`Channel index ${channelIndex} not found in song ${song.id}.`);
                            continue;
                        }

                        const steps = trackData.steps || [];
                        const step = steps.find(s => (typeof s === "number" && s === stepIndex) || (s.index === stepIndex));

                        if (step !== undefined) {
                            const reverse = typeof step === "object" && step.reverse;
                            schedulePlayback(song, channel, stepTime, reverse, audioBuffers, reverseAudioBuffers, state.stepDuration);
                        }
                    }

                    state.nextStepIndex += 1;
                    if (state.nextStepIndex >= 64) {
                        state.completed = true;
                        console.log(`Sequence ${sequenceName} has completed all steps.`);
                        break;
                    }
                    state.nextStepTime += state.stepDuration;
                }
            }

            if (allSequencesCompleted) {
                console.log("All sequences have completed.");

                const totalSongs = globalData.songsArray.length; // Update totalSongs

                // Handle looping and sequential playback based on flags
                if (globalData.isLoopedPlayback) {
                    if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                        // Move to the next song in the list
                        currentSongIndex += 1;
                        if (currentSongIndex >= totalSongs) {
                            currentSongIndex = 0; // Loop back to the first song
                            console.log("Reached the end of the playlist. Looping back to the first song.");
                        } else {
                            console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        }
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Loop the current song
                        console.log(`Looping the current song: ${song.id}`);
                        resetPlayback();
                        startPlayback();
                    }
                } else if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                    // Move to the next song without looping
                    currentSongIndex += 1;
                    if (currentSongIndex < totalSongs) {
                        console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Reached the end of the playlist
                        console.log("Reached the end of the playlist. Stopping playback.");
                        stopPlayback();
                    }
                } else {
                    // Single song playback without looping
                    console.log("Playback has completed the single song.");
                    stopPlayback();
                }
            }
        };

        /**
         * Schedules playback of an individual audio buffer.
         * @param {Object} song - The current song object.
         * @param {Object} channel - The current channel object.
         * @param {number} time - The scheduled start time in seconds.
         * @param {boolean} reverse - Indicates if the audio should be played in reverse.
         * @param {Object} audioBuffers - The loaded audio buffers.
         * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
         * @param {number} stepDuration - Duration of each step in seconds.
         */
        const schedulePlayback = (song, channel, time, reverse, audioBuffers, reverseAudioBuffers, stepDuration) => {
            const bufferKey = `${song.id}_${channel.id}_${reverse ? 'reverse' : 'normal'}`;
            const buffer = reverse ? reverseAudioBuffers[song.id]?.[channel.id] : audioBuffers[song.id]?.[channel.id];

            if (!buffer) {
                if (!missingBuffers.has(bufferKey)) {
                    missingBuffers.add(bufferKey);
                    console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
                }
                return;
            }

            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.playbackRate.value = channel.metadata.playbackSpeed || 1;
            source.connect(globalData.masterGain || audioContext.destination);
            source.start(time);
            // Uncomment the following line for detailed scheduling logs
            // console.log(`Scheduled playback for Channel: ${channel.id} at ${time.toFixed(2)}s${reverse ? " (Reverse)" : ""}`);
        };

        /**
         * Resets the Playback Engine for the next song.
         */
        const resetPlayback = () => {
            // Stop current playback and reset states without completely stopping the engine
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback reset for the next song.');
        };

        /**
         * Handles keypress events to toggle playback.
         * @param {KeyboardEvent} event - The keydown event object.
         */
        const onKeyPress = (event) => {
            if (event.key.toLowerCase() === 'p') {
                if (!isPlaying) {
                    startPlayback();
                } else {
                    stopPlayback();
                }
            }
        };

        /**
         * Initializes playback after audio buffers are ready.
         */
        const initializePlayback = () => {
            console.log("Audio buffers are ready. Playback can begin.");
            initPlaybackEngine();
        };

        /**
         * Sets up event listeners for custom events dispatched by Section 2.
         */
        const setupEventListeners = () => {
            // Listen for the initialAudioBuffersReady event to activate the P-key listener
            document.addEventListener("initialAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    console.log("Initial audio buffers are ready. You can now press 'P' to start playback.");
                    // P-key listener is already set up in the main initialization below
                }
            });

            // Listen for the allAudioBuffersReady event to log completion
            document.addEventListener("allAudioBuffersReady", (event) => {
                if (event.detail.success) {
                    console.log("All audio buffers have been loaded and are ready.");
                    // Optionally, perform additional actions here, such as updating the UI
                }
            });

            // Listen for the playbackStarted event if needed elsewhere
            document.addEventListener("playbackStarted", (event) => {
                if (event.detail.success) {
                    console.log("Playback has been successfully started.");
                    // Optionally, perform additional actions here
                }
            });
        };

        /**
         * Initializes the Playback Engine and sets up event listeners.
         */
        const setupPlaybackEngine = () => {
            initializePlayback();
            setupEventListeners();
            // Activate the P-key listener
            window.addEventListener('keydown', onKeyPress);
            console.log('Press "P" to start playback.');
        };

        /**
         * Starts the entire setup process.
         * If audio buffers are already loaded, initialize immediately.
         * Otherwise, wait for the initialAudioBuffersReady event.
         */
        const startSetup = () => {
            if (Object.keys(globalData.audioBuffers || {}).length) {
                // If audioBuffers are already loaded, initialize playback
                setupPlaybackEngine();
            } else {
                // Otherwise, wait for the initialAudioBuffersReady event
                document.addEventListener("initialAudioBuffersReady", setupPlaybackEngine);
            }
        };

        // Initialization
        startSetup();

    })();
    </script>
</section>

</body>
</html>