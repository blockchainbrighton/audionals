<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Optimized</title>
</head>
<body>
    <h1>Web3 Audio Sequencer Playback Engine Optimized</h1>
    <p>Check the console for the 2D array of songs and channels with metadata.</p>

<!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->
<section>
<script>
(async () => {
   

    const songDataUrls = [
                    // "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH
                    // "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM
                    "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA
                    "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE ** MIGHT BE THIS ONE THAT IS OUT OF SYNC??
                    // "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress
                    // "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP
                    // "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY
                    // "/content/a4fb0b49181975450a6710f20128eb0b3acc51f4aa1ce87ebdbc9607562013a2i0", // MintyFresh Vibes
                    // "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE
                    "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240
                    "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch
                    // "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60
                    "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // ON-CHAIN IN THE MEMBRANE        
                    ];



                     // Initialize globalData
    const globalData = window.globalData = window.globalData || {
        isSingleSong: false,
        isMultipleSongs: true,
        isNormalPlayer: true,
        isLoopedPlayback: false,
        isSequentialPlayback: true,
        isRemixPlayer: false,
        songsArray: [],
        audioBuffers: {},
        reverseAudioBuffers: {},
        audioFetchCache: new Map()
    };

    // Configuration
    const keyMap = {
        0: "projectName",
        1: "artistName",
        2: "projectBPM",
        3: "currentSequence",
        4: "channelURLs",
        5: "channelVolume",
        6: "channelPlaybackSpeed",
        7: "trimSettings",
        8: "projectChannelNames",
        9: "startSliderValue",
        10: "endSliderValue",
        11: "totalSampleDuration",
        12: "start",
        13: "end",
        14: "projectSequences",
        15: "steps"
    };

    const reverseKeyMap = {};
    for (const [k, v] of Object.entries(keyMap)) {
        reverseKeyMap[v] = +k;
    }

    const channelMap = Array.from({ length: 26 }, (_, i) => String.fromCharCode(65 + i));
    const reverseChannelMap = {};
    channelMap.forEach((letter, i) => { reverseChannelMap[letter] = i; });

    // Utility Functions
    const loadPako = async () => {
        try {
            const { default: pako } = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
            window.pako = pako;
        } catch (error) {
            console.error("Error loading Pako library:", error);
            throw error;
        }
    };

    const decompressSteps = (steps) => steps.flatMap(step => {
        if (typeof step === "number") return step;
        if (step?.r) {
            const [start, end] = step.r;
            return Array.from({ length: end - start + 1 }, (_, i) => start + i);
        }
        if (typeof step === "string" && step.endsWith("r")) {
            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
        }
        return [];
    });

    const deserialize = (data) => {
        const recurse = (obj) => {
            if (Array.isArray(obj)) return obj.map(recurse);
            if (obj && typeof obj === "object") {
                return Object.entries(obj).reduce((acc, [k, v]) => {
                    const key = keyMap[k] || k;
                    if (key === "projectSequences") {
                        acc[key] = Object.entries(v).reduce((seqAcc, [seqK, seqV]) => {
                            const seqName = `Sequence${seqK.replace(/^s/, "")}`;
                            seqAcc[seqName] = Object.entries(seqV).reduce((trackAcc, [trackK, trackV]) => {
                                const chName = `ch${reverseChannelMap[trackK]}`;
                                const steps = trackV[reverseKeyMap.steps] || [];
                                trackAcc[chName] = { steps: decompressSteps(steps) };
                                return trackAcc;
                            }, {});
                            return seqAcc;
                        }, {});
                    } else {
                        acc[key] = recurse(v);
                    }
                    return acc;
                }, {});
            }
            return obj;
        };
        return recurse(data);
    };

    const fetchAndDeserialize = async (url) => {
        try {
            const response = await fetch(url);
            if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
            const arrayBuffer = await response.arrayBuffer();
            const inflatedData = window.pako.inflate(new Uint8Array(arrayBuffer));
            const jsonString = new TextDecoder("utf-8").decode(inflatedData);
            return deserialize(JSON.parse(jsonString));
        } catch (error) {
            console.error(`Error fetching/deserializing URL ${url}:`, error);
            throw error;
        }
    };

    const fetchAndProcessData = async (urls) => {
        const results = await Promise.all(urls.map(url => fetchAndDeserialize(url).catch(error => {
            console.error(`Failed to process URL ${url}:`, error);
            return null;
        })));
        const validResults = results.filter(Boolean);
        if (!validResults.length) throw new Error("No valid data was processed.");
        return validResults;
    };

    const processSongsAndChannels = (deserializedData) => {
        const songsArray = deserializedData.map((songData, songIndex) => {
            const {
                projectName = `Song_${songIndex + 1}`,
                artistName = "Unknown Artist",
                projectBPM = 120,
                projectSequences = {},
                channelURLs = [],
                channelVolume = [],
                channelPlaybackSpeed = [],
                trimSettings = {}
            } = songData;

            const channels = Array.from({ length: 16 }, (_, i) => ({
                id: channelMap[i] || `Channel_${i + 1}`,
                url: channelURLs[i] || `URL_not_found`,
                metadata: {
                    volume: channelVolume[i] ?? 1.0,
                    playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                    trimStartTime_Percentage: trimSettings[i]?.start || 0,
                    trimEndTime_Percentage: trimSettings[i]?.end || 100,
                    requiresReversal: false
                }
            }));

            Object.values(projectSequences).forEach(sequence => {
                Object.entries(sequence).forEach(([channelSequenceId, channelSequence]) => {
                    const steps = channelSequence.steps || [];
                    const hasReverseStep = steps.some(step => typeof step === 'object' && step.reverse);
                    if (hasReverseStep) {
                        const match = channelSequenceId.match(/^ch(\d+)$/);
                        if (match) {
                            const channelIndex = parseInt(match[1], 10);
                            if (!isNaN(channelIndex) && channelIndex >= 0 && channelIndex < channels.length) {
                                channels[channelIndex].metadata.requiresReversal = true;
                            }
                        }
                    }
                });
            });

            return {
                id: projectName,
                artist: artistName,
                bpm: projectBPM,
                totalSequences: Object.keys(projectSequences).length,
                channels,
                projectSequences
            };
        });

        globalData.songsArray = songsArray;
        return songsArray;
    };

    const logSongsArray = (songsArray) => {
        console.log(`Total Songs: ${songsArray.length}`);
        songsArray.forEach((song, songIndex) => {
            console.log(`\nSong #${songIndex + 1}: ${song.id} by ${song.artist} - BPM: ${song.bpm} - Total Sequences: ${song.totalSequences}`);
            song.channels.forEach((channel, channelIndex) => {
                const meta = channel.metadata;
                console.log(`\tChannel ${channelIndex + 1} - ${channel.id}, Volume: ${meta.volume}, Playback Speed: ${meta.playbackSpeed}, Trim Start: ${meta.trimStartTime_Percentage}%, Trim End: ${meta.trimEndTime_Percentage}%, Requires Reversal: ${meta.requiresReversal}`);
            });
            console.log(`\tProject Sequences for ${song.id}:\n${JSON.stringify(song.projectSequences, null, 2)}`);
        });

        globalData.isSingleSong = songsArray.length === 1;
        globalData.isMultipleSongs = songsArray.length > 1;
        console.log(`\nFlags set - isSingleSong: ${globalData.isSingleSong}, isMultipleSongs: ${globalData.isMultipleSongs}`);

        document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
            detail: {
                success: true,
                totalSongs: songsArray.length,
                songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
            }
        }));
    };

    // Initialization
    try {
       
        const validUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
        if (validUrls.length) {
            await loadPako();
            const deserializedData = await fetchAndProcessData(validUrls);
            const songsArray = processSongsAndChannels(deserializedData);
            logSongsArray(songsArray);
        } else {
            console.log('No valid song data URLs to process.');
        }
    } catch (error) {
        console.error('Error during initialization:', error);
    }
})();
</script>
</section>

<!-- Section 2 - Audio Buffering and Mapping -->
<section>
<script>
(async () => {
    const globalData = window.globalData;
    const audioContext = globalData.audioContext = globalData.audioContext || new (window.AudioContext || window.webkitAudioContext)();

    const base64ToArrayBuffer = (base64) => Uint8Array.from(atob(base64), c => c.charCodeAt(0)).buffer;

    const extractBase64FromHTML = (html) => {
        const match = html.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="([^"]+)"/i);
        if (match && match[1].includes("base64")) {
            const base64Index = match[1].indexOf("base64,");
            if (base64Index !== -1) return match[1].substring(base64Index + 7);
        }
        return null;
    };

    const extractBase64FromJSON = (jsonData) => {
        try {
            const parsed = JSON.parse(jsonData);
            if (parsed.audioData) {
                const base64Index = parsed.audioData.indexOf("base64,");
                if (base64Index !== -1) return parsed.audioData.substring(base64Index + 7);
            }
        } catch (e) {}
        return null;
    };

    const isValidBase64 = (str) => {
        const cleanedStr = str.replace(/\s+/g, '');
        if (cleanedStr.length % 4 !== 0) return false;
        try { atob(cleanedStr); return true; } catch (e) { return false; }
    };

    /**
 * Fetches and decodes audio data from a given URL based on its content type.
 * @param {Response} response - The fetch response object.
 * @param {string} contentType - The content type of the response.
 * @param {string} url - The URL of the audio resource.
 * @returns {Promise<AudioBuffer|Array<AudioBuffer>|null>} - The decoded AudioBuffer, an array of AudioBuffers, or null if decoding fails.
 */
const fetchAndDecodeAudio = async (response, contentType, url) => {
    const cache = globalData.audioFetchCache;
    if (cache.has(url)) return cache.get(url);

    let audioBuffer;
    try {
        if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
            const arrayBuffer = await response.arrayBuffer();
            audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            console.log(`Successfully decoded audio from URL ${url}`);
        } else if (/application\/json/.test(contentType)) {
            const textData = await response.text();
            const base64Data = extractBase64FromJSON(textData);
            if (base64Data && isValidBase64(base64Data)) {
                const arrayBuffer = base64ToArrayBuffer(base64Data);
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                console.log(`Successfully decoded JSON audio from URL ${url}`);
            } else {
                console.warn(`Invalid or missing base64 audio data in JSON for URL ${url}. Skipping this channel.`);
                return null; // Gracefully handle invalid base64
            }
        } else if (/text\/html/.test(contentType)) {
            const textData = await response.text();
            const base64Data = extractBase64FromHTML(textData);
            if (base64Data && isValidBase64(base64Data)) {
                const arrayBuffer = base64ToArrayBuffer(base64Data);
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                console.log(`Successfully decoded HTML audio from URL ${url}`);
            } else {
                console.warn(`Invalid or missing base64 audio data in HTML for URL ${url}. Skipping this channel.`);
                return null; // Gracefully handle invalid base64
            }
        } else if (/audio\//.test(contentType)) {
            const arrayBuffer = await response.arrayBuffer();
            audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            console.log(`Successfully decoded audio from URL ${url}`);
        } else {
            console.warn(`Unsupported content type (${contentType}) or missing audio data for URL ${url}. Skipping this channel.`);
            return null; // Gracefully handle unsupported content types
        }

        cache.set(url, audioBuffer);
        return audioBuffer;
    } catch (error) {
        console.warn(`Error decoding audio from URL ${url}:`, error.message);
        return null; // Gracefully handle decoding errors
    }
};

    const reverseArray = (array) => {
        const reversed = new Float32Array(array.length);
        for (let i = 0, len = array.length; i < len; i++) {
            reversed[i] = array[len - i - 1];
        }
        return reversed;
    };

    const createReverseAudioBuffer = (audioBuffer) => {
        const reverseBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
        for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
            const data = audioBuffer.getChannelData(channel);
            reverseBuffer.getChannelData(channel).set(reverseArray(data));
        }
        return reverseBuffer;
    };

    const extractFileName = (url) => url.split('/').pop() || "Unknown";

    /**
 * Processes an individual audio channel for a song.
 * @param {Object} song - The song object.
 * @param {Object} channel - The channel object.
 * @param {Array} logEntries - The array to store log entries.
 */
const processChannel = async (song, channel, logEntries) => {
    try {
        const response = await fetch(channel.url);
        if (!response.ok) {
            console.warn(`Network response was not ok for URL: ${channel.url}. Skipping this channel.`);
            return; // Gracefully skip this channel
        }

        const contentType = response.headers.get("Content-Type") || "";
        console.log(`Fetching URL: ${channel.url} with Content-Type: ${contentType}`);

        const audioBuffer = await fetchAndDecodeAudio(response, contentType, channel.url);

        // Check if audioBuffer is null (decoding failed)
        if (!audioBuffer) {
            console.warn(`Failed to decode audio for Song: ${song.id}, Channel: ${channel.id}. Skipping this channel.`);
            return; // Gracefully skip this channel
        }

        const { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = channel.metadata;
        if (trimEndTime_Percentage <= trimStartTime_Percentage) {
            console.warn(`Trim end percentage (${trimEndTime_Percentage}%) is <= start percentage (${trimStartTime_Percentage}%) for Song: ${song.id}, Channel: ${channel.id}`);
            return; // Skip processing this channel
        }

        const trimStartTime = (trimStartTime_Percentage / 100) * audioBuffer.duration;
        const trimEndTime = (trimEndTime_Percentage / 100) * audioBuffer.duration;

        const startSample = Math.floor(trimStartTime * audioBuffer.sampleRate);
        const endSample = Math.floor(trimEndTime * audioBuffer.sampleRate);
        const trimmedLength = endSample - startSample;

        if (trimmedLength <= 0) {
            console.warn(`Trimmed length (${trimmedLength} samples) is non-positive for Song: ${song.id}, Channel: ${channel.id}`);
            return; // Skip processing this channel
        }

        const trimmedAudioBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, trimmedLength, audioBuffer.sampleRate);
        for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
            trimmedAudioBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(startSample, endSample));
        }

        globalData.audioBuffers[song.id] = globalData.audioBuffers[song.id] || {};
        globalData.reverseAudioBuffers[song.id] = globalData.reverseAudioBuffers[song.id] || {};
        globalData.audioBuffers[song.id][channel.id] = trimmedAudioBuffer;

        if (requiresReversal) {
            const reversedBuffer = createReverseAudioBuffer(trimmedAudioBuffer);
            globalData.reverseAudioBuffers[song.id][channel.id] = reversedBuffer;
        }

        logEntries.push({
            songId: song.id,
            channelId: channel.id,
            audioFileName: extractFileName(channel.url),
            fullDuration: audioBuffer.duration.toFixed(2),
            durationAfterTrimming: trimmedAudioBuffer.duration.toFixed(2),
            requiresReversal
        });

        console.log(`Processed audio for Song: ${song.id}, Channel: ${channel.id}${requiresReversal ? " (Reversed)" : ""}`);
    } catch (error) {
        console.warn(`Failed to process audio for Song: ${song.id}, Channel: ${channel.id}: ${error.message}`);
        // Optionally, you can implement fallback mechanisms here, such as assigning a silent buffer
    }
};

    const logDetailedInfo = (logEntries) => {
        if (logEntries.length > 0) {
            console.table(logEntries.map(entry => ({
                "Song ID": entry.songId,
                "Channel ID": entry.channelId,
                "Audio File Name": entry.audioFileName,
                "Full Duration (s)": entry.fullDuration,
                "Duration After Trimming (s)": entry.durationAfterTrimming,
                "Requires Reversal": entry.requiresReversal
            })));
        } else {
            console.warn("No audio samples were processed successfully.");
        }
    };

    const processAllAudioChannels = async () => {
        const { songsArray } = globalData;
        if (!songsArray.length) {
            console.error("No songs available to process.");
            return;
        }

        const logEntries = [];
        const promises = songsArray.flatMap(song => song.channels.map(channel => processChannel(song, channel, logEntries)));
        const results = await Promise.allSettled(promises);

        results.forEach((result, index) => {
            if (result.status === 'rejected') {
                console.warn(`Processing failed for Channel ${index + 1}:`, result.reason);
            }
        });

        logDetailedInfo(logEntries);
        console.log("All trimmed audio buffers and reverse audio buffers have been created and mapped.");
        document.dispatchEvent(new CustomEvent("audioBuffersReady", { detail: { success: true } }));
    };

    const ensureAudioContextRunning = async () => {
        if (audioContext.state === 'suspended') await audioContext.resume();
    };

    const initAudioProcessing = async () => {
        try {
            await ensureAudioContextRunning();
            await processAllAudioChannels();
        } catch (error) {
            console.error("Error during audio processing initialization:", error);
        }
    };

    document.addEventListener("dataLoadingComplete", initAudioProcessing);
    if (globalData.songsArray.length) initAudioProcessing();
})();
</script>
</section>

<!-- Section 3 - Playback Engine -->
<section>
    <script>
    (() => {
        const globalData = window.globalData;
        const audioContext = globalData.audioContext;
    
        const lookahead = 0.1;
        const schedulerInterval = 25;
        let isPlaying = false;
        let schedulerTimerID = null;
        let sequenceStates = {}; // Changed to let for reassignment
    
        // Variables for Handling Multiple Songs and Looping
        let currentSongIndex = 0; // Tracks the index of the current song
    
        // Set to keep track of missing audio buffers to prevent multiple warnings
        const missingBuffers = new Set();
    
        const initPlaybackEngine = () => {
            const { songsArray } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }
            console.log("Playback Engine Initialization Complete.");
            console.log("Playback is ready. Press 'p' to start.");
        };
    
        const startPlayback = () => {
            const { songsArray, audioBuffers, reverseAudioBuffers } = globalData;
            if (!songsArray.length) {
                console.error("No songs available for playback.");
                return;
            }
    
            // Update totalSongs dynamically
            const totalSongs = songsArray.length;
    
            // Ensure currentSongIndex is within bounds
            if (currentSongIndex >= totalSongs) {
                currentSongIndex = 0;
            }
    
            const song = songsArray[currentSongIndex];
            const sequences = song.projectSequences || {};
            console.log(`Starting playback for Song: ${song.id} (${currentSongIndex + 1}/${totalSongs}) with ${Object.keys(sequences).length} sequences.`);
            console.log(`Song BPM: ${song.bpm}`);
    
            const stepsPerBeat = 4;
            const stepDuration = (60 / song.bpm) / stepsPerBeat;
            const sequenceDuration = 64 * stepDuration;
    
            // Reset sequenceStates and missingBuffers for the new song
            sequenceStates = {};
            missingBuffers.clear(); // Clear missing buffers set
    
            let sequenceStartOffset = 0;
            for (const [sequenceName, sequence] of Object.entries(sequences)) {
                const startTime = audioContext.currentTime + sequenceStartOffset;
                sequenceStates[sequenceName] = {
                    nextStepIndex: 0,
                    nextStepTime: startTime,
                    stepDuration,
                    startTime,
                    endTime: startTime + sequenceDuration,
                    completed: false
                };
                console.log(`Initialized scheduler for sequence: ${sequenceName} starting at +${sequenceStartOffset.toFixed(2)}s`);
                sequenceStartOffset += sequenceDuration;
            }
    
            isPlaying = true;
            schedulerTimerID = setInterval(() => schedulerLoop(song, audioBuffers, reverseAudioBuffers), schedulerInterval);
            console.log('Playback started.');
        };
    
        const stopPlayback = () => {
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback stopped and sequence states reset.');
        };
    
        const schedulerLoop = (song, audioBuffers, reverseAudioBuffers) => {
            const currentTime = audioContext.currentTime;
            let allSequencesCompleted = true;
    
            for (const [sequenceName, sequence] of Object.entries(song.projectSequences || {})) {
                const state = sequenceStates[sequenceName];
                if (!state || state.completed) continue;
    
                // Check if the sequence has ended
                if (currentTime >= state.endTime) {
                    state.completed = true;
                    console.log(`Sequence ${sequenceName} has completed.`);
                    continue;
                }
    
                allSequencesCompleted = false;
    
                // Schedule steps within the lookahead window
                while (state.nextStepTime < currentTime + lookahead && isPlaying) {
                    const stepIndex = state.nextStepIndex;
                    const stepTime = state.nextStepTime;
    
                    for (const [trackName, trackData] of Object.entries(sequence)) {
                        const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                        const channel = song.channels[channelIndex];
    
                        if (!channel) continue;
    
                        const steps = trackData.steps || [];
                        const step = steps.find(s => (typeof s === "number" && s === stepIndex) || (s.index === stepIndex));
    
                        if (step !== undefined) {
                            const reverse = typeof step === "object" && step.reverse;
                            schedulePlayback(song, channel, stepTime, reverse, audioBuffers, reverseAudioBuffers, state.stepDuration);
                        }
                    }
    
                    state.nextStepIndex += 1;
                    if (state.nextStepIndex >= 64) {
                        state.completed = true;
                        console.log(`Sequence ${sequenceName} has completed all steps.`);
                        break;
                    }
                    state.nextStepTime += state.stepDuration;
                }
            }
    
            if (allSequencesCompleted) {
                console.log("All sequences have completed.");
    
                const totalSongs = globalData.songsArray.length; // Update totalSongs
    
                // Handle looping and sequential playback based on flags
                if (globalData.isLoopedPlayback) {
                    if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                        // Move to the next song in the list
                        currentSongIndex += 1;
                        if (currentSongIndex >= totalSongs) {
                            currentSongIndex = 0; // Loop back to the first song
                            console.log("Reached the end of the playlist. Looping back to the first song.");
                        } else {
                            console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        }
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Loop the current song
                        console.log(`Looping the current song: ${song.id}`);
                        resetPlayback();
                        startPlayback();
                    }
                } else if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                    // Move to the next song without looping
                    currentSongIndex += 1;
                    if (currentSongIndex < totalSongs) {
                        console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                        resetPlayback();
                        startPlayback();
                    } else {
                        // Reached the end of the playlist
                        console.log("Reached the end of the playlist. Stopping playback.");
                        stopPlayback();
                    }
                } else {
                    // Single song playback without looping
                    console.log("Playback has completed the single song.");
                    stopPlayback();
                }
            }
        };
    
        const schedulePlayback = (song, channel, time, reverse, audioBuffers, reverseAudioBuffers, stepDuration) => {
            const bufferKey = `${song.id}_${channel.id}_${reverse ? 'reverse' : 'normal'}`;
            const buffer = reverse ? reverseAudioBuffers[song.id][channel.id] : audioBuffers[song.id][channel.id];
    
            if (!buffer) {
                if (!missingBuffers.has(bufferKey)) {
                    missingBuffers.add(bufferKey);
                    console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
                }
                return;
            }
    
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.playbackRate.value = channel.metadata.playbackSpeed || 1;
            source.connect(audioContext.destination);
            source.start(time);
            // console.log(`Scheduled playback for Channel: ${channel.id} at ${time.toFixed(2)}s${reverse ? " (Reverse)" : ""}`);
        };
    
        const resetPlayback = () => {
            // Stop current playback and reset states without completely stopping the engine
            if (schedulerTimerID) clearInterval(schedulerTimerID);
            isPlaying = false;
            sequenceStates = {}; // Reset sequence states
            missingBuffers.clear(); // Clear missing buffers set
            console.log('Playback reset for the next song.');
        };
    
        const onKeyPress = (event) => {
            if (event.key.toLowerCase() === 'p') {
                if (!isPlaying) {
                    startPlayback();
                } else {
                    stopPlayback();
                }
            }
        };
    
        const initializePlayback = () => {
            console.log("Audio buffers are ready. Playback can begin.");
            initPlaybackEngine();
        };
    
        document.addEventListener("audioBuffersReady", () => {
            initializePlayback();
            console.log('Press "p" to start playback.');
            document.addEventListener('keydown', onKeyPress);
        });
    
        // Initialize immediately if audio buffers are already loaded
        if (Object.keys(globalData.audioBuffers).length) {
            initializePlayback();
            console.log('Press "p" to start playback.');
            document.addEventListener('keydown', onKeyPress);
        }
    })();
    </script>
    </section>

</body>
</html>