<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes">
    <title>Audionals Algo Player</title>

<style>
        /* Basic Reset and Centering */
        body, html {
            height: 100%;
            margin: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            background-color: #000;
            position: relative;
            /* Remove the transform: scale(0.7); */
        }

        /* Add scaling to the canvas container */
        #canvas-container {
            width: 50vmin; /* Responsive width */
            height: 50vmin; /* Responsive height */
            display: flex;
            justify-content: center;
            align-items: center;
            background-color: #fff;
            position: relative;
            z-index: 10;
            transform: scale(0.7); /* Scale only the canvas container */
        }

        /* Canvas for Visuals */
        canvas#cv {
            position: absolute; /* Overlay on the container */
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 9999; /* Above other elements */
            pointer-events: none; /* Prevent interference with mouse events */
        }

        /* Button Container for Additional Controls */
        #button-container {
            position: fixed;
            right: 10px;
            top: 60px;
            display: flex;
            flex-direction: column;
            gap: 10px;
            z-index: 10002;
        }

        /* Play Button Styles */
        #play-button {
            position: absolute; /* Cover the entire canvas */
            top: 0;
            left: 0;
            width: 100%; /* Full coverage */
            height: 100%; /* Full coverage */
            border: none; /* No border */
            background: transparent; /* Transparent background */
            cursor: pointer; /* Change cursor to pointer */
            z-index: 10000; /* Above all other elements */
            opacity: 0; /* Initially hidden */
            pointer-events: auto; /* Allow mouse events */
        }

        /* Styles for the Playing State of the Button */
        #play-button.playing {
            background-color: red; /* Change color when playing */
        }

        /* Hover Effects */
        #play-button:hover {
            background-color: #33c9ff; /* Light blue on hover */
        }

        #play-button.playing:hover {
            background-color: #ff4d4d; /* Darker red when playing */
        }

        /* New Information Panel Styles */
        /* New Information Panel Styles */
        #info-panel {
            position: fixed; /* Fixes the panel relative to the viewport */
            top: 0;          /* Aligns the panel to the top */
            right: 0;        /* Aligns the panel to the right */
            width: 300px;    /* Sets a fixed width for the panel */
            height: 100vh;   /* Makes the panel full height */
            background-color: rgba(255, 255, 255, 0.9); /* Semi-transparent background */
            box-shadow: -2px 0 5px rgba(0,0,0,0.5);    /* Adds a subtle shadow */
            padding: 20px;   /* Adds padding inside the panel */
            box-sizing: border-box; /* Ensures padding doesn't affect overall width */
            overflow-y: auto; /* Adds scroll if content overflows */
            z-index: 1000;    /* Ensures the panel is above other elements */
        }

        /* Hidden State for Information Panel */
        .hidden {
            display: none;
        }

        /* Optional: Add a class for the hidden state with transitions */
        #info-panel.hidden {
            transform: translateX(100%);
            opacity: 0;
        }

        /* Optional: Style the Information Content */
        #info-panel h2 {
            margin-top: 0;
            color: #333;
        }

        #info-canvas {
            display: block;
            margin: 20px 0;
            width: 100%;
            height: 100px; /* Adjust height as needed */
            border: 1px solid #ccc; /* Optional: Adds a border */
        }

        /* Style for the toggle button (Optional) */
        #toggle-info-button {
            padding: 10px 20px;
            font-size: 16px;
            cursor: pointer;
        }

        /* Styles for the information canvas */
        #info-canvas {
            display: block;
            margin: 20px 0;
            width: 100%;
            height: 100px; /* Adjust height as needed */
            border: 1px solid #ccc; /* Optional: Adds a border */
        }

        /* Background colors for Seed and BPM */
        :root {
            --seed-bg-color: #4CAF50; /* Green for Seed */
            --bpm-bg-color: #FF9800; /* Orange for BPM */
            --text-color: #FFFFFF; /* White text color */
            --font-size: 12px; /* Font size */
        }
        

        
</style>
</head>
<body>
    <div id="canvas-container">
        <img id="artwork" alt="Artwork">
        <canvas id="cv"></canvas> <!-- Removed width and height attributes -->
        <button id="play-button">Play</button>
    </div>

    <!-- Information Panel -->
<div id="info-panel">
        <h2>Information</h2>
        <div class="current-seed">
            <canvas id="info-canvas" width="200" height="100"></canvas>
            <div>
                <label for="seed-input">Enter Seed:</label>
                <input type="text" id="seed-input" />
                <button id="load-seed-button">Load Seed</button> <!-- Load Seed button -->
                <button id="clear-seeds-button">Clear Previous Seeds</button> <!-- Clear button -->
            </div>
            <div class="previous-seeds">
                <h3>Previous Seeds Played:</h3>
                <div id="previous-seeds-container"></div> <!-- Container for previously played seeds -->
            </div>
        </div>
</div>

<script id="globalMetadata">
       window.globalMetadata = {
            volumeLevels: {},
            playbackSpeeds: {},
            trimTimes: {},
            };
</script>

<seedAndBpmManagement>
    <details>
      <summary>Seed and BPM Management Documentation</summary>
  
      ### Overview
      This unified script manages both seed generation and BPM (Beats Per Minute) mapping within the audio playback application. It handles the retrieval and generation of seed values, maps seeds to BPM values, manages user interactions related to seeds, and maintains a history of previously used seeds. Additionally, it provides functionalities to toggle the visibility of the information panel, display current seed and BPM values, and allow users to copy or clear their seed history. By consolidating these functionalities, the script ensures streamlined and efficient management of seed-related operations, enhancing the application's reproducibility and user customization capabilities.
  
      ### Seed Management
  
      #### Seed Retrieval and Generation
      - **Query Parameter Extraction**: The script begins by extracting a seed value from the URL's query parameters. If a seed is provided, it is used as the fixed seed; otherwise, the fixed seed is initialized as an empty string.
      - **Seed Generation**: If no fixed seed is provided via the URL, the script generates a new seed consisting of a 20-digit numeric string. This ensures that each session can have a unique identifier influencing the application's behavior.
      - **Logging**: All actions related to seed generation and retrieval are logged with timestamps to facilitate debugging and tracking of seed-related activities.
  
      #### Seed Storage and Protection
      - **Immutable Seed Property**: The generated or retrieved seed is assigned to a global `seed` property on the `window` object. This property is defined as non-writable and non-configurable to prevent accidental modifications during runtime.
      - **Additional Seed Generation**: A function is provided to generate additional seeds, allowing for the creation of new identifiers without altering the original seed. This can be useful for creating variations or resetting the playback sequence.
  
      #### Seed Increment and Page Reload
      - **Increment Functionality**: The script includes a function to increment the current seed by one. This function parses the existing seed as an integer, increments it, updates the fixed seed, and reloads the page with the new seed appended as a query parameter. This facilitates seamless transitions to new playback sequences based on the updated seed.
  
      #### Seed Cleanup
      - **One-Time Use Seed**: If a seed is provided via the URL, the script removes it from the URL after retrieval. This ensures that the seed parameter is used only once, maintaining the integrity of seed-based operations and preventing unintended reuse.
  
      ### BPM Mapping
  
      #### Seed to BPM Conversion
      - **Predefined BPM Options**: A set of BPM values is defined, allowing the application to select from a standardized range of tempos.
      - **Hashing Mechanism**: The seed string is converted into a numerical hash by iterating over each character, applying a mathematical transformation to distribute the hash values uniformly.
      - **Deterministic Selection**: The resulting hash is used to index into the BPM options array, ensuring that the same seed consistently maps to the same BPM value. This deterministic approach guarantees reproducibility in audio playback based on the seed.
  
      #### Displaying Seed and BPM
      - **Information Panel Integration**: Upon loading, the application displays the current seed and its corresponding BPM value on an information panel. This provides users with immediate feedback on the parameters influencing their audio experience.
      - **Canvas Rendering**: The seed and BPM are rendered on a canvas element, with distinct background colors and text styles to differentiate between the two pieces of information. This visual representation enhances user understanding and engagement.
  
      ### User Interaction and Seed Management
  
      #### Information Panel Toggle
      - **Keyboard Shortcut**: Users can toggle the visibility of the information panel by pressing the "I" key. This provides quick access to seed and BPM information without navigating away from the main interface.
      - **State Persistence**: The visibility state of the information panel is stored in local storage, ensuring that user preferences are maintained across sessions.
  
      #### Seed History Management
      - **Previous Seeds Display**: The application maintains a history of previously used seeds, displaying them in a dedicated section. This allows users to reference or revisit past playback sequences.
      - **Copy Functionality**: Each listed seed includes a copy button, enabling users to easily copy seed values to the clipboard for sharing or future use.
      - **Clearing Seed History**: Users can clear the history of previous seeds through a dedicated button, providing control over their seed data and ensuring privacy or decluttering as needed.
  
      #### Seed Input and Validation
      - **Manual Seed Entry**: Users can input their own seed values through an input field. Upon submission, the application validates the seed to ensure it meets the required format (e.g., numeric) before reloading the page with the new seed.
      - **Input Validation**: The script enforces that seeds are numeric, preventing invalid or malformed seeds from being used, which could disrupt the application's deterministic behavior.
  
      ### Logging and Debugging
      - **Timestamped Logs**: All significant actions, such as seed generation, mapping, and user interactions, are logged with timestamps. This comprehensive logging facilitates debugging and provides a clear audit trail of seed-related activities.
      - **Error Handling**: The script includes error handling mechanisms that log errors encountered during seed retrieval, generation, or BPM mapping. This ensures that issues can be promptly identified and addressed.
  
      ### Organization
      - **Modular Structure**: The seed and BPM management functionalities are encapsulated within a single, cohesive script, promoting separation of concerns and enhancing code maintainability.
      - **Global Namespace Management**: By attaching essential properties and functions to the `window` object, the script ensures that these functionalities are accessible throughout the application while maintaining a clear structure.
      - **Event-Driven Workflow**: The script leverages event listeners to handle user interactions and state changes, ensuring a responsive and interactive user experience.
  
      ### Identified Improvements
  
      - **Modularization Enhancements**:
        - **Dedicated Modules**: Further segregate seed management and BPM mapping into separate functions within the script to enhance clarity and facilitate independent development and testing.
        - **Utility Consolidation**: Consolidate utility functions like `getQueryParam` and `log` into a centralized section within the script to promote reuse and reduce redundancy.
  
      - **Error Handling Enhancements**:
        - **User Feedback**: Implement user-facing notifications for critical errors, informing users of issues that may affect their experience.
        - **Robust Validation**: Expand validation checks to cover more edge cases, ensuring that seeds and BPM values are always within expected parameters.
  
      - **Performance Optimizations**:
        - **Efficient Seed Generation**: Optimize the seed generation logic to handle larger seeds or different formats if future requirements evolve.
        - **Local Storage Management**: Implement strategies to manage the size of the seed history, preventing excessive storage usage and maintaining performance.
  
      - **User Experience Enhancements**:
        - **Seed Visualization**: Enhance the visual representation of seeds and BPM values with animations or graphical elements to make the information more engaging.
        - **Accessibility Improvements**: Ensure that all interactive elements, such as buttons and input fields, are accessible and usable by individuals with disabilities.
  
      - **Testing and Validation**:
        - **Unit Testing**: Develop comprehensive unit tests for all functions related to seed management and BPM mapping to ensure reliability and correctness.
        - **Integration Testing**: Test the interaction between seed management, BPM mapping, and other application components to identify and resolve any integration issues.
  
      ### Workflow Understanding
  
      - **Seed Lifecycle**: The seed management process begins with retrieval from the URL or generation of a new seed. The seed is then used to map to a BPM value, which influences the audio playback. Users can interact with the seed by viewing, copying, or generating new seeds, ensuring a dynamic and customizable audio experience.
      - **BPM Influence**: The BPM value derived from the seed directly affects the tempo of the audio playback, allowing for a varied and engaging listening experience based on user-defined or randomized seeds.
      - **User Interactions**: Through keyboard shortcuts and interactive UI elements, users can easily manage seeds and view relevant information, enhancing the application's usability and responsiveness.
  
      ### User Interaction Improvement
  
      - **Enhanced Customization**: By allowing users to input their own seeds and view BPM mappings, the application offers a high degree of customization, enabling users to tailor the audio experience to their preferences.
      - **Transparency and Control**: Displaying seed and BPM information, along with the history of previously used seeds, provides users with transparency and control over the factors influencing their audio playback.
      - **Ease of Use**: Intuitive interactions, such as keyboard shortcuts for toggling information panels and straightforward methods for copying and managing seeds, contribute to a user-friendly experience.
      - **Responsive Feedback**: Logging messages during seed generation, mapping, and user interactions provide transparency into the application's state, aiding both developers and users in understanding the system's behavior.
  
    </details>
    
    <script id="seedAndBpmManagement">
      (function() {
          /**
           * Retrieves the value of a query parameter from the URL.
           * @param {string} param - The name of the query parameter.
           * @returns {string|null} - The value of the query parameter or null if not found.
           */
          function getQueryParam(param) {
              const urlParams = new URLSearchParams(window.location.search);
              return urlParams.get(param);
          }
  
          // Initialize fixedSeed from query parameter if available
          const seedFromURL = getQueryParam('seed') || "";
          window.fixedSeed = seedFromURL;
  
          /**
           * Generates a seed.
           * @returns {string} - The generated seed.
           */
          function generateSeed() {
              if (typeof window.fixedSeed === "string" && window.fixedSeed.length > 0) {
                  return window.fixedSeed;
              }
              return Array.from({ length: 20 }, () => Math.floor(Math.random() * 10)).join("");
          }
  
          /**
           * Logs messages with a timestamp.
           * @param {string} message - The message to log.
           */
          function log(message) {
              console.log(`[${new Date().toISOString()}] ${message}`);
          }
  
          window.log = log;
  
          window.log("Generating new seed...");
          const newSeed = generateSeed();
          window.log(`New seed generated: ${newSeed}`);
  
          Object.defineProperty(window, "seed", {
              value: newSeed,
              writable: false,
              configurable: false,
              enumerable: true
          });
  
          window.generateAdditionalSeed = function() {
              const additionalSeed = generateSeed();
              window.log(`Generating additional seed: ${additionalSeed}`);
              return additionalSeed;
          };
  
          // If a seed was provided via URL, remove it to make the request temporary
          if (seedFromURL) {
              const url = new URL(window.location);
              url.searchParams.delete('seed');
              window.history.replaceState({}, document.title, url.toString());
              window.log("Seed parameter removed from URL to make it a one-time use.");
          }
  
          /**
           * Increments the current seed by 1 and reloads the page with the new seed.
           */
          window.incrementSeedAndReload = function() {
              // Convert the current seed to an integer
              let currentSeedInt = parseInt(window.seed, 10);
  
              // Handle potential NaN
              if (isNaN(currentSeedInt)) {
                  currentSeedInt = 0;
              }
  
              // Increment the seed
              const newSeedInt = currentSeedInt + 1;
  
              // Update window.fixedSeed
              window.fixedSeed = newSeedInt.toString();
  
              // Update the URL with the new seed
              const url = new URL(window.location.href);
              url.searchParams.set('seed', window.fixedSeed);
  
              // Reload the page with the updated URL
              window.location.href = url.toString();
          }
  
          /**
           * Toggles the visibility of the Information Panel.
           */
          function toggleInfoPanel() {
              const infoPanel = document.getElementById("info-panel");
              if (!infoPanel) {
                  window.log("Info panel element not found.");
                  return;
              }
              infoPanel.classList.toggle("hidden");
              // Store the state
              localStorage.setItem("infoPanelHidden", infoPanel.classList.contains("hidden"));
          }
  
          window.toggleInfoPanel = toggleInfoPanel;
  
          /**
           * Displays the Seed and BPM on the info canvas.
           * @param {string} seed - The seed value.
           * @param {number} bpm - The BPM value.
           */
          function displaySeedAndBPM(seed, bpm) {
              const infoCanvas = document.getElementById("info-canvas");
              if (!infoCanvas) {
                  window.log("Info canvas element not found.");
                  return;
              }
              const ctx = infoCanvas.getContext("2d");
  
              // Clear the canvas before drawing
              ctx.clearRect(0, 0, infoCanvas.width, infoCanvas.height);
  
              // Draw background rectangles using CSS variables or defaults
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--seed-bg-color') || 'green'; // Default to green
              ctx.fillRect(0, 0, infoCanvas.width, infoCanvas.height / 2);
  
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bpm-bg-color') || 'orange'; // Default to orange
              ctx.fillRect(0, infoCanvas.height / 2, infoCanvas.width, infoCanvas.height / 2);
  
              // Set text properties for Seed
              ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--text-color') || 'white'; // Default to white
              ctx.font = `${getComputedStyle(document.documentElement).getPropertyValue('--font-size') || '16px'} Arial`; // Default font size
              ctx.textAlign = "center";
              ctx.textBaseline = "middle";
              ctx.fillText(`Seed: ${seed}`, infoCanvas.width / 2, infoCanvas.height / 4);
  
              // Set text properties for BPM
              ctx.fillText(`BPM: ${bpm}`, infoCanvas.width / 2, (3 * infoCanvas.height) / 4);
  
              // Save the seed to local storage
              saveSeed(seed);
          }
  
          window.displaySeedAndBPM = displaySeedAndBPM;
  
          /**
           * Saves the seed to local storage and updates the list of previous seeds.
           * @param {string} seed - The seed to save.
           */
          function saveSeed(seed) {
              const previousSeeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
              
              // Avoid duplicates
              if (!previousSeeds.includes(seed)) {
                  previousSeeds.push(seed);
                  localStorage.setItem("previousSeeds", JSON.stringify(previousSeeds));
                  displayPreviousSeeds(previousSeeds);
              }
          }
  
          window.saveSeed = saveSeed;
  
          /**
           * Displays the list of previously played seeds.
           * @param {Array<string>} seeds - The array of previous seeds.
           */
          function displayPreviousSeeds(seeds) {
              const previousSeedsContainer = document.getElementById("previous-seeds-container");
              if (!previousSeedsContainer) {
                  window.log("Previous seeds container element not found.");
                  return;
              }
  
              // Clear existing seeds
              previousSeedsContainer.innerHTML = "";
  
              const seedList = document.createElement("ul");
  
              seeds.forEach(seed => {
                  const listItem = document.createElement("li");
                  listItem.textContent = seed;
  
                  // Create a copy button for each seed
                  const copyButton = document.createElement("button");
                  copyButton.textContent = "Copy";
                  copyButton.onclick = () => copyToClipboard(seed);
                  listItem.appendChild(copyButton);
  
                  seedList.appendChild(listItem);
              });
  
              previousSeedsContainer.appendChild(seedList);
          }
  
          window.displayPreviousSeeds = displayPreviousSeeds;
  
          /**
           * Copies the seed to the clipboard.
           * @param {string} seed - The seed to copy.
           */
          function copyToClipboard(seed) {
              navigator.clipboard.writeText(seed).then(() => {
                  alert("Seed copied to clipboard: " + seed);
              }).catch(err => {
                  console.error("Could not copy text: ", err);
              });
          }
  
          window.copyToClipboard = copyToClipboard;
  
          /**
           * Clears the previous seeds from local storage and updates the display.
           */
          function clearPreviousSeeds() {
              if (confirm("Are you sure you want to clear all previous seeds?")) {
                  localStorage.removeItem("previousSeeds"); // Clear local storage
                  displayPreviousSeeds([]); // Update the display to show an empty list
              }
          }
  
          window.clearPreviousSeeds = clearPreviousSeeds;
  
          /**
           * Maps the seed to a BPM value based on a predefined list.
           * @param {string} seed - The seed value.
           * @returns {number} - The selected BPM.
           */
          function mapSeedToBpm(seed) {
              const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
              const hash = seed.split("").reduce((acc, char) => {
                  return (10 * acc + parseInt(char, 10)) % 1000000007;
              }, 0);
              const selectedBpm = bpmOptions[hash % bpmOptions.length];
              window.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
              return selectedBpm;
          }
  
          window.mapSeedToBpm = mapSeedToBpm;
  
          /**
           * Displays the Seed and BPM on the info canvas.
           * @param {string} seed - The seed value.
           * @param {number} bpm - The BPM value.
           */
          window.displaySeedAndBPM = displaySeedAndBPM;
  
          // On page load, set the initial state
          window.addEventListener("DOMContentLoaded", () => {
              const infoPanel = document.getElementById("info-panel");
              if (!infoPanel) {
                  window.log("Info panel element not found.");
              } else {
                  const isHidden = localStorage.getItem("infoPanelHidden") === "true";
                  if (isHidden) {
                      infoPanel.classList.add("hidden");
                  }
              }
              
              // Load previously played seeds
              const previousSeeds = JSON.parse(localStorage.getItem("previousSeeds")) || [];
              displayPreviousSeeds(previousSeeds);
  
              // Display current seed and BPM
              const seed = window.seed;
              const bpm = mapSeedToBpm(seed);
              displaySeedAndBPM(seed, bpm);
          });
  
          /**
           * Event listener for the "I" key to toggle the Information Panel.
           */
          document.addEventListener("keydown", function(event) {
              if (event.key === "I" || event.key === "i") {
                  toggleInfoPanel();
              }
          });
  
          /**
           * Event handler for the "Clear Previous Seeds" button.
           */
          document.getElementById("clear-seeds-button").addEventListener("click", clearPreviousSeeds);
  
          /**
           * Event handler for the "Load Seed" button.
           */
          document.getElementById("load-seed-button").addEventListener("click", () => {
              const seedInput = document.getElementById("seed-input").value.trim();
              if (seedInput.length === 0) {
                  alert("Please enter a seed.");
                  return;
              }
              // Optional: Validate seed format (e.g., numeric)
              if (!/^\d+$/.test(seedInput)) {
                  alert("Seed must be numeric.");
                  return;
              }
              // Reload the page with the seed as a query parameter
              const url = new URL(window.location.href);
              url.searchParams.set('seed', seedInput);
              window.location.href = url.toString();
          });
  
      })();
    </script>
</seedAndBpmManagement>
  
<!-- Song Inputs -->
<script id="song-inputs">
    window.init = function() {
        window.log('Init function called. Preparing to process song data URLs...');

        const songDataUrls = [


            "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM

            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH

            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA

            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE ** MIGHT BE THIS ONE THAT IS OUT OF SYNC??


            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress

            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP

            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY // Turn Down Channels 1 + 2 (Apollo 13) Turn down Channel 5 - Hindenburg /  Turn channel 8 up - Hi hats

            "/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0", // MintyFresh Vibes

            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE

            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240

            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch

            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60

            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // ON-CHAIN IN THE MEMBRANE
            // Add or remove song URLs as needed
        ];

       // Filter out commented URLs
       const validSongUrls = songDataUrls.filter(url => !url.trim().startsWith('//'));

        window.log(`Found ${validSongUrls.length} valid song data URLs to process.`);

        // Determine playback mode based on the number of songs
        let playbackMode;
        if (validSongUrls.length === 1) {
            playbackMode = 'normal playback mode';
        } else if (validSongUrls.length > 1) {
            playbackMode = 'multiple playback mode';
        } else {
            window.log('No valid songs to process.');
            return;
        }

        window.log(`Player is now in ${playbackMode}.`);

        // Modify the first URL using the global seed
        const seed = window.seed;
        if (typeof seededRandom === 'function') {
            validSongUrls[0] += `?v=${Math.floor(seededRandom(seed) * 1000)}`;
            window.log(`First song URL has been modified using seeded random. New URL: ${validSongUrls[0]}`);
        } else {
            window.log("seededRandom function is not defined.");
        }

        if (validSongUrls.length) {
            window.log('Beginning processing of songDataUrls...');
            if (typeof processSerializedData === 'function') {
                processSerializedData(validSongUrls, VOLUME_CONTROLS, SPEED_CONTROLS);
            } else {
                window.log("processSerializedData function is not defined.");
            }
        } else {
            window.log('songDataUrls array is empty. No data to process.');
        }

        window.log('Init function execution complete.');
        };
        </script>

<!-- Main Initialization -->
<script id="main-initialization">
    window.initializeMultiplierArrays=async function(){window.log("Initializing multiplier arrays..."),window.multiplierArrays=[],window.log("Multiplier arrays initialized.")};

    (async function() {
        window.visualiserMode = false; // Set to true to enable visualiser scripts

        // Ensure the seed is already set
        if (!window.seed) {
            window.log('Seed is not set. Initialization aborted.');
            return;
        }

        // Initialize multiplier arrays
        if (typeof window.initializeMultiplierArrays === 'function') {
            await window.initializeMultiplierArrays();
        } else {
            window.log("initializeMultiplierArrays function is not defined.");
        }

        // Initialize the main application
        if (typeof window.init === 'function') {
            window.init();
            window.log("Main application initialized.");
        } else {
            window.log("init function is not defined.");
        }

        // Conditional Loading of Visualizer or Artwork Scripts
        if (window.visualiserMode && window.enableVisualizerScripts) {
            if (typeof window.loadVisualiserScripts === 'function') {
                await window.loadVisualiserScripts();
                window.log("Visualizer scripts loaded.");
            } else {
                window.log("loadVisualiserScripts function is not defined.");
            }
        } else {
            if (typeof window.loadArtworkScripts === 'function') {
                await window.loadArtworkScripts();
                window.log("Artwork scripts loaded.");
            } else {
                window.log("loadArtworkScripts function is not defined.");
            }
        }

        // Load the image
        document.getElementById('artwork').src = '/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0';
        document.getElementById('artwork').alt = 'Loaded Artwork';

        // Removed Event Listener for Song Completion
    })();
</script>
<details>

  



<mainInitialisation>
<summary>Main Initialization Documentation</summary>
 <details>
      Main Initialization Documentation
      
        ### Overview
        This script is responsible for initializing the main components of the audio playback application. It ensures that essential configurations are set, necessary scripts are loaded based on the application's mode, and the artwork is properly displayed. The script performs several key actions in sequence, including checking for a seed value, initializing multiplier arrays, invoking the main application initializer, and conditionally loading visualizer or artwork scripts. Additionally, it sets the source and alternative text for the artwork image element.
      
        ### Script Breakdown
      
        #### Immediately-Invoked Async Function
        - **Purpose**: Executes the initialization process as soon as the script is loaded.
        - **Description**:
          - Runs an asynchronous function immediately to handle the initialization steps without blocking the main thread.
          - Ensures that all asynchronous operations (like loading scripts) are handled properly using `await`.
        
        #### Initialization Steps
        1. **Set Visualizer Mode**:
          
           - **Purpose**: Configures the application to determine whether to load visualizer scripts or artwork scripts.
           - **Default Setting**: Disabled (`false`), meaning artwork scripts will be loaded by default.
      
        2. **Seed Validation**:
          
      
           - **Purpose**: Checks if a global `seed` value is set, which is likely crucial for deterministic behaviors in the application.
           - **Behavior**:
             - If `window.seed` is not defined or falsy, logs an error message and aborts the initialization process.
             - Prevents the application from running without a necessary seed, ensuring data integrity.
      
        3. **Initialize Multiplier Arrays**:
         
           - **Purpose**: Initializes multiplier arrays that likely affect audio playback parameters like volume and speed.
           - **Behavior**:
             - Checks if `window.initializeMultiplierArrays` is a defined function.
             - If defined, calls and awaits its completion to ensure multiplier arrays are set before proceeding.
             - If not defined, logs a warning message indicating the missing function.
      
        4. **Main Application Initialization**:
          
           - **Purpose**: Calls the primary initializer of the application to set up core functionalities.
           - **Behavior**:
             - Checks if `window.init` is a defined function.
             - If defined, invokes it to initialize the main application components and logs a success message.
             - If not defined, logs a warning message indicating the missing function.
      
        5. **Conditional Script Loading**:
          

           - **Purpose**: Loads additional scripts based on the application's mode—either visualizer scripts or artwork scripts.
           - **Behavior**:
             - If `window.visualiserMode` and `window.enableVisualizerScripts` are both `true`, attempts to load visualizer scripts.
               - Checks if `window.loadVisualiserScripts` is a defined function.
               - If defined, calls and awaits its completion, then logs a success message.
               - If not defined, logs a warning message.
             - If visualizer mode is not enabled, attempts to load artwork scripts instead.
               - Checks if `window.loadArtworkScripts` is a defined function.
               - If defined, calls and awaits its completion, then logs a success message.
               - If not defined, logs a warning message.
      
        6. **Artwork Element Configuration**:
        
           - **Purpose**: Sets the source and alternative text for the artwork image element in the DOM.
           - **Behavior**:
             - Locates the DOM element with the ID `artwork`.
             - Assigns the `src` attribute to point to the specified artwork resource.
             - Sets the `alt` attribute to provide descriptive text for accessibility and fallback scenarios.
      
        ### Organization
        - **Sequential Initialization**: The script follows a logical sequence—validating the seed, initializing multiplier arrays, invoking the main initializer, conditionally loading additional scripts, and configuring the artwork element.
        - **Conditional Logic**: Uses conditional statements to handle different modes (visualizer vs. artwork) and the presence of necessary functions, ensuring flexibility and robustness.
        - **Asynchronous Handling**: Employs asynchronous operations (`await`) to manage the loading of scripts without blocking the execution flow, enhancing performance and user experience.
      
        ### Identified Improvements
      
        - **Modularizing**:
          - **Separate Initialization Concerns**: Consider breaking down the initialization steps into separate functions or modules (e.g., seed validation, multiplier initialization, script loading) to enhance readability and maintainability.
          - **Error Handling Enhancements**: Implement more robust error handling mechanisms, such as retry logic for failed script loads or user notifications for critical failures.
      
        - **Optimizing**:
          - **Function Existence Checks**: While the script checks for the existence of functions before calling them, further optimization could include defining default behaviors or polyfills if certain functions are missing.
          - **Performance Enhancements**: Optimize the script loading process by leveraging dynamic imports or bundling scripts to reduce the number of network requests.
      
        - **Error Handling**:
          - **Graceful Degradation**: Ensure that the application can still function in a limited capacity even if certain scripts fail to load, providing fallback options or default behaviors.
          - **User Notifications**: Inform users of critical issues during initialization through UI alerts or messages, improving transparency and user trust.
      
        - **Code Readability and Maintainability**:
          - **Consistent Logging**: Use a consistent logging mechanism (e.g., centralized logging functions) to manage log messages, making it easier to track and debug.
          - **Inline Documentation**: Add comments explaining the purpose of each initialization step, especially for complex conditional logic.
      
        - **Testing**:
          - **Unit Tests**: Develop unit tests for each initialization function to ensure they behave correctly under various scenarios.
          - **Integration Tests**: Test the entire initialization workflow to verify that all components load and initialize as expected without conflicts.
      
        ### Initialization Workflow Understanding
      
        - **Seed Dependency**: The application's initialization is contingent upon the presence of a valid seed (`window.seed`), which likely influences deterministic behaviors such as audio playback sequences or randomness.
        - **Multiplier Arrays**: Initializes multiplier arrays that probably modulate audio parameters like volume and speed, allowing for dynamic adjustments based on user inputs or other factors.
        - **Main Application Initialization**: Invokes the core initializer (`window.init`), setting up the fundamental functionalities required for the application to operate.
        - **Mode-Based Script Loading**: Determines whether to load visualizer or artwork scripts based on the application's mode settings, ensuring that only relevant scripts are loaded, optimizing performance and resource usage.
        - **Artwork Configuration**: Sets the artwork image source and alternative text, ensuring that the UI displays the correct visual elements upon initialization.
      
        ### User Interaction Improvement
      
        - **Responsive Initialization**: By handling asynchronous script loading and initialization steps, the application ensures a smooth startup experience without noticeable delays or freezes.
        - **Mode Flexibility**: Allows users to switch between different modes (visualizer vs. artwork) seamlessly, providing a customizable experience tailored to user preferences.
        - **Visual Feedback**: Updates the artwork element promptly upon initialization, ensuring that users see the correct visuals without manual intervention.
        - **Error Transparency**: Logs detailed messages during initialization, aiding developers in diagnosing issues and ensuring that users are not left with a non-functional application.
      
</details>
<script id="main-initialization">(async function(){window.visualiserMode=false;if(!window.seed){window.log('Seed is not set. Initialization aborted.');return;}if(typeof window.initializeMultiplierArrays=="function")await window.initializeMultiplierArrays();else window.log("initializeMultiplierArrays function is not defined.");if(typeof window.init=="function"){window.init();window.log("Main application initialized.");}else window.log("init function is not defined.");if(window.visualiserMode&&window.enableVisualizerScripts){if(typeof window.loadVisualiserScripts=="function"){await window.loadVisualiserScripts();window.log("Visualizer scripts loaded.");}else window.log("loadVisualiserScripts function is not defined.");}else{if(typeof window.loadArtworkScripts=="function"){await window.loadArtworkScripts();window.log("Artwork scripts loaded.");}else window.log("loadArtworkScripts function is not defined.");}document.getElementById("artwork").src="/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0";document.getElementById("artwork").alt="Loaded Artwork";})();</script>
</mainInitialisation>


<constants-and-variables> 
<details>
        <summary>Constants and Variables Documentation</summary>
      
        ### Overview
        This script defines a set of constants, global variables, and utility functions that are foundational to the audio playback application's functionality. It includes configurations for volume and speed controls, manages multiplier arrays, and provides functions to apply scheduling multipliers to audio playback speeds. These elements collectively influence how audio channels are processed and played back, ensuring a consistent and customizable user experience.
      
        ### Constants and Variables
      
        #### `VOLUME_CONTROLS`
        - **Type**: `ArrayArraynumber
        - **Structure**:
          - An array containing 16 inner arrays.
          - Each inner array represents volume control settings for a specific song or channel group.
          - The first element of each inner array is `0.75`, followed by sixteen `1`s.
        - **Purpose**:
          - Modulates the volume levels of audio channels.
          - The first element (`0.75`) likely serves as a global volume multiplier for the entire group.
          - Subsequent `1`s indicate individual channel volume multipliers, allowing for granular control.

       
          ```
        - **Purpose**:
          - Stores metadata for each audio channel, including volume levels, playback speeds, and trim times.
          - Facilitates easy access and modification of these parameters during audio processing and playback.
      
        ### Functions
      
        #### `initializeMultiplierArrays()`
        - **Type**: `Function` (Assigned to `window.initializeMultiplierArrays`)
        - **Purpose**: Initializes the `multiplierArrays` used to adjust audio parameters.
        - **Description**:
          - Logs the start of the multiplier array initialization process.
          - Sets `window.multiplierArrays` to an empty array.
          - Logs the completion of the initialization.
        - **Implementation Details**:
          ```javascript
          window.initializeMultiplierArrays = async function() {
              window.log("Initializing multiplier arrays...");
              window.multiplierArrays = [];
              window.log("Multiplier arrays initialized.");
          };
          ```
        - **Usage**:
          - Called during the main initialization process to set up the necessary arrays for audio parameter adjustments.
      
        #### `applyScheduleMultiplier(e, l)`
        - **Type**: `Function`
        - **Purpose**: Applies schedule multipliers to the playback speeds of audio channels.
        - **Description**:
          - Iterates through the `channelPlaybackSpeed` array of a song object.
          - Multiplies each playback speed by `1.1` if the corresponding index in the `scheduleMultiplierOnOff` array is `1`.
          - Logs a success message upon completion.
          - Catches and logs any errors that occur during the process.
        - **Parameters**:
          - `e` (`Object`): The song object containing the `channelPlaybackSpeed` array.
          - `l` `Arraynumber`: The `scheduleMultiplierOnOff` array determining which channels receive the multiplier.
 
        - **Behavior**:
          - Enhances playback speeds for selected channels based on the `scheduleMultiplierOnOff` settings.
          - Ensures that only channels within the bounds of the multiplier array are affected.
      
        ### Organization
        - **Configuration Constants**: `VOLUME_CONTROLS`, `SPEED_CONTROLS`, and `scheduleMultiplierOnOff` provide structured configurations for audio parameter adjustments, allowing for scalable and organized control over multiple audio channels.
        - **Global Flags and Arrays**: Variables like `seedSet`, `arraysInitialized`, and `audioElements` manage the state and resources necessary for audio processing and playback.
        - **Metadata Management**: `window.globalMetadata` centralizes the storage of essential audio parameters, facilitating easy access and updates during runtime.
        - **Utility Functions**: Functions like `initializeMultiplierArrays` and `applyScheduleMultiplier` encapsulate specific functionalities, promoting code reuse and maintainability.
      
        ### Identified Improvements
      
        - **Modularizing**:
          - **Separate Configuration Files**: Move `VOLUME_CONTROLS`, `SPEED_CONTROLS`, and `scheduleMultiplierOnOff` into separate configuration files or modules to enhance organization and ease of updates.
          - **Utility Module**: Encapsulate functions like `initializeMultiplierArrays` and `applyScheduleMultiplier` into a dedicated utility module to promote reuse and separation of concerns.
          - **Metadata Handling**: Consider creating a dedicated module for managing `window.globalMetadata` to centralize metadata operations and prevent clutter in the global scope.
      
        - **Optimizing**:
          - **Array Initialization**: Instead of initializing `window.multiplierArrays` as an empty array, populate it with predefined values if applicable, reducing the need for dynamic population later.
          - **Performance Enhancements**: Optimize the `applyScheduleMultiplier` function by minimizing the number of operations within the `map` callback, especially for large audio projects.
      
        - **Error Handling**:
          - **Enhanced Validation**: In `applyScheduleMultiplier`, validate the structure of the song object (`e`) and the multiplier array (`l`) before processing to prevent unexpected errors.
          - **User Feedback**: Implement user-facing notifications for critical errors during audio parameter adjustments to inform users of any issues affecting playback.
      
        - **Code Readability and Maintainability**:
          - **Descriptive Naming**: Use more descriptive variable names instead of single letters (e.g., `e`, `l`, `c`) to improve code clarity and understanding.
          - **Inline Documentation**: Add comments explaining the purpose and functionality of each function and significant code blocks, aiding future developers in understanding the codebase.
      
        - **Testing**:
          - **Unit Tests**: Develop unit tests for `applyScheduleMultiplier` to ensure it correctly modifies playback speeds based on various multiplier configurations.
          - **Integration Tests**: Test the interaction between `initializeMultiplierArrays` and other components that rely on `multiplierArrays` to ensure seamless integration and functionality.
      
        ### Constants and Variables Workflow Understanding
      
        - **Volume and Speed Controls**: `VOLUME_CONTROLS` and `SPEED_CONTROLS` provide a structured way to adjust audio parameters across multiple channels and songs, allowing for both global and individual channel modifications.
        - **Schedule Multiplier Toggle**: `scheduleMultiplierOnOff` enables or disables the application of playback speed multipliers on a per-channel basis, offering flexibility in audio dynamics.
        - **Multiplier Arrays Initialization**: The `initializeMultiplierArrays` function sets up the necessary arrays for applying audio parameter adjustments, ensuring that the system is ready for dynamic modifications during playback.
        - **Playback Speed Adjustments**: The `applyScheduleMultiplier` function modifies playback speeds based on user settings, enhancing the audio experience by allowing real-time speed variations.
      
        ### User Interaction Improvement
      
        - **Customizable Audio Experience**: By providing structured controls for volume and speed, users can tailor the audio playback to their preferences, enhancing engagement and satisfaction.
        - **Dynamic Adjustments**: The ability to apply schedule multipliers allows for real-time changes to playback speeds, enabling creative audio effects and responsive interactions.
        - **Consistent Parameter Management**: Centralized storage and management of audio parameters through `window.globalMetadata` ensure that changes are applied uniformly across all channels, maintaining a coherent audio experience.
        - **Initialization Feedback**: Logging messages during the initialization of multiplier arrays and application of schedule multipliers provide transparency into the application's state, aiding both developers and users in understanding the system's behavior.
      
</details>     
<script id="constants-and-variables">
    window.initializeMultiplierArrays=async function(){window.log("Initializing multiplier arrays..."),window.multiplierArrays=[],window.log("Multiplier arrays initialized.")};

const VOLUME_CONTROLS=[[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[.75,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],SPEED_CONTROLS=[[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]];scheduleMultiplierOnOff=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1];let seedSet=!1,arraysInitialized=!1,audioElements=[];function applyScheduleMultiplier(e,l){try{e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,c)=>c<l.length&&l[c]?1.1*e:e)),console.log("Schedule multiplier applied successfully.")}catch(e){console.error("Error in applyScheduleMultiplier:",e)}}
</script>
</constants-and-variables>


<dataLoadingAndDeserialisation>
<details>
        <summary>Data Loading and Deserialization Documentation</summary>
        Overview

        This script is responsible for loading, fetching, and deserializing compressed audio data required for the audio playback application. It utilizes the Pako library for data inflation, handles network requests to retrieve serialized data, maps user-provided seeds to BPM (Beats Per Minute) values, and initializes global metadata essential for audio processing. The script ensures that all necessary data is correctly loaded and prepared before playback begins, and it communicates the completion of data processing through custom events.
        
        Functions
        
        loadPako()
        
            •	Purpose: Dynamically loads the Pako library, which is essential for decompressing data used in the application.
            •	Description:
            •	Fetches a specific resource containing the Pako library.
            •	Parses the fetched HTML content to extract the Pako script.
            •	Validates the presence of the Pako library within the fetched script.
            •	Injects the Pako script into the documents head to make its functionalities available globally.
            •	Logs the success or failure of the Pako library loading process.
            •	Parameters: void
            •	Returns: Promise void - Resolves when Pako is successfully loaded, rejects if an error occurs.
            •	Key Variables/Functions:
            •	response: The HTTP response from fetching the Pako library.
            •	textContent: The text content of the fetched response.
            •	scriptContent: The extracted script content containing the Pako library.
            •	scriptElement: A new script element created to inject the Pako library into the DOM.


        fetchAndDeserialize(url)

            •	Purpose: Fetches compressed data from a given URL, inflates it using the Pako library, and deserializes it into a usable JavaScript object.
            •	Description:
            •	Sends a network request to retrieve data from the specified URL.
            •	Validates the success of the network response.
            •	Converts the received data into an ArrayBuffer.
            •	Uses Pako to inflate (decompress) the data.
            •	Decodes the inflated data into a JSON string.
            •	Parses the JSON string and deserializes it into a JavaScript object.
            •	Returns the deserialized data.
            •	Parameters:
            •	url (string): The URL from which to fetch the compressed serialized data.
            •	Returns: Promise object - Resolves with the deserialized JavaScript object, rejects if an error occurs.
            •	Key Variables/Functions:
            •	response: The HTTP response from fetching the data.
            •	arrayBuffer: The binary data retrieved from the response.
            •	inflatedData: The decompressed data using Pako.
            •	jsonString: The decoded JSON string from the inflated data.
            

            fetchAndProcessData(urls)

            •	Purpose: Concurrently fetches and deserializes data from multiple URLs, ensuring only valid data is processed.
            •	Description:
            •	Accepts an array of URLs to fetch data from.
            •	Uses Promise.all to handle multiple asynchronous fetch operations.
            •	For each URL, it attempts to fetch and deserialize the data using fetchAndDeserialize.
            •	Validates that the deserialized data contains the necessary projectSequences property.
            •	Filters out any unsuccessful or invalid data fetches.
            •	Returns an array of successfully processed data objects.
            •	Logs errors for individual URL processing failures without halting the entire operation.
            •	Parameters:
            •	urls  Array string : An array of URLs pointing to the compressed serialized data.
            •	Returns: Promise ArrayObject - Resolves with an array of valid deserialized data objects, rejects if all fetches fail.
            •	Key Variables/Functions:
            •	results: The array of successfully deserialized data objects.



                    mapSeedToBpm(seed)

            •	Purpose: Maps a given seed string to a BPM value from a predefined set, ensuring deterministic BPM selection based on the seed.
            •	Description:
            •	Defines a set of possible BPM values.
            •	Generates a hash from the seed string by iterating through each character and applying a mathematical transformation.
            •	Uses the hash to select a BPM value from the bpmOptions array.
            •	Logs the mapping process for debugging purposes.
            •	Returns the selected BPM value.
            •	Parameters:
            •	seed (string): The seed string used to determine the BPM.
            •	Returns: number - The BPM value selected based on the seed.
            •	Key Variables/Functions:
            •	bpmOptions Array number : The predefined set of BPM values to choose from.
            •	hash (number): The numerical representation of the seed string.
            •	selectedBpm (number): The BPM value selected based on the hash.



                    processSerializedDataPart1(songUrls, VOLUME_CONTROLS, SPEED_CONTROLS)

            •	Purpose: Orchestrates the initial phase of data processing by loading necessary libraries, fetching and deserializing data, mapping seeds to BPM, and initializing global metadata.
            •	Description:
            •	Calls loadPako() to ensure the Pako library is loaded for data inflation.
            •	Fetches and processes data from the provided songUrls using fetchAndProcessData.
            •	Maps the global seed (window.seed) to a BPM value using mapSeedToBpm.
            •	Displays the seed and BPM information in the application’s information panel.
            •	Initializes the window.globalMetadata object to store volume levels, playback speeds, and trim times for each channel.
            •	Populates window.globalMetadata by iterating through the deserialized data and extracting relevant channel information.
            •	Stores the processed data and user controls (VOLUME_CONTROLS, SPEED_CONTROLS) in window.processedData for use in subsequent processing stages.
            •	Dispatches a dataLoadingComplete event to signal that data processing is complete.
            •	Logs the completion of data loading and deserialization.
            •	Handles any errors that occur during the process by logging them to the console.
            •	Parameters:
            •	songUrls Arraystring: An array of URLs pointing to the compressed serialized song data.
            •	VOLUME_CONTROLS Array Arraynumber: User-defined volume control settings for each song and channel.
            •	SPEED_CONTROLS ArrayArraynumber: User-defined speed control settings for each song and channel.
            •	Returns: Promise void - Completes the data processing workflow, resolves when done, rejects if an error occurs.
            •	Key Variables/Functions:
            •	deserializedData Array Object The array of deserialized song data objects fetched from songUrls.
            •	selectedBPM (number): The BPM value selected based on the global seed.
            •	window.globalMetadata: An object storing metadata for all audio channels, including volume levels and playback speeds.
            •	window.processedData: An object containing all processed data necessary for further audio assembly and playback.

                    Event Listeners

        dataLoadingComplete Event

            •	Event: dataLoadingComplete
            •	Handler: Triggered by other scripts (e.g., Local Data Processing section) to commence further data processing once data loading and deserialization are complete.
            •	Purpose: Signals that the initial data loading phase is complete, allowing subsequent processes to begin.
            •	Implementation Details:

            Organization

            •	Library Loading:
            •	Pako Integration: Ensures that the Pako library is dynamically loaded and available for decompressing fetched data.
            •	Data Fetching and Deserialization:
            •	Concurrent Fetching: Utilizes asynchronous operations to fetch and process multiple data sources efficiently.
            •	Data Validation: Confirms that fetched data contains necessary properties (projectSequences) before processing.
            •	Seed to BPM Mapping:
            •	Deterministic BPM Selection: Maps user-provided seeds to BPM values in a repeatable manner, allowing for consistent audio playback settings.
            •	Global Metadata Initialization:
            •	Centralized Metadata Storage: Initializes and populates window.globalMetadata to store essential audio parameters for each channel, facilitating easy access and manipulation during playback.
            •	Event-Driven Workflow:
            •	Custom Events: Uses custom events (dataLoadingComplete) to coordinate the data processing workflow, ensuring that each stage of processing occurs in the correct sequence.

        Identified Improvements

            •	Modularizing:
            •	Separate Concerns:
            •	Library Management: Isolate the loadPako function into a dedicated module responsible solely for managing external library dependencies.
            •	Data Fetching and Deserialization: Create separate modules or files for fetchAndDeserialize and fetchAndProcessData to encapsulate data retrieval logic.
            •	Metadata Management: Move global metadata initialization and population into a separate module to centralize metadata handling.
            •	Function Decomposition:
            •	Process Workflow: Break down processSerializedDataPart1 into smaller, single-responsibility functions (e.g., initializeMetadata, displaySeedAndBPM) to enhance readability and maintainability.
            •	Event Handling:
            •	Encapsulate Event Listeners: Group all event listener registrations into a single initialization function or module to keep the main script organized.
            •	Optimizing:
            •	Performance Enhancements:
            •	Parallel Processing: Ensure that fetching and deserialization operations are optimized for parallel execution without unnecessary blocking.
            •	Efficient Data Handling: Minimize redundant data copying or transformations to improve performance, especially with large datasets.
            •	Resource Management:
            •	Library Caching: Implement caching mechanisms to prevent redundant loading of the Pako library if it has already been loaded previously.
            •	Error Handling:
            •	Comprehensive Validation:
            •	Input Validation: Validate all inputs (e.g., songUrls, VOLUME_CONTROLS, SPEED_CONTROLS) before processing to prevent unexpected errors.
            •	Library Availability: Confirm that the Pako library is successfully loaded and available before attempting to use it in data inflation.
            •	Graceful Degradation:
            •	Fallback Mechanisms: Provide fallback behaviors or user notifications if critical operations (like data fetching or deserialization) fail, ensuring the application remains user-friendly even in error scenarios.
            •	Code Readability and Maintainability:
            •	Consistent Naming Conventions: Use descriptive and consistent variable and function names to improve code clarity (e.g., avoid abbreviations like e or t).
            •	Inline Documentation: Add more inline comments within complex functions to explain non-obvious logic or important decisions.
            •	Structured Logging: Implement a structured logging approach or use a logging library to manage log levels and outputs more effectively, making debugging easier.
            •	Testing:
            •	Unit Tests:
            •	Function-Level Testing: Develop unit tests for individual functions like loadPako, fetchAndDeserialize, mapSeedToBpm, and adjustChannelData to ensure they handle various input scenarios correctly.
            •	Integration Tests:
            •	Workflow Testing: Test the entire data loading and deserialization workflow to verify that all components interact as expected and handle edge cases gracefully.
            •	Mocking External Dependencies:
            •	Simulate Network Responses: Use mocking techniques to simulate network responses for functions like fetchAndDeserialize to test error handling and data processing without relying on actual network requests.

        Data Processing Workflow Understanding

            •	Library Dependency Management:
            •	The script begins by ensuring that the Pako library is loaded, which is critical for decompressing fetched data. This dependency is managed dynamically to avoid unnecessary loading and to handle potential errors gracefully.
            •	Data Retrieval and Deserialization:
            •	Data is fetched from multiple URLs concurrently, leveraging asynchronous operations for efficiency. Each fetched data blob is decompressed using Pako and then deserialized into a JavaScript object, making it ready for further processing.
            •	Seed-Based BPM Selection:
            •	The application uses a user-provided seed to deterministically select a BPM value from a predefined set. This ensures that the same seed consistently maps to the same BPM, providing a predictable audio experience.
            •	Global Metadata Initialization:
            •	A global metadata object is initialized to store volume levels, playback speeds, and trim times for each audio channel. This centralized storage facilitates easy access and manipulation of audio parameters throughout the application.
            •	Event-Driven Processing:
            •	The script dispatches a dataLoadingComplete event upon successful data processing, signaling other parts of the application (e.g., data processing and audio assembly modules) to proceed with their respective tasks. This ensures a synchronized and orderly workflow.

        User Interaction Improvement

            •	Transparent Feedback:
            •	By displaying the seed and selected BPM in the information panel, users gain visibility into how their inputs influence the audio playback, enhancing trust and engagement.
            •	Robust Data Handling:
            •	The application ensures that only valid and correctly formatted data is processed, preventing potential playback issues and enhancing the overall user experience.
            •	Responsive Error Reporting:
            •	Comprehensive error logging provides developers with the necessary information to diagnose and resolve issues promptly, leading to a more stable and reliable application for users.
            •	Consistent Playback Settings:
            •	The deterministic mapping of seeds to BPM values ensures that users can recreate specific audio experiences by using the same seed, offering a personalized and consistent interaction with the application.

</details>

    <script>
        const loadPako = async () => {
            try {
                const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
                const textContent = await response.text();
                const scriptContent = (new DOMParser).parseFromString(textContent, "text/html").querySelector("script")?.textContent;
                if (!scriptContent?.includes("pako")) throw new Error("Pako library not found in the fetched content.");
                const scriptElement = document.createElement("script");
                scriptElement.textContent = scriptContent;
                document.head.appendChild(scriptElement);
                console.log("Pako library loaded successfully.");
            } catch (error) {
                console.error("Error occurred during Pako loading:", error);
                throw error;
            }
        };
        
        const fetchAndDeserialize = async (url) => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                const arrayBuffer = await response.arrayBuffer();
                const inflatedData = pako.inflate(new Uint8Array(arrayBuffer));
                const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                return deserialize(JSON.parse(jsonString));
            } catch (error) {
                console.error("Error in fetchAndDeserialize:", error);
                throw error;
            }
        };
        
        const fetchAndProcessData = async (urls) => {
            try {
                const results = (await Promise.all(urls.map(async (url) => {
                    try {
                        const data = await fetchAndDeserialize(url);
                        if (!data?.projectSequences) throw new Error(`Invalid data at URL ${url}`);
                        return data;
                    } catch (error) {
                        console.error(`Error processing URL: ${url}`, error);
                        return null;
                    }
                }))).filter(Boolean);
        
                if (!results.length) throw new Error("No valid data was processed.");
                return results;
            } catch (error) {
                console.error("Error in fetchAndProcessData:", error);
                throw error;
            }
        };
        
        function mapSeedToBpm(seed) {
            const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
            const hash = seed.split("").reduce((acc, char) => (10 * acc + parseInt(char, 10)) % 1000000007, 0);
            const selectedBpm = bpmOptions[hash % bpmOptions.length];
            console.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
            return selectedBpm;
        }
        
        const processSerializedDataPart1 = async (songUrls, VOLUME_CONTROLS, SPEED_CONTROLS) => {
            try {
                await loadPako();
                const deserializedData = await fetchAndProcessData(songUrls);
                const selectedBPM = mapSeedToBpm(window.seed);
                
                // Display Seed and BPM in the information panel
                displaySeedAndBPM(window.seed, selectedBPM);
        
                // Initialize global metadata object
                window.globalMetadata = {
                    volumeLevels: {},
                    playbackSpeeds: {},
                    trimTimes: {},
                };
        
                // Populate globalMetadata with initial data
                deserializedData.forEach((songData, songIndex) => {
                    songData.channelURLs.forEach((url, channelIndex) => {
                        const channelId = `Channel_${songIndex}_${channelIndex}`;
                        // Store metadata in globalMetadata
                        window.globalMetadata.volumeLevels[channelId] = songData.channelVolume[channelIndex];
                        window.globalMetadata.playbackSpeeds[channelId] = songData.channelPlaybackSpeed[channelIndex];
                        window.globalMetadata.trimTimes[channelId] = songData.trimSettings[channelIndex];
                    });
                });
        
                window.processedData = {
                    deserializedData: deserializedData,
                    selectedBPM: selectedBPM,
                    VOLUME_CONTROLS: VOLUME_CONTROLS,
                    SPEED_CONTROLS: SPEED_CONTROLS,
                    songDataUrls: songUrls
                };
        
                console.log("Data loading and deserialization complete.");
                document.dispatchEvent(new CustomEvent("dataLoadingComplete"));
            } catch (error) {
                console.error("Error in processSerializedDataPart1:", error);
            }
        };
        window.processSerializedData = processSerializedDataPart1;
        console.log("DataLoadingAndDeserializationScript initialized.");
        </script>
</dataLoadingAndDeserialisation>


<localdataprocessing>
<details>
        <summary>Local Data Processing Documentation</summary>
      
        ### Overview
        This script handles the local processing of serialized audio data within the audio playback application. It includes utility functions for shuffling arrays deterministically, adjusting channel data based on user-selected parameters, and processing the serialized data to assemble a final song object. The script ensures that audio channels are appropriately randomized, volume levels and playback speeds are adjusted according to user preferences, and the processed data is prepared for playback. Additionally, it listens for specific events to trigger the data processing workflow.
      
        ### Helper Functions
      
        #### `shuffleArray(array, seed)`
        - **Purpose**: Randomly shuffles the elements of an array in a deterministic manner based on a provided seed.
        - **Description**:
          - Implements the Fisher-Yates shuffle algorithm.
          - Uses a seeded random number generator (`seededRandom`) to ensure that the shuffle order is reproducible for a given seed.
          - Increments the seed with each iteration to produce a new random index.
        - **Parameters**:
          - `array` (`Array`): The array to be shuffled.
          - `seed` (`number`): The initial seed value used for randomization.
        - **Returns**: The shuffled array.
        - **Key Variables/Functions**:
          - `i` (`number`): The current index in the array being shuffled.
          - `j` (`number`): The randomly generated index used for swapping elements.
          - `seededRandom(seed++)`: Function that generates a pseudo-random number based on the current seed.
        - **Implementation Details**:
          ```javascript
          const shuffleArray = (array, seed) => {
              for (let i = array.length - 1; i > 0; i--) {
                  const j = Math.floor(seededRandom(seed++) * (i + 1));
                  [array[i], array[j]] = [array[j], array[i]];
              }
              return array;
          };
          ```
      
        #### `adjustChannelData(songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS)`
        - **Purpose**: Adjusts the playback speed and volume levels of audio channels based on the selected BPM and user-defined controls.
        - **Description**:
          - Calculates the BPM ratio by comparing the selected BPM with the song's original BPM.
          - Adjusts each channel's playback speed by multiplying it with the BPM ratio and any additional speed controls.
          - Ensures that playback speeds do not fall below a minimum threshold (0.1) to prevent inaudible or excessively slow audio.
          - Adjusts each channel's volume by applying global and individual volume controls.
          - Updates the global metadata with the new volume levels and playback speeds for each channel.
        - **Parameters**:
          - `songData` (`Object`): The data object representing a single song's configuration.
          - `songIndex` (`number`): The index of the current song in the dataset.
          - `selectedBPM` (`number`): The BPM selected by the user for playback.
          - `VOLUME_CONTROLS` (`Array<Array<number>>`): User-defined volume control settings for each song and channel.
          - `SPEED_CONTROLS` (`Array<Array<number>>`): User-defined speed control settings for each song and channel.
        - **Returns**: `void` (modifies `songData` and `window.globalMetadata` in place).
        - **Key Variables/Functions**:
          - `bpmRatio` (`number`): The ratio of selected BPM to the song's original BPM.
          - `selectedBPM`: User-selected beats per minute for playback.
          - `VOLUME_CONTROLS`: User-defined volume adjustments.
          - `SPEED_CONTROLS`: User-defined playback speed adjustments.
          - `window.globalMetadata`: Global object storing metadata for all channels.
        - **Implementation Details**:
          ```javascript
          const adjustChannelData = (songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS) => {
              const bpmRatio = selectedBPM / songData.projectBPM;
              songData.channelPlaybackSpeed = songData.channelPlaybackSpeed.map((speed, index) => {
                  let adjustedSpeed = speed * bpmRatio * (SPEED_CONTROLS[songIndex]?.[index] || 1);
                  return Math.max(isNaN(adjustedSpeed) ? 0.1 : adjustedSpeed, 0.1);
              });
          
              const volumeControl = VOLUME_CONTROLS[songIndex] || [];
              const globalVolume = volumeControl[0] || 1;
              songData.channelVolume = songData.channelVolume.map((volume, index) => {
                  return volume * globalVolume * (volumeControl[index + 1] || 1);
              });
          
              // Update globalMetadata with adjusted values
              songData.channelURLs.forEach((url, channelIndex) => {
                  const channelId = `Channel_${songIndex}_${channelIndex}`;
                  window.globalMetadata.volumeLevels[channelId] = songData.channelVolume[channelIndex];
                  window.globalMetadata.playbackSpeeds[channelId] = songData.channelPlaybackSpeed[channelIndex];
                  // Trim times remain the same as they were already set
              });
          };
          ```
      
        #### `processSerializedDataPart2()`
        - **Purpose**: Processes the serialized audio data by adjusting channel data, assembling the final song, applying schedule multipliers, and preparing the data for playback.
        - **Description**:
          - Extracts necessary data (`deserializedData`, `selectedBPM`, `VOLUME_CONTROLS`, `SPEED_CONTROLS`) from `window.processedData`.
          - Iterates through each song in `deserializedData` to adjust channel data using `adjustChannelData`.
          - Assembles the final song object using `assembleProcessedSong`.
          - Applies a schedule multiplier if the function `applyScheduleMultiplier` is defined.
          - Converts the final song object to a JSON blob and creates a URL for it.
          - Dispatches a `dataProcessingComplete` event to signal the completion of data processing.
          - Logs relevant information and handles errors gracefully.
        - **Parameters**: `void`
        - **Returns**: `void`
        - **Key Variables/Functions**:
          - `deserializedData` (`Array<Object>`): Array of song data objects.
          - `selectedBPM` (`number`): User-selected BPM for playback.
          - `VOLUME_CONTROLS` (`Array<Array<number>>`): User-defined volume settings.
          - `SPEED_CONTROLS` (`Array<Array<number>>`): User-defined speed settings.
          - `assembleProcessedSong`: Function that assembles the final song object from processed data.
          - `applyScheduleMultiplier`: Optional function to adjust the song's scheduling based on user settings.
          - `window.globalJsonData`: Stores the final processed song data.
          - `window.jsonDataUrl`: URL pointing to the JSON representation of the final song.
        - **Implementation Details**:
          ```javascript
          const processSerializedDataPart2 = async () => {
              try {
                  const { deserializedData, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS } = window.processedData;
                  deserializedData.forEach((songData, songIndex) => adjustChannelData(songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS));
                  const finalSong = assembleProcessedSong(deserializedData, selectedBPM);
          
                  // Apply schedule multiplier if the function exists
                  if (typeof applyScheduleMultiplier === 'function') {
                      applyScheduleMultiplier(finalSong, window.scheduleMultiplierOnOff);
                  } else {
                      console.warn("applyScheduleMultiplier is not defined.");
                  }
          
                  window.globalJsonData = finalSong;
                  window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(finalSong)], { type: "application/json" }));
                  document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
                  console.log("Local data processing complete.");
              } catch (error) {
                  console.error("Error in processSerializedDataPart2:", error);
              }
          };
          ```
      
        ### Event Listeners
      
        #### `dataLoadingComplete` Event Listener
        - **Event**: `dataLoadingComplete`
        - **Handler**: Calls `processSerializedDataPart2` to initiate data processing once data loading is complete.
        - **Purpose**: Ensures that data processing only begins after all necessary data has been successfully loaded.
        - **Implementation Details**:
          ```javascript
          document.addEventListener("dataLoadingComplete", processSerializedDataPart2);
          console.log("LocalDataProcessingScript initialized and awaiting data.");
          ```
      
        ### Organization
        - **Randomness Utilities**:
          - `shuffleArray`: Provides deterministic shuffling of arrays, essential for reproducible audio channel selection.
        - **Data Adjustment**:
          - `adjustChannelData`: Centralizes the logic for modifying channel playback speeds and volumes based on user inputs and selected BPM.
        - **Data Processing Workflow**:
          - `processSerializedDataPart2`: Orchestrates the overall processing of serialized data, integrating adjusted channel data, assembling the final song, applying additional multipliers, and preparing the data for playback.
        - **Event Handling**:
          - Listens for the `dataLoadingComplete` event to trigger the data processing workflow, ensuring synchronization between data loading and processing stages.
      
        ### Identified Improvements
      
        - **Modularizing**:
          - **Separate Utilities**: 
            - Move `shuffleArray` and `adjustChannelData` into dedicated utility modules (e.g., `randomUtils.js`, `audioUtils.js`) to promote reusability and maintainability.
          - **Process Workflow**:
            - Split `processSerializedDataPart2` into smaller functions (e.g., `applyMultipliers`, `prepareFinalSong`) to enhance readability and facilitate testing.
          - **Event Management**:
            - Encapsulate event listener registrations into a separate initialization module or function to keep the main script organized.
        
        - **Optimizing**:
          - **Seeded Random Generator**:
            - Ensure that `seededRandom` is defined and accessible within the scope of `shuffleArray`. If not, import or define it appropriately.
          - **Performance Enhancements**:
            - Optimize `shuffleArray` for large datasets by minimizing operations within the loop.
            - Cache frequently accessed properties (e.g., `window.processedData`) to reduce lookup times.
        
        - **Error Handling**:
          - **Function Existence Checks**:
            - Verify that dependent functions like `assembleProcessedSong` and `applyScheduleMultiplier` are defined before invoking them to prevent runtime errors.
          - **Data Validation**:
            - Validate the structure and contents of `window.processedData` before processing to ensure all required fields are present and correctly formatted.
          - **Graceful Degradation**:
            - Implement fallback mechanisms or default behaviors in case certain functionalities are unavailable or fail during processing.
        
        - **Code Readability and Maintainability**:
          - **Consistent Naming Conventions**:
            - Use consistent and descriptive variable names (e.g., avoid abbreviations like `t` in `const t = [...]`) to improve code clarity.
          - **Inline Documentation**:
            - Add comments within complex logic blocks (e.g., sequence processing) to explain the purpose and flow of operations.
          - **Function Decomposition**:
            - Break down large functions like `assembleProcessedSong` and `processSerializedDataPart2` into smaller, single-responsibility functions to simplify logic and enhance testability.
        
        - **Testing**:
          - **Unit Tests**:
            - Develop unit tests for `shuffleArray`, `adjustChannelData`, and other helper functions to ensure they behave as expected with various inputs.
          - **Integration Tests**:
            - Test the interaction between `processSerializedDataPart2` and other parts of the application (e.g., `assembleProcessedSong`, `applyScheduleMultiplier`) to identify and fix integration issues.
        
        ### Data Processing Workflow Understanding
      
        - **Deterministic Shuffling**:
          - `shuffleArray` ensures that the order of audio channels is randomized in a repeatable way based on a seed, which is crucial for applications requiring consistent procedural generation.
        - **Channel Data Adjustment**:
          - `adjustChannelData` modifies each channel's playback speed and volume according to the selected BPM and user-defined controls, allowing for dynamic and customizable audio playback experiences.
        - **Final Song Assembly**:
          - `processSerializedDataPart2` integrates all adjustments and assembles the final song object, applying any additional scheduling multipliers and preparing the data for seamless playback.
        - **Event-Driven Processing**:
          - The script listens for the `dataLoadingComplete` event to ensure that data processing only begins after all necessary data has been loaded, maintaining synchronization within the application workflow.
      
        ### User Interaction Improvement
      
        - **Customizable Playback**:
          - By allowing users to adjust volume levels and playback speeds, the application offers a tailored audio experience that can adapt to individual preferences.
        - **Consistent Behavior**:
          - Deterministic shuffling based on a seed ensures that users can expect consistent audio channel arrangements when using the same seed and settings, enhancing reliability.
        - **Feedback and Transparency**:
          - Detailed logging within `assembleProcessedSong` and `processSerializedDataPart2` provides transparency into the data processing workflow, aiding in debugging and user support.
        - **Responsive Data Handling**:
          - The event-driven approach ensures that data processing is responsive to the application's state, preventing issues related to asynchronous data loading and processing.
      
</details>
<script>
        const shuffleArray = (array, seed) => {
            for (let i = array.length - 1; i > 0; i--) {
                const j = Math.floor(seededRandom(seed++) * (i + 1));
                [array[i], array[j]] = [array[j], array[i]];
            }
            return array;
        };
        
        const adjustChannelData = (songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS) => {
            const bpmRatio = selectedBPM / songData.projectBPM;
            songData.channelPlaybackSpeed = songData.channelPlaybackSpeed.map((speed, index) => {
                let adjustedSpeed = speed * bpmRatio * (SPEED_CONTROLS[songIndex]?.[index] || 1);
                return Math.max(isNaN(adjustedSpeed) ? 0.1 : adjustedSpeed, 0.1);
            });
        
            const volumeControl = VOLUME_CONTROLS[songIndex] || [];
            const globalVolume = volumeControl[0] || 1;
            songData.channelVolume = songData.channelVolume.map((volume, index) => {
                return volume * globalVolume * (volumeControl[index + 1] || 1);
            });
        
            // Update globalMetadata with adjusted values
            songData.channelURLs.forEach((url, channelIndex) => {
                const channelId = `Channel_${songIndex}_${channelIndex}`;
                window.globalMetadata.volumeLevels[channelId] = songData.channelVolume[channelIndex];
                window.globalMetadata.playbackSpeeds[channelId] = songData.channelPlaybackSpeed[channelIndex];
                // Trim times remain the same as they were already set
            });
        };
        
        const processSerializedDataPart2 = async () => {
            try {
                const { deserializedData, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS } = window.processedData;
                deserializedData.forEach((songData, songIndex) => adjustChannelData(songData, songIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS));
                const finalSong = assembleProcessedSong(deserializedData, selectedBPM);
        
                // Apply schedule multiplier if the function exists
                if (typeof applyScheduleMultiplier === 'function') {
                    applyScheduleMultiplier(finalSong, window.scheduleMultiplierOnOff);
                } else {
                    console.warn("applyScheduleMultiplier is not defined.");
                }
        
                window.globalJsonData = finalSong;
                window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(finalSong)], { type: "application/json" }));
                document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
                console.log("Local data processing complete.");
            } catch (error) {
                console.error("Error in processSerializedDataPart2:", error);
            }
        };
        
        // Event listener to start processing after data is loaded
        document.addEventListener("dataLoadingComplete", processSerializedDataPart2);
        console.log("LocalDataProcessingScript initialized and awaiting data.");
</script>
</localdataprocessing>


<helperfunctions>
<details>
    <summary>Helper Functions Documentation</summary>
  
    ### Overview
    This section contains a collection of utility functions that enhance the functionality and efficiency of the audio playback application. These helper functions handle tasks such as generating random numbers with a seed, converting string seeds to integers, parsing volume levels, and assembling processed songs from serialized data. By encapsulating these common operations, the application ensures better code reusability, maintainability, and clarity.
  
    ### Helper Functions
  
    #### `createSeededRandomGenerator(seed)`
    - **Purpose**: Generates a deterministic random number generator based on a provided seed using the Linear Congruential Generator (LCG) algorithm.
    - **Description**:
      - Implements the LCG algorithm to produce a sequence of pseudo-random numbers.
      - Ensures reproducibility by generating the same sequence of numbers for a given seed.
      - Useful for scenarios where consistent randomness is required, such as procedural content generation.
    - **Parameters**:
      - `seed` (`number`): The initial seed value to start the random number generation.
    - **Returns**: A function that, when called, returns the next pseudo-random number between `0` and `1`.
    - **Key Variables**:
      - `a`: Intermediate variable used in the LCG calculation, derived from the seed.
      - `16807` and `2147483647`: Constants used in the LCG formula to ensure a full period and good randomness properties.
    - **Implementation Details**:
      ```javascript
      function createSeededRandomGenerator(seed) {
          var a = seed % 2147483647;
          if (a <= 0) a += 2147483646;
          return function() {
              a = (a * 16807) % 2147483647;
              return (a - 1) / 2147483646;
          };
      }
      ```
  
    #### `stringToSeedInt(seedStr)`
    - **Purpose**: Converts a string-based seed into a 32-bit integer suitable for initializing random number generators.
    - **Description**:
      - Iterates over each character in the input string.
      - Accumulates the character codes into a single integer using a hashing-like method.
      - Ensures that the resulting integer is within the 32-bit signed integer range.
    - **Parameters**:
      - `seedStr` (`string`): The string to be converted into a numerical seed.
    - **Returns**: A 32-bit integer derived from the input string.
    - **Key Variables**:
      - `seed` (`number`): Accumulator for the numerical seed.
      - `31`: A prime number used as a multiplier to distribute the hash values uniformly.
      - `0x7fffffff`: Ensures the seed remains within the positive range of 32-bit integers.
    - **Implementation Details**:
      ```javascript
      function stringToSeedInt(seedStr) {
          let seed = 0;
          for (let i = 0; i < seedStr.length; i++) {
              seed = (seed * 31 + seedStr.charCodeAt(i)) & 0x7fffffff;
          }
          return seed;
      }
      ```
  
    #### `parseVolumeLevel(input)`
    - **Purpose**: Safely parses and constrains a volume level input to a predefined range.
    - **Description**:
      - Converts the input to a floating-point number if it's not already a number.
      - Ensures the volume level stays within the range of `0` (mute) to `3` (maximum).
      - Defaults to `1` if the input is invalid or not a number.
    - **Parameters**:
      - `input` (`number | string`): The input value representing the desired volume level.
    - **Returns**: A validated volume level between `0` and `3`.
    - **Key Variables**:
      - `volume` (`number`): The parsed volume level after validation.
    - **Implementation Details**:
      ```javascript
      function parseVolumeLevel(input) {
          const volume = typeof input === "number" ? input : parseFloat(input);
          return Math.max(0, Math.min(isNaN(volume) ? 1 : volume, 3));
      }
      ```
  
    #### `assembleProcessedSong(deserializedData, selectedBPM)`
    - **Purpose**: Constructs a processed song object from deserialized data, selecting and organizing audio channels based on specified criteria.
    - **Description**:
      - Logs the start of the song assembly process.
      - Flattens all audio channels from the input data into a single array, capturing relevant properties like URL, volume, speed, trim settings, source, and index.
      - Converts a global string seed (`window.seed`) into an integer for deterministic shuffling.
      - Shuffles the channels using the seeded random generator and selects the first 28 channels.
      - Assigns a `globalIndex` to each selected channel for reference.
      - Splits the selected channels into three groups for further processing.
      - Constructs the final song object by mapping selected channels and their properties.
      - Processes each sequence in the project, assigning channels based on the sequence number.
      - Logs detailed information about the channels and sequences added.
      - Returns the fully assembled song object ready for playback or further manipulation.
    - **Parameters**:
      - `deserializedData` (`Array<Object>`): The raw song data that has been deserialized from a storage format (e.g., JSON).
      - `selectedBPM` (`number`): The beats per minute setting for the project.
    - **Returns**: A `finalSong` object structured with the selected channels and sequences.
    - **Key Variables**:
      - `allChannels` (`Array<Object>`): Consolidated list of all channels extracted from the deserialized data.
      - `seedInt` (`number`): Integer seed derived from `window.seed` for shuffling.
      - `shuffledChannels` (`Array<Object>`): Channels shuffled deterministically based on the seed.
      - `selectedChannels` (`Array<Object>`): The top 28 channels selected after shuffling.
      - `t` (`Array<Array<Object>>`): Grouped channels split into three distinct groups.
      - `finalSong` (`Object`): The assembled song object containing all necessary properties and sequences.
      - `songDataMapping` (`Object`): Mapping of song data for easy reference during sequence processing.
      - `channelAdditionLog` (`Array<Object>`): Logs detailing channel additions to each sequence.

      - **Detailed Steps**:
        1. **Initialization and Logging**:
           - Logs the commencement of the song assembly process.
        2. **Channel Extraction**:
           - Iterates through each song in `deserializedData`.
           - Extracts channel URLs and their corresponding properties.
           - Aggregates all channels into the `allChannels` array.
        3. **Shuffling and Selection**:
           - Converts the global seed string to an integer using `stringToSeedInt`.
           - Shuffles the `allChannels` array deterministically based on the seed.
           - Selects the first 28 channels from the shuffled array.
           - Assigns a `globalIndex` to each selected channel for tracking.
        4. **Grouping Channels**:
           - Splits the `selectedChannels` into three groups (`t`) for organized processing.
        5. **Final Song Object Construction**:
           - Initializes the `finalSong` object with selected channel properties and an empty `projectSequences` object.
        6. **Sequence Processing**:
           - Iterates through each sequence in the first song's `projectSequences`.
           - Determines which group of channels to assign based on the sequence number.
           - Logs the addition of channels to sequences.
           - Maps channel data into the `finalSong.projectSequences` structure, ensuring each channel has its steps and `globalIndex`.
        7. **Final Logging and Return**:
           - Logs the total number of sequences and the number of channels per sequence.
           - Logs detailed information about channel additions.
           - Returns the fully assembled `finalSong` object.
  
    ### Organization
    - **Randomness Utilities**:
      - `createSeededRandomGenerator` and `stringToSeedInt` handle the creation of deterministic random sequences, essential for reproducible procedural generation.
    - **Volume Parsing**:
      - `parseVolumeLevel` ensures volume inputs are sanitized and within acceptable ranges, preventing unexpected behavior.
    - **Song Assembly**:
      - `assembleProcessedSong` is a comprehensive function that transforms raw deserialized data into a structured song object, integrating channel selection, shuffling, and sequence mapping.
    - **Logging**:
      - Extensive use of `console.log` statements within `assembleProcessedSong` aids in debugging and tracking the song assembly process.
  
    ### Identified Improvements
  
    - **Modularizing**:
      - **Separate Concerns**: 
        - **Randomness Utilities**: Move `createSeededRandomGenerator` and `stringToSeedInt` to a dedicated randomness module to encapsulate all randomness-related functionalities.
        - **Volume Parsing**: Isolate `parseVolumeLevel` into a utility module focused on audio parameter validation.
        - **Song Assembly**: Consider breaking down `assembleProcessedSong` into smaller, more focused functions (e.g., channel extraction, shuffling, sequence mapping) to enhance readability and maintainability.
      - **Logging Enhancements**:
        - Centralize logging mechanisms or use a dedicated logging library to manage log levels and outputs more effectively.
    
    - **Optimizing**:
      - **Performance**:
        - **Shuffling Efficiency**: Ensure that the `shuffleArray` function used within `assembleProcessedSong` is optimized for performance, especially when dealing with large datasets.
        - **Avoid Redundant Operations**: In `assembleProcessedSong`, the `allChannels.slice()` creates a shallow copy; verify if this is necessary or if it can be optimized.
      - **Data Structures**:
        - **Use of Maps vs. Objects**: Evaluate if using `Map` objects instead of plain objects for `songDataMapping` would offer performance or readability benefits.
    
    - **Error Handling**:
      - **Input Validation**: 
        - Ensure that `deserializedData` and `selectedBPM` are validated before processing to prevent runtime errors.
        - Handle cases where `window.seed` might be undefined or invalid.
      - **Graceful Failures**:
        - Implement try-catch blocks around critical sections, especially where asynchronous operations or external dependencies are involved.
        - Provide fallback mechanisms or default behaviors in case of unexpected input or state.
    
    - **Code Readability and Maintainability**:
      - **Consistent Naming Conventions**: Ensure that variable names are consistent and descriptive throughout the functions to improve readability.
      - **Documentation**: Add inline comments within complex sections of `assembleProcessedSong` to explain intricate logic or decisions.
      - **Function Decomposition**: Break down large functions like `assembleProcessedSong` into smaller helper functions to simplify the logic and enhance testability.
    
    - **Testing**:
      - **Unit Tests**: Develop unit tests for each helper function to ensure they behave as expected with various inputs.
      - **Integration Tests**: Test the interaction between these helper functions and other parts of the application to identify and fix any integration issues.
  
    ### Understanding Helper Functionality
  
    - **Deterministic Randomness**:
      - The `createSeededRandomGenerator` and `stringToSeedInt` functions work together to provide a repeatable random number sequence, crucial for applications requiring consistent procedural generation based on a seed.
    - **Volume Control**:
      - `parseVolumeLevel` ensures that volume levels remain within a safe and expected range, preventing potential audio distortions or user experience issues.
    - **Song Assembly Logic**:
      - `assembleProcessedSong` orchestrates the transformation of raw data into a structured format, selecting appropriate channels, organizing them into sequences, and ensuring that the final song adheres to the desired BPM and configuration.
      - The function emphasizes deterministic behavior through seed-based shuffling, ensuring that the same seed and input data produce the same song structure.
  
    ### User Interaction Improvement
    - **Consistent User Experience**:
      - By ensuring that channel selection and song assembly are deterministic and repeatable, users can expect consistent behavior when using the application with the same seed and configurations.
    - **Enhanced Debugging**:
      - Detailed logging within `assembleProcessedSong` provides developers with insights into the song assembly process, facilitating easier debugging and validation of song structures.
    - **Flexibility in Configuration**:
      - Functions like `parseVolumeLevel` allow users or other parts of the application to input flexible volume settings while maintaining control over the acceptable range, enhancing the application's adaptability to different user preferences.
  
  </details>
<!-- Helper Functions -->
<script id="helper-functions">
    // Linear Congruential Generator (LCG) implementation for better randomness
    function createSeededRandomGenerator(seed) {
        var a = seed % 2147483647;
        if (a <= 0) a += 2147483646;
        return function() {
            a = (a * 16807) % 2147483647;
            return (a - 1) / 2147483646;
        };
    }
    
    // Function to convert a string seed to a 32-bit integer
    function stringToSeedInt(seedStr) {
        let seed = 0;
        for (let i = 0; i < seedStr.length; i++) {
            seed = (seed * 31 + seedStr.charCodeAt(i)) & 0x7fffffff;
        }
        return seed;
    }
        // Function to parse volume level
        function parseVolumeLevel(input) {
        const volume = typeof input === "number" ? input : parseFloat(input);
        return Math.max(0, Math.min(isNaN(volume) ? 1 : volume, 3));
    }


    const assembleProcessedSong = (deserializedData, selectedBPM) => {
        console.log("[songAssemblyLogs] Starting to assemble the processed song...");
    
        // Flatten all channels from all songs into a single array
        const allChannels = deserializedData.flatMap((song, songIndex) =>
            song.channelURLs.map((url, channelIndex) => ({
                url,
                volume: song.channelVolume[channelIndex],
                speed: song.channelPlaybackSpeed[channelIndex],
                trim: song.trimSettings[channelIndex],
                source: `data${songIndex + 1}`,
                index: channelIndex
            }))
        );
    
        // Log all channels before selection
        console.log("[songAssemblyLogs] All channels (before selection):", allChannels);
    
        // Total number of channels before selection
        const totalChannels = allChannels.length;
        console.log(`[songAssemblyLogs] Total number of channels in the array: ${totalChannels}`);
    
        // Convert the seed to an integer
        const seedInt = stringToSeedInt(window.seed);
    
        // Shuffle and slice the channels for final selection
        const shuffledChannels = shuffleArray(allChannels.slice(), seedInt); // Use a copy of allChannels
        const selectedChannels = shuffledChannels.slice(0, 28);
    
        // Add global index to selected channels
        selectedChannels.forEach((channel, index) => {
            channel.globalIndex = index;
        });
    
        // Log the selected channels
        console.log("[songAssemblyLogs] Selected channels for the new song:", selectedChannels);
    
        // Total number of selected channels
        const totalSelectedChannels = selectedChannels.length;
        console.log(`[songAssemblyLogs] Total number of selected channels for this song: ${totalSelectedChannels}`);
    
        // Split selected channels into groups for further processing
        const t = [
            selectedChannels.slice(0, 20),
            selectedChannels.slice(20, 24),
            selectedChannels.slice(24, 28)
        ];
    
        // Create the new song object
        const finalSong = {
            ...deserializedData[0], // Start with the structure of the first song
            projectBPM: selectedBPM,
            channelURLs: selectedChannels.map(channel => channel.url),
            channelVolume: selectedChannels.map(channel => channel.volume),
            channelPlaybackSpeed: selectedChannels.map(channel => channel.speed),
            trimSettings: selectedChannels.map(channel => channel.trim),
            projectSequences: {}
        };
    
        // Create a mapping for all song data
        const songDataMapping = deserializedData.reduce((acc, song, index) => {
            acc[`data${index + 1}`] = song;
            return acc;
        }, {});
    
        // Variables for logging channel addition
        let currentChannels = [];
        let totalChannelsAdded = 0;
        const channelAdditionLog = [];
    
        // Process sequences
        for (const sequenceId in deserializedData[0].projectSequences) {
            finalSong.projectSequences[sequenceId] = {};
            const sequenceNumber = parseInt(sequenceId.replace(/\D/g, ""), 10);
    
            // Select channels to add to each sequence based on sequence number
            if (sequenceNumber <= 1) {
                currentChannels = t[0];
            } else if (sequenceNumber <= 3) {
                currentChannels = [...t[0], ...t[1]];
            } else if (sequenceNumber <= 11) {
                currentChannels = [...t[0], ...t[1], ...t[2]];
            }
    
            // Log channels added for each sequence
            if (currentChannels.length > totalChannelsAdded) {
                channelAdditionLog.push({
                    sequenceNumber,
                    channelsAdded: currentChannels.length - totalChannelsAdded,
                    totalChannels: currentChannels.length
                });
                totalChannelsAdded = currentChannels.length;
            }
    
            // Map channels to the final song structure
            currentChannels.forEach((channel, index) => {
                const channelData = (songDataMapping[channel.source]?.projectSequences[sequenceId] || {})[`ch${channel.index}`] || { steps: [] };
                finalSong.projectSequences[sequenceId][`ch${index}`] = {
                    ...channelData,
                    steps: Array.isArray(channelData.steps) ? channelData.steps : [],
                    globalIndex: channel.globalIndex
                };
            });
        }
    
        // Log the number of sequences and the number of channels in each
        const totalSequences = Object.keys(finalSong.projectSequences).length;
        console.log(`[songAssemblyLogs] Total number of sequences in the new generative song: ${totalSequences}`);
        Object.keys(finalSong.projectSequences).forEach(sequenceId => {
            console.log(`[songAssemblyLogs] Sequence ${sequenceId} contains ${Object.keys(finalSong.projectSequences[sequenceId]).length} channels.`);
        });
    
        // Log channel addition log
        console.log("[songAssemblyLogs] Channel addition log:", channelAdditionLog);
    
        // Return the final song object
        return finalSong;
    };
    </script>

</helperfunctions>

<audioContextManager>
<details>
        <summary>Audio Context Manager Documentation</summary>
      
        ### Overview
        The `AudioContextManager` is a singleton class responsible for managing the `AudioContext` within the audio playback application. It ensures that only one instance of `AudioContext` exists, providing centralized control over audio operations. This manager handles the initialization, resumption, suspension, and resetting of the `AudioContext`, facilitating efficient resource management and consistent audio behavior across the application.
      
        ### Class Definition
      
        #### `ACM` (Audio Context Manager)
        - **Type**: `Class`
        - **Purpose**: Manages the lifecycle of the `AudioContext`, ensuring a single instance and providing methods to control its state.
        - **Singleton Pattern**: Ensures that only one instance of the `AudioContextManager` exists throughout the application.
      
        ### Constructor
      
        #### `constructor()`
        - **Purpose**: Initializes the `AudioContextManager` instance.
        - **Behavior**:
          - Checks if an instance already exists (`t.instance`).
          - If not, initializes `this.aCtx` to `null` and assigns the instance to `t.instance`.
          - Returns the existing instance if already created, enforcing the singleton pattern.
        - **Key Variables**:
          - `this.aCtx`: Holds the reference to the `AudioContext`.
          - `t.instance`: Static property to store the singleton instance.
      
        ### Methods
      
        #### `init()`
        - **Purpose**: Initializes the `AudioContext` if it is not already initialized or if it has been closed.
        - **Behavior**:
          - Checks if `this.aCtx` exists and its state is not `"closed"`.
          - If not, creates a new `AudioContext` using `AudioContext` or `webkitAudioContext` for compatibility.
          - Assigns an empty handler to `this.aCtx.onstatechange` to manage state changes (currently a placeholder for future implementations).
        - **Key Variables/Functions**:
          - `this.aCtx`: The managed `AudioContext` instance.
          - `AudioContext` / `webkitAudioContext`: Web APIs for managing audio operations.
          - `onstatechange`: Event handler for monitoring state changes of the `AudioContext`.
      
        #### `getCtx()`
        - **Purpose**: Retrieves the current `AudioContext`, initializing it if necessary.
        - **Behavior**:
          - Calls `this.init()` to ensure the `AudioContext` is initialized.
          - Returns the `AudioContext` instance (`this.aCtx`).
        - **Key Variables/Functions**:
          - `this.aCtx`: The managed `AudioContext` instance.
          - `this.init()`: Ensures the `AudioContext` is initialized before retrieval.
      
        #### `resume()`
        - **Purpose**: Resumes the `AudioContext` if it is in a suspended state.
        - **Behavior**:
          - Calls `this.init()` to ensure the `AudioContext` is initialized.
          - Checks if `this.aCtx.state` is `"suspended"`.
          - If suspended, asynchronously resumes the `AudioContext` using `this.aCtx.resume()`.
        - **Key Variables/Functions**:
          - `this.aCtx.state`: Current state of the `AudioContext` (`"running"`, `"suspended"`, etc.).
          - `this.aCtx.resume()`: Method to resume a suspended `AudioContext`.
      
        #### `suspend()`
        - **Purpose**: Suspends the `AudioContext` if it is currently running.
        - **Behavior**:
          - Checks if `this.aCtx` exists and its state is `"running"`.
          - If running, asynchronously suspends the `AudioContext` using `this.aCtx.suspend()`.
        - **Key Variables/Functions**:
          - `this.aCtx.state`: Current state of the `AudioContext`.
          - `this.aCtx.suspend()`: Method to suspend the `AudioContext`.
      
        #### `resetApp()`
        - **Purpose**: Resets the application’s audio state to its initial configuration.
        - **Behavior**:
          - Checks if `stopPlayback` is a function and calls it asynchronously to stop any ongoing playback.
          - Clears and resets various global variables related to audio playback, including:
            - `window.audioElements`
            - `window.activeSources`
            - `window.arraysInitialized`
            - `window.isReadyToPlay`
            - `globalJsonData`
            - `globalAudioBuffers`
            - `preprocessedSequences`
            - `currentStep`, `beatCount`, `barCount`, `currentSequence`
            - `playbackTimeoutId`, `nextNoteTime`, `totalSequences`, `isPlaying`
            - `globalTrimTimes`, `globalVolumeLevels`, `globalPlaybackSpeeds`
            - `activeSources`, `globalReversedAudioBuffers`, `isReversePlay`
          - Checks if `cleanUpWorker` is a function and calls it asynchronously to clean up any web workers.
          - Calls `initApp()` asynchronously to reinitialize the application.
        - **Key Variables/Functions**:
          - `stopPlayback()`: Function to stop current audio playback.
          - `cleanUpWorker()`: Function to clean up web workers.
          - `initApp()`: Function to initialize the application.
          - Various global variables related to audio state and playback.
      
        ### Initialization
      
        - **Self-Executing Function**:
          - Encapsulates the `AudioContextManager` class definition and ensures it runs immediately.
          - Checks if `window.ACM` already exists to prevent redefinition.
          - Assigns a new instance of `t` (the `AudioContextManager` class) to `window.ACM`.
      
        ### Property Definitions
      
        - **Singleton Instance**:
          - `window.ACM`: Exposes the `AudioContextManager` instance globally, allowing other parts of the application to access and control the `AudioContext`.
      
        ### Organization
        - **Singleton Pattern**: The use of a singleton ensures that all parts of the application interact with the same `AudioContext`, preventing conflicts and redundant resource usage.
        - **Audio State Management**: Centralizes the control of the `AudioContext`, making it easier to manage audio playback states across the application.
        - **Application Reset**: Provides a comprehensive method to reset the audio state, facilitating scenarios where the application needs to restart or recover from an error.
      
        ### Identified Improvements
      
        - **Modularizing**:
          - **Separate Concerns**: Consider splitting the `AudioContextManager` into separate modules for initialization, state management, and reset functionality to enhance readability and maintainability.
          - **Event Handling**: Implement meaningful handlers for `onstatechange` to respond to `AudioContext` state changes appropriately.
        
        - **Optimizing**:
          - **Lazy Initialization**: Ensure that the `AudioContext` is only initialized when necessary to improve performance, especially during the initial load.
          - **Method Enhancements**: Expand the `sP()` function referenced in the previous scripts to integrate seamlessly with the `resetApp()` method for consistent stopping of playback.
        
        - **Error Handling**:
          - **Robust Error Management**: Add try-catch blocks around asynchronous operations like `resume()`, `suspend()`, and `resetApp()` to handle potential errors gracefully.
          - **State Validation**: Before performing actions like suspending or resuming, validate the current state to prevent redundant operations.
        
        - **Performance Enhancements**:
          - **Resource Cleanup**: Ensure that all audio nodes and buffers are properly disconnected and dereferenced during `resetApp()` to prevent memory leaks.
          - **Asynchronous Operations**: Optimize the use of asynchronous functions to prevent blocking the main thread, especially during heavy operations like resetting the application state.
      
        ### Playback Control Understanding
        - **Centralized Audio Management**: By managing the `AudioContext` through a singleton, the application ensures consistent audio behavior and prevents conflicts from multiple contexts.
        - **State Control**: Methods like `resume()`, `suspend()`, and `resetApp()` provide comprehensive control over the audio playback state, enabling features like pausing, stopping, and resetting audio seamlessly.
        - **Resource Management**: Proper initialization and cleanup of the `AudioContext` and related resources help maintain optimal performance and prevent resource leaks.
      
        ### User Interaction Improvement
        - **Consistent Audio Behavior**: Central management of the `AudioContext` ensures that user actions like play, pause, and stop are handled uniformly across the application.
        - **Responsive Reset Functionality**: The `resetApp()` method allows the application to recover from errors or restart playback without requiring a full page reload, enhancing the user experience.
        - **Scalable Architecture**: The modular and centralized approach facilitates future enhancements, such as adding new audio features or integrating visualizers, without disrupting existing functionality.
      
</details>
<script id="audio-context-manager">
!function(){if(!window.ACM){class t{constructor(){return t.instance||(this.aCtx=null,t.instance=this),t.instance}init(){this.aCtx&&"closed"!==this.aCtx.state||(this.aCtx=new(window.AudioContext||window.webkitAudioContext),this.aCtx.onstatechange=()=>{})}getCtx(){return this.aCtx||this.init(),this.aCtx}async resume(){this.init(),"suspended"===this.aCtx.state&&await this.aCtx.resume()}async suspend(){this.aCtx&&"running"===this.aCtx.state&&await this.aCtx.suspend()}async resetApp(){"function"==typeof stopPlayback&&await stopPlayback(),window.audioElements=[],window.activeSources=[],window.arraysInitialized=!1,window.isReadyToPlay=!1,globalJsonData=null,globalAudioBuffers=[],preprocessedSequences={},currentStep=0,beatCount=0,barCount=0,currentSequence=0,playbackTimeoutId=null,nextNoteTime=0,totalSequences=0,isPlaying=!1,globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalReversedAudioBuffers={},isReversePlay=!1,"function"==typeof cleanUpWorker&&await cleanUpWorker(),await initApp()}}window.ACM=new t}}();
</script>
</audioContextManager>


<audioControl>
<details>
  <summary>Audio Control Functions Documentation</summary>

  ### Overview
  This section contains functions responsible for controlling audio playback within the application. Specifically, it handles suspending and stopping audio contexts and active audio sources, ensuring smooth transitions and proper resource management.

  ### Functions

  #### `sS()`
  - **Purpose**: Suspends the audio context if it is currently running.
  - **Description**:
    - Checks if the `audioCtx` (Audio Context) state is `"running"`.
    - If running, it asynchronously suspends the `audioCtx`.
  - **Key Variables/Functions**:
    - `audioCtx`: The main Audio Context managing audio operations.
    - `audioCtx.state`: Indicates the current state of the Audio Context (`"running"`, `"suspended"`, etc.).
    - `audioCtx.suspend()`: Method to suspend the Audio Context.

  #### `sp()`
  - **Purpose**: Stops all active audio sources with a fade-out effect and suspends the audio context.
  - **Description**:
    - Iterates over all `activeSources`.
    - For each active source:
      - Cancels any scheduled gain values at the current time.
      - Sets the gain to its current value immediately.
      - Applies a linear ramp to reduce the gain to `0` over the duration specified by `fadeDuration`.
      - Stops the audio source after the fade-out completes.
      - Disconnects both the audio source and its associated gain node.
    - Clears the list of active sources.
    - After a short delay (50 milliseconds), suspends the `audioCtx` and resets the playback state.
  - **Key Variables/Functions**:
    - `activeSources`: An object tracking all currently active audio sources.
    - `audioCtx.currentTime`: The current time of the Audio Context, used for scheduling.
    - `gainNode`: Controls the volume of the audio source.
    - `fadeDuration`: Duration over which the audio fades out.
    - `a.stop()`: Stops the audio source after the fade-out.
    - `a.disconnect()`: Disconnects the audio source from the Audio Context.
    - `e.disconnect()`: Disconnects the gain node.
    - `setTimeout()`: Delays the suspension of the Audio Context and resets playback state.

  ### Organization
  - **Related Functions**: Both `sS()` and `sp()` deal with controlling the state of the Audio Context and managing active audio sources.
  - **Variables**:
    - `audioCtx`: Central to both functions for managing audio state.
    - `activeSources`: Managed within `sp()` to track and control audio sources.

  ### Identified Improvements
  - **Modularizing**:
    - **Separate Concerns**: Consider separating the suspension of the Audio Context (`sS()`) from the stopping of active sources (`sp()`) into different modules or utilities for better maintainability.
    - **Fade-Out Handling**: Extract the fade-out logic into a dedicated function to promote reusability and clarity.
  - **Optimizing**:
    - **Error Handling**: Implement error handling to manage potential issues when suspending the Audio Context or stopping sources.
    - **Performance**: Review the use of `setTimeout` to ensure it's the most efficient way to handle the delay. Consider using Promises or async/await for better readability and control.

  ### Playback Control Understanding
  - **Suspending Audio**: The `sS()` function ensures that the audio context can be paused, preventing further audio from playing without fully shutting down the resources.
  - **Stopping Audio**: The `sp()` function provides a controlled way to stop all active audio sources with a smooth fade-out, enhancing the user experience by avoiding abrupt stops.

  ### User Interaction Improvement
  - By clearly defining how audio playback can be suspended or stopped, these functions contribute to responsive and intuitive user controls, allowing users to manage audio playback seamlessly.

</details>
<script id="audio-control-functions">
async function sS(){"running"===audioCtx.state&&await audioCtx.suspend()}async function sp(){for(const a in activeSources)activeSources[a].forEach((({source:a,gainNode:e})=>{const n=audioCtx.currentTime;e.gain.cancelScheduledValues(n),e.gain.setValueAtTime(e.gain.value,n),e.gain.linearRampToValueAtTime(0,n+fadeDuration),a.stop(n+fadeDuration),a.disconnect(),e.disconnect()})),activeSources[a]=[];setTimeout((async()=>{await audioCtx.suspend(),resetPlaybackState()}),50)}
</script>
</audioControl>



<globalDefinitionsAndInitialisations>
<details>
  <summary>Global Definitions and Initialization Documentation</summary>

  ### Overview
  This script initializes and defines global variables, configurations, and essential functions required for the audio playback application. It sets up the audio context, manages global states such as volume, playback speed, and handles user interactions like stopping playback. Additionally, it establishes communication channels for playback messages.

  ### Global Variables and Constants

  #### Audio Context and Related Variables
  - **`audioCtx` / `aCtx`**
    - **Type**: `AudioContext`
    - **Purpose**: Manages all audio operations within the application.
    - **Initialization**:
      - Attempts to retrieve an existing Audio Context from `window.AudioContextManager`.
      - If unavailable, creates a new instance using `AudioContext` or `webkitAudioContext` for compatibility.
    - **Debugging**:
      - Logs a message to the console upon initialization: `"[globalDefinitionsDebug] AudioContext initialized outside of property definitions."`
  
  #### Volume and Playback Control
  - **`globalVolumeMultiplier`**
    - **Type**: `number`
    - **Default**: `1`
    - **Purpose**: Multiplies the global volume level, allowing for volume adjustments across all audio sources.
  - **`globalTrimTimes`**
    - **Type**: `object`
    - **Purpose**: Stores trim times for audio clips, allowing precise control over playback start and end points.
  - **`globalVolumeLevels`**
    - **Type**: `object`
    - **Purpose**: Manages individual volume levels for different audio sources or tracks.
  - **`globalPlaybackSpeeds`**
    - **Type**: `object`
    - **Purpose**: Controls the playback speed of audio sources, enabling effects like slow motion or fast-forward.
  
  #### Audio Source Management
  - **`activeSources` / `aS`**
    - **Type**: `array`
    - **Purpose**: Tracks currently active audio sources that are playing.
  - **`globalGainNodes` / `gGN`**
    - **Type**: `Map`
    - **Purpose**: Maps audio sources to their corresponding gain nodes for volume control.
  - **`gainNodes`**
    - **Type**: `object`
    - **Purpose**: Stores gain nodes used to adjust the volume of individual audio sources.
  
  #### Audio Buffers
  - **`globalAudioBuffers` / `gAB`**
    - **Type**: `array`
    - **Purpose**: Holds audio buffer data for loaded audio clips.
  - **`globalReversedAudioBuffers` / `gRAB`**
    - **Type**: `object`
    - **Purpose**: Contains reversed versions of audio buffers for effects that require playing audio backwards.
  
  #### Playback State Variables
  - **`isReversePlay` / `isRP`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates whether the current playback is in reverse mode.
  - **`isReadyToPlay` / `isReadyToPlay`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Signals whether the application is ready to start playback.
  - **`isToggleInProgress` / `isToggleInProgress`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Flags if a toggle action (like play/pause) is currently being processed.
  - **`isPlaying` / `isP`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates whether audio is currently playing.
  
  #### Playback Timing
  - **`currentStep` / `cS`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Tracks the current step in a sequence of audio playback.
  - **`currentSequence` / `cQ`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Identifies the current sequence being played.
  - **`nextNoteTime` / `nNT`**
    - **Type**: `number`
    - **Purpose**: Schedules the timing for the next note in the playback sequence.
  - **`fadeDuration` / `fD`**
    - **Type**: `number`
    - **Default**: `0.01`
    - **Purpose**: Duration for fade-in and fade-out effects during audio transitions.
  - **`defaultVolume` / `dV`**
    - **Type**: `number`
    - **Default**: `1`
    - **Purpose**: Sets the default volume level for audio playback.
  
  #### Data Structures
  - **`globalJsonData`**
    - **Type**: `object` or `null`
    - **Default**: `null`
    - **Purpose**: Stores JSON data related to audio configurations or sequences.
  - **`sourceChannelMap` / `gVM`**
    - **Type**: `Map`
    - **Purpose**: Maps audio sources to their respective channels for organized playback.
  - **`preprocessedSequences`**
    - **Type**: `object`
    - **Purpose**: Contains sequences that have been preprocessed for efficient playback.
  
  #### Playback Controls
  - **`bpm`**
    - **Type**: `number`
    - **Default**: `0`
    - **Purpose**: Beats per minute setting for timing audio sequences.
  - **`isReadyToPlay`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Indicates if the application has loaded all necessary resources and is ready for playback.
  
  #### Broadcast Channels
  - **`AudionalPlayerMessages` / `APC`**
    - **Type**: `BroadcastChannel`
    - **Purpose**: Facilitates communication for playback messages across different contexts or threads.
  - **`window.enableVisualizerScripts` / `window.eVS`**
    - **Type**: `boolean`
    - **Default**: `false`
    - **Purpose**: Toggles the enabling of visualizer scripts for audio visualization.
  
  ### Functions

  #### `eACS()`
  - **Purpose**: Ensures the Audio Context is active and resumes it if suspended.
  - **Description**:
    - Checks if `aCtx` exists; if not, initializes it.
    - If the Audio Context state is `"suspended"`, it resumes the context asynchronously.
  - **Key Variables/Functions**:
    - `aCtx`: The Audio Context being managed.
    - `aCtx.state`: Current state of the Audio Context (`"running"`, `"suspended"`, etc.).
    - `aCtx.resume()`: Method to resume a suspended Audio Context.

  #### `sP()`
  - **Purpose**: Placeholder for a function to handle stopping playback.
  - **Description**:
    - Currently empty, intended to be implemented with logic to stop audio playback.
  - **Key Variables/Functions**:
    - To be defined based on playback stopping requirements.

  ### Property Definitions

  #### `window.isPlaying`
  - **Type**: `property` with getter and setter
  - **Purpose**: Provides controlled access to the `isP` variable.
  - **Getter**: Returns the current value of `isP`.
  - **Setter**: Updates the value of `isP` with the provided value `e`.

  #### `window.currentStep`
  - **Type**: `property` with getter and setter
  - **Purpose**: Manages access to the `cS` variable tracking the current playback step.
  - **Getter**: Returns the current value of `cS`.
  - **Setter**: Updates the value of `cS` with the provided value `e`.

  #### `window.currentSequence`
  - **Type**: `property` with getter and setter
  - **Purpose**: Manages access to the `cQ` variable tracking the current playback sequence.
  - **Getter**: Returns the current value of `cQ`.
  - **Setter**: Updates the value of `cQ` with the provided value `e`.

  ### Event Listeners

  #### Stop Button Listener
  - **Selector**: `document.getElementById("stop-button")`
  - **Event**: `click`
  - **Handler**: Asynchronously calls the `sP()` function when the stop button is clicked.
  - **Purpose**: Allows users to stop audio playback through the UI.

  ### Organization
  - **Global State Management**: Variables like `isPlaying`, `currentStep`, and `currentSequence` manage the overall playback state.
  - **Audio Control**: `audioCtx`, `aCtx`, and related gain nodes handle the audio processing and control.
  - **Playback Configuration**: Variables such as `globalVolumeMultiplier`, `bpm`, and `fadeDuration` configure playback settings.
  - **Communication Channels**: `AudionalPlayerMessages` and `APC` manage inter-process or inter-thread communication for playback control.

  ### Identified Improvements

  - **Modularizing**:
    - **Separate Initialization**: Divide the initialization of global variables and the Audio Context into separate modules or files to enhance readability and maintainability.
    - **Encapsulate State Management**: Group related state variables and their property definitions into a dedicated state management module or object.
    - **Event Handling**: Isolate event listeners into their own module to keep the global script uncluttered.

  - **Optimizing**:
    - **Redundant Variables**: There are duplicate variables (`audioCtx` and `aCtx`, `AudionalPlayerMessages` and `APC`, etc.). Consolidate these to avoid confusion and potential bugs.
    - **Lazy Initialization**: Initialize heavy objects like `AudioContext` only when needed to improve initial load performance.
    - **Use Constants Appropriately**: Ensure that values like `fadeDuration` and `defaultVolume` are defined as constants if they are not meant to change during runtime.

  - **Error Handling**:
    - **Audio Context Errors**: Implement error handling for scenarios where the Audio Context fails to initialize or resume.
    - **Event Listener Robustness**: Check for the existence of the stop button before adding an event listener to prevent potential errors.

  - **Performance Enhancements**:
    - **Efficient Data Structures**: Review the use of `Map` vs. plain objects for `sourceChannelMap`, `globalGainNodes`, etc., to ensure optimal performance based on usage patterns.
    - **Asynchronous Operations**: Utilize `async/await` consistently for asynchronous functions to improve code readability and maintainability.

  ### Playback Control Understanding
  - **Audio Context Management**: The script ensures that the Audio Context is properly initialized and managed, allowing for control over the audio processing lifecycle.
  - **Global State Tracking**: Variables like `isPlaying`, `currentStep`, and `currentSequence` provide a mechanism to track and control the playback state, enabling features like play, pause, stop, and sequence navigation.
  - **User Interaction Handling**: The stop button event listener allows users to interact with the playback controls, enhancing the application's responsiveness and usability.

  ### User Interaction Improvement
  - **Responsive Controls**: By managing playback states and providing event listeners for user actions, the application ensures that user interactions are handled smoothly and intuitively.
  - **Feedback Mechanisms**: Implementing state tracking variables allows the UI to provide real-time feedback to users about the current playback status, improving the overall user experience.

</details>
<script>
window.enableVisualizerScripts=!1;let globalVolumeMultiplier=1,globalJsonData=null,bpm=0;const sourceChannelMap=new Map;let globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalGainNodes=new Map,globalAudioBuffers=[],globalReversedAudioBuffers={},isReversePlay=!1;const gainNodes={};let audioCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext);console.log("[globalDefinitionsDebug] AudioContext initialized outside of property definitions.");let preprocessedSequences={},isReadyToPlay=!1,currentStep=0,currentSequence=0,nextNoteTime=0;const fadeDuration=.01,defaultVolume=1;let isToggleInProgress=!1,isPlaying=!1;const AudionalPlayerMessages=new BroadcastChannel("channel_playback");
window.eVS=!1;let gVM=1,gJD=null,gTM=new Map,gTT={},gVL={},gPS={},aS=[],gGN=new Map,gAB=[],gRAB={},isRP=!1,gN={},aCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext),pS={},isR=!1,cS=0,cQ=0,nNT=0;const fD=.01,dV=1,tIP=!1,isP=!1,APC=new BroadcastChannel("channel_playback");async function eACS(){aCtx||(aCtx=new(window.AudioContext||window.webkitAudioContext)),"suspended"===aCtx.state&&await aCtx.resume()}async function sP(){}Object.defineProperty(window,"isPlaying",{get:()=>isP,set(e){isP=e}}),Object.defineProperty(window,"currentStep",{get:()=>cS,set(e){cS=e}}),Object.defineProperty(window,"currentSequence",{get:()=>cQ,set(e){cQ=e}}),document.getElementById("stop-button")?.addEventListener("click",(async()=>{await sP()}));
</script>   
</globalDefinitionsAndInitialisations>


<jsonloadingandplayback>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is responsible for loading JSON data that defines the structure and sequences of the generative song. It processes this JSON data to prepare it for playback by performing the following tasks:
            <ul>
                <li><strong>Fetching JSON Data:</strong> Retrieves the JSON file from a specified URL.</li>
                <li><strong>Analyzing JSON Structure:</strong> Recursively examines the JSON to gather statistics about sequences, channels, and data types.</li>
                <li><strong>Preparing Playback Data:</strong> Organizes the JSON data into a format suitable for playback, calculating timings based on the BPM and segregating normal and reverse steps.</li>
                <li><strong>Managing Global Metadata:</strong> Stores essential metadata such as volume levels, playback speeds, and trim times in the global <code>window.globalMetadata</code> object to ensure accessibility across the application.</li>
                <li><strong>Audio Data Processing:</strong> Initiates the fetching and decoding of audio files associated with each channel and schedules them for playback.</li>
                <li><strong>Scheduling Playback:</strong> Preprocesses the playback data to calculate precise timings and schedules the playback loop.</li>
            </ul>
            <br/>
            **Key Components:**
            <ul>
                <li><strong>Global Metadata:</strong> <code>window.globalMetadata</code> stores <code>trimTimes</code>, <code>volumeLevels</code>, and <code>playbackSpeeds</code> for each channel, ensuring consistent access and modification throughout the application.</li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>loadJsonFromUrl(url)</code>: Fetches and processes the JSON data from the provided URL.</li>
                        <li><code>analyzeJsonStructure(jsonData, stats)</code>: Analyzes the JSON structure to collect statistics.</li>
                        <li><code>findAndSetEndSequence(projectData)</code>: Identifies and sets the end sequence in the project data.</li>
                        <li><code>prepareForPlayback(jsonData, stats)</code>: Prepares the JSON data for playback, setting up metadata and organizing sequences.</li>
                        <li><code>preprocessAndSchedulePlayback(playbackData)</code>: Preprocesses playback data to calculate timings and schedules the playback.</li>
                        <li><code>processSteps(steps)</code>: Calculates the timing for each step based on BPM.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong> Comprehensive logging is implemented to track each step of the data loading and processing pipeline, aiding in debugging and ensuring transparency in data handling.</li>
            </ul>
            <br/>
            **Error Handling:**
            <ul>
                <li>Errors during data fetching, JSON parsing, or processing are caught and logged to the console, preventing the application from crashing and facilitating easier debugging.</li>
            </ul>
        </p>
    </details>
<script>
    
    // Fetch and process the audio data
    const fetchAndProcessAudioData = async (urls) => {
        // Process each URL and create reversed buffers after all are processed
        await Promise.all(urls.map((url, index) => processAudioUrl(url, index + 1)));
        createReversedBuffers();
    };

    // Get or create a gain node for the given channel
    const getOrCreateGainNode = (channel) => {
        // If the gain node doesn't exist for this channel, create it
        if (!gainNodes[channel]) {
            const gainNode = audioCtx.createGain(); // Create a gain node
            gainNode.connect(audioCtx.destination); // Connect it to the audio context destination (output)
            gainNodes[channel] = gainNode; // Store the gain node for this channel
        }
        return gainNodes[channel]; // Return the gain node
    };

   // Process the audio URL for each channel
const processAudioUrl = async (url, channelIndex) => {
    const channelName = `Channel ${channelIndex}`; // Name the channel based on the index

    // Log the URL being processed
    console.log(`[LOG] Processing URL: ${url} for channel: ${channelName}`);

    // Log specific processing for the targeted URL
    if (url.endsWith("3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0")) {
        console.log(`[LOG] Processing targeted URL for channel: ${channelName}`);
    }

    try {
        const response = await fetch(url); // Fetch the audio URL

        // Check if the fetch was successful
        if (!response.ok) {
            throw new Error(`Fetch failed: ${url}, Status: ${response.status}`);
        }

        const contentType = response.headers.get("Content-Type"); // Get the content type
        const audioBuffer = await fetchAndDecodeAudio(response, contentType); // Decode the audio based on the content type

        if (audioBuffer) {
            const gainNode = getOrCreateGainNode(channelName); // Get or create the gain node for the channel
            gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channelName]) * globalVolumeMultiplier; // Set the gain value based on global settings

            // Log audio buffer processing completion for the targeted URL
            if (url.endsWith("3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0")) {
                console.log(`[LOG] Successfully processed audio buffer for targeted URL: ${url}, Channel: ${channelName}`);
            }

            // Push the decoded buffer and gain node to the global audio buffer array
            globalAudioBuffers.push({
                buffer: audioBuffer,
                gainNode: gainNode,
                channel: channelName
            });

            // Log completion of audio buffer processing for the URL
            console.log(`[LOG] Successfully processed audio buffer for URL: ${url}, Channel: ${channelName}`);
        } else {
            console.error(`Decoding failed for ${channelName}: ${url}`);
        }
    } catch (error) {
        console.error(`Error processing ${channelName}:`, error);
    }
};


    // Set the global volume multiplier and apply it to all gain nodes
    const setGlobalVolumeMultiplier = (multiplier) => {
        globalVolumeMultiplier = Math.max(0, multiplier); // Ensure the multiplier is non-negative

        // Update the gain value for each channel based on the global volume multiplier
        globalAudioBuffers.forEach(({ gainNode, channel }) => {
            gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channel]) * globalVolumeMultiplier;
        });
    };

    // Fetch and decode the audio data based on the content type
    const fetchAndDecodeAudio = async (response, contentType) => {
        try {
            if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer(); // Get the audio data as an ArrayBuffer
                return audioCtx.decodeAudioData(arrayBuffer); // Decode the audio data
            }

            const textData = await response.text(); // If it's not audio, get it as text
            let base64Data = null;

            if (/application\/json/.test(contentType)) {
                base64Data = JSON.parse(textData).audioData; // Extract audio data from JSON
            } else if (/text\/html/.test(contentType)) {
                base64Data = extractBase64FromHTML(textData); // Extract base64 from HTML
            }

            if (base64Data) {
                const audioBuffer = base64ToArrayBuffer(base64Data.split(",")[1]); // Convert base64 to ArrayBuffer
                return audioCtx.decodeAudioData(audioBuffer); // Decode the audio data
            }

            if (/audio\//.test(contentType)) {
                const arrayBuffer = await response.arrayBuffer(); // Get the audio data
                return audioCtx.decodeAudioData(arrayBuffer); // Decode the audio data
            }
        } catch (error) {
            console.error("[fetchAndDecodeAudio] Decoding error:", error);
        }
        return null; // Return null if decoding fails
    };

    // Create reversed buffers for channels that require it
    const createReversedBuffers = () => {
        const channelsToReverse = new Set(); // Set to keep track of channels to reverse

        // Iterate through project sequences to find channels with steps marked to reverse
        Object.values(globalJsonData.projectSequences).forEach((sequence) => {
            Object.entries(sequence).forEach(([trackId, trackData]) => {
                if (trackData.steps.some(step => step.reverse)) {
                    const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;
                    channelsToReverse.add(channelName); // Add the channel to the set if it has any steps to reverse
                }
            });
        });

        // Reverse the audio buffers for the channels that need reversing
        globalAudioBuffers.forEach(({ buffer, channel }) => {
            if (channelsToReverse.has(channel)) {
                globalReversedAudioBuffers[channel] = reverseBuffer(buffer); // Store the reversed buffer
            }
        });
    };

    // Reverse the audio buffer for a given channel
    const reverseBuffer = (buffer) => {
        const reversedBuffer = audioCtx.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate); // Create a new buffer for reversed audio

        // Reverse the audio data for each channel
        for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
            const originalChannelData = buffer.getChannelData(channel); // Get the original channel data
            const reversedChannelData = reversedBuffer.getChannelData(channel); // Get the reversed channel data

            for (let i = 0; i < originalChannelData.length; i++) {
                reversedChannelData[i] = originalChannelData[originalChannelData.length - i - 1]; // Reverse the data
            }
        }

        return reversedBuffer; // Return the reversed buffer
    };

    // Convert base64 encoded data to an ArrayBuffer
    const base64ToArrayBuffer = (base64) => {
        try {
            const binaryString = atob(base64); // Decode base64
            const len = binaryString.length;
            const bytes = new Uint8Array(len);

            // Convert binary string to a byte array
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer; // Return the ArrayBuffer
        } catch (error) {
            console.error("[base64ToArrayBuffer] Conversion error:", error);
            return null; // Return null on error
        }
    };

    // Extract base64 encoded audio data from an HTML response
    const extractBase64FromHTML = (html) => {
        try {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, "text/html");
            const audioSrc = doc.querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");

            if (/^data:audio\/(wav|mp3|mp4);base64,/.test(audioSrc?.toLowerCase()) || /audio\//.test(audioSrc?.toLowerCase())) {
                return audioSrc; // Return the base64 encoded audio source
            }

            console.error("[extractBase64FromHTML] Invalid audio source format.");
        } catch (error) {
            console.error("[extractBase64FromHTML] Parsing error:", error);
        }
        return null; // Return null on error
    };

    // Initialization log
    console.log("Audio processing script loaded.");
   
// Load JSON from a URL, process it, and prepare for playback
const loadJsonFromUrl = async (url) => {
    try {
        // Fetch JSON data from the URL
        const response = await fetch(url);
        
        // Check if the request was successful
        if (!response.ok) {
            throw new Error(`HTTP error: ${response.status}`);
        }

        // Parse the JSON data and store it in globalJsonData
        globalJsonData = await response.json();

        // Initialize an object to collect stats and details about the JSON structure
        const stats = {
            channelsWithUrls: 0, // Count channels with URLs
            sequencesCount: 0, // Count the number of sequences
            activeStepsPerSequence: {}, // Active steps per sequence
            activeChannelsPerSequence: {}, // Active channels per sequence
            types: {} // Data types found in the JSON structure
        };

        // Analyze the structure of the JSON data and populate stats
        analyzeJsonStructure(globalJsonData, stats);

        // Prepare the JSON data for playback
        const playbackData = prepareForPlayback(globalJsonData, stats);

        // Fetch and process audio data based on the channel URLs
        await fetchAndProcessAudioData(playbackData.channelURLs);

        // Preprocess the data and schedule it for playback
        preprocessAndSchedulePlayback(playbackData);

    } catch (error) {
        console.error("Failed to load JSON:", error);
    }
};

// Analyze the structure of the JSON data and gather stats
const analyzeJsonStructure = (jsonData, stats) => {
    // Check if projectSequences exists and is an object
    if (jsonData.projectSequences && typeof jsonData.projectSequences === 'object') {
        // Iterate through projectSequences entries
        Object.entries(jsonData.projectSequences).forEach(([sequenceId, sequenceData]) => {
            // Initialize step counts and active channels for each sequence
            stats.activeStepsPerSequence[sequenceId] = 0;
            stats.activeChannelsPerSequence[sequenceId] = [];

            // Iterate through each track in the sequence
            Object.entries(sequenceData).forEach(([trackId, trackData]) => {
                const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;

                // Count the number of steps for the track
                stats.activeStepsPerSequence[sequenceId] += trackData.steps.length;

                // Add the channel to the list of active channels for this sequence
                stats.activeChannelsPerSequence[sequenceId].push(channelName);
            });
        });
    }

    // Analyze the rest of the JSON structure
    Object.entries(jsonData).forEach(([key, value]) => {
        if (key !== "projectSequences") {
            // Determine the type of each top-level key
            const type = Array.isArray(value) ? "array" : typeof value;
            stats.types[type] = (stats.types[type] || 0) + 1;

            // Recursively analyze nested objects or arrays
            if (["object", "array"].includes(type)) {
                analyzeJsonStructure(value, stats);
            }
        }
    });
};

// Find and set the end sequence for the project
const findAndSetEndSequence = (projectData) => {
    if (projectData?.sequences) {
        let lastNonEmptySequence = null;

        // Iterate through the sequences to find the last one with normal steps
        for (const [sequenceId, sequenceData] of Object.entries(projectData.sequences)) {
            // Check if the sequence has any non-empty normal steps
            const isEmpty = Object.values(sequenceData.normalSteps).every(steps => !steps.length);

            // If it's non-empty, save it as the last non-empty sequence
            if (!isEmpty) {
                lastNonEmptySequence = sequenceData;
            }

            // Set the end sequence when an empty sequence is found after a non-empty one
            if (isEmpty && lastNonEmptySequence) {
                projectData.endSequence = lastNonEmptySequence;
                break;
            }
        }

        // If no end sequence is set, use the last non-empty sequence
        if (!projectData.endSequence && lastNonEmptySequence) {
            projectData.endSequence = lastNonEmptySequence;
        }
    }
};

// Prepare the JSON data for playback
const prepareForPlayback = (jsonData, stats) => {
    const {
        channelURLs, // List of channel URLs
        trimSettings = [], // Trim settings for each channel
        channelVolume = [], // Volume settings for each channel
        channelPlaybackSpeed = [], // Playback speed settings for each channel
        projectSequences, // Sequences data
        projectName, // Name of the project
        projectBPM, // BPM for the project
        currentSequence // Current sequence being played
    } = jsonData;

    // Set global variables for playback
    bpm = projectBPM;
    totalSequences = currentSequence;
    globalTrimTimes = {};
    globalVolumeLevels = {};
    globalPlaybackSpeeds = {};

    // Initialize trim times, volume, and playback speed for each channel
    channelURLs.forEach((url, index) => {
        const channelName = `Channel ${index + 1}`;
        const trimSetting = trimSettings[index] || {};

        globalTrimTimes[channelName] = {
            startTrim: +(trimSetting.startSliderValue || 0) / 100,
            endTrim: +(trimSetting.endSliderValue || 100) / 100
        };

        globalVolumeLevels[channelName] = +parseVolumeLevel(channelVolume[index] || 1).toFixed(3);
        globalPlaybackSpeeds[channelName] = +Math.min(Math.max(channelPlaybackSpeed[index] || 1, 0.1), 100).toFixed(3);
    });

    // Reduce the project sequences to a more manageable format for playback
    const sequences = Object.entries(projectSequences).reduce((acc, [sequenceId, sequenceData]) => {
        const normalSteps = {};
        const reverseSteps = {};

        // Iterate through each track in the sequence
        Object.entries(sequenceData).forEach(([trackId, trackData]) => {
            const channelName = `Channel ${parseInt(trackId.slice(2)) + 1}`;
            normalSteps[channelName] = [];
            reverseSteps[channelName] = [];

            // Sort steps into normal and reverse steps
            trackData.steps.forEach(step => {
                const stepIndex = typeof step === 'object' ? step.index : step;
                if (step.reverse) {
                    reverseSteps[channelName].push(stepIndex);
                } else {
                    normalSteps[channelName].push(stepIndex);
                }
            });
        });

        acc[sequenceId] = { normalSteps, reverseSteps };
        return acc;
    }, {});

    // Create a playback data object
    const playbackData = {
        projectName,
        bpm: projectBPM,
        channels: channelURLs.length,
        channelURLs,
        trimTimes: globalTrimTimes,
        stats,
        sequences
    };

    // Find and set the end sequence
    findAndSetEndSequence(playbackData);

    return playbackData;
};

// Preprocess and schedule the playback data
const preprocessAndSchedulePlayback = (playbackData) => {
    if (!playbackData?.sequences) {
        return console.error("Playback data missing.");
    }

    // Set the BPM globally
    bpm = playbackData.bpm;

    // Preprocess the steps for each sequence
    preprocessedSequences = Object.fromEntries(
        Object.entries(playbackData.sequences).map(([sequenceId, sequenceData]) => [
            sequenceId,
            {
                normalSteps: processSteps(sequenceData.normalSteps),
                reverseSteps: processSteps(sequenceData.reverseSteps)
            }
        ])
    );

    // Check if the sequences are ready for playback
    isReadyToPlay = Object.values(preprocessedSequences).some(
        sequence => Object.keys(sequence.normalSteps).length || Object.keys(sequence.reverseSteps).length
    );
};

// Process the steps of a sequence by calculating timing based on BPM
const processSteps = (steps) => {
    return Object.fromEntries(
        Object.entries(steps)
            .filter(([, stepArray]) => stepArray.length)
            .map(([channelName, stepArray]) => [
                channelName,
                stepArray.map(step => ({
                    step,
                    timing: +(step * (60 / bpm)).toFixed(3) // Calculate the timing based on the BPM
                }))
            ])
    );
};
</script>
</jsonloadingandplayback>





<hashingAndRandomnessUtilities>
 <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is a crucial part of the application responsible for processing and preparing JSON data that defines the structure and sequences of the generative song. Here's a comprehensive breakdown of its functionalities:

            <h3>1. **Hashing and Randomness Utilities**</h3>
            <ul>
                <li><strong>hashString(e):</strong>
                    <ul>
                        <li>Takes a string input `e` and generates a numerical hash value.</li>
                        <li>Extracts a number from the string by splitting at the character "i" and parsing the subsequent substring.</li>
                        <li>Rearranges the string based on the extracted number and performs a reduction using a polynomial rolling hash method.</li>
                        <li>Ensures the hash value stays within the range of `0` to `1.4e8` (140,000,000).</li>
                    </ul>
                </li>
                <li><strong>seededRandom(e):</strong>
                    <ul>
                        <li>Generates a pseudo-random number based on the input `e` using the sine function.</li>
                        <li>Multiplies the sine of `e` by `10,000` and returns the fractional part, ensuring a deterministic yet varied output.</li>
                    </ul>
                </li>
            </ul>

            <h3>2. **Playback Status Management**</h3>
            <ul>
                <li><strong>setPlaybackStatus(e):</strong>
                    <ul>
                        <li>Updates the global playback status by setting `window.playbackStarted` to the value of `e`.</li>
                        <li>This flag is used to control and monitor the playback state across the application.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Key and Channel Mappings**</h3>
            <ul>
                <li><strong>keyMap:</strong>
                    <ul>
                        <li>An object that maps numerical indices (0-15) to specific project-related keys such as "projectName", "artistName", "projectBPM", etc.</li>
                        <li>Facilitates the translation of numerical identifiers into meaningful property names during data processing.</li>
                    </ul>
                </li>
                <li><strong>reverseKeyMap:</strong>
                    <ul>
                        <li>Creates an inverse mapping from `keyMap`, allowing retrieval of numerical indices based on key names.</li>
                        <li>Essential for scenarios where reverse lookup from key names to indices is required.</li>
                    </ul>
                </li>
                <li><strong>channelMap:</strong>
                    <ul>
                        <li>Generates an array of uppercase alphabet letters (A-Z) representing channel identifiers.</li>
                        <li>Used to standardize channel naming and indexing throughout the application.</li>
                    </ul>
                </li>
                <li><strong>reverseChannelMap:</strong>
                    <ul>
                        <li>Creates an inverse mapping from `channelMap`, mapping each letter back to its corresponding index.</li>
                        <li>Facilitates quick and efficient channel index retrieval based on channel identifiers.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Step Decompression and Deserialization**</h3>
            <ul>
                <li><strong>decompressSteps(e):</strong>
                    <ul>
                        <li>Processes an array of steps, handling different representations:</li>
                        <li>Numbers are treated as direct step indices.</li>
                        <li>Objects with an `r` property represent a range of steps, which are expanded into individual step indices.</li>
                        <li>Strings ending with an "r" denote steps that should be reversed, creating objects with `index` and `reverse` properties.</li>
                    </ul>
                </li>
                <li><strong>deserialize(e):</strong>
                    <ul>
                        <li>Transforms a nested data structure into a more usable format for the application.</li>
                        <li>Utilizes `keyMap` to translate numerical keys into meaningful property names.</li>
                        <li>Handles "projectSequences" specially by mapping track IDs to channel IDs using `reverseChannelMap` and decompressing steps with `decompressSteps`.</li>
                        <li>Ensures that the final data structure is organized and accessible for playback and other functionalities.</li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Initialization and Seed Generation**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Initializes playback-related functionalities. (Note: The actual implementation details are not provided in this script.)</li>
                    </ul>
                </li>
                <li><strong>seedValue:</strong>
                    <ul>
                        <li>Generated by passing a specific string to `hashString`, producing a deterministic seed value.</li>
                        <li>This seed value is used to ensure consistent randomness across different parts of the application.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Logs the generated seed value and indicates that the processing utilities have been initialized.</li>
                        <li>Provides transparency into the initialization process, aiding in debugging and monitoring.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Window Load Event Handler**</h3>
            <ul>
                <li><strong>window.onload:</strong>
                    <ul>
                        <li>Sets up an event handler that logs a message when the window's load event is triggered.</li>
                        <li>Indicates that the entire page has been loaded, which can be useful for triggering subsequent initialization steps.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Overall Role within the Program:**</h3>
            <p>
                This script serves as a utility module that prepares and structures the JSON data defining the generative song for playback. By handling hashing, randomness, key and channel mappings, step decompression, and deserialization, it ensures that the data is in the correct format and that all necessary metadata is accessible globally through `window.globalMetadata`. This centralization facilitates consistent access and manipulation of playback settings across different parts of the application, enhancing maintainability and scalability.
            </p>

            <h3>**Dependencies and Interactions:**</h3>
            <ul>
                <li><strong>Global Variables:</strong>
                    <ul>
                        <li><code>window.globalMetadata</code>: Stores metadata related to channels, including volume levels, playback speeds, and trim times.</li>
                        <li><code>window.playbackStarted</code>: Indicates the playback status, controlled by <code>setPlaybackStatus</code>.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>initializePlayback()</code>: Initializes playback functionalities.</li>
                        <li><code>deserialize()</code>: Transforms raw JSON data into a structured format.</li>
                        <li><code>decompressSteps()</code>: Processes and expands step data for playback.</li>
                        <li><code>hashString()</code> and <code>seededRandom()</code>: Generate deterministic values for consistent randomness.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Provides detailed console logs for tracking the initialization process, seed generation, and any potential errors.</li>
                        <li>Aids in debugging by offering insights into the internal state and data transformations.</li>
                    </ul>
                </li>
            </ul>
        </p>
</details>

<script>
    // Hash a string by rotating it based on a numeric value extracted from the string
const hashString = (input) => {
    // Parse the integer part after 'i' in the string
    const rotateIndex = parseInt(input.split("i")[1], 10);

    // Rotate the string by the parsed index and then reduce it to a hash value
    const rotatedString = (input.slice(rotateIndex) + input.slice(0, rotateIndex));
    
    // Reduce the rotated string to a number using character codes
    return rotatedString.split("").reduce((accumulator, char) => {
        return (31 * accumulator + char.charCodeAt(0)) % Number.MAX_SAFE_INTEGER;
    }, 0) % 1400000000;  // Result modded to a maximum value
};

// Generate a seeded random value based on an input seed
const seededRandom = (seed) => {
    const randomValue = 10000 * Math.sin(seed);
    return randomValue - Math.floor(randomValue);
};

// Set the playback status (true for started, false for stopped)
const setPlaybackStatus = (status) => {
    window.playbackStarted = status;
};

// Key mapping for deserialization process
const keyMap = {
    0: "projectName",
    1: "artistName",
    2: "projectBPM",
    3: "currentSequence",
    4: "channelURLs",
    5: "channelVolume",
    6: "channelPlaybackSpeed",
    7: "trimSettings",
    8: "projectChannelNames",
    9: "startSliderValue",
    10: "endSliderValue",
    11: "totalSampleDuration",
    12: "start",
    13: "end",
    14: "projectSequences",
    15: "steps"
};

// Reverse the keyMap for reverse lookup
const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([key, value]) => [value, +key]));

// Create a map of letters 'A' to 'Z' representing channels
const channelMap = Array.from({ length: 26 }, (value, index) => String.fromCharCode(65 + index));  // 'A' to 'Z'

// Reverse map to convert channel letters back to their index
const reverseChannelMap = Object.fromEntries(channelMap.map((letter, index) => [letter, index]));

// Decompress the steps data
// If the step is a number, return it as-is
// If it contains a range 'r', expand the range into individual numbers
// If it's a reverse step (ends with 'r'), convert it into an object with 'reverse: true'
const decompressSteps = (steps) => steps.flatMap(step => {
    if (typeof step === "number") return step;
    
    if (step && typeof step === "object" && "r" in step) {
        const [start, end] = step.r;
        return Array.from({ length: end - start + 1 }, (v, i) => start + i);
    }
    
    if (typeof step === "string" && step.endsWith("r")) {
        return { index: parseInt(step.slice(0, -1), 10), reverse: true };
    }
    
    return [];
});

// Deserialize function that converts encoded data into a usable format
const deserialize = (data) => {
    const recursiveDeserialize = (obj) => {
        if (Array.isArray(obj)) {
            return obj.map(item => (typeof item === "object" ? recursiveDeserialize(item) : item));
        }
        if (obj && typeof obj === "object") {
            return Object.entries(obj).reduce((acc, [key, value]) => {
                const mappedKey = keyMap[key] || key;
                if (mappedKey === "projectSequences") {
                    acc[mappedKey] = Object.entries(value).reduce((sequenceAcc, [seqKey, seqValue]) => {
                        const sequenceName = seqKey.replace(/^s/, "Sequence");
                        sequenceAcc[sequenceName] = Object.entries(seqValue).reduce((trackAcc, [trackKey, trackValue]) => {
                            const channelName = `ch${reverseChannelMap[trackKey]}`;
                            const steps = trackValue[reverseKeyMap.steps] || [];
                            trackAcc[channelName] = {
                                steps: decompressSteps(steps)
                            };
                            return trackAcc;
                        }, {});
                        return sequenceAcc;
                    }, {});
                } else {
                    acc[mappedKey] = recursiveDeserialize(value);
                }
                return acc;
            }, {});
        }
        return obj;
    };

    return recursiveDeserialize(data);
};



// Hash a string and set a seed value based on it
const seedValue = hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");
console.log(`Seed value: ${seedValue}`);

// Log when the processing utilities are initialized
console.log("ProcessingUtilities initialized.");

// Handle window load event
window.onload = () => {
    console.log("window.onload triggered.");
};
</script>

</hashingAndRandomnessUtilities>


<playback>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script manages the playback of the generative song by handling sequences, steps, and audio controls. It ensures that the song progresses through its sequences and steps in a controlled manner, allowing for play, pause, resume, and stop functionalities. Additionally, it handles the incrementing of seeds to regenerate or alter the song upon completion.

            <h3>1. **Playback State Variables**</h3>
            <ul>
                <li><strong>totalSequencesInNewSong:</strong> Tracks the total number of sequences in the new song.</li>
                <li><strong>currentSequenceIndex:</strong> Indicates the index of the currently playing sequence.</li>
                <li><strong>currentStepIndex:</strong> Represents the index of the current step within the active sequence.</li>
                <li><strong>playbackTimeoutId:</strong> Stores the identifier for the playback timeout, allowing for control over the playback loop.</li>
            </ul>

            <h3>2. **Playback Loop Initialization**</h3>
            <ul>
                <li><strong>startPlaybackLoop():</strong>
                    <ul>
                        <li>Checks if `globalJsonData` and its `projectSequences` are defined.</li>
                        <li>Sets the BPM (`bpm`) from the JSON data.</li>
                        <li>Retrieves all sequence keys and determines the total number of sequences.</li>
                        <li>Logs the start of playback and initiates the first sequence using `playSequence()`.</li>
                        <li>Handles scenarios where no sequences are found by logging an error.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Sequence Playback Management**</h3>
            <ul>
                <li><strong>playSequence(sequenceKey):</strong>
                    <ul>
                        <li>Retrieves the specific sequence data using the provided `sequenceKey`.</li>
                        <li>Determines the total number of steps in the current sequence by finding the maximum steps across all channels.</li>
                        <li>Logs the sequence being played and calls `playNextStep()` to begin step playback.</li>
                        <li>Handles cases where the sequence data is missing by logging an error.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Step Playback Control**</h3>
            <ul>
                <li><strong>playNextStep():</strong>
                    <ul>
                        <li>Checks if playback is active (`isPlaying` is `true`).</li>
                        <li>If there are remaining steps in the current sequence:
                            <ul>
                                <li>Logs the current step number.</li>
                                <li>Increments the `currentStepIndex`.</li>
                                <li>Schedules the next step playback using `setTimeout` based on the BPM.</li>
                            </ul>
                        </li>
                        <li>If the sequence is complete:
                            <ul>
                                <li>Logs the completion of the current sequence.</li>
                                <li>Resets the `currentStepIndex` and increments the `currentSequenceIndex`.</li>
                                <li>Logs the progress of sequence playback.</li>
                                <li>Determines if there are more sequences to play:
                                    <ul>
                                        <li>If yes, initiates the next sequence with `playSequence()`.</li>
                                        <li>If no, logs that the end of the song is reached, increments the seed, and reloads the page to generate a new song.</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Playback Initialization**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Checks if the `audioCtx` (Audio Context) is in a suspended state and resumes it if necessary.</li>
                        <li>Logs the state of the Audio Context.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to start playback from the beginning.</li>
                        <li>Sets the `isPlaying` flag to `true` to indicate active playback.</li>
                        <li>Logs the initiation of the playback loop.</li>
                        <li>Starts the playback loop by calling `startPlaybackLoop()`.</li>
                        <li>Checks if `startWorker` is defined and invokes it to handle any additional playback-related tasks.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Playback Control Functions**</h3>
            <ul>
                <li><strong>pausePlayback():</strong>
                    <ul>
                        <li>Logs the pause action.</li>
                        <li>Sets `isPlaying` to `false` to halt the playback loop.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps.</li>
                        <li>Checks if the Audio Context is running and suspends it if so.</li>
                        <li>Updates the play button's appearance and text to reflect the paused state.</li>
                    </ul>
                </li>
                <li><strong>resumePlayback():</strong>
                    <ul>
                        <li>Resumes the Audio Context if it's suspended.</li>
                        <li>Logs the resumption of the Audio Context.</li>
                        <li>Checks if playback is not active and resumes playback by setting `isPlaying` to `true` and calling `playNextStep()`.</li>
                        <li>Updates the play button's appearance and text to reflect the active playback state.</li>
                        <li>Logs if playback is already running to prevent redundant actions.</li>
                    </ul>
                </li>
                <li><strong>stopPlayback():</strong>
                    <ul>
                        <li>Logs the stop action.</li>
                        <li>Sets `isPlaying` to `false` to halt playback.</li>
                        <li>Clears any existing playback timeouts.</li>
                        <li>Iterates through all active audio sources and:
                            <ul>
                                <li>Cancels any scheduled gain value changes.</li>
                                <li>Ramps down the gain to zero over a short duration (`fadeDuration`).</li>
                                <li>Stops the audio source after the fade-out.</li>
                                <li>Disconnects the audio source and gain node to release resources.</li>
                            </ul>
                        </li>
                        <li>Resets the `activeSources` array for all channels.</li>
                        <li>Schedules the suspension of the Audio Context and resets playback state after a brief delay.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to prepare for a fresh start.</li>
                        <li>Logs the completion of the stop action and reset.</li>
                        <li>Updates the play button's appearance and text to reflect the stopped state.</li>
                    </ul>
                </li>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Checks if a playback toggle is not already in progress to prevent overlapping actions.</li>
                        <li>Sets the `isToggleInProgress` flag to `true` to indicate an ongoing toggle action.</li>
                        <li>Attempts to either stop or start playback based on the current state (`isPlaying`).</li>
                        <li>Catches and logs any errors that occur during the toggle process.</li>
                        <li>Resets the `isToggleInProgress` flag after the action is complete.</li>
                    </ul>
                </li>
            </ul>

            <h3>7. **Seed Management and Page Reloading**</h3>
            <ul>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Parses the current seed from `window.seed` and ensures it is a valid integer.</li>
                        <li>Increments the seed by 1 to generate a new seed value.</li>
                        <li>Updates the `window.seed` with the new seed value.</li>
                        <li>Modifies the current URL to include the new seed as a query parameter.</li>
                        <li>Logs the action of reloading the page with the new seed.</li>
                        <li>Reloads the page to apply the new seed, thereby generating a new version of the song.</li>
                    </ul>
                </li>
            </ul>

            <h3>8. **Logging Functionality**</h3>
            <ul>
                <li><strong>log(message):</strong>
                    <ul>
                        <li>Assumed to be a custom logging function that prefixes messages with a specific tag or formatting.</li>
                        <li>Used extensively throughout the playback functions to provide real-time feedback on playback status and actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Overall Role within the Program:**</h3>
            <p>
                This playback script orchestrates the flow of the generative song by managing sequences and steps, controlling the Audio Context, and handling user interactions such as play, pause, resume, and stop. It ensures that audio is played in the correct order and timing based on the BPM and sequence data. Additionally, it handles the regeneration of the song by incrementing the seed and reloading the page upon completion of all sequences. By maintaining and updating global state variables, it ensures consistent behavior across the application's different components.
            </p>

            <h3>**Key Components and Their Interactions:**</h3>
            <ul>
                <li><strong>Global Variables:</strong>
                    <ul>
                        <li><code>globalJsonData:</code> Contains the parsed JSON data defining the song's structure and sequences.</li>
                        <li><code>audioCtx:</code> The Audio Context used for audio processing and playback.</li>
                        <li><code>activeSources:</code> Tracks active audio sources for each channel to manage playback controls.</li>
                        <li><code>isPlaying:</code> A flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress:</code> Prevents simultaneous playback toggle actions.</li>
                        <li><code>fadeDuration:</code> Defines the duration for audio fade-out during stop actions.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>startPlaybackLoop()</code>: Initiates the playback loop by starting the first sequence.</li>
                        <li><code>playSequence(sequenceKey)</code>: Handles the playback of a specific sequence, determining the total steps and initiating step playback.</li>
                        <li><code>playNextStep()</code>: Manages the progression through steps within a sequence, scheduling subsequent steps based on BPM.</li>
                        <li><code>initializePlayback()</code>: Sets up the initial playback state and starts the playback loop.</li>
                        <li><code>pausePlayback()</code>: Pauses the ongoing playback, suspending the Audio Context and updating UI elements.</li>
                        <li><code>resumePlayback()</code>: Resumes playback from a paused state, resuming the Audio Context and continuing step playback.</li>
                        <li><code>stopPlayback()</code>: Completely stops playback, fades out audio, disconnects sources, and resets playback state.</li>
                        <li><code>togglePlayback()</code>: Toggles between play and pause states, ensuring no overlapping actions occur.</li>
                        <li><code>incrementSeedAndReload()</code>: Increments the seed value and reloads the page to generate a new version of the song.</li>
                    </ul>
                </li>
                <li><strong>Logging:</strong>
                    <ul>
                        <li>Provides detailed logs at each critical step to monitor the playback process, aiding in debugging and ensuring transparency in operations.</li>
                        <li>Logs actions such as starting playback, playing sequences and steps, pausing, resuming, stopping, and reloading with new seeds.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Potential Areas for Modularization and Optimization:**</h3>
            <ul>
                <li><strong>Logging Function:</strong>
                    <ul>
                        <li>The current script assumes a <code>log()</code> function exists. It would be beneficial to define a centralized logging utility to standardize log messages across the application.</li>
                    </ul>
                </li>
                <li><strong>Playback Control Functions:</strong>
                    <ul>
                        <li>Functions like <code>pausePlayback()</code>, <code>resumePlayback()</code>, and <code>stopPlayback()</code> share common operations (e.g., updating UI elements). These can be refactored into helper functions to reduce code duplication.</li>
                    </ul>
                </li>
                <li><strong>State Management:</strong>
                    <ul>
                        <li>Consider using a state management library or pattern to handle playback states more efficiently, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Seed Management:</strong>
                    <ul>
                        <li>The <code>incrementSeedAndReload()</code> function handles both seed incrementation and page reloading. These responsibilities can be separated to enhance clarity and flexibility.</li>
                    </ul>
                </li>
                <li><strong>Audio Source Handling:</strong>
                    <ul>
                        <li>The management of <code>activeSources</code> involves iterating over channels and handling gain nodes. Encapsulating this logic within dedicated classes or modules can improve maintainability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement more granular error handling and possibly user notifications for playback errors to enhance user experience.</li>
                    </ul>
                </li>
                <li><strong>Playback Timing:</strong>
                    <ul>
                        <li>Utilize more precise timing mechanisms (e.g., Web Audio's scheduling capabilities) to ensure accurate step playback, reducing reliance on <code>setTimeout</code>.</li>
                    </ul>
                </li>
            </ul>

            <h3>**Error Handling and Edge Cases:**</h3>
            <ul>
                <li>Ensures that playback does not start if `globalJsonData` or `projectSequences` are undefined, logging appropriate errors.</li>
                <li>Handles missing sequence data gracefully by logging errors without disrupting the entire playback process.</li>
                <li>Prevents multiple simultaneous playback toggles with the `isToggleInProgress` flag.</li>
                <li>Manages audio source cleanup to prevent memory leaks or unintended audio playback after stopping.</li>
                <li>Validates and safely increments seed values, ensuring that page reloads do not result in invalid URLs or states.</li>
            </ul>
        </p>
    </details>
    <script>
        // Playback State Variables
        let totalSequencesInNewSong = 0;
        let currentSequenceIndex = 0;
        let currentStepIndex = 0;
        let playbackTimeoutId = null;



        // Initialize Playback Loop
        const startPlaybackLoop = () => {
            if (globalJsonData?.projectSequences) {
                bpm = globalJsonData.projectBPM;
                const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                totalSequencesInNewSong = sequenceKeys.length;

                log(`Starting playback of song with ${totalSequencesInNewSong} sequences.`);
                if (totalSequencesInNewSong > 0) {
                    playSequence(sequenceKeys[currentSequenceIndex]);
                } else {
                    console.error("[songAssemblyLogs] No sequences found in the project data.");
                }
            } else {
                console.error("[songAssemblyLogs] Playback cannot start because globalJsonData or projectSequences are undefined.");
            }
        };

        // Play a Specific Sequence
        const playSequence = (sequenceKey) => {
            const sequence = globalJsonData.projectSequences[sequenceKey];
            if (!sequence) {
                console.error(`[songAssemblyLogs] Sequence data missing for key: ${sequenceKey}`);
                return;
            }

            const channelKeys = Object.keys(sequence);
            totalStepsInCurrentSequence = channelKeys.reduce(
                (maxSteps, channelKey) => Math.max(maxSteps, (sequence[channelKey].steps || []).length),
                0
            );

            log(`Playing sequence: ${sequenceKey}`);
            playNextStep();
        };

        // Play the Next Step in the Sequence
        const playNextStep = () => {
            if (isPlaying) {
                if (currentStepIndex < totalStepsInCurrentSequence) {
                    log(`Current Step: ${currentStepIndex + 1}/${totalStepsInCurrentSequence}`);
                    currentStepIndex++;
                    playbackTimeoutId = setTimeout(playNextStep, (60 / bpm) * 1000);
                } else {
                    log("Finished current sequence. Moving to the next sequence.");
                    currentStepIndex = 0;
                    currentSequenceIndex++;
                    log(`Current Sequence Index: ${currentSequenceIndex} / Total Sequences: ${totalSequencesInNewSong}`);

                    if (currentSequenceIndex < totalSequencesInNewSong) {
                        const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                        playSequence(sequenceKeys[currentSequenceIndex]);
                    } else {
                        log("Reached the end of the last sequence. Incrementing seed and reloading...");
                        incrementSeedAndReload(); // Increment seed and reload
                    }
                }
            }
        };

        // Initialize Playback
        const initializePlayback = async () => {
            if (audioCtx.state === "suspended") {
                await audioCtx.resume();
            }
            log(`AudioContext resumed: ${audioCtx.state}`);
            currentSequenceIndex = 0;
            currentStepIndex = 0;
            isPlaying = true;
            log("Starting playback loop from the beginning.");
            startPlaybackLoop();
            if (typeof startWorker === "function") {
                startWorker();
            }
        };

        // Pause Playback
        const pausePlayback = async () => {
            log("Pausing playback.");
            isPlaying = false;
            if (playbackTimeoutId !== null) {
                clearTimeout(playbackTimeoutId);
                playbackTimeoutId = null;
            }
            if (audioCtx.state === "running") {
                await audioCtx.suspend();
                log(`AudioContext suspended: ${audioCtx.state}`);
            }
            const playButton = document.getElementById("play-button");
            if (playButton) {
                playButton.textContent = "Play";
                playButton.classList.remove("playing");
            }
        };

        // Resume Playback
        const resumePlayback = async () => {
            if (audioCtx.state === "suspended") {
                await audioCtx.resume();
            }
            log(`AudioContext resumed: ${audioCtx.state}`);
            if (!isPlaying) {
                isPlaying = true;
                log("Resuming playback.");
                playNextStep();
                const playButton = document.getElementById("play-button");
                if (playButton) {
                    playButton.textContent = "Stop";
                    playButton.classList.add("playing");
                }
            } else {
                log("Playback is already running.");
            }
        };

        // Stop Playback
        const stopPlayback = async () => {
            log("Stopping playback...");
            isPlaying = false;
            if (playbackTimeoutId !== null) {
                clearTimeout(playbackTimeoutId);
                playbackTimeoutId = null;
            }
            for (const channel in activeSources) {
                activeSources[channel].forEach(({ source, gainNode }) => {
                    const currentTime = audioCtx.currentTime;
                    gainNode.gain.cancelScheduledValues(currentTime);
                    gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
                    gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeDuration);
                    source.stop(currentTime + fadeDuration);
                    source.disconnect();
                    gainNode.disconnect();
                });
                activeSources[channel] = [];
            }
            setTimeout(async () => {
                if (audioCtx.state === "running") {
                    await audioCtx.suspend();
                    log(`AudioContext suspended: ${audioCtx.state}`);
                }
                resetPlaybackState();
            }, 50);
            currentSequenceIndex = 0;
            currentStepIndex = 0;
            log("Playback stopped and reset to initial state.");
            const playButton = document.getElementById("play-button");
            if (playButton) {
                playButton.textContent = "Play";
                playButton.classList.remove("playing");
            }
        };

        // Toggle Playback (Play/Pause)
        const togglePlayback = async () => {
            if (!isToggleInProgress) {
                isToggleInProgress = true;
                try {
                    isPlaying ? await stopPlayback() : await initializePlayback();
                } catch (error) {
                    console.error(`Error during playback toggle: ${error}`);
                } finally {
                    isToggleInProgress = false;
                }
            }
        };

        /**
         * Increments the current seed by 1 and reloads the page with the new seed as a query parameter.
         */
        function incrementSeedAndReload() {
            let currentSeedInt = parseInt(window.seed, 10);
            if (isNaN(currentSeedInt)) {
                currentSeedInt = 0;
            }
            const newSeedInt = currentSeedInt + 1;
            window.seed = newSeedInt.toString();

            const url = new URL(window.location.href);
            url.searchParams.set('seed', window.seed);
            log(`Reloading page with new seed: ${window.seed}`);
            window.location.href = url.toString();
        }
    </script>
</playback>






<bigSection>>
    <details>
        <summary>Detailed notes about this section</summary>
        <p>
            This script is responsible for managing all event listeners related to user interactions and playback controls within the generative audio application. It ensures that user actions, such as clicking the play button, trigger the appropriate responses in the audio playback system. Additionally, it handles various playback states, updates the user interface accordingly, and maintains synchronization between different parts of the application through event dispatching and handling.

            <h3>1. **Utility Functions**</h3>
            <ul>
                <li><strong>log(message):</strong>
                    <ul>
                        <li>A utility function that logs messages to the console with a timestamp. This aids in debugging and tracking the flow of events by providing a clear and chronological record of actions and state changes.</li>
                    </ul>
                </li>
                <li><strong>clampVolume(volume):</strong>
                    <ul>
                        <li>Ensures that the volume level stays within the acceptable range of 0 to 3. This prevents audio distortion by avoiding excessively high or negative volume values.</li>
                    </ul>
                </li>
                <li><strong>calculateReversedTrimTimes(trimTimes):</strong>
                    <ul>
                        <li>Calculates reversed trim times based on the provided start and end trim points. This is useful for handling audio playback in reverse, ensuring that the audio segments are correctly trimmed when played backwards.</li>
                    </ul>
                </li>
                <li><strong>resumeAudioContext():</strong>
                    <ul>
                        <li>Attempts to resume the AudioContext if it has been suspended. This is essential for browsers that require user interaction to start audio playback, ensuring that audio can resume smoothly after being paused or interrupted.</li>
                    </ul>
                </li>
                <li><strong>ensureAudioContextState():</strong>
                    <ul>
                        <li>Checks the current state of the AudioContext and resumes it if it is not already running. This function ensures that the audio system is in the correct state before initiating playback, preventing issues related to inactive audio contexts.</li>
                    </ul>
                </li>
                <li><strong>resetPlaybackState():</strong>
                    <ul>
                        <li>Resets playback-related state variables to their initial values. This is important when stopping playback to ensure a clean state for the next playback session, preventing residual states from affecting future playback.</li>
                    </ul>
                </li>
                <li><strong>normalizeBuffer(buffer, normalizationLevel):</strong>
                    <ul>
                        <li>Normalizes an AudioBuffer so that its peak amplitude does not exceed the specified threshold. This function maintains audio quality by preventing clipping and ensuring consistent volume levels across different audio buffers.</li>
                    </ul>
                </li>
                <li><strong>loadAndNormalizeAudio(url):</strong>
                    <ul>
                        <li>Fetches an audio file from the provided URL, decodes it into an AudioBuffer, and normalizes the audio buffer. It includes specific logging for targeted audio samples to monitor their properties, such as duration, number of channels, sample rate, and amplitude levels.</li>
                        <li>Handles errors gracefully by logging them and throwing exceptions to prevent the application from proceeding with faulty audio data.</li>
                    </ul>
                </li>
                <li><strong>loadMultipleAudio(audioUrls):</strong>
                    <ul>
                        <li>Loads and normalizes multiple audio files concurrently. It stores the resulting AudioBuffers in a global object for later playback, ensuring that all necessary audio data is prepared before playback begins.</li>
                        <li>Uses `Promise.all` to handle multiple asynchronous fetch and decode operations efficiently.</li>
                    </ul>
                </li>
                <li><strong>waitForAudioContext():</strong>
                    <ul>
                        <li>Waits until the AudioContext is in a running state before proceeding. This ensures that all audio operations can execute smoothly without interruptions caused by an inactive audio context.</li>
                        <li>Implements an event listener for state changes to resolve or reject the promise based on the AudioContext's state, enhancing reliability in audio playback initialization.</li>
                    </ul>
                </li>
                <li><strong>playBuffer(buffer, options, trackId, startTime):</strong>
                    <ul>
                        <li>Handles the playback of a specific AudioBuffer with given options such as trim times and volume control. It manages the creation of buffer sources and gain nodes, applies volume ramping for smooth audio transitions, and tracks active audio sources for each channel.</li>
                        <li>Ensures that audio buffers are played with the correct playback rate and volume, and that they are properly connected to the AudioContext's destination.</li>
                        <li>Manages the lifecycle of audio sources by tracking them in `activeSources` and cleaning them up once playback ends, preventing memory leaks and ensuring efficient resource utilization.</li>
                    </ul>
                </li>
            </ul>

            <h3>2. **Playback Control Variables**</h3>
            <ul>
                <li><strong>Playback State Variables:</strong>
                    <ul>
                        <li><em>totalSequencesInNewSong:</em> Keeps track of the total number of sequences in the newly generated song, enabling the playback system to know when it has reached the end of the song.</li>
                        <li><em>currentSequenceIndex:</em> Indicates the index of the currently playing sequence, allowing the system to navigate through sequences sequentially.</li>
                        <li><em>currentStepIndex:</em> Represents the index of the current step within the active sequence, facilitating step-by-step playback control.</li>
                        <li><em>playbackTimeoutId:</em> Stores the identifier for the playback timeout, allowing the system to control the playback loop by scheduling and clearing timeouts as needed.</li>
                    </ul>
                </li>
                <li><strong>Active Sources:</strong>
                    <ul>
                        <li>Manages the active audio sources and their corresponding gain nodes for each channel. This ensures that audio can be controlled (e.g., paused, stopped) effectively and that resources are properly managed during playback.</li>
                    </ul>
                </li>
                <li><strong>isPlaying:</strong>
                    <ul>
                        <li>A flag indicating whether playback is currently active. This flag is used to control the flow of the playback loop, preventing unwanted actions when playback is paused or stopped.</li>
                    </ul>
                </li>
                <li><strong>isToggleInProgress:</strong>
                    <ul>
                        <li>Prevents multiple simultaneous toggles of playback state, ensuring that play/pause actions are processed sequentially and avoiding race conditions.</li>
                    </ul>
                </li>
            </ul>

            <h3>3. **Event Listeners**</h3>
            <ul>
                <li><strong>Play Button Click Listener:</strong>
                    <ul>
                        <li>Attached to the play button element in the user interface. When the play button is clicked, it logs the action, ensures that the AudioContext is in the correct state, toggles playback (either playing or pausing), and dispatches a custom event (`playbackStarted`) to indicate that playback has begun.</li>
                        <li>Includes error handling to log issues if the `ensureAudioContextState` function is not defined or fails during execution, ensuring that playback cannot proceed without a valid AudioContext state.</li>
                    </ul>
                </li>
                <li><strong>Playback Started Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackStarted` custom event. Upon receiving this event, it updates the user interface to display the current seed used for generating the song, manages the display timing (shows the seed for 10 seconds before hiding it), updates playback status flags, and calls functions to update the UI accordingly.</li>
                        <li>Handles scenarios where the seed display element is not found by logging an error, ensuring that UI updates do not fail silently.</li>
                    </ul>
                </li>
                <li><strong>Data Loading Complete Listener:</strong>
                    <ul>
                        <li>Listens for the `dataLoadingComplete` custom event, which is dispatched after the JSON data defining the song's structure has been loaded and processed. When triggered, it initiates the second part of data processing by calling `processSerializedDataPart2()`, ensuring that playback is set up with the newly loaded data.</li>
                        <li>Logs the initiation of local data processing for transparency and debugging purposes.</li>
                    </ul>
                </li>
                <li><strong>Window Load Listener:</strong>
                    <ul>
                        <li>Attaches an event listener to the window's load event. Once the window is fully loaded, it logs the event, attempts to initialize the application by calling `initApp()`, and handles any errors that occur during initialization.</li>
                        <li>This ensures that the application only starts initializing once all resources are fully loaded, preventing issues related to incomplete resource loading.</li>
                    </ul>
                </li>
                <li><strong>Sequence Updated Listener:</strong>
                    <ul>
                        <li>Listens for the `sequenceUpdated` custom event, which carries details about the current sequence and step. This event is likely dispatched during the playback loop to indicate progression through sequences and steps.</li>
                        <li>Tracks the last sequence played to log only when a new sequence starts, thereby reducing console verbosity by avoiding step-by-step logs.</li>
                        <li>Logs the start of a new sequence, aiding in monitoring the progression of playback and ensuring that sequence transitions are functioning correctly.</li>
                    </ul>
                </li>
                <li><strong>Playback Paused Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackPaused` custom event. When triggered, it logs that playback has been paused, allowing for UI updates or other pause-related actions to be handled elsewhere in the application.</li>
                    </ul>
                </li>
                <li><strong>Playback Stopped Listener:</strong>
                    <ul>
                        <li>Listens for the `playbackStopped` custom event. When triggered, it logs that playback has been stopped, facilitating UI resets or other stop-related actions to ensure the application reflects the paused state.</li>
                    </ul>
                </li>
            </ul>

            <h3>4. **Playback Control Functions**</h3>
            <ul>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Handles the play/pause toggle functionality. It checks if a toggle operation is already in progress to prevent race conditions.</li>
                        <li>Depending on the current playback state (`isPlaying`), it either stops or initializes playback by calling `stopPlayback()` or `initializePlayback()` respectively.</li>
                        <li>Ensures that only one toggle operation occurs at a time by using the `isToggleInProgress` flag, enhancing the reliability of playback controls.</li>
                        <li>Includes error handling to log any issues encountered during the toggle process, aiding in debugging and maintaining application stability.</li>
                    </ul>
                </li>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Increments the current seed value by 1 to generate a new seed, which is used to create a new generative song with different parameters.</li>
                        <li>Updates the seed in the URL's query parameters to reflect the new seed value, ensuring that the new seed is used upon page reload.</li>
                        <li>Reloads the page with the updated seed, triggering the generation of a new song based on the new seed.</li>
                        <li>Logs the new seed value and the action of reloading the page for transparency and to aid in tracking seed changes during development and debugging.</li>
                    </ul>
                </li>
            </ul>

            <h3>5. **Utility Functions for Playback Control**</h3>
            <ul>
                <li><strong>clampVolume(volume):</strong>
                    <ul>
                        <li>Ensures that the volume level remains within the range of 0 to 3. This prevents audio distortion by avoiding excessively high or negative volume levels.</li>
                    </ul>
                </li>
                <li><strong>calculateReversedTrimTimes(trimTimes):</strong>
                    <ul>
                        <li>Calculates reversed trim times based on the provided start and end trim points. This is useful for handling audio playback in reverse, ensuring that the audio segments are correctly trimmed when played backwards.</li>
                    </ul>
                </li>
                <li><strong>resumeAudioContext():</strong>
                    <ul>
                        <li>Attempts to resume the AudioContext if it has been suspended. Essential for browsers that require user interaction to start audio playback, ensuring that audio can resume smoothly after being paused or interrupted.</li>
                    </ul>
                </li>
                <li><strong>ensureAudioContextState():</strong>
                    <ul>
                        <li>Checks the current state of the AudioContext and resumes it if it is not already running. This function ensures that the audio system is in the correct state before initiating playback, preventing issues related to inactive audio contexts.</li>
                    </ul>
                </li>
                <li><strong>resetPlaybackState():</strong>
                    <ul>
                        <li>Resets playback-related state variables to their initial values. This is important when stopping playback to ensure a clean state for the next playback session, preventing residual states from affecting future playback.</li>
                    </ul>
                </li>
                <li><strong>normalizeBuffer(buffer, normalizationLevel):</strong>
                    <ul>
                        <li>Normalizes an AudioBuffer so that its peak amplitude does not exceed the specified threshold. This prevents clipping and maintains audio quality by ensuring consistent volume levels across different audio buffers.</li>
                    </ul>
                </li>
                <li><strong>loadAndNormalizeAudio(url):</strong>
                    <ul>
                        <li>Fetches an audio file from the provided URL, decodes it into an AudioBuffer, and normalizes the audio buffer. It includes specific logging for targeted audio samples to monitor their properties, such as duration, number of channels, sample rate, and amplitude levels.</li>
                        <li>Handles errors gracefully by logging them and throwing exceptions to prevent the application from proceeding with faulty audio data.</li>
                    </ul>
                </li>
                <li><strong>loadMultipleAudio(audioUrls):</strong>
                    <ul>
                        <li>Loads and normalizes multiple audio files concurrently. It stores the resulting AudioBuffers in a global object for later playback, ensuring that all necessary audio data is prepared before playback begins.</li>
                        <li>Uses `Promise.all` to handle multiple asynchronous fetch and decode operations efficiently.</li>
                    </ul>
                </li>
                <li><strong>waitForAudioContext():</strong>
                    <ul>
                        <li>Waits until the AudioContext is in a running state before proceeding. This ensures that all audio operations can execute smoothly without interruptions caused by an inactive audio context.</li>
                        <li>Implements an event listener for state changes to resolve or reject the promise based on the AudioContext's state, enhancing reliability in audio playback initialization.</li>
                    </ul>
                </li>
                <li><strong>playBuffer(buffer, options, trackId, startTime):</strong>
                    <ul>
                        <li>Handles the playback of a specific AudioBuffer with given options such as trim times and volume control. It manages the creation of buffer sources and gain nodes, applies volume ramping for smooth audio transitions, and tracks active audio sources for each channel.</li>
                        <li>Ensures that audio buffers are played with the correct playback rate and volume, and that they are properly connected to the AudioContext's destination.</li>
                        <li>Manages the lifecycle of audio sources by tracking them in `activeSources` and cleaning them up once playback ends, preventing memory leaks and ensuring efficient resource utilization.</li>
                    </ul>
                </li>
            </ul>

            <h3>6. **Playback Flow Control**</h3>
            <ul>
                <li><strong>startPlaybackLoop():</strong>
                    <ul>
                        <li>Initiates the playback loop by checking if `globalJsonData` and its `projectSequences` are defined.</li>
                        <li>Sets the BPM (`bpm`) from the JSON data.</li>
                        <li>Retrieves all sequence keys and determines the total number of sequences.</li>
                        <li>Logs the start of playback and initiates the first sequence using `playSequence()`.</li>
                        <li>Handles scenarios where no sequences are found by logging an error, ensuring that playback does not proceed without valid data.</li>
                    </ul>
                </li>
                <li><strong>playSequence(sequenceKey):</strong>
                    <ul>
                        <li>Retrieves the specific sequence data using the provided `sequenceKey`.</li>
                        <li>Determines the total number of steps in the current sequence by finding the maximum steps across all channels, enabling accurate step-by-step playback.</li>
                        <li>Logs the sequence being played and calls `playNextStep()` to begin step playback.</li>
                        <li>Handles cases where the sequence data is missing by logging an error, preventing playback from proceeding with invalid sequence data.</li>
                    </ul>
                </li>
                <li><strong>playNextStep():</strong>
                    <ul>
                        <li>Checks if playback is active (`isPlaying` is `true`).</li>
                        <li>If there are remaining steps in the current sequence:
                            <ul>
                                <li>Logs the current step number.</li>
                                <li>Increments the `currentStepIndex` to move to the next step.</li>
                                <li>Schedules the next step playback using `setTimeout` based on the BPM, ensuring timing consistency.</li>
                            </ul>
                        </li>
                        <li>If the sequence is complete:
                            <ul>
                                <li>Logs the completion of the current sequence.</li>
                                <li>Resets the `currentStepIndex` and increments the `currentSequenceIndex` to move to the next sequence.</li>
                                <li>Logs the progress of sequence playback.</li>
                                <li>Determines if there are more sequences to play:
                                    <ul>
                                        <li>If yes, initiates the next sequence with `playSequence()`.</li>
                                        <li>If no, logs that the end of the song is reached, increments the seed, and reloads the page to generate a new song.</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
            </ul>

            <h3>7. **Playback Control Functions**</h3>
            <ul>
                <li><strong>initializePlayback():</strong>
                    <ul>
                        <li>Ensures that the AudioContext is active by resuming it if it's in a suspended state.</li>
                        <li>Logs the state of the AudioContext for debugging purposes.</li>
                        <li>Resets `currentSequenceIndex` and `currentStepIndex` to start playback from the beginning.</li>
                        <li>Sets the `isPlaying` flag to `true` to indicate active playback.</li>
                        <li>Logs the initiation of the playback loop and starts it by calling `startPlaybackLoop()`.</li>
                        <li>Checks if `startWorker` is defined and invokes it to handle any additional playback-related tasks, such as visualizations or background processing.</li>
                    </ul>
                </li>
                <li><strong>pausePlayback():</strong>
                    <ul>
                        <li>Logs the pause action.</li>
                        <li>Sets `isPlaying` to `false` to halt the playback loop.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps, preventing further step playback until resumed.</li>
                        <li>Checks if the AudioContext is running and suspends it if so, conserving system resources during pause.</li>
                        <li>Updates the play button's appearance and text to reflect the paused state, enhancing user interface feedback.</li>
                    </ul>
                </li>
                <li><strong>resumePlayback():</strong>
                    <ul>
                        <li>Checks if the AudioContext is suspended and resumes it if necessary, ensuring that audio playback can continue.</li>
                        <li>Logs the state of the AudioContext after attempting to resume.</li>
                        <li>If playback is not currently active (`isPlaying` is `false`), it sets `isPlaying` to `true`, logs the resumption, calls `playNextStep()` to continue playback, and updates the play button's appearance and text to indicate active playback.</li>
                        <li>If playback is already running, it logs that no action is needed, preventing redundant operations.</li>
                    </ul>
                </li>
                <li><strong>stopPlayback():</strong>
                    <ul>
                        <li>Logs the stop action and sets `isPlaying` to `false` to halt playback.</li>
                        <li>Clears any existing playback timeouts to stop scheduled steps.</li>
                        <li>Iterates through all active audio sources, applying a fade-out effect to the gain nodes to ensure smooth audio cessation.</li>
                        <li>Stops and disconnects all audio sources and gain nodes, effectively terminating all audio playback and freeing resources.</li>
                        <li>Suspends the AudioContext after a short delay to ensure all audio processes have been properly terminated.</li>
                        <li>Resets playback state variables (`currentSequenceIndex` and `currentStepIndex`) to their initial values, preparing the system for a new playback session.</li>
                        <li>Logs the completion of the stop process and updates the play button's appearance and text to reflect the stopped state.</li>
                    </ul>
                </li>
                <li><strong>togglePlayback():</strong>
                    <ul>
                        <li>Handles the play/pause toggle functionality. It checks if a toggle operation is already in progress to prevent race conditions.</li>
                        <li>Depending on the current playback state (`isPlaying`), it either stops or initializes playback by calling `stopPlayback()` or `initializePlayback()` respectively.</li>
                        <li>Ensures that only one toggle operation occurs at a time by using the `isToggleInProgress` flag, enhancing the reliability of playback controls.</li>
                        <li>Includes error handling to log any issues encountered during the toggle process, aiding in debugging and maintaining application stability.</li>
                    </ul>
                </li>
                <li><strong>incrementSeedAndReload():</strong>
                    <ul>
                        <li>Increments the current seed value by 1 to generate a new seed, which is used to create a new generative song with different parameters.</li>
                        <li>Updates the seed in the URL's query parameters to reflect the new seed value, ensuring that the new seed is used upon page reload.</li>
                        <li>Reloads the page with the updated seed, triggering the generation of a new song based on the new seed.</li>
                        <li>Logs the new seed value and the action of reloading the page for transparency and to aid in tracking seed changes during development and debugging.</li>
                    </ul>
                </li>
            </ul>

            <h3>8. **Playback Flow Control**</h3>
            <ul>
                <li><strong>playSequenceStep(time):</strong>
                    <ul>
                        <li>Manages the playback of each step within the current sequence. It checks if the system is ready to play and if there are any preprocessed sequences available.</li>
                        <li>Ensures that the `currentSequence` index wraps around based on the total number of sequences, maintaining continuous playback.</li>
                        <li>Retrieves the current sequence data and initiates playback of its steps by calling `playSteps()`.</li>
                        <li>Handles step incrementation and sequence transitions by calling `incrementStepAndSequence()` after each step.</li>
                    </ul>
                </li>
                <li><strong>playSteps(steps, time, isReverse):</strong>
                    <ul>
                        <li>Iterates through the provided steps for each channel, identifying and playing the steps that match the `currentStep` index.</li>
                        <li>Determines whether the steps should be played in reverse based on the `isReverse` flag.</li>
                        <li>Calls `playChannelStep()` for each matching step, passing along the necessary parameters for playback.</li>
                        <li>Returns a boolean indicating whether any steps were played, allowing for conditional logic in the playback flow.</li>
                    </ul>
                </li>
                <li><strong>playChannelStep(channel, stepData, time, isReverse):</strong>
                    <ul>
                        <li>Handles the playback of a specific step for a given channel. It retrieves the appropriate audio buffer and trim times from the global metadata.</li>
                        <li>Determines whether to use the reversed audio buffer based on the `isReverse` flag and calculates the adjusted trim times accordingly.</li>
                        <li>Calls `playBuffer()` to play the audio segment, passing along the buffer, trim times, channel identifier, and scheduled start time.</li>
                        <li>Notifies the visualizer (likely a UI component) of the current step, enabling real-time visual feedback during playback.</li>
                    </ul>
                </li>
                <li><strong>scheduleNotes():</strong>
                    <ul>
                        <li>Continuously schedules playback steps by calculating the next note time based on the current BPM.</li>
                        <li>Ensures that steps are played within a short window (0.1 seconds ahead of the current time) to maintain timing accuracy.</li>
                        <li>Calls `playSequenceStep()` to handle the playback of each scheduled step, maintaining the rhythm and progression of the song.</li>
                    </ul>
                </li>
                <li><strong>incrementStepAndSequence(totalSequences):</strong>
                    <ul>
                        <li>Increments the `currentStep` index, looping back to 0 after reaching 64 to maintain a consistent step cycle.</li>
                        <li>Increments the `currentSequence` index when a full cycle of steps is completed, looping back based on the total number of sequences to ensure continuous playback.</li>
                        <li>Dispatches a `sequenceUpdated` custom event with details about the current sequence and step, enabling other parts of the application (e.g., UI components) to respond to sequence changes.</li>
                    </ul>
                </li>
                <li><strong>logChannelAddition():</strong>
                    <ul>
                        <li>Retrieves and processes channel addition logs from `globalJsonData`, specifically looking for entries that match the current sequence number.</li>
                        <li>Handles the logging of channel additions without cluttering the console with excessive information, maintaining a clean and informative logging environment.</li>
                    </ul>
                </li>
            </ul>

            <h3>9. **Overall Role within the Program**</h3>
            <p>
                The Playback script is essential for managing the flow and control of audio playback within the generative audio application. It handles the sequencing of audio steps, manages playback states (play, pause, stop), and ensures that audio is played in sync with the defined BPM and sequence structure. By handling user interactions through event listeners and maintaining playback state variables, the script ensures a responsive and dynamic audio experience. Additionally, it manages the progression through sequences and steps, handles the incrementing of seeds to generate new songs, and integrates with other parts of the application through custom events and global metadata. This centralizes playback logic, making the system modular and maintainable, while also providing hooks for UI updates and other interactive features.
            </p>

            <h3>10. **Potential Areas for Modularization and Optimization**</h3>
            <ul>
                <li><strong>Separation of Concerns:</strong>
                    <ul>
                        <li>Consider moving utility functions like `log`, `clampVolume`, and `normalizeBuffer` to a separate utility module. This promotes reusability and keeps the playback script focused solely on playback logic.</li>
                    </ul>
                </li>
                <li><strong>Playback State Management:</strong>
                    <ul>
                        <li>Encapsulate playback state variables and related functions within a dedicated playback controller object or class. This enhances maintainability and allows for easier state management, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Event Handling:</strong>
                    <ul>
                        <li>Abstract event listener setups into separate functions or modules. For instance, creating a function to attach playback control listeners can reduce redundancy and improve readability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement a centralized error handling mechanism to uniformly manage and log errors across different functions. This enhances debugging and ensures consistent error management.</li>
                    </ul>
                </li>
                <li><strong>Logging Enhancements:</strong>
                    <ul>
                        <li>Integrate a more sophisticated logging system that can toggle verbosity levels or categorize logs. This makes it easier to trace issues during development and production without overwhelming the console with unnecessary information.</li>
                    </ul>
                </li>
                <li><strong>Performance Optimization:</strong>
                    <ul>
                        <li>Review the use of global variables and consider minimizing their usage by encapsulating related data and functions within modules or classes. This reduces the risk of variable collisions and improves code clarity.</li>
                        <li>Optimize the playback loop to handle a larger number of sequences and steps without performance degradation, possibly by implementing more efficient scheduling mechanisms.</li>
                    </ul>
                </li>
                <li><strong>Asynchronous Operations:</strong>
                    <ul>
                        <li>Ensure that all asynchronous operations, especially those involving AudioContext and playback controls, are handled efficiently to prevent blocking the main thread and ensure smooth user interactions.</li>
                    </ul>
                </li>
            </ul>

            <h3>11. **Dependencies and Interactions**</h3>
            <ul>
                <li><strong>Global Objects:</strong>
                    <ul>
                        <li><code>window.globalJsonData</code>: Stores the JSON data defining the song's structure and sequences.</li>
                        <li><code>window.globalMetadata</code>: Holds global metadata such as volume levels, playback speeds, and trim times for each channel.</li>
                        <li><code>audioCtx</code>: The AudioContext instance used for managing and playing audio.</li>
                        <li><code>activeSources</code>: Tracks active audio sources and their gain nodes for each channel, enabling effective control over ongoing audio playback.</li>
                        <li><code>preprocessedSequences</code>: Contains sequences that have been processed and are ready for playback, including their normal and reverse steps.</li>
                        <li><code>globalReversedAudioBuffers</code>: Stores reversed audio buffers for channels that require reverse playback.</li>
                        <li><code>isPlaying</code>: A boolean flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress</code>: A boolean flag preventing multiple simultaneous playback toggle operations.</li>
                        <li><code>fadeDuration</code>: Specifies the duration over which volume fades occur, ensuring smooth transitions during playback control actions.</li>
                        <li><code>globalVolumeMultiplier</code>: A global multiplier applied to all channel volumes, allowing for overall volume control.</li>
                        <li><code>nextNoteTime</code>: Tracks the scheduled time for the next playback step, ensuring precise timing based on BPM.</li>
                        <li><code>audioBuffers</code>: Stores loaded and normalized audio buffers for playback.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>togglePlayback()</code>: Toggles the playback state between play and pause, managing the initiation and cessation of the playback loop.</li>
                        <li><code>initializePlayback()</code>: Initializes the playback process, ensuring the AudioContext is active and starting the playback loop.</li>
                        <li><code>stopPlayback()</code>: Stops the playback, clears active sources, and resets playback state variables.</li>
                        <li><code>playNextStep()</code>: Advances to the next step in the sequence, scheduling the next step based on BPM.</li>
                        <li><code>playSequence()</code>: Initiates playback of a specific sequence.</li>
                        <li><code>startPlaybackLoop()</code>: Begins the playback loop by starting the first sequence.</li>
                        <li><code>incrementSeedAndReload()</code>: Generates a new seed to create a new song and reloads the page with the updated seed.</li>
                        <li><code>playSequenceStep(time)</code>: Manages the playback of each step within the current sequence.</li>
                        <li><code>playSteps(steps, time, isReverse)</code>: Iterates through the provided steps for each channel, identifying and playing the steps that match the current step index.</li>
                        <li><code>playChannelStep(channel, stepData, time, isReverse)</code>: Handles the playback of a specific step for a given channel, including buffer selection and trim time adjustments.</li>
                        <li><code>scheduleNotes()</code>: Continuously schedules playback steps based on BPM to maintain timing accuracy.</li>
                        <li><code>incrementStepAndSequence(totalSequences)</code>: Increments the step and sequence indices, managing the transition between steps and sequences.</li>
                        <li><code>logChannelAddition()</code>: Retrieves and processes channel addition logs from `globalJsonData`, handling logging for channel additions without excessive verbosity.</li>
                    </ul>
                </li>
                <li><strong>Custom Events:</strong>
                    <ul>
                        <li><code>playbackStarted</code>: Dispatched when playback begins, triggering UI updates and other related actions.</li>
                        <li><code>dataLoadingComplete</code>: Dispatched after JSON data is loaded and processed, initiating the next phase of data handling.</li>
                        <li><code>sequenceUpdated</code>: Dispatched when a new sequence starts, allowing for sequence-specific logging or UI updates.</li>
                        <li><code>playbackPaused</code>: Dispatched when playback is paused, enabling UI changes or other pause-related actions.</li>
                        <li><code>playbackStopped</code>: Dispatched when playback is stopped, facilitating UI resets or other stop-related actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>12. **Overall Role within the Program**</h3>
            <p>
                The Playback script is central to managing the flow and control of audio playback within the generative audio application. It orchestrates the sequencing of audio steps, handles user interactions through event listeners, and maintains playback state variables to ensure smooth and consistent audio playback. By integrating with global metadata and responding to custom events, it ensures that playback is synchronized with the application's state and user interface. The script also facilitates the generation of new songs through seed incrementation and page reloading, allowing for dynamic and varied audio experiences. Its comprehensive management of playback states, timing, and audio resources ensures that the application delivers a seamless and responsive user experience.
            </p>

            <h3>13. **Potential Areas for Modularization and Optimization**</h3>
            <ul>
                <li><strong>Separation of Concerns:</strong>
                    <ul>
                        <li>Utility functions like `log`, `clampVolume`, and `normalizeBuffer` could be moved to a separate utility module to promote reusability and cleaner code organization.</li>
                    </ul>
                </li>
                <li><strong>Playback State Management:</strong>
                    <ul>
                        <li>Encapsulate playback state variables and related functions within a dedicated playback controller object or class. This enhances maintainability and allows for easier state management, especially as the application scales.</li>
                    </ul>
                </li>
                <li><strong>Event Handling:</strong>
                    <ul>
                        <li>Abstract event listener setups into separate functions or modules. For instance, creating a function to attach playback control listeners can reduce redundancy and improve readability.</li>
                    </ul>
                </li>
                <li><strong>Error Handling:</strong>
                    <ul>
                        <li>Implement a centralized error handling mechanism to uniformly manage and log errors across different functions. This enhances debugging and ensures consistent error management.</li>
                    </ul>
                </li>
                <li><strong>Logging Enhancements:</strong>
                    <ul>
                        <li>Integrate a more sophisticated logging system that can toggle verbosity levels or categorize logs. This makes it easier to trace issues during development and production without overwhelming the console with unnecessary information.</li>
                    </ul>
                </li>
                <li><strong>Performance Optimization:</strong>
                    <ul>
                        <li>Review the use of global variables and consider minimizing their usage by encapsulating related data and functions within modules or classes. This reduces the risk of variable collisions and improves code clarity.</li>
                        <li>Optimize the playback loop to handle a larger number of sequences and steps without performance degradation, possibly by implementing more efficient scheduling mechanisms.</li>
                    </ul>
                </li>
                <li><strong>Asynchronous Operations:</strong>
                    <ul>
                        <li>Ensure that all asynchronous operations, especially those involving AudioContext and playback controls, are handled efficiently to prevent blocking the main thread and ensure smooth user interactions.</li>
                    </ul>
                </li>
            </ul>

            <h3>14. **Dependencies and Interactions**</h3>
            <ul>
                <li><strong>Global Objects:</strong>
                    <ul>
                        <li><code>window.globalJsonData</code>: Stores the JSON data defining the song's structure and sequences.</li>
                        <li><code>window.globalMetadata</code>: Holds global metadata such as volume levels, playback speeds, and trim times for each channel.</li>
                        <li><code>audioCtx</code>: The AudioContext instance used for managing and playing audio.</li>
                        <li><code>activeSources</code>: Tracks active audio sources and their gain nodes for each channel, enabling effective control over ongoing audio playback.</li>
                        <li><code>preprocessedSequences</code>: Contains sequences that have been processed and are ready for playback, including their normal and reverse steps.</li>
                        <li><code>globalReversedAudioBuffers</code>: Stores reversed audio buffers for channels that require reverse playback.</li>
                        <li><code>isPlaying</code>: A boolean flag indicating whether playback is currently active.</li>
                        <li><code>isToggleInProgress</code>: A boolean flag preventing multiple simultaneous playback toggle operations.</li>
                        <li><code>fadeDuration</code>: Specifies the duration over which volume fades occur, ensuring smooth transitions during playback control actions.</li>
                        <li><code>globalVolumeMultiplier</code>: A global multiplier applied to all channel volumes, allowing for overall volume control.</li>
                        <li><code>nextNoteTime</code>: Tracks the scheduled time for the next playback step, ensuring precise timing based on BPM.</li>
                        <li><code>audioBuffers</code>: Stores loaded and normalized audio buffers for playback.</li>
                        <li><code>defaultVolume</code>: Specifies a default volume level to be used if no specific volume setting is provided for a channel.</li>
                        <li><code>fadeDuration</code>: Defines the duration for fade-in and fade-out effects during playback transitions.</li>
                    </ul>
                </li>
                <li><strong>Functions:</strong>
                    <ul>
                        <li><code>togglePlayback()</code>: Toggles the playback state between play and pause, managing the initiation and cessation of the playback loop.</li>
                        <li><code>initializePlayback()</code>: Initializes the playback process, ensuring the AudioContext is active and starting the playback loop.</li>
                        <li><code>stopPlayback()</code>: Stops the playback, clears active sources, and resets playback state variables.</li>
                        <li><code>playNextStep()</code>: Advances to the next step in the sequence, scheduling the next step based on BPM.</li>
                        <li><code>playSequence()</code>: Initiates playback of a specific sequence.</li>
                        <li><code>startPlaybackLoop()</code>: Begins the playback loop by starting the first sequence.</li>
                        <li><code>incrementSeedAndReload()</code>: Generates a new seed to create a new song and reloads the page with the updated seed.</li>
                        <li><code>playSequenceStep(time)</code>: Manages the playback of each step within the current sequence.</li>
                        <li><code>playSteps(steps, time, isReverse)</code>: Iterates through the provided steps for each channel, identifying and playing the steps that match the current step index.</li>
                        <li><code>playChannelStep(channel, stepData, time, isReverse)</code>: Handles the playback of a specific step for a given channel, including buffer selection and trim time adjustments.</li>
                        <li><code>scheduleNotes()</code>: Continuously schedules playback steps based on BPM to maintain timing accuracy.</li>
                        <li><code>incrementStepAndSequence(totalSequences)</code>: Increments the step and sequence indices, managing the transition between steps and sequences.</li>
                        <li><code>logChannelAddition()</code>: Retrieves and processes channel addition logs from `globalJsonData`, handling logging for channel additions without excessive verbosity.</li>
                    </ul>
                </li>
                <li><strong>Custom Events:</strong>
                    <ul>
                        <li><code>playbackStarted</code>: Dispatched when playback begins, triggering UI updates and other related actions.</li>
                        <li><code>dataLoadingComplete</code>: Dispatched after JSON data is loaded and processed, initiating the next phase of data handling.</li>
                        <li><code>sequenceUpdated</code>: Dispatched when a new sequence starts, allowing for sequence-specific logging or UI updates.</li>
                        <li><code>playbackPaused</code>: Dispatched when playback is paused, enabling UI changes or other pause-related actions.</li>
                        <li><code>playbackStopped</code>: Dispatched when playback is stopped, facilitating UI resets or other stop-related actions.</li>
                    </ul>
                </li>
            </ul>

            <h3>14. **Overall Role within the Program**</h3>
            <p>
                The EventListeners script is pivotal in managing user interactions and controlling the playback flow within the generative audio application. It listens for user actions, such as clicking the play button, and orchestrates the playback process by interacting with other parts of the system, including audio buffer management and playback state variables. By handling custom events, it ensures that different components of the application remain synchronized, providing a seamless and responsive user experience. The script also includes utility functions that support audio processing tasks, such as normalizing audio buffers and managing the AudioContext state, further enhancing the robustness and flexibility of the playback system.
            </p>
        </p>
    </details>

    <script>
        // Utility log function with timestamp
        const log = message => console.log(`[${new Date().toISOString()}] ${message}`);

        // Play button click listener
        document.getElementById("play-button").addEventListener("click", async () => {
            log("[eventListeners] Play button clicked.");
            if (typeof window.ensureAudioContextState === "function") {
                try {
                    log("[eventListeners] Ensuring AudioContext state.");
                    await window.ensureAudioContextState();
                    await togglePlayback();
                    document.dispatchEvent(new CustomEvent("playbackStarted"));
                    log("[eventListeners] Dispatched playbackStarted event.");
                } catch (error) {
                    console.error("[eventListeners] Error during playback toggle:", error);
                }
            } else {
                console.error("[eventListeners] ensureAudioContextState is not defined or not a function");
            }
        });

        // Playback started listener
        document.addEventListener("playbackStarted", () => {
            log("Playback started. Displaying seed.");
          
            const seedDisplay = document.getElementById("seed-display");
            if (seedDisplay) {
                log("[eventListeners] Updating seed display with seed:", window.seed);
                seedDisplay.textContent = `Seed: ${window.seed}`;
                seedDisplay.style.opacity = "1";
                setTimeout(() => {
                    seedDisplay.style.opacity = "0";
                    log("[eventListeners] Seed display hidden.");
                }, 10000);
            } else {
                console.error("[eventListeners] Seed display element not found.");
            }

            window.psTime = Date.now();
            setPlaybackStatus(true);
            log("[eventListeners] Playback status set to true.");
            if (typeof displayPlayText === "function") {
                displayPlayText();
                log("[eventListeners] Called displayPlayText function.");
            }
        });

        // Data loading complete listener
        document.addEventListener("dataLoadingComplete", () => {
            log("[eventListeners] Received dataLoadingComplete event. Starting local data processing.");
            processSerializedDataPart2();
        });

        // Window load listener
        window.addEventListener("load", async () => {
            log("Window load event triggered. Starting app initialization.");
            try {
                await initApp();
                log("initApp function execution complete.");
            } catch (error) {
                console.error("[eventListeners] Error during app initialization:", error);
            }
        });

        // Sequence updated listener - refined to log only when a new sequence starts
        let lastSequence = null;
        document.addEventListener("sequenceUpdated", ({ detail: { currentSequence, currentStep } }) => {
            if (currentSequence !== lastSequence) {
                log(`[songAssemblyLogs] Sequence ${currentSequence} started.`);
                lastSequence = currentSequence;
            }
            // Removed logging for every step to reduce verbosity
        });

        // Playback paused listener
        document.addEventListener("playbackPaused", () => {
            log("[eventListeners] Playback paused.");
        });

        // Playback stopped listener
        document.addEventListener("playbackStopped", () => {
            log("[eventListeners] Playback stopped.");
        });

    // Clamp volume between 0 and 3
    function clampVolume(volume) {
        return Math.max(0, Math.min(volume, 3));
    }

    
    // Calculate reversed trim times based on start and end trim points
    function calculateReversedTrimTimes(trimTimes) {
        return {
            startTrim: 1 - trimTimes.endTrim,
            endTrim: 1 - trimTimes.startTrim
        };
    }
    
    // Resume the AudioContext if it has been suspended
    async function resumeAudioContext() {
        try {
            await audioCtx.resume();
        } catch (error) {
            console.error("Error resuming AudioContext:", error);
        }
    }
    
    // Ensure that the AudioContext is in a running state before playback
    async function ensureAudioContextState() {
        if (audioCtx.state !== "running") {
            await resumeAudioContext();
        }
    }
    
    // Reset playback state variables to their initial values
    function resetPlaybackState() {
        currentSequence = 0;
        currentStep = 0;
        isReversePlay = false;
        nextNoteTime = 0;
    }
    
    // Normalize an audio buffer so that its peak amplitude does not exceed the given threshold
    function normalizeBuffer(buffer, normalizationLevel = 0.9) {
        console.log("Normalizing buffer...");
        if (!(buffer instanceof AudioBuffer)) return buffer;
        
        const numberOfChannels = buffer.numberOfChannels;
        let maxAmplitude = 0;
        
        // Find the maximum absolute amplitude across all channels
        for (let channel = 0; channel < numberOfChannels; channel++) {
            const channelData = buffer.getChannelData(channel);
            for (let i = 0; i < channelData.length; i++) {
                const amplitude = Math.abs(channelData[i]);
                if (amplitude > maxAmplitude) {
                    maxAmplitude = amplitude;
                }
            }
        }
        
        // Calculate normalization ratio
        const normalizationFactor = normalizationLevel / maxAmplitude;
        
        // Apply normalization if needed
        if (normalizationFactor < 1) {
            for (let channel = 0; channel < numberOfChannels; channel++) {
                const channelData = buffer.getChannelData(channel);
                for (let i = 0; i < channelData.length; i++) {
                    channelData[i] *= normalizationFactor;
                }
            }
        }
        
        return buffer;
    }
    
    // Load and normalize an audio file from a URL
    async function loadAndNormalizeAudio(url) {
        console.log(`[loadAndNormalizeAudio] Loading and normalizing audio from URL: ${url}`);
        try {
            const response = await fetch(url);
            if (!response.ok) {
                throw new Error(`Network response was not ok for ${url}: ${response.statusText}`);
            }
            const arrayBuffer = await response.arrayBuffer();
            const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
            
            /**
             * Specific Audio Sample ID to Monitor
             */
            const targetSampleId = "3364803cb3032ce95f4138a214c15a9b36dcb70f574a477f27615d448e1cdeb8i0";
            
            /**
             * Check if the current URL corresponds to the target sample ID
             * This assumes that the sample ID is part of the URL.
             * Adjust the condition below if the mapping between URL and sample ID is different.
             */
            if (url.includes(targetSampleId)) {
                console.log(`\n=== Specific Audio Sample Loaded ===`);
                console.log(`Sample ID: ${targetSampleId}`);
                console.log(`URL: ${url}`);
                console.log(`Duration: ${audioBuffer.duration.toFixed(2)} seconds`);
                console.log(`Number of Channels: ${audioBuffer.numberOfChannels}`);
                console.log(`Sample Rate: ${audioBuffer.sampleRate} Hz`);
                console.log(`Total Length (samples per channel): ${audioBuffer.length}`);
                console.log(`===================================\n`);
                
                /**
                 * Additional Useful Information:
                 * - Peak Amplitude
                 * - Average Amplitude
                 * - Any metadata if available
                 */
                
                // Calculate Peak Amplitude
                let peakAmplitude = 0;
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        const amplitude = Math.abs(channelData[i]);
                        if (amplitude > peakAmplitude) {
                            peakAmplitude = amplitude;
                        }
                    }
                }
                console.log(`Peak Amplitude: ${peakAmplitude.toFixed(4)}`);
                
                // Calculate Average Amplitude
                let sumAmplitude = 0;
                let totalSamples = 0;
                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const channelData = audioBuffer.getChannelData(channel);
                    for (let i = 0; i < channelData.length; i++) {
                        sumAmplitude += Math.abs(channelData[i]);
                        totalSamples++;
                    }
                }
                const averageAmplitude = sumAmplitude / totalSamples;
                console.log(`Average Amplitude: ${averageAmplitude.toFixed(4)}\n`);
            }
            
            return normalizeBuffer(audioBuffer);
        } catch (error) {
            console.error("Error loading and normalizing audio:", error);
            throw error;
        }
    }
    
    // Load multiple audio files and normalize them
    async function loadMultipleAudio(audioUrls) {
        const promises = audioUrls.map(async (url, index) => {
            try {
                const buffer = await loadAndNormalizeAudio(url);
                audioBuffers[index] = buffer;
            } catch (error) {
                console.error("Error loading multiple audio files:", error);
                throw error;
            }
        });
        await Promise.all(promises);
    }
    
    // Wait until the AudioContext is in a running state
    async function waitForAudioContext() {
        if (audioCtx.state !== "running") {
            return new Promise((resolve, reject) => {
                const checkState = () => {
                    if (audioCtx.state === "running") {
                        audioCtx.removeEventListener("statechange", checkState);
                        resolve();
                    } else if (audioCtx.state === "closed") {
                        audioCtx.removeEventListener("statechange", checkState);
                        reject(new Error("AudioContext was closed."));
                    }
                };
                audioCtx.addEventListener("statechange", checkState);
            });
        }
    }
    
    // Play a section of an AudioBuffer with trimming and volume control
    function playBuffer(buffer, { startTrim, endTrim }, trackId, startTime) {
        if (!(buffer instanceof AudioBuffer)) return;
        
        const startTrimClamped = Math.max(0, Math.min(startTrim, 1));
        const endTrimClamped = Math.max(startTrimClamped, Math.min(endTrim, 1));
        const normalizedBuffer = normalizeBuffer(buffer);
        
        // Create a buffer source and gain node for playback
        const source = audioCtx.createBufferSource();
        source.buffer = normalizedBuffer;
        source.playbackRate.value = globalPlaybackSpeeds[trackId] || 1;
        
        const gainNode = audioCtx.createGain();
        const volumeLevel = parseVolumeLevel(globalVolumeLevels[trackId] || defaultVolume) * globalVolumeMultiplier;
        const currentTime = audioCtx.currentTime;
        
        // Set the gain (volume) with a fade-in effect
        gainNode.gain.cancelScheduledValues(currentTime);
        gainNode.gain.setValueAtTime(0, currentTime);
        gainNode.gain.linearRampToValueAtTime(volumeLevel, currentTime + fadeDuration);
        
        source.connect(gainNode);
        gainNode.connect(audioCtx.destination);
        
        const startTimeOffset = startTrimClamped * normalizedBuffer.duration;
        const playbackDuration = (endTrimClamped - startTrimClamped) * normalizedBuffer.duration;
        
        source.start(startTime, startTimeOffset, playbackDuration);
        
        // Track active sources
        if (!activeSources[trackId]) {
            activeSources[trackId] = [];
        }
        activeSources[trackId].push({ source, gainNode });
        
        source.onended = () => {
            activeSources[trackId] = activeSources[trackId].filter(({ source: s }) => s !== source);
        };
    }
    
    // Load multiple audio files and normalize them
    const audioBuffers = {};
    async function loadMultipleAudio(audioUrls) {
        const promises = audioUrls.map(async (url, index) => {
            try {
                const buffer = await loadAndNormalizeAudio(url);
                audioBuffers[index] = buffer;
            } catch (error) {
                console.error("Error loading multiple audio files:", error);
                throw error;
            }
        });
        await Promise.all(promises);
    }
    
    // Example of waiting for AudioContext and playing audio
    (async () => {
        try {
            await waitForAudioContext();
            const buffer = await loadAndNormalizeAudio(audioUrl);
            playBuffer(buffer, { startTrim: 0, endTrim: 1 }, 0, audioCtx.currentTime);
        } catch (error) {
            console.error("Error during audio playback:", error);
        }
    })();

    const dispatchSequenceEvent = (eventName, detail) => {
    document.dispatchEvent(new CustomEvent(eventName, { detail }));
};

const playSequenceStep = (time) => {
    if (!isReadyToPlay || !Object.keys(preprocessedSequences).length) return;

    const sequenceKeys = Object.keys(preprocessedSequences);
    currentSequence %= sequenceKeys.length;
    const currentSequenceData = preprocessedSequences[sequenceKeys[currentSequence]];

    if (currentStep === 0) {
        logChannelAddition();
    }

    if (currentSequenceData) {
        playSteps(currentSequenceData.normalSteps, time) || playSteps(currentSequenceData.reverseSteps, time, true);
    }

    incrementStepAndSequence(sequenceKeys.length);
};

const playSteps = (steps, time, isReverse = false) => {
    if (!steps || typeof steps !== "object") return false;

    Object.entries(steps).forEach(([channel, channelSteps]) => {
        if (Array.isArray(channelSteps)) {
            const stepData = channelSteps.find(step => step.step === currentStep);
            if (stepData) playChannelStep(channel, stepData, time, isReverse);
        }
    });

    return true;
};

const playChannelStep = (channel, stepData, time, isReverse) => {
    const audioBuffer = globalAudioBuffers.find(buffer => buffer.channel === channel);
    const trimTime = globalTrimTimes[channel];

    if (audioBuffer?.buffer && trimTime) {
        const bufferToPlay = isReverse ? globalReversedAudioBuffers[channel] : audioBuffer.buffer;
        const adjustedTrimTime = isReverse ? calculateReversedTrimTimes(trimTime) : trimTime;
        playBuffer(bufferToPlay, adjustedTrimTime, channel, time);
        notifyVisualizer(parseInt(channel.slice(8)) - 1, stepData.step);
    }
};

const scheduleNotes = () => {
    const currentTime = audioCtx.currentTime;

    for (nextNoteTime = Math.max(nextNoteTime, currentTime); nextNoteTime < currentTime + 0.1;) {
        playSequenceStep(nextNoteTime);
        nextNoteTime += getStepDuration();
    }
};

const incrementStepAndSequence = (totalSequences) => {
    currentStep = (currentStep + 1) % 64;
    if (currentStep === 0) {
        currentSequence = (currentSequence + 1) % totalSequences;
    }

    const eventName = "sequenceUpdated";
    const detail = { currentSequence, currentStep };
    document.dispatchEvent(new CustomEvent(eventName, { detail }));
};

const logChannelAddition = () => {
    const channelAddition = globalJsonData?.channelAdditionLog?.find(log => log.sequenceNumber === currentSequence);
    if (channelAddition) {
        const { channelsAdded, totalChannels } = channelAddition;
        // Removed logging for channel addition
    }
};
</script>
</bigSection>>

<script>
const LOOKAHEAD=.1,SCHEDULE_INTERVAL=50;let audioWorker,lastBPM,workerUrl;const debounce=(e,o)=>{let r;return(...t)=>{clearTimeout(r),r=setTimeout((()=>e(...t)),o)}},workerBlob="\n        self.onmessage = e => {\n            const { action, stepDuration, lookahead, scheduleInterval } = e.data;\n            let timerID, workloadTimerID, scheduleNotesCount = 0;\n\n            const startScheduling = (sd, la, si) => {\n                clearInterval(timerID);\n                clearInterval(workloadTimerID);\n                timerID = setInterval(() => {\n                    self.postMessage({ action: 'scheduleNotes' });\n                    scheduleNotesCount++;\n                }, si);\n                workloadTimerID = setInterval(() => {\n                    self.postMessage({ action: 'audioWorkerWorkloadDebug', scheduleNotesCount });\n                    scheduleNotesCount = 0;\n                }, 1000);\n            };\n\n            if (action === 'start') startScheduling(stepDuration, lookahead, scheduleInterval);\n            else if (action === 'stop') { clearInterval(timerID); clearInterval(workloadTimerID); }\n            else if (action === 'updateStepDuration') stepDuration = e.data.stepDuration;\n            else console.warn(\"[Worker] Unknown action:\", action);\n        };\n    ",initializeWorker=()=>{window.Worker?audioWorker?console.warn("[AudioWorker] Worker already initialized."):(workerUrl=URL.createObjectURL(new Blob([workerBlob],{type:"application/javascript"})),audioWorker=new Worker(workerUrl),audioWorker.onmessage=handleWorkerMessage,window.addEventListener("bpmChanged",debounce(updateWorkerStepDuration,100)),console.log("[AudioWorker] Worker initialized.")):console.error("[AudioWorker] Web Workers not supported.")},handleWorkerMessage=({data:{action:e,message:o,scheduleNotesCount:r}})=>{"scheduleNotes"===e?scheduleNotes?.():"audioWorkerWorkloadDebug"===e||("error"===e?console.error("[AudioWorker] Worker Error:",o):console.warn("[AudioWorker] Unknown action from worker:",e))},startWorker=()=>{audioWorker?audioWorker.postMessage({action:"start",stepDuration:getStepDuration(),lookahead:.1,scheduleInterval:50}):console.error("[AudioWorker] Initialize worker first.")},stopWorker=()=>{audioWorker&&audioWorker.postMessage({action:"stop"})},getStepDuration=()=>{const e=window.globalJsonData?.projectBPM||120;return e!==lastBPM&&console.log(`[getStepDuration] BPM changed: ${lastBPM} -> ${e}`),lastBPM=e,60/(4*e)},cleanUpWorker=async()=>{audioWorker&&(audioWorker.terminate(),audioWorker=null),workerUrl&&(URL.revokeObjectURL(workerUrl),workerUrl=null),"undefined"!=typeof audioCtx&&"closed"!==audioCtx.state&&await audioCtx.close(),window.removeEventListener("bpmChanged",updateWorkerStepDuration),console.log("[AudioWorker] Cleanup completed.")},updateWorkerStepDuration=()=>{audioWorker&&audioWorker.postMessage({action:"updateStepDuration",stepDuration:getStepDuration()})};window.addEventListener("beforeunload",cleanUpWorker),document.getElementById("loadVisualizerButton")?.addEventListener("click",initializeWorker),document.getElementById("visualizerCanvas")?.addEventListener("click",startWorker);
</script>
<visualiserScripts>
<script>
function resetVisualState(){"undefined"!=typeof cci2&&"undefined"!=typeof initialCCI2&&(cci2=initialCCI2),isChannel11Active=isPlaybackActive=!1,activeChannelIndex=null,activeArrayIndex={},renderingState={},"function"==typeof immediateVisualUpdate&&immediateVisualUpdate()}function resetAllStates(){resetPlaybackState?.(),resetVisualState()}function notifyVisualizer(e,t){const a={action:"activeStep",channelIndex:e,step:t};AudionalPlayerMessages.postMessage(a),document.dispatchEvent(new CustomEvent("internalAudioPlayback",{detail:a}))}const loadScript=e=>new Promise(((t,a)=>{const c=document.createElement("script");c.src=e,c.async=!0,c.onload=()=>{console.log(`Loaded: ${e}`),t()},c.onerror=()=>{console.error(`Failed to load script: ${e}`),a(new Error(`Failed to load script: ${e}`))},document.body.appendChild(c)})),loadScriptsSequentially=async(e,t)=>{for(const a of e)try{await loadScript(a)}catch(e){console.error(`Error loading ${t} script ${a}:`,e)}console.log(`All ${t} scripts loaded successfully.`)},loadVisualiserScripts=()=>loadScriptsSequentially(window.visualizerScripts||[],"visualizer"),loadArtworkScripts=()=>loadScriptsSequentially(window.artworkScripts||[],"artwork");window.artworkScripts=[],window.visualizerScripts=["/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0","/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0","/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0","/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0","/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0","/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0","/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0","/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0","/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0","/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0","/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0","/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0","/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0","/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0","/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0","/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0","/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0","/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0"],async function(){const e=Object.assign(document.createElement("canvas"),{id:"cv"});document.body.appendChild(e),Object.assign(document.body.style,{display:"flex",justifyContent:"center",alignItems:"center",height:"100vh",margin:"0"});const t=async()=>{window.cci2=window.initialCCI2=0,resetAllStates(),loadJsonFromUrl?.(window.jsonDataUrl),initializeWorker?.(),window.visualiserMode?(await loadScriptsSequentially(window.visualizerScripts||[],"visualizer"),(window.log||console.log)("Visualizer scripts loaded.")):(await loadScriptsSequentially(window.artworkScripts||[],"artwork"),(window.log||console.log)("Artwork scripts loaded."))};try{await new Promise((e=>{const t=()=>window.jsonDataUrl?e():setTimeout(t,100);t()})),console.log("Fetching from URL:",window.jsonDataUrl);const e=await fetch(window.jsonDataUrl);if(!e.ok)throw new Error(`HTTP error! status: ${e.status}`);window.settings=await e.json(),console.log("Settings loaded:",window.settings),await(ensureAudioContextState?.()),"loading"===document.readyState?document.addEventListener("DOMContentLoaded",t):await t()}catch(e){console.error("Error initializing the app:",e)}console.log(`[${(new Date).toISOString()}] [debugScriptLoading] ScriptLoader initialized.`)}();
</script>
