<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=yes"><title>? ? ? ? ? ? ?</title><style>body,html{height:100%;margin:0;display:flex;align-items:center;justify-content:center;background-color:#000;position:relative;transform:scale(.7)}body{margin:0;padding:0;width:100%;height:100%;overflow:hidden;display:flex;justify-content:center;align-items:center}#canvas-container{width:50vmin;height:50vmin;display:flex;justify-content:center;align-items:center;background-color:#fff;position:relative;z-index:10}canvas#cv{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);z-index:9999;pointer-events:none}#button-container{position:fixed;right:10px;top:60px;display:flex;flex-direction:column;gap:10px;z-index:10002}#play-button{padding:10px 20px;font-size:18px;font-weight:700;color:#fff;border:none;cursor:pointer;transition:background-color .3s;border-radius:5px}#play-button{background-color:#00bfff}#play-button.playing{background-color:red}#play-button:hover{background-color:#33c9ff}#play-button.playing:hover{background-color:#ff4d4d}</style><htmlelements><div id="canvas-container"><img id="artwork" alt="Artwork"></div><div id="button-container"><button id="play-button">Play</button></htmlelements><script id="seed-management">window.fixedSeed = ''; // Set a fixed seed here or leave it empty for a random seed
!function(){function e(){return"string"==typeof window.fixedSeed&&window.fixedSeed.length>0?(n(`Fixed seed found: ${window.fixedSeed}`),window.fixedSeed):Array.from({length:20},(()=>Math.floor(10*Math.random()))).join("")}function n(e){console.log(`[${(new Date).toISOString()}] ${e}`)}n("Generating new seed...");const d=e();n(`New seed generated: ${d}`),Object.defineProperty(window,"seed",{value:d,writable:!1,configurable:!1,enumerable:!0}),window.generateAdditionalSeed=function(){const d=e();return n(`Generating additional seed: ${d}`),d}}();
</script>
<script id="utility-functions">// Global logging function with ISO timestamp
    window.log = function(message) {
        console.log(`[${new Date().toISOString()}] ${message}`);
    };</script>

    <script id="initialize-multiplier-arrays">window.initializeMultiplierArrays = async function() {

        // Placeholder implementation
        // Replace this with your actual multiplier array initialization logic
        window.log("Initializing multiplier arrays...");
        // Example: Initialize some global arrays or variables
        window.multiplierArrays = [/* Your multiplier data */];
        window.log("Multiplier arrays initialized.");
    };
</script>

<script id="song-inputs">window.init=function(){window.log("Init function called. Preparing to process song data URLs...");const songDataUrls=["/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0","/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0","/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0","/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0","/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0","/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0","/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0","/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0","/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0","/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0","/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0","/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0"];const validSongUrls=songDataUrls.filter(url=>!url.trim().startsWith("//"));window.log(`Found ${validSongUrls.length} valid song data URLs to process.`);let playbackMode=validSongUrls.length===1?'normal playback mode':validSongUrls.length>1?'multiple playback mode':(window.log('No valid songs to process.'),null);if(!playbackMode)return;window.log(`Player is now in ${playbackMode}.`);const seed=window.seed;if(typeof seededRandom=="function"){validSongUrls[0]+=`?v=${Math.floor(seededRandom(seed)*1000)}`;window.log(`First song URL has been modified using seeded random. New URL: ${validSongUrls[0]}`);}else window.log("seededRandom function is not defined.");if(validSongUrls.length){window.log('Beginning processing of songDataUrls...');if(typeof processSerializedData=="function")processSerializedData(validSongUrls,VOLUME_CONTROLS,SPEED_CONTROLS);else window.log("processSerializedData function is not defined.");}else window.log('songDataUrls array is empty. No data to process.');window.log('Init function execution complete.');};</script>

<script id="main-initialization">(async function(){window.visualiserMode=false;if(!window.seed){window.log('Seed is not set. Initialization aborted.');return;}if(typeof window.initializeMultiplierArrays=="function")await window.initializeMultiplierArrays();else window.log("initializeMultiplierArrays function is not defined.");if(typeof window.init=="function"){window.init();window.log("Main application initialized.");}else window.log("init function is not defined.");if(window.visualiserMode&&window.enableVisualizerScripts){if(typeof window.loadVisualiserScripts=="function"){await window.loadVisualiserScripts();window.log("Visualizer scripts loaded.");}else window.log("loadVisualiserScripts function is not defined.");}else{if(typeof window.loadArtworkScripts=="function"){await window.loadArtworkScripts();window.log("Artwork scripts loaded.");}else window.log("loadArtworkScripts function is not defined.");}document.getElementById("artwork").src="/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0";document.getElementById("artwork").alt="Loaded Artwork";})();</script>



<constants-and-variables>
    
    <script id="constants-and-variables">// All Song Files contain 16 channels. Volume controls below represent a master volume for the song 
  // and then a volume multiplier for every channel. These must be mapped into the new songs that are generated
  // Then the chosen 24 channels for the generative mix can be correctly mapped to the audio mixer faders.

const VOLUME_CONTROLS = [
//Master,  1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16   
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 1
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 2
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 3
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 4
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 5
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 5
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 6
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 7
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 8
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 9
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 10
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 11
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 12
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 13
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 14
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 15
    [0.75, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 16
  
];




const SPEED_CONTROLS = [
// Master,  1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 1
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 2
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 3
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 4
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 5
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 6
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 7
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 8
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 9
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 10
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 11
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 12
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 13
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 14
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 15
     [1,    1, 1, 1, 1, 1, 1, 1, 1, 1, 1,  1,  1,  1,  1,  1,  1], // Song 16
];


scheduleMultiplierOnOff=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1];

let seedSet=!1,arraysInitialized=!1,audioElements=[];
function applyScheduleMultiplier(e,l){try{e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,c)=>c<l.length&&l[c]?1.1*e:e)),console.log("Schedule multiplier applied successfully.")}catch(e){console.error("Error in applyScheduleMultiplier:",e)}}
</script>

</constants-and-variables>

<script>
const loadPako=async()=>{try{const r=await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0"),e=(new DOMParser).parseFromString(await r.text(),"text/html").querySelector("script")?.textContent;if(!e?.includes("pako"))throw new Error("Pako library not found.");const t=document.createElement("script");t.textContent=e,document.head.appendChild(t),console.log("Pako library loaded.")}catch(r){throw console.error("Error loading Pako:",r),r}},fetchAndDeserialize=async r=>{try{const e=await fetch(r);if(!e.ok)throw new Error(`Network error: ${r}`);const t=new TextDecoder("utf-8").decode(pako.inflate(new Uint8Array(await e.arrayBuffer())));return deserialize(JSON.parse(t))}catch(r){throw console.error("Fetch/Deserialize error:",r),r}},fetchAndProcessData=async r=>{try{const e=(await Promise.all(r.map((async r=>{try{const e=await fetchAndDeserialize(r);if(!e?.projectSequences)throw new Error(`Invalid data: ${r}`);return e}catch{return console.error(`Error: ${r}`),null}})))).filter(Boolean);if(!e.length)throw new Error("No valid data processed.");return e}catch(r){throw console.error("Process Data error:",r),r}};
function mapSeedToBpm(e){const a=[80,100,120,140,160,180,240],o=e.split("").reduce(((e,a)=>(10*e+parseInt(a,10))%1000000007),0),t=a[o%a.length];return console.log(`Seed: ${e}, Hash: ${o}`),t}const processSerializedDataPart1=async(e,a,o)=>{try{await loadPako();const t=await fetchAndProcessData(e),s=mapSeedToBpm(window.seed);window.processedData={deserializedData:t,selectedBPM:s,VOLUME_CONTROLS:a,SPEED_CONTROLS:o,songDataUrls:e},console.log("Data loading complete."),document.dispatchEvent(new CustomEvent("dataLoadingComplete"))}catch(e){console.error("Process Data error:",e)}};window.processSerializedData=processSerializedDataPart1,console.log("DataLoadingScript initialized.");
</script>



</dataloadinganddeserialisation>
<localdataprocessing>
    <script>
const shuffleArray=(e,a)=>{for(let n=e.length-1;n>0;n--){const l=Math.floor(seededRandom(a++)*(n+1));[e[n],e[l]]=[e[l],e[n]]}return e},adjustChannelData=(e,a,n,l,t)=>{const c=n/e.projectBPM;e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,n)=>{let l=e*c*(t[a]?.[n]||1);return Math.max(isNaN(l)?.1:l,.1)}));const o=l[a]||[],h=o[0]||1;e.channelVolume=e.channelVolume.map(((e,a)=>e*h*(o[a+1]||1)))};
// Global variable to store audio channels and their gain nodes
 window.audioChannels = [];
// Function to initialize 24 gain nodes and map them to the first 24 channels
const createAndAssignGainNodes=(n,e)=>{const a=[];for(let o=0;o<24;o++){const i=n.createGain();i.gain.value=.5,a.push(i),e[o]&&(e[o].gainNode=i,e[o].audioContext=n,window.audioChannels.push({channel:e[o],gainNode:i}),console.log(`Channel ${o} assigned to GainNode with default value 0.5`))}return a};
const assembleProcessedSong=(e,n)=>{console.log("Starting to assemble the processed song...");const s=e.flatMap(((e,n)=>e.channelURLs.map(((s,c)=>({url:s,volume:e.channelVolume[c],speed:e.channelPlaybackSpeed[c],trim:e.trimSettings[c],source:`data${n+1}`,index:c}))))),c=shuffleArray(s,window.seed).slice(0,28);c.forEach(((e,n)=>{e.globalIndex=n}));const t=[c.slice(0,20),c.slice(20,24),c.slice(24,28)],o={...e[0],projectBPM:n,channelURLs:c.map((e=>e.url)),channelVolume:c.map((e=>e.volume)),channelPlaybackSpeed:c.map((e=>e.speed)),trimSettings:c.map((e=>e.trim)),projectSequences:{}},l=e.reduce(((e,n,s)=>(e[`data${s+1}`]=n,e)),{});let a=[],r=0;const i=[],d=new(window.AudioContext||window.webkitAudioContext),p=createAndAssignGainNodes(d,c);for(const n in e[0].projectSequences){o.projectSequences[n]={};const e=parseInt(n.replace(/\D/g,""),10);e<=1?a=t[0]:e<=3?a=[...t[0],...t[1]]:e<=11&&(a=[...t[0],...t[1],...t[2]]),a.length>r&&i.push({sequenceNumber:e,channelsAdded:a.length-r,totalChannels:a.length}),r=a.length,a.forEach(((e,s)=>{const c=(l[e.source]?.projectSequences[n]||{})[`ch${e.index}`]||{steps:[]};o.projectSequences[n][`ch${s}`]={...c,steps:Array.isArray(c.steps)?c.steps:[],globalIndex:e.globalIndex}}))}o.channelAdditionLog=i;const u=Object.keys(o.projectSequences).length;return console.log(`Total number of sequences in the new generative song: ${u}`),Object.keys(o.projectSequences).forEach((e=>{console.log(`Sequence ${e} contains ${Object.keys(o.projectSequences[e]).length} channels.`)})),p.forEach((e=>e.connect(d.destination))),o};
const processSerializedDataPart2=async()=>{try{const{deserializedData:e,selectedBPM:a,VOLUME_CONTROLS:o,SPEED_CONTROLS:t}=window.processedData;e.forEach(((e,l)=>adjustChannelData(e,l,a,o,t)));const l=assembleProcessedSong(e,a);"function"==typeof applyScheduleMultiplier?applyScheduleMultiplier(l,window.scheduleMultiplierOnOff):console.warn("applyScheduleMultiplier is not defined."),window.globalJsonData=l,window.jsonDataUrl=URL.createObjectURL(new Blob([JSON.stringify(l)],{type:"application/json"})),document.dispatchEvent(new CustomEvent("dataProcessingComplete")),console.log("Local data processing complete.")}catch(e){console.error("Error in processSerializedDataPart2:",e)}};
// Event listener to start processing after data is loaded
document.addEventListener("dataLoadingComplete", processSerializedDataPart2);
console.log("LocalDataProcessingScript initialized and awaiting data.");
</script>
</localdataprocessing>
<helperfunctions>
<script id="helper-functions">
const aSM=(e,t,r)=>{for(const[o,n]of Object.entries(e.projectSequences))for(const[e,o]of Object.entries(n)){const e=o?.source;if(!e||"string"!=typeof e)continue;const n=parseInt(e.slice(4),10)-1;if(!(n<0||isNaN(n))&&1===t[n]){if(!r.some((t=>t.source===e&&t.index===o.globalIndex)))continue;const t=Array.isArray(o.steps)?o.steps.filter((e=>"number"==typeof e)):[];if(!t.length)continue;o.steps=rS(t,"half")}}},rS=(e,t)=>{const r={half:2,quarter:4}[t];if(!r)throw new Error("Unsupported multiplier type");return e.filter(((e,t)=>t%r==0))},gRS=()=>Math.floor(1e16*Math.random());
</script>
<script id="audio-context-manager">
!function(){if(!window.ACM){class t{constructor(){return t.instance||(this.aCtx=null,t.instance=this),t.instance}init(){this.aCtx&&"closed"!==this.aCtx.state||(this.aCtx=new(window.AudioContext||window.webkitAudioContext),this.aCtx.onstatechange=()=>{})}getCtx(){return this.aCtx||this.init(),this.aCtx}async resume(){this.init(),"suspended"===this.aCtx.state&&await this.aCtx.resume()}async suspend(){this.aCtx&&"running"===this.aCtx.state&&await this.aCtx.suspend()}async resetApp(){"function"==typeof stopPlayback&&await stopPlayback(),window.audioElements=[],window.activeSources=[],window.arraysInitialized=!1,window.isReadyToPlay=!1,globalJsonData=null,globalAudioBuffers=[],preprocessedSequences={},currentStep=0,beatCount=0,barCount=0,currentSequence=0,playbackTimeoutId=null,nextNoteTime=0,totalSequences=0,isPlaying=!1,globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalReversedAudioBuffers={},isReversePlay=!1,"function"==typeof cleanUpWorker&&await cleanUpWorker(),await initApp()}}window.ACM=new t}}();
</script>
<script id="audio-control-functions">
async function sS(){"running"===audioCtx.state&&await audioCtx.suspend()}async function sp(){for(const a in activeSources)activeSources[a].forEach((({source:a,gainNode:e})=>{const n=audioCtx.currentTime;e.gain.cancelScheduledValues(n),e.gain.setValueAtTime(e.gain.value,n),e.gain.linearRampToValueAtTime(0,n+fadeDuration),a.stop(n+fadeDuration),a.disconnect(),e.disconnect()})),activeSources[a]=[];setTimeout((async()=>{await audioCtx.suspend(),resetPlaybackState()}),50)}
</script>
<script>
window.enableVisualizerScripts=!1;let globalVolumeMultiplier=1,globalJsonData=null,bpm=0;const sourceChannelMap=new Map;let globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalGainNodes=new Map,globalAudioBuffers=[],globalReversedAudioBuffers={},isReversePlay=!1;const gainNodes={};let audioCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext);console.log("[globalDefinitionsDebug] AudioContext initialized outside of property definitions.");let preprocessedSequences={},isReadyToPlay=!1,currentStep=0,currentSequence=0,nextNoteTime=0;const fadeDuration=.01,defaultVolume=1;let isToggleInProgress=!1,isPlaying=!1;const AudionalPlayerMessages=new BroadcastChannel("channel_playback");
window.eVS=!1;let gVM=1,gJD=null,gTM=new Map,gTT={},gVL={},gPS={},aS=[],gGN=new Map,gAB=[],gRAB={},isRP=!1,gN={},aCtx=window.AudioContextManager?.getAudioContext()||new(window.AudioContext||window.webkitAudioContext),pS={},isR=!1,cS=0,cQ=0,nNT=0;const fD=.01,dV=1,tIP=!1,isP=!1,APC=new BroadcastChannel("channel_playback");async function eACS(){aCtx||(aCtx=new(window.AudioContext||window.webkitAudioContext)),"suspended"===aCtx.state&&await aCtx.resume()}async function sP(){}Object.defineProperty(window,"isPlaying",{get:()=>isP,set(e){isP=e}}),Object.defineProperty(window,"currentStep",{get:()=>cS,set(e){cS=e}}),Object.defineProperty(window,"currentSequence",{get:()=>cQ,set(e){cQ=e}}),document.getElementById("stop-button")?.addEventListener("click",(async()=>{await sP()}));
</script>
        
        
        
    
<script>
        
        // Function to fetch and process audio data
const fetchAndProcessAudioData = async (urls) => {
    await Promise.all(urls.map((url, index) => processAudioUrl(url, index + 1)));
    createReversedBuffers();
};

// Function to get or create a gain node for a specific channel
const getOrCreateGainNode = (channel) => {
    if (!gainNodes[channel]) {
        const gainNode = audioCtx.createGain();
        gainNode.connect(audioCtx.destination);
        gainNodes[channel] = gainNode;
    }
    return gainNodes[channel];
};

// Function to process audio URLs and fetch audio data
const processAudioUrl = async (url, channelNumber) => {
    const channelName = `Channel ${channelNumber}`;
    try {
        const response = await fetch(url);
        if (!response.ok) {
            throw new Error(`Fetch failed: ${url}, Status: ${response.status}`);
        }

        const contentType = response.headers.get("Content-Type");
        const decodedAudio = await fetchAndDecodeAudio(response, contentType);

        if (decodedAudio) {
            const gainNode = getOrCreateGainNode(channelName);
            gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channelName]) * globalVolumeMultiplier;

            // Push the decoded audio buffer and gain node into globalAudioBuffers
            globalAudioBuffers.push({
                buffer: decodedAudio,
                gainNode: gainNode,
                channel: channelName
            });
        } else {
            console.error(`Decoding failed for ${channelName}: ${url}`);
        }
    } catch (error) {
        console.error(`Error processing ${channelName}:`, error);
    }
};

// Function to set the global volume multiplier
const setGlobalVolumeMultiplier = (multiplier) => {
    globalVolumeMultiplier = Math.max(0, multiplier);
    globalAudioBuffers.forEach(({ gainNode, channel }) => {
        gainNode.gain.value = parseVolumeLevel(globalVolumeLevels[channel]) * globalVolumeMultiplier;
    });
};

// Function to fetch and decode audio data
const fetchAndDecodeAudio = async (response, contentType) => {
    try {
        if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
            const arrayBuffer = await response.arrayBuffer();
            return audioCtx.decodeAudioData(arrayBuffer);
        }

        const responseText = await response.text();
        let audioData = null;

        if (/application\/json/.test(contentType)) {
            audioData = JSON.parse(responseText).audioData;
        } else if (/text\/html/.test(contentType)) {
            audioData = extractBase64FromHTML(responseText);
        }

        if (audioData) {
            const arrayBuffer = base64ToArrayBuffer(audioData.split(",")[1]);
            return audioCtx.decodeAudioData(arrayBuffer);
        }

        if (/audio\//.test(contentType)) {
            const arrayBuffer = await response.arrayBuffer();
            return audioCtx.decodeAudioData(arrayBuffer);
        }
    } catch (error) {
        console.error("[fetchAndDecodeAudio] Decoding error:", error);
    }
    return null;
};

// Function to create reversed buffers for channels that need reverse playback
const createReversedBuffers = () => {
    const channelsToReverse = new Set();

    Object.values(globalJsonData.projectSequences).forEach((sequence) => {
        Object.entries(sequence).forEach(([channelKey, channelData]) => {
            if (channelData.steps.some(step => step.reverse)) {
                const channelName = `Channel ${parseInt(channelKey.slice(2)) + 1}`;
                channelsToReverse.add(channelName);
            }
        });
    });

    globalAudioBuffers.forEach(({ buffer, channel }) => {
        if (channelsToReverse.has(channel)) {
            globalReversedAudioBuffers[channel] = reverseBuffer(buffer);
        }
    });
};

// Function to reverse an audio buffer
const reverseBuffer = (buffer) => {
    const reversedBuffer = audioCtx.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate);

    for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
        const originalChannelData = buffer.getChannelData(channel);
        const reversedChannelData = reversedBuffer.getChannelData(channel);

        for (let i = 0; i < originalChannelData.length; i++) {
            reversedChannelData[i] = originalChannelData[originalChannelData.length - i - 1];
        }
    }

    return reversedBuffer;
};

// Function to convert base64 to ArrayBuffer
const base64ToArrayBuffer = (base64) => {
    try {
        const binaryString = atob(base64);
        const length = binaryString.length;
        const bytes = new Uint8Array(length);

        for (let i = 0; i < length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }

        return bytes.buffer;
    } catch (error) {
        console.error("[base64ToArrayBuffer] Conversion error:", error);
        return null;
    }
};

// Function to extract base64 from HTML content
const extractBase64FromHTML = (html) => {
    try {
        const doc = new DOMParser().parseFromString(html, "text/html");
        const audioSource = doc.querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");

        if (/^data:audio\/(wav|mp3|mp4);base64,/.test(audioSource?.toLowerCase()) || /audio\//.test(audioSource?.toLowerCase())) {
            return audioSource;
        }

        console.error("[extractBase64FromHTML] Invalid audio source format.");
    } catch (error) {
        console.error("[extractBase64FromHTML] Parsing error:", error);
    }
    return null;
};

console.log("Audio processing script loaded.");
</script>




</audiodataprocessing><jsonloadingandplayback><script>const loadJsonFromUrl = async (url) => {
        try {
            const response = await fetch(url);
            if (!response.ok) throw new Error(`HTTP error: ${response.status}`);
            
            globalJsonData = await response.json();
            
            const stats = {
                channelsWithUrls: 0,
                sequencesCount: 0,
                activeStepsPerSequence: {},
                activeChannelsPerSequence: {},
                types: {}
            };

            analyzeJsonStructure(globalJsonData, stats);
            const playbackData = prepareForPlayback(globalJsonData, stats);

            await fetchAndProcessAudioData(playbackData.channelURLs);
            preprocessAndSchedulePlayback(playbackData);
        } catch (error) {
            console.error("Failed to load JSON:", error);
        }
    };

    const analyzeJsonStructure = (json, stats) => {
        if (json.projectSequences && typeof json.projectSequences === "object") {
            Object.entries(json.projectSequences).forEach(([sequenceId, sequenceData]) => {
                stats.activeStepsPerSequence[sequenceId] = 0;
                stats.activeChannelsPerSequence[sequenceId] = [];

                Object.entries(sequenceData).forEach(([channelId, channelData]) => {
                    const channelName = `Channel ${parseInt(channelId.slice(2)) + 1}`;
                    stats.activeStepsPerSequence[sequenceId] += channelData.steps.length;
                    stats.activeChannelsPerSequence[sequenceId].push(channelName);
                });
            });
        }

        Object.entries(json).forEach(([key, value]) => {
            if (key !== "projectSequences") {
                const type = Array.isArray(value) ? "array" : typeof value;
                stats.types[type] = (stats.types[type] || 0) + 1;
                
                if (["object", "array"].includes(type)) {
                    analyzeJsonStructure(value, stats);
                }
            }
        });
    };

    const findAndSetEndSequence = (playbackData) => {
        if (playbackData?.sequences) {
            let lastNonEmptySequence = null;
            
            for (const [sequenceId, sequence] of Object.entries(playbackData.sequences)) {
                const isEmpty = Object.values(sequence.normalSteps).every(steps => !steps.length);
                
                if (isEmpty && lastNonEmptySequence) {
                    playbackData.endSequence = lastNonEmptySequence;
                    break;
                }
                
                if (!isEmpty) {
                    lastNonEmptySequence = sequence;
                }
            }

            if (!playbackData.endSequence && lastNonEmptySequence) {
                playbackData.endSequence = lastNonEmptySequence;
            }
        }
    };

    const prepareForPlayback = (json, stats) => {
        const {
            channelURLs,
            trimSettings = [],
            channelVolume = [],
            channelPlaybackSpeed = [],
            projectSequences,
            projectName,
            projectBPM,
            currentSequence
        } = json;

        bpm = projectBPM;
        totalSequences = currentSequence;
        globalTrimTimes = {};
        globalVolumeLevels = {};
        globalPlaybackSpeeds = {};

        channelURLs.forEach((url, index) => {
            const channelName = `Channel ${index + 1}`;
            const trim = trimSettings[index] || {};

            globalTrimTimes[channelName] = {
                startTrim: +(trim.startSliderValue || 0) / 100,
                endTrim: +(trim.endSliderValue || 100) / 100
            };

            globalVolumeLevels[channelName] = +parseVolumeLevel(channelVolume[index] || 1).toFixed(3);
            globalPlaybackSpeeds[channelName] = +Math.min(Math.max(channelPlaybackSpeed[index] || 1, 0.1), 100).toFixed(3);
        });

        const sequences = Object.entries(projectSequences).reduce((acc, [sequenceId, sequenceData]) => {
            const normalSteps = {};
            const reverseSteps = {};

            Object.entries(sequenceData).forEach(([channelId, channelSteps]) => {
                const channelName = `Channel ${parseInt(channelId.slice(2)) + 1}`;
                normalSteps[channelName] = [];
                reverseSteps[channelName] = [];

                channelSteps.steps.forEach((stepData) => {
                    const stepIndex = typeof stepData === "object" ? stepData.index : stepData;
                    if (stepData.reverse) {
                        reverseSteps[channelName].push(stepIndex);
                    } else {
                        normalSteps[channelName].push(stepIndex);
                    }
                });
            });

            acc[sequenceId] = { normalSteps, reverseSteps };
            return acc;
        }, {});

        const playbackData = {
            projectName,
            bpm: projectBPM,
            channels: channelURLs.length,
            channelURLs,
            trimTimes: globalTrimTimes,
            stats,
            sequences
        };

        findAndSetEndSequence(playbackData);

        return playbackData;
    };

    const preprocessAndSchedulePlayback = (playbackData) => {
        if (!playbackData?.sequences) {
            return console.error("Playback data missing.");
        }

        bpm = playbackData.bpm;
        preprocessedSequences = Object.fromEntries(
            Object.entries(playbackData.sequences).map(([sequenceId, sequence]) => [
                sequenceId,
                {
                    normalSteps: processSteps(sequence.normalSteps),
                    reverseSteps: processSteps(sequence.reverseSteps)
                }
            ])
        );

        isReadyToPlay = Object.values(preprocessedSequences).some(
            sequence => Object.keys(sequence.normalSteps).length || Object.keys(sequence.reverseSteps).length
        );
    };

    const processSteps = (steps) => {
        return Object.fromEntries(
            Object.entries(steps).filter(([, stepArray]) => stepArray.length).map(([channelName, stepArray]) => [
                channelName,
                stepArray.map(step => ({
                    step,
                    timing: +(step * (60 / bpm)).toFixed(3)
                }))
            ])
        );
    };
    </script>
    
    
    
    </jsonloadingandplayback><dataprocessingutilities><script>// Function to hash a string based on a specific algorithm involving shifting parts of the string
const hashString = (inputString) => {
    const shiftIndex = parseInt(inputString.split("i")[1], 10);  // Extract the shift index
    const shiftedString = inputString.slice(shiftIndex) + inputString.slice(0, shiftIndex);  // Shift the string
    return shiftedString
        .split("")
        .reduce((hash, char) => (31 * hash + char.charCodeAt(0)) % Number.MAX_SAFE_INTEGER, 0) % 1400000000;
};

// Function that generates a seeded random number based on input
const seededRandom = (seed) => {
    const randomValue = 10000 * Math.sin(seed);
    return randomValue - Math.floor(randomValue);  // Returns the fractional part
};

// Function to set the global playback status
const setPlaybackStatus = (status) => {
    window.playbackStarted = status;
};

// Key map to translate between keys and indices
const keyMap = {
    0: "projectName",
    1: "artistName",
    2: "projectBPM",
    3: "currentSequence",
    4: "channelURLs",
    5: "channelVolume",
    6: "channelPlaybackSpeed",
    7: "trimSettings",
    8: "projectChannelNames",
    9: "startSliderValue",
    10: "endSliderValue",
    11: "totalSampleDuration",
    12: "start",
    13: "end",
    14: "projectSequences",
    15: "steps"
};

// Reverse key map to translate from field names to their corresponding index
const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([index, key]) => [key, +index]));

// Channel map to assign letters A-Z to channel indices
const channelMap = Array.from({ length: 26 }, (_, index) => String.fromCharCode(65 + index));

// Reverse channel map to translate letters back to their indices
const reverseChannelMap = Object.fromEntries(channelMap.map((letter, index) => [letter, index]));

// Function to decompress step data
const decompressSteps = (stepData) => {
    return stepData.flatMap((step) => {
        if (typeof step === "number") {
            return step;  // If it's just a number, return it directly
        }
        if (step && typeof step === "object" && "r" in step) {
            const [start, end] = step.r;  // Extract range
            return Array.from({ length: end - start + 1 }, (_, i) => start + i);  // Return array for range
        }
        if (typeof step === "string" && step.endsWith("r")) {
            return { index: parseInt(step.slice(0, -1), 10), reverse: true };  // Reverse step
        }
        return [];
    });
};

// Function to deserialize JSON data into a readable structure
const deserialize = (data) => {
    const parseData = (input) => {
        if (Array.isArray(input)) {
            return input.map((item) => (typeof item === "object" ? parseData(item) : item));
        }
        if (input && typeof input === "object") {
            return Object.entries(input).reduce((accumulator, [key, value]) => {
                const mappedKey = keyMap[key] || key;
                if (mappedKey === "projectSequences") {
                    // Process project sequences
                    accumulator[mappedKey] = Object.entries(value).reduce((sequenceAccumulator, [sequenceKey, sequenceValue]) => {
                        const sequenceId = sequenceKey.replace(/^s/, "Sequence");  // Change 's0' to 'Sequence0'
                        sequenceAccumulator[sequenceId] = Object.entries(sequenceValue).reduce((channelAccumulator, [channelKey, channelData]) => {
                            const channelName = `ch${reverseChannelMap[channelKey]}`;
                            const steps = channelData[reverseKeyMap.steps] || [];
                            channelAccumulator[channelName] = {
                                steps: decompressSteps(steps)  // Decompress the steps
                            };
                            return channelAccumulator;
                        }, {});
                        return sequenceAccumulator;
                    }, {});
                } else {
                    accumulator[mappedKey] = parseData(value);
                }
                return accumulator;
            }, {});
        }
        return input;
    };
    return parseData(data);
};

// Initialize playback (assumed to be defined elsewhere in your codebase)
initializePlayback();

// Hash the string to generate a seed value
const seedValue = hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");
console.log(`Seed value: ${seedValue}`);

// Initialize processing utilities when the window loads
console.log("ProcessingUtilities initialized.");
window.onload = () => {
    console.log("window.onload triggered.");
};</script></dataprocessingutilities><playback><script>// Global variables are defined elsewhere:
        // let isPlaying = false;
        // let isToggleInProgress = false;
        // let isFirstLoopCompleted = false;


       
        // Function to start the playback loop
        function startPlaybackLoop() {
            if (globalJsonData && globalJsonData.projectSequences) {
                bpm = globalJsonData.projectBPM;
                const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                totalSequencesInNewSong = sequenceKeys.length;  // Total number of sequences in the song

                console.log(`Starting playback of song with ${totalSequencesInNewSong} sequences.`);

                // Play the first sequence if available
                if (totalSequencesInNewSong > 0) {
                    playSequence(sequenceKeys[currentSequenceIndex]);
                } else {
                    console.error("No sequences found in the project data.");
                }
            } else {
                console.error("Playback cannot start because globalJsonData or projectSequences are undefined.");
            }
        }

        // Function to play a sequence
        function playSequence(sequenceKey) {
            const sequence = globalJsonData.projectSequences[sequenceKey];
            const channels = Object.keys(sequence);

            console.log(`Playing sequence ${sequenceKey} with ${channels.length} channels.`);
            totalStepsInCurrentSequence = channels.reduce((maxSteps, channel) => {
                const steps = sequence[channel].steps || [];
                return Math.max(maxSteps, steps.length); // Find the maximum number of steps in this sequence
            }, 0);

            playNextStep();
        }

        // Function to play the next step in the current sequence
        function playNextStep() {
          if (currentStepIndex < totalStepsInCurrentSequence && isPlaying) {
              // Play the current step for all channels
              console.log(`Playing step ${currentStepIndex + 1}/${totalStepsInCurrentSequence} in sequence ${currentSequenceIndex + 1}/${totalSequencesInNewSong}`);
              currentStepIndex++;

              // Schedule the next step playback based on the BPM and store the timeout ID
              const nextStepTime = 60 / bpm;
              playbackTimeoutId = setTimeout(playNextStep, nextStepTime * 1000);
          } else if (isPlaying) {
              // End of the current sequence
              currentStepIndex = 0;
              currentSequenceIndex++;

              const sequenceKeys = Object.keys(globalJsonData.projectSequences);

              if (currentSequenceIndex < sequenceKeys.length) {
                  // Play the next sequence
                  playSequence(sequenceKeys[currentSequenceIndex]);
              } else {
                  // End of the song; stop playback
                  console.log("Reached the end of the last sequence. Stopping playback.");
                  stopPlayback(); // Call the stopPlayback function to clean up
              }
          }
      }


      // Function to initialize playback
    async function initializePlayback(autoStart = false) {
        if (audioCtx.state === 'suspended') {
            await audioCtx.resume();
            console.log("AudioContext resumed:", audioCtx.state);
        }

        // Reset playback state variables
        currentSequenceIndex = 0;
        currentStepIndex = 0;
        isPlaying = true; // Set playing state to true
        console.log("Starting playback loop from the beginning.");

        // Update Play button to "Stop" and change color to indicate playing
        const playButton = document.getElementById('play-button');
        if (playButton) {
            playButton.textContent = "Stop";
            playButton.classList.add('playing');
        }

        startPlaybackLoop();

        // Start any additional workers or processes needed
        if (typeof startWorker === 'function') {
            startWorker();
        }
    }


    // Function to pause playback
    async function pausePlayback() {
        console.log("Pausing playback.");

        isPlaying = false; // Set playing state to false

        // Clear the scheduled timeout
        if (playbackTimeoutId !== null) {
            clearTimeout(playbackTimeoutId);
            playbackTimeoutId = null;
        }

        // Suspend the audio context to pause playback
        if (audioCtx.state === 'running') {
            await audioCtx.suspend();
            console.log("AudioContext suspended:", audioCtx.state);
        }

        // Update Play button to "Play" and change color back to blue
        const playButton = document.getElementById('play-button');
        if (playButton) {
            playButton.textContent = "Play";
            playButton.classList.remove('playing');
        }
    }


    // Optional: Function to resume playback
    async function resumePlayback() {
        if (audioCtx.state === 'suspended') {
            await audioCtx.resume();
            console.log("AudioContext resumed:", audioCtx.state);
        }

        if (!isPlaying) {
            isPlaying = true;
            console.log("Resuming playback.");
            playNextStep(); // Continue playback from the current step

            // Update Play button to "Stop" and change color to red
            const playButton = document.getElementById('play-button');
            if (playButton) {
                playButton.textContent = "Stop";
                playButton.classList.add('playing');
            }
        } else {
            console.log("Playback is already running.");
        }
    }

    // Function to stop playback
    async function stopPlayback() {
        console.log("Stopping playback...");
        isPlaying = false;  // Ensure playback stops

        // Clear the scheduled timeout
        if (playbackTimeoutId !== null) {
            clearTimeout(playbackTimeoutId);
            playbackTimeoutId = null;
        }

        // Stop all active audio sources with fade-out effect
        for (const a in activeSources) {
            activeSources[a].forEach(({ source, gainNode }) => {
                const currentTime = audioCtx.currentTime;
                gainNode.gain.cancelScheduledValues(currentTime);
                gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
                gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeDuration);
                source.stop(currentTime + fadeDuration);
                source.disconnect();
                gainNode.disconnect();
            });
            activeSources[a] = [];
        }

        // Suspend the audio context after stopping playback
        setTimeout(async () => {
            if (audioCtx.state === 'running') {
                await audioCtx.suspend();
                console.log("AudioContext suspended:", audioCtx.state);
            }
            resetPlaybackState();  // Ensure the playback state is fully reset
        }, 50);

        // Reset global state variables
        currentSequenceIndex = 0;
        currentStepIndex = 0;
        isFirstLoopCompleted = false; // Reset the loop completion state

        // Update Play button to "Play" and change color back to blue
        const playButton = document.getElementById('play-button');
        if (playButton) {
            playButton.textContent = "Play";
            playButton.classList.remove('playing');
        }
    }


    // Function to toggle playback
    async function togglePlayback() {
        if (!isToggleInProgress) {
            isToggleInProgress = true;
            try {
                if (isPlaying) {
                    // Stop the playback if it is currently playing
                    await stopPlayback();
                } else {
                    // Start playback from the beginning or resume if paused
                    await initializePlayback();
                }
            } catch (error) {
                console.error("Error during playback toggle:", error);
            } finally {
                isToggleInProgress = false;
            }
        }
    }</script></playback><eventlisteners><script>// **Modify the global click event to prevent unintended playback toggles**
        document.getElementById('play-button').addEventListener("click", async () => {
            console.log("[eventListeners] Play button clicked.");
            if (typeof window.ensureAudioContextState === "function") {
                try {
                    console.log("[eventListeners] Ensuring AudioContext state.");
                    await window.ensureAudioContextState();
                    await togglePlayback();  // Toggle playback when the button is clicked
                    document.dispatchEvent(new CustomEvent("playbackStarted"));
                    console.log("[eventListeners] Dispatched playbackStarted event.");
                } catch (e) {
                    console.error("[eventListeners] Error during playback toggle:", e);
                }
            } else {
                console.error("[eventListeners] ensureAudioContextState is not defined or not a function");
            }
        });
    
        // Event listeners to handle playback state changes
        document.addEventListener("playbackStarted", () => {
            log("Playback started. Displaying seed.");
            const seedDisplay = document.getElementById("seed-display");
            if (seedDisplay) {
                console.log("[eventListeners] Updating seed display with seed:", window.seed);
                seedDisplay.textContent = `Seed: ${window.seed}`;
                seedDisplay.style.opacity = "1";
                setTimeout(() => {
                    seedDisplay.style.opacity = "0";
                    console.log("[eventListeners] Seed display hidden.");
                }, 10000);
            } else {
                console.error("[eventListeners] Seed display element not found.");
            }
            window.psTime = Date.now();
            setPlaybackStatus(true);
            console.log("[eventListeners] Playback status set to true.");
            if (typeof displayPlayText === "function") {
                displayPlayText();
                console.log("[eventListeners] Called displayPlayText function.");
            }
        });
    
        document.addEventListener("dataLoadingComplete", () => {
            console.log("[eventListeners] Received dataLoadingComplete event. Starting local data processing.");
            processSerializedDataPart2();
        });
    
        window.addEventListener("load", async () => {
            log("Window load event triggered. Starting app initialization.");
            try {
                await initApp();
                log("initApp function execution complete.");
            } catch (e) {
                console.error("[eventListeners] Error during app initialization:", e);
            }
        });
    
        document.addEventListener("sequenceUpdated", ({ detail: { currentSequence, currentStep } }) => {
            // Handle sequence updates, if necessary
            console.log(`[eventListeners] Sequence updated: Current Sequence: ${currentSequence}, Current Step: ${currentStep}`);
        });
    
        // Show the "Resume" button when playback is paused
        document.addEventListener("playbackPaused", () => {
            console.log("[eventListeners] Playback paused.");
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'inline-block';
                console.log("[eventListeners] Resume button displayed.");
            } else {
                console.error("[eventListeners] Resume button not found.");
            }
        });
    
        // Hide the "Resume" button when playback starts or stops
        document.addEventListener("playbackStarted", () => {
            console.log("[eventListeners] Playback started. Hiding resume button.");
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
                console.log("[eventListeners] Resume button hidden.");
            } else {
                console.error("[eventListeners] Resume button not found.");
            }
        });
    
        document.addEventListener("playbackStopped", () => {
            console.log("[eventListeners] Playback stopped. Hiding resume button.");
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
                console.log("[eventListeners] Resume button hidden.");
            } else {
                console.error("[eventListeners] Resume button not found.");
            }
        });
    
        // Add this function if it's not already defined
        function log(e) {
            console.log(`[${(new Date).toISOString()}] ${e}`);
        }</script></eventlisteners><audiobuffering><script>// Clamp volume within the range 0 to 3
            function clampVolume(e) {
                return Math.max(0, Math.min(e, 3));
            }
        
            // Parse the volume level and ensure it's a valid number
            function parseVolumeLevel(e) {
                const t = typeof e === "number" ? e : parseFloat(e);
                const parsedVolume = clampVolume(isNaN(t) ? defaultVolume : t);
                console.log(`[parseVolumeLevel] Volume level parsed: ${parsedVolume}`);
                return parsedVolume;
            }
        
            // Reverse trim times for audio playback
            function calculateReversedTrimTimes(e) {
                const reversed = { startTrim: 1 - e.endTrim, endTrim: 1 - e.startTrim };
                console.log(`[calculateReversedTrimTimes] Reversed trim times:`, reversed);
                return reversed;
            }
        
            // Ensure AudioContext is running, resume if suspended
            async function resumeAudioContext() {
                try {
                    await audioCtx.resume();
                    console.log("[resumeAudioContext] AudioContext resumed:", audioCtx.state);
                } catch (e) {
                    console.error("[resumeAudioContext] Failed to resume AudioContext:", e);
                }
            }
        
            // Ensure the AudioContext state is running
            async function ensureAudioContextState() {
                if (audioCtx.state !== "running") {
                    await resumeAudioContext();
                }
                console.log("[ensureAudioContextState] AudioContext state:", audioCtx.state);
            }
        
            // Reset playback state variables
            function resetPlaybackState() {
                currentSequence = 0;
                currentStep = 0;
                isReversePlay = false;
                nextNoteTime = 0;
                console.log("[resetPlaybackState] Playback state reset.");
            }
        
            // Normalize the audio buffer
            function normalizeBuffer(e, t = 0.9) {
                if (!(e instanceof AudioBuffer)) {
                    console.error("[normalizeBuffer] Invalid buffer provided.");
                    return e;
                }
        
                const numberOfChannels = e.numberOfChannels;
                let maxAmplitude = 0;
                for (let t = 0; t < numberOfChannels; t++) {
                    const channelData = e.getChannelData(t);
                    for (let i = 0; i < channelData.length; i++) {
                        const amplitude = Math.abs(channelData[i]);
                        if (amplitude > maxAmplitude) {
                            maxAmplitude = amplitude;
                        }
                    }
                }
                const normalizationFactor = t / maxAmplitude;
        
                if (normalizationFactor !== 1) {
                    for (let t = 0; t < numberOfChannels; t++) {
                        const channelData = e.getChannelData(t);
                        for (let i = 0; i < channelData.length; i++) {
                            channelData[i] *= normalizationFactor;
                        }
                    }
                    console.log("[normalizeBuffer] Buffer normalized.");
                }
        
                return e;
            }
        
            // Load and normalize audio from a given URL
            async function loadAndNormalizeAudio(e) {
                try {
                    console.log(`[loadAndNormalizeAudio] Fetching audio from ${e}`);
                    const t = await fetch(e);
                    if (!t.ok) throw new Error(`Network response was not ok for ${e}: ${t.statusText}`);
                    const arrayBuffer = await t.arrayBuffer();
                    const decodedBuffer = await audioCtx.decodeAudioData(arrayBuffer);
                    console.log("[loadAndNormalizeAudio] Audio successfully decoded and normalized.");
                    return normalizeBuffer(decodedBuffer);
                } catch (t) {
                    console.error(`[loadAndNormalizeAudio] Error loading or decoding audio from ${e}:`, t);
                    throw t;
                }
            }
        
            // Wait for AudioContext to be in the 'running' state
            async function waitForAudioContext() {
                if (audioCtx.state === "running") return;
                return new Promise((resolve, reject) => {
                    const onStateChange = () => {
                        if (audioCtx.state === "running") {
                            audioCtx.removeEventListener("statechange", onStateChange);
                            resolve();
                        } else if (audioCtx.state === "closed") {
                            audioCtx.removeEventListener("statechange", onStateChange);
                            reject(new Error("AudioContext was closed."));
                        }
                    };
                    audioCtx.addEventListener("statechange", onStateChange);
                });
            }
        
            // Play the buffer with specified trim times
            function playBuffer(buffer, { startTrim, endTrim }, index, startTime) {
                if (!buffer || !(buffer instanceof AudioBuffer)) {
                    console.error("[playBuffer] Invalid audio buffer provided.");
                    return;
                }
        
                // Clamp trim times
                startTrim = Math.max(0, Math.min(startTrim, 1));
                endTrim = Math.max(startTrim, Math.min(endTrim, 1));
        
                const normalizedBuffer = normalizeBuffer(buffer);
                const bufferSource = audioCtx.createBufferSource();
                bufferSource.buffer = normalizedBuffer;
                bufferSource.playbackRate.value = globalPlaybackSpeeds[index] || 1;
        
                const gainNode = audioCtx.createGain();
                const gainValue = parseVolumeLevel(globalVolumeLevels[index] || defaultVolume) * globalVolumeMultiplier;
                const currentTime = audioCtx.currentTime;
        
                gainNode.gain.cancelScheduledValues(currentTime);
                gainNode.gain.setValueAtTime(0, currentTime);
                gainNode.gain.linearRampToValueAtTime(gainValue, currentTime + fadeDuration);
        
                bufferSource.connect(gainNode);
                gainNode.connect(audioCtx.destination);
        
                const startPosition = startTrim * normalizedBuffer.duration;
                const duration = (endTrim - startTrim) * normalizedBuffer.duration;
                bufferSource.start(startTime, startPosition, duration);
                
                console.log(`[playBuffer] Buffer playing at index ${index}, startTime: ${startTime}, duration: ${duration}`);
        
                activeSources[index] = activeSources[index] || [];
                activeSources[index].push({ source: bufferSource, gainNode });
        
                bufferSource.onended = () => {
                    activeSources[index] = activeSources[index].filter(({ source }) => source !== bufferSource);
                    console.log(`[playBuffer] Buffer finished playing at index ${index}.`);
                };
            }
        
            // Load multiple audio files
            const audioBuffers = {};
            async function loadMultipleAudio(urls) {
                const promises = urls.map(async (url, index) => {
                    try {
                        const buffer = await loadAndNormalizeAudio(url);
                        audioBuffers[index] = buffer;
                        console.log(`[loadMultipleAudio] Successfully loaded audio at index ${index}`);
                    } catch (e) {
                        console.error(`[loadMultipleAudio] Failed to load audio at index ${index}:`, e);
                    }
                });
                await Promise.all(promises);
            }
        
            // Example usage to load and play a single audio buffer
            (async () => {
                try {
                    await waitForAudioContext();
                    const buffer = await loadAndNormalizeAudio(audioUrl);
                    playBuffer(buffer, { startTrim: 0, endTrim: 1 }, 0, audioCtx.currentTime);
                } catch (e) {
                    console.error("[audioBuffering] Failed to load and play audio:", e);
                }
            })();</script></audiobuffering><processsteps><script>// Dispatch a custom event with details
        const dispatchSequenceEvent = (e, t) => {
            console.log(`[dispatchSequenceEvent] Event: ${e}`, t);
            document.dispatchEvent(new CustomEvent(e, { detail: t }));
        };

        // Play a sequence step
        const playSequenceStep = (e) => {
            if (!isReadyToPlay || !Object.keys(preprocessedSequences).length) 
                return console.error("[playSequenceStep] Sequence data unavailable.");
            
            const sequenceKeys = Object.keys(preprocessedSequences);
            currentSequence %= sequenceKeys.length;
            const sequenceData = preprocessedSequences[sequenceKeys[currentSequence]];
            
            if (currentStep === 0) {
                console.log(`[${(new Date).toISOString()}] Now playing sequence ${currentSequence}`);
                logChannelAddition();
            }

            sequenceData ? playSteps(sequenceData.normalSteps, e) || playSteps(sequenceData.reverseSteps, e, true)
                         : console.error(`[playSequenceStep] No data for ${sequenceKeys[currentSequence]}`);
            
            incrementStepAndSequence(sequenceKeys.length);
        };

        // Play steps for normal or reverse sequences
        const playSteps = (stepData, stepTime, reverse = false) => {
            if (stepData && typeof stepData === "object") {
                Object.entries(stepData).forEach(([channel, steps]) => {
                    if (Array.isArray(steps)) {
                        const currentStepData = steps.find(step => step.step === currentStep);
                        currentStepData && playChannelStep(channel, currentStepData, stepTime, reverse);
                    } else {
                        console.error(`[playSteps] Expected array for channel "${channel}", got:`, steps);
                    }
                });
            } else {
                console.error("[playSteps] Invalid steps data:", stepData);
            }
        };

        // Play an individual channel step
        const playChannelStep = (channel, stepData, stepTime, reverse) => {
            const bufferEntry = globalAudioBuffers.find(buffer => buffer.channel === channel);
            const trimTimes = globalTrimTimes[channel];
            
            if (bufferEntry?.buffer && trimTimes) {
                const buffer = reverse ? globalReversedAudioBuffers[channel] : bufferEntry.buffer;
                const calculatedTrimTimes = reverse ? calculateReversedTrimTimes(trimTimes) : trimTimes;

                playBuffer(buffer, calculatedTrimTimes, channel, stepTime);
                notifyVisualizer(parseInt(channel.slice(8)) - 1, stepData.step);
            } else {
                console.error(`[playChannelStep] No buffer or trim times for channel ${channel}`);
            }
        };

        // Schedule notes for the audio context
        const scheduleNotes = () => {
            const currentTime = audioCtx.currentTime;
            console.log(`[scheduleNotes] Scheduling. Current time: ${currentTime}`);

            for (nextNoteTime = Math.max(nextNoteTime, currentTime); nextNoteTime < currentTime + 0.1;) {
                playSequenceStep(nextNoteTime);
                if (audioCtx.currentTime > nextNoteTime) {
                    console.warn(`[scheduleNotes] Missed note at ${nextNoteTime.toFixed(3)}, current time: ${audioCtx.currentTime.toFixed(3)}.`);
                }
                nextNoteTime += getStepDuration();
                console.log(`[scheduleNotes] Next note scheduled at: ${nextNoteTime}`);
            }
        };

        // Increment step and sequence and dispatch event
        const incrementStepAndSequence = (sequenceLength) => {
            currentStep = (currentStep + 1) % 64;
            if (currentStep === 0) currentSequence = (currentSequence + 1) % sequenceLength;
            dispatchSequenceEvent("sequenceUpdated", { currentSequence, currentStep });
            console.log(`[incrementStepAndSequence] Sequence: ${currentSequence}, Step: ${currentStep}`);
        };

        // Log channel addition if available
        const logChannelAddition = () => {
            const logEntry = globalJsonData?.channelAdditionLog?.find(entry => entry.sequenceNumber === currentSequence);
            if (logEntry) {
                const { channelsAdded, totalChannels } = logEntry;
                console.log(`Added ${channelsAdded} channel(s) at sequence ${currentSequence} (total ${totalChannels} channels).`);
            }
        };</script></processsteps><audiowebworkers><script>const LOOKAHEAD = 0.1, SCHEDULE_INTERVAL = 50;
        let audioWorker, lastBPM, workerUrl;

        // Debounce function to prevent frequent worker updates
        const debounce = (func, wait) => {
            let timeout;
            return (...args) => {
                clearTimeout(timeout);
                timeout = setTimeout(() => func(...args), wait);
            };
        };

        // Worker blob code
        const workerBlob = `
            self.onmessage = e => {
                const { action, stepDuration, lookahead, scheduleInterval } = e.data;
                let timerID = null, workloadTimerID = null, scheduleNotesCount = 0;

                const startScheduling = (sd, la, si) => {
                    clearInterval(timerID);
                    clearInterval(workloadTimerID);
                    timerID = setInterval(() => {
                        self.postMessage({ action: 'scheduleNotes' });
                        scheduleNotesCount++;
                    }, si);
                    workloadTimerID = setInterval(() => {
                        self.postMessage({ action: 'audioWorkerWorkloadDebug', scheduleNotesCount });
                        scheduleNotesCount = 0;
                    }, 1000);
                };

                if (action === 'start') startScheduling(stepDuration, lookahead, scheduleInterval);
                else if (action === 'stop') clearInterval(timerID), clearInterval(workloadTimerID);
                else if (action === 'updateStepDuration') stepDuration = e.data.stepDuration;
                else console.warn("[Worker] Unknown action:", action);
            };
        `;

        // Initialize the Web Worker
        const initializeWorker = () => {
            if (!window.Worker) return console.error("[AudioWorker] Web Workers not supported.");
            if (audioWorker) return console.warn("[AudioWorker] Worker already initialized.");

            workerUrl = URL.createObjectURL(new Blob([workerBlob], { type: "application/javascript" }));
            audioWorker = new Worker(workerUrl);
            audioWorker.onmessage = handleWorkerMessage;

            window.addEventListener("bpmChanged", debounce(updateWorkerStepDuration, 100));
            console.log("[AudioWorker] Worker initialized.");
        };

        // Handle messages from the Web Worker
        const handleWorkerMessage = ({ data: { action, message, scheduleNotesCount } }) => {
            if (action === "scheduleNotes") scheduleNotes?.();
            else if (action === "audioWorkerWorkloadDebug") 
                console.log(`[audioWorkerWorkloadDebug] Messages sent: ${scheduleNotesCount}`);
            else if (action === "error") console.error("[AudioWorker] Worker Error:", message);
            else console.warn("[AudioWorker] Unknown action from worker:", action);
        };

        // Start the Web Worker
        const startWorker = () => {
            if (!audioWorker) return console.error("[AudioWorker] Initialize worker first.");
            audioWorker.postMessage({ action: "start", stepDuration: getStepDuration(), lookahead: LOOKAHEAD, scheduleInterval: SCHEDULE_INTERVAL });
        };

        // Stop the Web Worker
        const stopWorker = () => audioWorker?.postMessage({ action: "stop" });

        // Get the step duration based on BPM
        const getStepDuration = () => {
            const bpm = window.globalJsonData?.projectBPM || 120;
            if (bpm !== lastBPM) console.log(`[getStepDuration] BPM changed: ${lastBPM} -> ${bpm}`);
            lastBPM = bpm;
            return 60 / (4 * bpm);
        };

        // Clean up the Web Worker and AudioContext on unload
        const cleanUpWorker = async () => {
            audioWorker?.terminate();
            audioWorker = null;
            workerUrl && URL.revokeObjectURL(workerUrl);
            typeof audioCtx !== "undefined" && audioCtx.state !== "closed" && await audioCtx.close();
            window.removeEventListener("bpmChanged", updateWorkerStepDuration);
            console.log("[AudioWorker] Cleanup completed.");
        };

        // Update worker's step duration when BPM changes
        const updateWorkerStepDuration = () => {
            audioWorker?.postMessage({ action: "updateStepDuration", stepDuration: getStepDuration() });
        };

        // Event listeners
        window.addEventListener("beforeunload", cleanUpWorker);
        document.getElementById("loadVisualizerButton")?.addEventListener("click", initializeWorker);
        document.getElementById("visualizerCanvas")?.addEventListener("click", startWorker);</script></audiowebworkers><visualizerloading><script>// ============================
        // Reset Visual State Functions
        // ============================

        /**
         * Resets the visual state to its initial configuration.
         */
        function resetVisualState() {
            if (typeof cci2 !== "undefined" && typeof initialCCI2 !== "undefined") {
                cci2 = initialCCI2;
            }
            isChannel11Active = false;
            isPlaybackActive = false;
            activeChannelIndex = null;
            activeArrayIndex = {};
            renderingState = {};

            if (typeof immediateVisualUpdate === "function") {
                immediateVisualUpdate();
            }
        }

        /**
         * Resets all states including playback and visual states.
         */
        function resetAllStates() {
            resetPlaybackState();
            resetVisualState();
        }

        // ============================
        // Notify Visualizer Function
        // ============================

        /**
         * Notifies the visualizer of the active step in a specific channel.
         * @param {number} channelIndex - The index of the channel.
         * @param {number} step - The current step.
         */
        function notifyVisualizer(channelIndex, step) {
            const message = { action: "activeStep", channelIndex, step };
            AudionalPlayerMessages.postMessage(message);
            document.dispatchEvent(new CustomEvent("internalAudioPlayback", { detail: message }));
        }

        // ============================
        // Script Loading Functions
        // ============================

        /**
         * Dynamically loads a single script.
         * @param {string} src - The source URL of the script to load.
         * @returns {Promise<void>}
         */
        function loadScript(src) {
            return new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.src = src;
                script.async = true;
                script.onload = () => {
                    console.log(`Loaded: ${src}`);
                    resolve();
                };
                script.onerror = () => {
                    console.error(`Failed to load script: ${src}`);
                    reject(new Error(`Failed to load script: ${src}`));
                };
                document.body.appendChild(script);
            });
        }

        /**
         * Loads an array of scripts sequentially.
         * @param {string[]} scriptUrls - Array of script URLs to load.
         * @param {string} scriptType - Type of scripts being loaded (for logging purposes).
         * @returns {Promise<void>}
         */
        async function loadScriptsSequentially(scriptUrls, scriptType) {
            for (const url of scriptUrls) {
                try {
                    await loadScript(url);
                } catch (error) {
                    console.error(`Error loading ${scriptType} script ${url}:`, error);
                    // Decide whether to continue loading other scripts or abort
                }
            }
            console.log(`All ${scriptType} scripts loaded successfully.`);
        }

        /**
         * Loads all visualizer scripts.
         * @returns {Promise<void>}
         */
        async function loadVisualiserScripts() {
            const scriptUrls = window.visualizerScripts || [];
            await loadScriptsSequentially(scriptUrls, "visualizer");
        }

        /**
         * Loads all artwork scripts.
         * @returns {Promise<void>}
         */
        async function loadArtworkScripts() {
            const scriptUrls = window.artworkScripts || [];
            await loadScriptsSequentially(scriptUrls, "artwork");
        }

        // ============================
        // Script Arrays Configuration
        // ============================

        // Define the array of artwork scripts to load
        window.artworkScripts = [
            // Add artwork script URLs here if any
        ];

        // Define the array of visualizer scripts to load
        window.visualizerScripts = [
            "/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0", // colourPalette.js
            "/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0", // colourSettingsaMaster
            "/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0", // colourSettingsLevel0.js
            "/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0", // colourSettingsLevel1 
            "/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0", // colourSettingsLevel2
            "/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0", // colourSettingsLevel3
            "/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0", // colourSettingsLevel4
            "/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0", // colourSettingsLevel5
            "/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0", // colourSettingsLevel6
            "/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0", // colourSettingsLevel7
            "/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0", // colourSettingsLevel8
            "/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0", // initVisualiser.js
            "/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0", // visualiserLogging.js
            "/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0", // visualiserMessageHandling_minified.js
            "/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0", // visualiserWorkers.js
            "/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0", // visualiserGeometry.js
            "/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0", // visualiserDrawingColours.js
            "/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0"  // PFP module
        ];

        // ============================
        // Visualizer Initialization
        // ============================

        /**
         * Initializes the visualizer or artwork application based on visualiserMode.
         */
        (async function initializeVisualizer() {
            // Create and configure the canvas element
            const canvas = document.createElement("canvas");
            canvas.id = "cv";
            document.body.appendChild(canvas);
            Object.assign(document.body.style, {
                display: "flex",
                justifyContent: "center",
                alignItems: "center",
                height: "100vh",
                margin: "0"
            });

            /**
             * Core initialization function.
             */
            const coreInit = async () => {
                window.cci2 = 0;
                window.initialCCI2 = 0;

                // Reset all states
                if (typeof resetAllStates === "function") {
                    resetAllStates();
                } else {
                    console.warn("Function resetAllStates is not defined.");
                }

                // Load JSON data
                if (typeof loadJsonFromUrl === "function") {
                    loadJsonFromUrl(window.jsonDataUrl);
                } else {
                    console.warn("Function loadJsonFromUrl is not defined.");
                }

                // Initialize Web Workers or other background tasks
                if (typeof initializeWorker === "function") {
                    initializeWorker();
                } else {
                    console.warn("Function initializeWorker is not defined.");
                }

                // Load scripts based on visualiserMode
                if (window.visualiserMode) {
                    if (typeof loadVisualiserScripts === "function") {
                        await loadVisualiserScripts();
                        if (typeof window.log === "function") {
                            window.log("Visualizer scripts loaded.");
                        } else {
                            console.log("Visualizer scripts loaded.");
                        }
                    } else {
                        console.warn("loadVisualiserScripts function is not defined.");
                    }
                } else {
                    if (typeof loadArtworkScripts === "function") {
                        await loadArtworkScripts();
                        if (typeof window.log === "function") {
                            window.log("Artwork scripts loaded.");
                        } else {
                            console.log("Artwork scripts loaded.");
                        }
                    } else {
                        console.warn("loadArtworkScripts function is not defined.");
                    }
                }
            };

            try {
                // Wait until window.jsonDataUrl is available
                await new Promise((resolve) => {
                    const checkJsonDataUrl = () => {
                        if (window.jsonDataUrl) {
                            resolve();
                        } else {
                            setTimeout(checkJsonDataUrl, 100);
                        }
                    };
                    checkJsonDataUrl();
                });

                console.log("Fetching from URL:", window.jsonDataUrl);

                // Fetch and load settings
                const response = await fetch(window.jsonDataUrl);
                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }
                window.settings = await response.json();
                console.log("Settings loaded:", window.settings);

                // Ensure the AudioContext is in the correct state
                if (typeof ensureAudioContextState === "function") {
                    await ensureAudioContextState();
                } else {
                    console.warn("Function ensureAudioContextState is not defined.");
                }

                // Initialize when the document is ready
                if (document.readyState === "loading") {
                    document.addEventListener("DOMContentLoaded", coreInit);
                } else {
                    await coreInit();
                }
            } catch (error) {
                console.error("Error initializing the app:", error);
            }

            console.log(`[${new Date().toISOString()}] [debugScriptLoading] ScriptLoader initialized.`);
        })();</script></visualizerloading></html>