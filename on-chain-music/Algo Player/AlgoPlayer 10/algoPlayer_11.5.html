<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Test</title>
</head>
<body>
    <h1>Web3 Audio Sequencer Playback Engine Test</h1>
    <p>Check the console for the 2D array of songs and channels with metadata.</p>

    <SectionOne>
        <!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->

        <script>
            // ---------------------- Global Data ---------------------- //
            window.globalData = window.globalData || {
                isSingleSong: false,
                isMultipleSongs: false,
                songsArray: [],
                audioBuffers: {},
                reverseAudioBuffers: {}
            };

            // ---------------------- Configuration ---------------------- //

            // Key mapping for deserialization process
            const keyMap = {
                0: "projectName",
                1: "artistName",
                2: "projectBPM",
                3: "currentSequence",
                4: "channelURLs",
                5: "channelVolume",
                6: "channelPlaybackSpeed",
                7: "trimSettings",
                8: "projectChannelNames",
                9: "startSliderValue",
                10: "endSliderValue",
                11: "totalSampleDuration",
                12: "start",
                13: "end",
                14: "projectSequences",
                15: "steps"
            };

            // Reverse keyMap for reverse lookup
            const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([k, v]) => [v, +k]));

            // Map of letters 'A' to 'Z' representing channels and their reverse
            const channelMap = Array.from({ length: 26 }, (_, i) => String.fromCharCode(65 + i));
            const reverseChannelMap = Object.fromEntries(channelMap.map((letter, i) => [letter, i]));

            // ---------------------- Utility Functions ---------------------- //

            /** Dynamically import the Pako library from the new Web3 address. */
            const loadPako = async () => {
                try {
                    const pakoModule = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
                    window.pako = pakoModule.default || pakoModule;
                } catch (error) {
                    console.error("Error loading Pako library:", error);
                    throw error;
                }
            };

            /** Decompress the steps data. */
            const decompressSteps = (steps) => steps.flatMap(step => {
                if (typeof step === "number") return step;
                if (step?.r) {
                    const [start, end] = step.r;
                    return Array.from({ length: end - start + 1 }, (_, i) => start + i);
                }
                if (typeof step === "string" && step.endsWith("r")) {
                    return { index: parseInt(step.slice(0, -1), 10), reverse: true };
                }
                return [];
            });

            /** Deserialize the fetched JSON data using the provided keyMap. */
            const deserialize = (data) => {
                const recursiveDeserialize = (obj) => {
                    if (Array.isArray(obj)) return obj.map(recursiveDeserialize);
                    if (obj && typeof obj === "object") {
                        return Object.entries(obj).reduce((acc, [key, value]) => {
                            const mappedKey = keyMap[key] || key;
                            if (mappedKey === "projectSequences") {
                                acc[mappedKey] = Object.entries(value).reduce((seqAcc, [seqKey, seqValue]) => {
                                    const sequenceName = `Sequence${seqKey.replace(/^s/, "")}`;
                                    seqAcc[sequenceName] = Object.entries(seqValue).reduce((trackAcc, [trackKey, trackValue]) => {
                                        const channelName = `ch${reverseChannelMap[trackKey]}`;
                                        const steps = trackValue[reverseKeyMap.steps] || [];
                                        trackAcc[channelName] = { steps: decompressSteps(steps) };
                                        return trackAcc;
                                    }, {});
                                    return seqAcc;
                                }, {});
                            } else {
                                acc[mappedKey] = recursiveDeserialize(value);
                            }
                            return acc;
                        }, {});
                    }
                    return obj;
                };
                return recursiveDeserialize(data);
            };

            /** Fetch and deserialize data from a given URL. */
            const fetchAndDeserialize = async (url) => {
                try {
                    const response = await fetch(url);
                    if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                    const arrayBuffer = await response.arrayBuffer();
                    const inflatedData = window.pako.inflate(new Uint8Array(arrayBuffer));
                    const jsonString = new TextDecoder("utf-8").decode(inflatedData);
                    return deserialize(JSON.parse(jsonString));
                } catch (error) {
                    console.error(`Error fetching/deserializing URL ${url}:`, error);
                    throw error;
                }
            };

            /** Fetch and process multiple URLs concurrently. */
            const fetchAndProcessData = async (urls) => {
                const fetchPromises = urls.map(url => fetchAndDeserialize(url).catch(error => {
                    console.error(`Failed to process URL ${url}:`, error);
                    return null;
                }));
                const results = (await Promise.all(fetchPromises)).filter(Boolean);
                if (!results.length) throw new Error("No valid data was processed.");
                return results;
            };

            /** Process the deserialized data to extract songs and their channels with metadata. */
            const processSongsAndChannels = (deserializedData) => {
                const songsArray = deserializedData.map((songData, songIndex) => {
                    const {
                        projectName = `Song_${songIndex + 1}`,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = songData;

                    const channels = Array.from({ length: 16 }, (_, i) => ({
                        id: channelMap[i] || `Channel_${i + 1}`,
                        url: channelURLs[i] || `URL_not_found`,
                        metadata: {
                            volume: channelVolume[i] ?? 1.0,
                            playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                            trimStartTime: trimSettings[i]?.start || 0,
                            trimEndTime: trimSettings[i]?.end || 0
                        }
                    }));

                    return {
                        id: projectName,
                        totalSequences: Object.keys(projectSequences).length,
                        channels,
                        projectSequences
                    };
                });

                window.globalData.songsArray = songsArray;
                return songsArray;
            };

            /** Log the structured 2D array of songs and channels with metadata. */
            const logSongsArray = (songsArray) => {
                console.log(`Total Songs: ${songsArray.length}`);
                songsArray.forEach((song, songIndex) => {
                    console.log(`\nSong #${songIndex + 1}: ${song.id} - Total Sequences: ${song.totalSequences}`);
                    song.channels.forEach((channel, channelIndex) => {
                        const { volume, playbackSpeed, trimStartTime, trimEndTime } = channel.metadata;
                        console.log(
                            `\tChannel ${channelIndex + 1} - ${channel.id}, ` +
                            `Volume: ${volume}, Playback Speed: ${playbackSpeed}, ` +
                            `Trim Start Time: ${trimStartTime}, Trim End Time: ${trimEndTime}`
                        );
                    });
                    const projectSequencesJSON = JSON.stringify(song.projectSequences, null, 2);
                    console.log(`\tProject Sequences for ${song.id}:\n${projectSequencesJSON}`);
                });

                window.globalData.isSingleSong = songsArray.length === 1;
                window.globalData.isMultipleSongs = songsArray.length > 1;
                console.log(`\nFlags set - isSingleSong: ${window.globalData.isSingleSong}, isMultipleSongs: ${window.globalData.isMultipleSongs}`);

                // Dispatch a custom event to notify that data loading is complete
                document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
                    detail: {
                        success: true,
                        totalSongs: songsArray.length,
                        songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
                    }
                }));
            };

            // ---------------------- Initialization ---------------------- //

            /** Initialize the data processing workflow. */
            (async () => {
                const songDataUrls = [
                    "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0" // TRUTH
                ];

                const validSongUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
                if (validSongUrls.length) {
                    try {
                        await loadPako();
                        const deserializedData = await fetchAndProcessData(validSongUrls);
                        const songsArray = processSongsAndChannels(deserializedData);
                        logSongsArray(songsArray);
                    } catch (error) {
                        console.error('Error during initialization:', error);
                    }
                } else {
                    console.log('No valid song data URLs to process.');
                }
            })();
        </script>

        <!-- By the end of Section 1, all song data is arranged in a 2D array of channels along with their metadata -->
    </SectionOne>

    <sectionTwo>
        <!-- Section 2 - Audio Buffering and Mapping -->

        <script>
            // ---------------------- Audio Buffering and Mapping ---------------------- //

            // Ensure that globalData exists
            window.globalData = window.globalData || {
                songsArray: [],
                audioBuffers: {},
                reverseAudioBuffers: {}
            };

            const audioContext = window.globalData.audioContext || new (window.AudioContext || window.webkitAudioContext)();
            window.globalData.audioContext = audioContext;

            /** Convert base64 encoded data to an ArrayBuffer. */
            const base64ToArrayBuffer = (base64) => {
                const binaryString = atob(base64);
                const bytes = Uint8Array.from(binaryString, char => char.charCodeAt(0));
                return bytes.buffer;
            };

            /** Extract base64 encoded audio data from an HTML response. */
            const extractBase64FromHTML = (html) => {
                const parser = new DOMParser();
                const doc = parser.parseFromString(html, "text/html");
                const audioSrc = doc.querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");
                return audioSrc && audioSrc.includes("base64") ? audioSrc : null;
            };

            /** Fetch and decode the audio data based on the content type. */
            const fetchAndDecodeAudio = async (response, contentType) => {
                if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    return audioContext.decodeAudioData(arrayBuffer);
                }

                const textData = await response.text();
                let base64Data = null;

                if (/application\/json/.test(contentType)) {
                    base64Data = JSON.parse(textData).audioData;
                } else if (/text\/html/.test(contentType)) {
                    base64Data = extractBase64FromHTML(textData);
                }

                if (base64Data) {
                    const audioBuffer = base64ToArrayBuffer(base64Data.split(",")[1]);
                    return audioContext.decodeAudioData(audioBuffer);
                }

                if (/audio\//.test(contentType)) {
                    const arrayBuffer = await response.arrayBuffer();
                    return audioContext.decodeAudioData(arrayBuffer);
                }

                throw new Error("Unsupported content type");
            };

            const reverseArray = (array) => {
                const len = array.length;
                const reversed = new Float32Array(len);
                for (let i = 0; i < len; i++) {
                    reversed[i] = array[len - i - 1];
                }
                return reversed;
            };

            /** Create a reverse audio buffer from the provided audio buffer. */
            const createReverseAudioBuffer = (audioBuffer) => {
                const reverseBuffer = audioContext.createBuffer(
                    audioBuffer.numberOfChannels,
                    audioBuffer.length,
                    audioBuffer.sampleRate
                );

                for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
                    const originalData = audioBuffer.getChannelData(channel);
                    const reversedData = reverseBuffer.getChannelData(channel);

                    // Reverse the original data safely
                    const reversedArray = reverseArray(originalData);

                    // Set the reversed data into the reverse buffer
                    reversedData.set(reversedArray);
                }

                return reverseBuffer;
            };


            /** Process all audio channels to create audio buffers and reverse buffers. */
            const processAllAudioChannels = async () => {
                const { songsArray, audioBuffers, reverseAudioBuffers } = window.globalData;
                if (!songsArray.length) return console.error("No songs available to process.");

                for (const song of songsArray) {
                    audioBuffers[song.id] = {};
                    reverseAudioBuffers[song.id] = {};

                    for (const channel of song.channels) {
                        try {
                            const response = await fetch(channel.url);
                            if (!response.ok) throw new Error(`Network response was not ok for URL: ${channel.url}`);
                            const audioBuffer = await fetchAndDecodeAudio(response, response.headers.get("Content-Type"));
                            audioBuffers[song.id][channel.id] = audioBuffer;
                            reverseAudioBuffers[song.id][channel.id] = createReverseAudioBuffer(audioBuffer);
                            console.log(`Processed audio for Song: ${song.id}, Channel: ${channel.id}`);
                        } catch (error) {
                            console.error(`Failed to process audio for Song: ${song.id}, Channel: ${channel.id}`, error);
                        }
                    }
                }

                console.log("All audio buffers and reverse audio buffers have been created and mapped.");
                document.dispatchEvent(new CustomEvent("audioBuffersReady", { detail: { success: true } }));
            };

            // ---------------------- Initialization for Section Two ---------------------- //

            /** Initialize the audio processing workflow. */
            const initAudioProcessing = async () => {
                await processAllAudioChannels();
            };

            // Listen for the completion of data loading and processing from Section One
            document.addEventListener("dataLoadingComplete", initAudioProcessing);

            // If Section One already processed data, initiate audio processing
            if (window.globalData.songsArray.length) initAudioProcessing();
        </script>

        <!-- By the end of Section 2, all audio buffers and reverse audio buffers are created and mapped -->
    </sectionTwo>

    <sectionThree>
        <!-- Section 3 - Playback Engine -->
        <!-- This section handles playback of the sequenced audio based on sequences, channels, and steps -->
    
        <script>
            // ---------------------- Playback Engine ---------------------- //
    
            const selectedBPM = 120;
    
            /**
             * Initialize the playback engine.
             * This function is called after audio buffers are ready and sets up necessary variables.
             */
            const initPlaybackEngine = () => {
                const { songsArray } = window.globalData;
                if (!songsArray.length) {
                    console.error("No songs available for playback.");
                    return;
                }
    
                console.log("Playback Engine Initialization Complete.");
                console.log("Playback is ready. Press 'p' to start.");
            };
    
            /**
             * Start the playback engine.
             * This function schedules all playback steps and starts the audio context.
             */
            const startPlayback = () => {
                const { songsArray, audioBuffers, reverseAudioBuffers, audioContext } = window.globalData;
                if (!songsArray.length) {
                    console.error("No songs available for playback.");
                    return;
                }
    
                const song = songsArray[0];
                const sequences = song.projectSequences || {};
                console.log(`Starting playback for Song: ${song.id} with ${Object.keys(sequences).length} sequences.`);
    
                // Calculate step duration based on BPM
                // Since there are 4 steps per beat, stepDuration = (60 / BPM) / 4
                const stepsPerBeat = 4;
                const stepDuration = (60 / selectedBPM) / stepsPerBeat;
    
                // Start time for playback
                let currentTime = audioContext.currentTime;
    
                // Iterate through each sequence
                for (const [sequenceName, sequence] of Object.entries(sequences)) {
                    console.log(`Scheduling ${sequenceName} for Song: ${song.id}`);
    
                    // Iterate over each of the 64 steps in the sequence
                    for (let stepIndex = 0; stepIndex < 64; stepIndex++) {
                        const stepTime = currentTime + stepIndex * stepDuration;
    
                        // Iterate over each channel (track) in the sequence
                        for (const [trackName, trackData] of Object.entries(sequence)) {
                            const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                            const channel = song.channels[channelIndex];
    
                            if (!channel) {
                                console.warn(`Channel ${trackName} not found in song ${song.id}.`);
                                continue;
                            }
    
                            const steps = trackData.steps || [];
    
                            // Check if this stepIndex is in the steps array
                            const step = steps.find(s => {
                                if (typeof s === "number") {
                                    return s === stepIndex;
                                } else if (typeof s === "object" && s.index !== undefined) {
                                    return s.index === stepIndex;
                                }
                                return false;
                            });
    
                            if (step !== undefined) {
                                const reverse = (typeof step === "object" && step.reverse) || false;
                                schedulePlayback(song, channel, stepTime, reverse);
                            }
                        }
                    }
    
                    // Update currentTime to account for the sequence duration
                    currentTime += 64 * stepDuration;
                }
    
                // Resume AudioContext if suspended (required in some browsers)
                if (audioContext.state === 'suspended') {
                    audioContext.resume();
                }
    
                console.log('Playback started.');
            };
    
            /**
             * Schedule playback for a channel at a specific time.
             * @param {Object} song - The song object.
             * @param {Object} channel - The channel object.
             * @param {number} time - The time at which to play the step.
             * @param {boolean} reverse - Whether to play in reverse.
             */
            const schedulePlayback = (song, channel, time, reverse = false) => {
                const { audioBuffers, reverseAudioBuffers, audioContext } = window.globalData;
                const buffer = reverse ? reverseAudioBuffers[song.id][channel.id] : audioBuffers[song.id][channel.id];
    
                if (!buffer) {
                    console.error(`Audio buffer for Song: ${song.id}, Channel: ${channel.id} not found.`);
                    return;
                }
    
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.playbackRate.value = channel.metadata.playbackSpeed;
                source.connect(audioContext.destination);
                source.start(time);
                console.log(`    Scheduled ${reverse ? 'reverse ' : ''}playback for Channel: ${channel.id} at time ${time.toFixed(2)}s.`);
            };
    
            // ---------------------- Initialization for Section Three ---------------------- //
    
            /** Initialize the playback engine after audio buffers are ready. */
            const initializePlayback = () => {
                console.log("Audio buffers are ready. Playback can begin.");
                initPlaybackEngine();
            };
    
            /** Listener function for 'p' key to start playback */
            const onKeyPress = (event) => {
                if (event.key.toLowerCase() === 'p') {
                    startPlayback();
                    console.log('Playback started by user.');
                    document.removeEventListener('keydown', onKeyPress);
                }
            };
    
            // Listen for the completion of audio buffering and mapping from Section Two
            document.addEventListener("audioBuffersReady", () => {
                initializePlayback();
                console.log('Press "p" to start playback.');
                document.addEventListener('keydown', onKeyPress);
            });
    
            // If Section Two already processed audio buffers, initiate playback setup
            if (Object.keys(window.globalData.audioBuffers).length) {
                initializePlayback();
                console.log('Press "p" to start playback.');
                document.addEventListener('keydown', onKeyPress);
            };
    
            /**
             * Structure Explanation:
             * - A Sequence contains 64 steps.
             * - Each Sequence can contain any number of channels.
             * - Each channel in a sequence has steps where audio is played.
             * - Steps can be either:
             *   - A number representing the step index (0 to 63).
             *   - An object with 'index' and 'reverse' properties for reverse playback.
             * - There are 16 steps per bar, 4 steps per beat.
             * - Time per step is calculated based on BPM: stepDuration = (60 / BPM) / 4.
             * - Playback is scheduled step by step, ensuring synchronization with the step sequencer.
             * - Playback direction (normal or reverse) is determined by the 'reverse' property.
             */
        </script>
    
        <!-- By the end of Section 3, playback should be initialized and ready -->
    </sectionThree>
    
    

</body>
</html>
