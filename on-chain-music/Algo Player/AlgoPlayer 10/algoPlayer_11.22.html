<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Web3 Audio Sequencer Playback Engine Optimized</title>
  
    <script>
        const artworkUrl = ["/content/01c48d3cceb02215bc3d44f9a2dc7fba63ea63719a2ef1c35d3f0c4db93ab8d5i0"];
        const songDataUrls = [
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE ** MIGHT BE THIS ONE THAT IS OUT OF SYNC??

            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH

            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA

            "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM

            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress

            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP

            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY // Turn Down Channels 1 + 2 (Apollo 13) Turn down Channel 5 - Hindenburg /  Turn channel 8 up - Hi hats

            "/content/a4fb0b49181975450a6710f20128eb0b3acc51f4aa1ce87ebdbc9607562013a2i0", // MintyFresh Vibes

            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE

            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240

            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch

            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60

            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // ON-CHAIN IN THE MEMBRANE
        ];
        const globalData = window.globalData = {
            isSingleSong: false,
            isMultipleSongs: true,
            isNormalPlayer: true,
            isLoopedPlayback: false,
            isSequentialPlayback: true,
            isRemixPlayer: false,
            songsArray: [],
            audioBuffers: {},
            reverseAudioBuffers: {},
            audioFetchCache: new Map(),
            isArtworkCover: true,
            isVisualiserCover: false,
            initialSampleOrder: [],
            isPlaying: false,
            audioContext: new (window.AudioContext || window.webkitAudioContext)(),
        };
        function startPlayback() {
            document.dispatchEvent(new CustomEvent("startPlaybackRequested"));
        }
        function stopPlayback() {
            document.dispatchEvent(new CustomEvent("stopPlaybackRequested"));
        }
        document.addEventListener("playbackStarted", () => {
            globalData.isPlaying = true;
            console.log("Playback has started.");
        });
        document.addEventListener("playbackStopped", () => {
            // globalData.isPlaying = false;
            console.log("Playback has stopped.");
        });
    </script>
      <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0; padding: 0;
            display: flex; flex-direction: column;
            align-items: center; justify-content: center;
            height: 100vh; background-color: #000;
        }
        #artworkCover {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            background-color: rgba(0, 0, 0, 0.8);
            display: flex; justify-content: center; align-items: center;
            z-index: 1000; cursor: pointer; transition: opacity 0.3s ease;
        }
        #artworkCover.hidden { opacity: 0; pointer-events: none; }
        #artworkImage {
            max-width: 80%; max-height: 80%; object-fit: contain;
            border: 4px solid #fff; border-radius: 10px;
            box-shadow: 0 0 20px rgba(255, 255, 255, 0.5);
            cursor: pointer;
        }
        #loadingSpinner {
            position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%);
            border: 8px solid #f3f3f3; border-top: 8px solid #3498db;
            border-radius: 50%; width: 60px; height: 60px;
            animation: spin 2s linear infinite; z-index: 1001; display: none;
        }
        @keyframes spin {
            0% { transform: rotate(0deg) translate(-50%, -50%); }
            100% { transform: rotate(360deg) translate(-50%, -50%); }
        }
    </style>
</head>
<body>
    <h1>Audionals</h1>
    <div id="loadingSpinner"></div>
    <div id="artworkCover">
        <img id="artworkImage" src="" alt="Artwork Cover">
    </div>


 <!-- Section 1 - Load Song Files and Create 2D Channel Array with All Metadata -->
<!-- <section>
    <script>
    (async () => {
        // Configuration
        const keyMap = [
            "projectName",
            "artistName",
            "projectBPM",
            "currentSequence",
            "channelURLs",
            "channelVolume",
            "channelPlaybackSpeed",
            "trimSettings",
            "projectChannelNames",
            "startSliderValue",
            "endSliderValue",
            "totalSampleDuration",
            "start",
            "end",
            "projectSequences",
            "steps"
        ];
        const reverseKeyMap = keyMap.reduce((acc, key, idx) => ({ ...acc, [key]: idx }), {});
        const channelMap = Array.from({ length: 16 }, (_, i) => String.fromCharCode(65 + i)); // A-P
        const reverseChannelMap = channelMap.reduce((acc, ch, idx) => ({ ...acc, [ch]: idx }), {});

        // Utility Functions
        const loadPako = async () => {
            try {
                const { default: pako } = await import('/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0');
                window.pako = pako;
            } catch (error) {
                console.error("Error loading Pako library:", error);
                throw error;
            }
        };

        const decompressSteps = steps => steps.flatMap(step => {
            if (typeof step === "number") return step;
            if (step?.r) return Array.from({ length: step.r[1] - step.r[0] + 1 }, (_, i) => step.r[0] + i);
            if (typeof step === "string" && step.endsWith("r")) return { index: parseInt(step.slice(0, -1), 10), reverse: true };
            return [];
        });

        const deserialize = data => {
            const recurse = obj => Array.isArray(obj) ? obj.map(recurse) :
                obj && typeof obj === "object" ? Object.entries(obj).reduce((acc, [k, v]) => {
                    const key = keyMap[k] || k;
                    acc[key] = key === "projectSequences" ? Object.fromEntries(
                        Object.entries(v).map(([seqK, seqV]) => [
                            `Sequence${seqK.replace(/^s/, "")}`,
                            Object.fromEntries(
                                Object.entries(seqV).map(([trackK, trackV]) => [
                                    `ch${reverseChannelMap[trackK]}`,
                                    { steps: decompressSteps(trackV[reverseKeyMap.steps] || []) }
                                ])
                            )
                        ])
                    ) : recurse(v);
                    return acc;
                }, {}) : obj;
            return recurse(data);
        };

        const fetchAndDeserialize = async url => {
            try {
                const response = await fetch(url);
                if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
                const inflatedData = window.pako.inflate(new Uint8Array(await response.arrayBuffer()));
                return deserialize(JSON.parse(new TextDecoder("utf-8").decode(inflatedData)));
            } catch (error) {
                console.error(`Error fetching/deserializing URL ${url}:`, error);
                throw error;
            }
        };

        const fetchAndProcessData = async urls => {
            const results = await Promise.all(urls.map((url, idx) => fetchAndDeserialize(url)
                .then(data => ({ data, idx }))
                .catch(error => {
                    console.error(`Failed to process URL ${url}:`, error);
                    return null;
                })
            ));
            const validResults = results.filter(Boolean);
            if (!validResults.length) throw new Error("No valid data was processed.");
            return validResults;
        };

        const processSongsAndChannels = dataWithIndices => {
            const songsArray = dataWithIndices
                .sort((a, b) => a.idx - b.idx)
                .map(({ data, idx }) => {
                    const {
                        projectName = `Song_${idx + 1}`,
                        artistName = "Unknown Artist",
                        projectBPM = 120,
                        projectSequences = {},
                        channelURLs = [],
                        channelVolume = [],
                        channelPlaybackSpeed = [],
                        trimSettings = {}
                    } = data;

                    const channels = channelMap.map((ch, i) => ({
                        id: ch,
                        url: channelURLs[i] || `URL_not_found`,
                        metadata: {
                            volume: channelVolume[i] ?? 1.0,
                            playbackSpeed: channelPlaybackSpeed[i] ?? 1.0,
                            trimStartTime_Percentage: trimSettings[i]?.start || 0,
                            trimEndTime_Percentage: trimSettings[i]?.end || 100,
                            requiresReversal: Object.values(projectSequences).some(seq =>
                                Object.values(seq).some(track => track.steps.some(s => typeof s === 'object' && s.reverse))
                            )
                        }
                    }));

                    return {
                        id: `Song ${idx + 1}: ${projectName}`,
                        artist: artistName,
                        bpm: projectBPM,
                        totalSequences: Object.keys(projectSequences).length,
                        channels,
                        projectSequences
                    };
                });

            globalData.songsArray = songsArray;
            if (songsArray.length) globalData.initialSampleOrder = getInitialSampleOrder(songsArray[0]);
            return songsArray;
        };

        const getInitialSampleOrder = song => {
            const { projectSequences } = song;
            const sampleOrder = [];
            const sequences = Object.keys(projectSequences).sort().slice(0, 2);

            sequences.forEach(seqName => {
                const sequence = projectSequences[seqName];
                Object.values(sequence).slice(0, 16).forEach(({ steps }, chIdx) => {
                    steps.slice(0, 16).forEach(step => {
                        if (typeof step === "number" || (typeof step === "object" && step.index !== undefined)) {
                            const key = `${chIdx}_${step.reverse ? "r" : "f"}`;
                            if (!sampleOrder.some(item => `${item.channelId}_${item.reverse ? "r" : "f"}` === key)) {
                                sampleOrder.push({ channelId: `ch${chIdx}`, reverse: step.reverse || false });
                            }
                        }
                    });
                });
            });

            return sampleOrder;
        };

        const logSongsArray = songsArray => {
            console.log(`Total Songs: ${songsArray.length}`);
            songsArray.forEach(({ id, artist, bpm, totalSequences, channels, projectSequences }, idx) => {
                console.log(`\n${id} by ${artist} - BPM: ${bpm} - Total Sequences: ${totalSequences}`);
                channels.forEach(({ id: chId, metadata }, chIdx) => {
                    const { volume, playbackSpeed, trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } = metadata;
                    console.log(`\tChannel ${chIdx + 1} - ${chId}, Volume: ${volume}, Speed: ${playbackSpeed}, Trim: ${trimStartTime_Percentage}% - ${trimEndTime_Percentage}%, Reversal: ${requiresReversal}`);
                });
                console.log(`\tProject Sequences:\n${JSON.stringify(projectSequences, null, 2)}`);
            });

            if (globalData.initialSampleOrder.length) {
                console.log(`\nInitial Sample Order for ${songsArray[0].id}:`);
                globalData.initialSampleOrder.forEach(({ channelId, reverse }, idx) => {
                    console.log(`\t${idx + 1}. Channel: ${channelId}, Reverse: ${reverse}`);
                });
            }

            if (globalData.isArtworkCover && artworkUrl.length) {
                console.log(`\nArtwork URL(s):`, artworkUrl);
                displayArtworkCover(artworkUrl[0]);
            }

            globalData.isSingleSong = songsArray.length === 1;
            globalData.isMultipleSongs = songsArray.length > 1;
            console.log(`\nFlags - Single Song: ${globalData.isSingleSong}, Multiple Songs: ${globalData.isMultipleSongs}`);

            document.dispatchEvent(new CustomEvent("dataLoadingComplete", {
                detail: {
                    success: true,
                    totalSongs: songsArray.length,
                    songs: songsArray.map(({ id, totalSequences }) => ({ id, totalSequences }))
                }
            }));
        };

        const displayArtworkCover = url => {
            const artworkImage = document.getElementById('artworkImage');
            if (artworkImage) {
                artworkImage.src = url;
                artworkImage.parentElement.style.display = 'flex';
            } else {
                console.warn("Artwork cover elements not found.");
            }
        };

        // Initialization
        try {
            const validUrls = songDataUrls.filter(url => url.trim() && !url.trim().startsWith('//'));
            if (validUrls.length) {
                await loadPako();
                const deserializedDataWithIndices = await fetchAndProcessData(validUrls);
                const songsArray = processSongsAndChannels(deserializedDataWithIndices);
                logSongsArray(songsArray);
            } else {
                console.log('No valid song data URLs to process.');
            }
        } catch (error) {
            console.error('Initialization error:', error);
        }
    })();
    </script>
</section> -->

<section1Minified>
    <script>
    (async()=>{const e=["projectName","artistName","projectBPM","currentSequence","channelURLs","channelVolume","channelPlaybackSpeed","trimSettings","projectChannelNames","startSliderValue","endSliderValue","totalSampleDuration","start","end","projectSequences","steps"],t=e.reduce(((e,t,r)=>({...e,[t]:r})),{}),r=Array.from({length:16},((e,t)=>String.fromCharCode(65+t))),a=r.reduce(((e,t,r)=>({...e,[t]:r})),{}),o=async r=>{try{const o=await fetch(r);if(!o.ok)throw new Error(`Network response was not ok for URL: ${r}`);const n=window.pako.inflate(new Uint8Array(await o.arrayBuffer()));return(r=>{const o=r=>Array.isArray(r)?r.map(o):r&&"object"==typeof r?Object.entries(r).reduce(((r,[n,s])=>{const l=e[n]||n;return r[l]="projectSequences"===l?Object.fromEntries(Object.entries(s).map((([e,r])=>[`Sequence${e.replace(/^s/,"")}`,Object.fromEntries(Object.entries(r).map((([e,r])=>{return[`ch${a[e]}`,{steps:(o=r[t.steps]||[],o.flatMap((e=>"number"==typeof e?e:e?.r?Array.from({length:e.r[1]-e.r[0]+1},((t,r)=>e.r[0]+r)):"string"==typeof e&&e.endsWith("r")?{index:parseInt(e.slice(0,-1),10),reverse:!0}:[])))}];var o})))]))):o(s),r}),{}):r;return o(r)})(JSON.parse(new TextDecoder("utf-8").decode(n)))}catch(e){throw console.error(`Error fetching/deserializing URL ${r}:`,e),e}},n=e=>{const{projectSequences:t}=e,r=[];return Object.keys(t).sort().slice(0,2).forEach((e=>{const a=t[e];Object.values(a).slice(0,16).forEach((({steps:e},t)=>{e.slice(0,16).forEach((e=>{if("number"==typeof e||"object"==typeof e&&void 0!==e.index){const a=`${t}_${e.reverse?"r":"f"}`;r.some((e=>`${e.channelId}_${e.reverse?"r":"f"}`===a))||r.push({channelId:`ch${t}`,reverse:e.reverse||!1})}}))}))})),r},s=e=>{const t=document.getElementById("artworkImage");t?(t.src=e,t.parentElement.style.display="flex"):console.warn("Artwork cover elements not found.")};try{const e=songDataUrls.filter((e=>e.trim()&&!e.trim().startsWith("//")));if(e.length){await(async()=>{try{const{default:e}=await import("/content/fba6f95fb1152db43304a27dce8cb8c65509eba6ab0b6958cedeb33e5f443077i0");window.pako=e}catch(e){throw console.error("Error loading Pako library:",e),e}})();const t=await(async e=>{const t=(await Promise.all(e.map(((e,t)=>o(e).then((e=>({data:e,idx:t}))).catch((t=>(console.error(`Failed to process URL ${e}:`,t),null))))))).filter(Boolean);if(!t.length)throw new Error("No valid data was processed.");return t})(e);(e=>{console.log(`Total Songs: ${e.length}`),e.forEach((({id:e,artist:t,bpm:r,totalSequences:a,channels:o,projectSequences:n},s)=>{console.log(`\n${e} by ${t} - BPM: ${r} - Total Sequences: ${a}`),o.forEach((({id:e,metadata:t},r)=>{const{volume:a,playbackSpeed:o,trimStartTime_Percentage:n,trimEndTime_Percentage:s,requiresReversal:l}=t;console.log(`\tChannel ${r+1} - ${e}, Volume: ${a}, Speed: ${o}, Trim: ${n}% - ${s}%, Reversal: ${l}`)})),console.log(`\tProject Sequences:\n${JSON.stringify(n,null,2)}`)})),globalData.initialSampleOrder.length&&(console.log(`\nInitial Sample Order for ${e[0].id}:`),globalData.initialSampleOrder.forEach((({channelId:e,reverse:t},r)=>{console.log(`\t${r+1}. Channel: ${e}, Reverse: ${t}`)}))),globalData.isArtworkCover&&artworkUrl.length&&(console.log("\nArtwork URL(s):",artworkUrl),s(artworkUrl[0])),globalData.isSingleSong=1===e.length,globalData.isMultipleSongs=e.length>1,console.log(`\nFlags - Single Song: ${globalData.isSingleSong}, Multiple Songs: ${globalData.isMultipleSongs}`),document.dispatchEvent(new CustomEvent("dataLoadingComplete",{detail:{success:!0,totalSongs:e.length,songs:e.map((({id:e,totalSequences:t})=>({id:e,totalSequences:t})))}}))})((e=>{const t=e.sort(((e,t)=>e.idx-t.idx)).map((({data:e,idx:t})=>{const{projectName:a=`Song_${t+1}`,artistName:o="Unknown Artist",projectBPM:n=120,projectSequences:s={},channelURLs:l=[],channelVolume:c=[],channelPlaybackSpeed:i=[],trimSettings:d={}}=e,g=r.map(((e,t)=>({id:e,url:l[t]||"URL_not_found",metadata:{volume:c[t]??1,playbackSpeed:i[t]??1,trimStartTime_Percentage:d[t]?.start||0,trimEndTime_Percentage:d[t]?.end||100,requiresReversal:Object.values(s).some((e=>Object.values(e).some((e=>e.steps.some((e=>"object"==typeof e&&e.reverse))))))}})));return{id:`Song ${t+1}: ${a}`,artist:o,bpm:n,totalSequences:Object.keys(s).length,channels:g,projectSequences:s}}));return globalData.songsArray=t,t.length&&(globalData.initialSampleOrder=n(t[0])),t})(t))}else console.log("No valid song data URLs to process.")}catch(e){console.error("Initialization error:",e)}})();
</script>
</section1Minified>

<!-- Section 2 - Audio Processing and Management -->
<!-- <section2>
    <script>
    (async () => {
        const globalData = window.globalData || (window.globalData = {});
        const audioContext = globalData.audioContext || (globalData.audioContext = new (window.AudioContext || window.webkitAudioContext)());

        // Utility Functions
        const base64ToArrayBuffer = base64 => Uint8Array.from(atob(base64), c => c.charCodeAt(0)).buffer;

        const extractBase64 = (data, type) => {
            if (type === 'json' && data.audioData) {
                const match = data.audioData.match(/base64,([A-Za-z0-9+/=]+)/);
                return match ? match[1] : null;
            } 
            if (type === 'html') {
                const match = data.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="data:audio\/[^;]+;base64,([^"]+)"/i);
                return match ? match[1] : null;
            }
            return null;
        };

        const isValidBase64 = str => {
            const cleaned = str.replace(/\s+/g, '');
            return cleaned.length % 4 === 0 && /^[A-Za-z0-9+/]+={0,2}$/.test(cleaned);
        };

        /**
         * Normalizes an AudioBuffer to a target peak amplitude.
         * @param {AudioBuffer} buffer 
         * @param {number} targetPeak 
         * @returns {AudioBuffer}
         */
        const normalizeAudioBuffer = (buffer, targetPeak = 0.5) => {
            let max = 0;
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                const data = buffer.getChannelData(i);
                for (let sample of data) {
                    const abs = Math.abs(sample);
                    if (abs > max) max = abs;
                }
            }
            const factor = max > 0 ? targetPeak / max : 1;
            if (factor !== 1) {
                for (let i = 0; i < buffer.numberOfChannels; i++) {
                    const data = buffer.getChannelData(i);
                    for (let j = 0; j < data.length; j++) {
                        data[j] *= factor;
                    }
                }
                console.log(`Normalized AudioBuffer to ${targetPeak} with factor ${factor.toFixed(4)}`);
            }
            return buffer;
        };

        /**
         * Fetches and decodes audio based on content type.
         * @param {Response} response 
         * @param {string} contentType 
         * @param {string} url 
         * @returns {Promise<AudioBuffer|null>}
         */
        const fetchAndDecodeAudio = async (response, contentType, url) => {
            const cache = globalData.audioFetchCache || (globalData.audioFetchCache = new Map());
            if (cache.has(url)) return cache.get(url);

            try {
                let buffer;
                if (/audio\/(wav|mpeg|mp4)|video\/mp4/.test(contentType)) {
                    buffer = await audioContext.decodeAudioData(await response.arrayBuffer());
                    console.log(`Decoded audio from ${url}`);
                } else if (/application\/json/.test(contentType)) {
                    const json = JSON.parse(await response.text());
                    const base64 = extractBase64(json, 'json');
                    if (base64 && isValidBase64(base64)) {
                        buffer = await audioContext.decodeAudioData(base64ToArrayBuffer(base64));
                        console.log(`Decoded JSON audio from ${url}`);
                    } else {
                        console.warn(`Invalid/missing base64 in JSON for ${url}`);
                        return null;
                    }
                } else if (/text\/html/.test(contentType)) {
                    const html = await response.text();
                    const base64 = extractBase64(html, 'html');
                    if (base64 && isValidBase64(base64)) {
                        buffer = await audioContext.decodeAudioData(base64ToArrayBuffer(base64));
                        console.log(`Decoded HTML audio from ${url}`);
                    } else {
                        console.warn(`Invalid/missing base64 in HTML for ${url}`);
                        return null;
                    }
                } else if (/audio\//.test(contentType)) {
                    buffer = await audioContext.decodeAudioData(await response.arrayBuffer());
                    console.log(`Decoded audio from ${url}`);
                } else {
                    console.warn(`Unsupported content type (${contentType}) for ${url}`);
                    return null;
                }

                cache.set(url, buffer);
                return buffer;
            } catch (error) {
                console.warn(`Decoding error for ${url}: ${error.message}`);
                return null;
            }
        };

        const reverseArray = array => {
            const reversed = new Float32Array(array.length);
            for (let i = 0, len = array.length; i < len; i++) {
                reversed[i] = array[len - i - 1];
            }
            return reversed;
        };

        const createReverseAudioBuffer = buffer => {
            const reversed = audioContext.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate);
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                reversed.getChannelData(i).set(reverseArray(buffer.getChannelData(i)));
            }
            return reversed;
        };

        const extractFileName = url => url.split('/').pop() || "Unknown";
        
        /**
         * Processes an individual audio channel.
         * @param {Object} song 
         * @param {Object} channel 
         * @param {Array} logs 
         */
        const processChannel = async (song, channel, logs) => {
            const { id: songId, channels } = song;
            const { id: channelId, url, metadata: { trimStartTime_Percentage, trimEndTime_Percentage, requiresReversal } } = channel;

            try {
                const response = await fetch(url);
                if (!response.ok) {
                    console.warn(`Fetch failed for ${url}. Skipping ${channelId}.`);
                    return;
                }

                const contentType = response.headers.get("Content-Type") || "";
                const audioBuffer = await fetchAndDecodeAudio(response, contentType, url);
                if (!audioBuffer) {
                    console.warn(`Decoding failed for ${songId}, ${channelId}. Skipping.`);
                    return;
                }

                if (trimEndTime_Percentage <= trimStartTime_Percentage) {
                    console.warn(`Invalid trim percentages for ${songId}, ${channelId}. Skipping.`);
                    return;
                }

                const start = Math.floor((trimStartTime_Percentage / 100) * audioBuffer.duration * audioBuffer.sampleRate);
                const end = Math.floor((trimEndTime_Percentage / 100) * audioBuffer.duration * audioBuffer.sampleRate);
                const length = end - start;

                if (length <= 0) {
                    console.warn(`Non-positive trimmed length for ${songId}, ${channelId}. Skipping.`);
                    return;
                }

                const trimmedBuffer = audioContext.createBuffer(audioBuffer.numberOfChannels, length, audioBuffer.sampleRate);
                for (let i = 0; i < audioBuffer.numberOfChannels; i++) {
                    trimmedBuffer.getChannelData(i).set(audioBuffer.getChannelData(i).subarray(start, end));
                }

                const normalizedBuffer = normalizeAudioBuffer(trimmedBuffer, 0.5);

                globalData.audioBuffers = globalData.audioBuffers || {};
                globalData.reverseAudioBuffers = globalData.reverseAudioBuffers || {};
                globalData.audioBuffers[songId] = globalData.audioBuffers[songId] || {};
                globalData.reverseAudioBuffers[songId] = globalData.reverseAudioBuffers[songId] || {};
                globalData.audioBuffers[songId][channelId] = normalizedBuffer;

                if (requiresReversal) {
                    const reversedBuffer = createReverseAudioBuffer(normalizedBuffer);
                    globalData.reverseAudioBuffers[songId][channelId] = normalizeAudioBuffer(reversedBuffer, 0.5);
                }

                logs.push({
                    "Song ID": songId,
                    "Channel ID": channelId,
                    "Audio File": extractFileName(url),
                    "Full Duration (s)": audioBuffer.duration.toFixed(2),
                    "Trimmed Duration (s)": normalizedBuffer.duration.toFixed(2),
                    "Requires Reversal": requiresReversal
                });

                console.log(`Processed ${songId}, ${channelId}${requiresReversal ? " (Reversed)" : ""}`);
            } catch (error) {
                console.warn(`Error processing ${songId}, ${channelId}: ${error.message}`);
            }
        };

        const logDetailedInfo = logs => {
            if (logs.length) {
                console.table(logs);
            } else {
                console.warn("No audio samples processed.");
            }
        };

        /**
         * Initializes the Master Gain Node.
         */
        const initializeMasterGain = () => {
            const masterGain = audioContext.createGain();
            masterGain.gain.value = 0.7;
            masterGain.connect(audioContext.destination);
            globalData.masterGain = masterGain;
            console.log("Master Gain initialized with gain:", masterGain.gain.value);
        };

        const ensureAudioContextRunning = async () => {
            if (audioContext.state === 'suspended') await audioContext.resume();
        };

        /**
         * Starts playback logic.
         */
        const startPlayback = () => {
            console.log("Playback started.");
            document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
        };

        /**
         * Processes initial audio channels for immediate playback.
         */
        const processInitialAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs to process.");
                return;
            }

            const logs = [];
            const promises = initialSampleOrder.map(sample => {
                const song = songsArray.find(s => s.id === sample.songId);
                return song ? song.channels.find(c => c.id === sample.channelId) ? processChannel(song, song.channels.find(c => c.id === sample.channelId), logs) : null : null;
            }).filter(p => p);

            await Promise.all(promises);
            logDetailedInfo(logs);
            console.log("Initial audio buffers ready.");

            initializeMasterGain();
            document.dispatchEvent(new CustomEvent("initialAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Processes remaining audio channels in the background.
         */
        const processRemainingAudioChannels = async () => {
            const { songsArray, initialSampleOrder } = globalData;
            if (!songsArray.length) {
                console.error("No songs to process.");
                return;
            }

            const logs = [];
            const concurrency = 4;
            const allChannels = songsArray.flatMap(song => song.channels.map(channel => ({ song, channel })));
            const initialSet = new Set(initialSampleOrder.map(s => `${s.songId}-${s.channelId}`));
            const remaining = allChannels.filter(({ song, channel }) => !initialSet.has(`${song.id}-${channel.id}`));

            const batches = [];
            while (remaining.length) {
                batches.push(remaining.splice(0, concurrency));
            }

            for (const batch of batches) {
                await Promise.all(batch.map(({ song, channel }) => processChannel(song, channel, logs)));
            }

            logDetailedInfo(logs);
            console.log("All background audio buffers processed.");
            document.dispatchEvent(new CustomEvent("allAudioBuffersReady", { detail: { success: true } }));
        };

        /**
         * Initializes the audio processing workflow.
         */
        const initAudioProcessing = async () => {
            try {
                await ensureAudioContextRunning();
                await processInitialAudioChannels();
                processRemainingAudioChannels().catch(error => console.error("Background processing error:", error));
            } catch (error) {
                console.error("Audio processing initialization error:", error);
            }
        };

        /**
         * Sets up audio processing upon data loading completion.
         */
        const setupAudioProcessing = () => {
            document.addEventListener("dataLoadingComplete", initAudioProcessing);
            if (globalData.songsArray?.length) {
                initAudioProcessing();
            }
        };

        /**
         * Sets up listener for initial buffer readiness.
         */
        const setupInitialBufferListener = () => {
            document.addEventListener("initialAudioBuffersReady", () => {
                console.log("Initial buffers ready. Press 'P' to play.");
                // Enable playback controls or prompt UI here if needed
            });
        };

        /**
         * Starts the setup process.
         */
        const startSetup = () => {
            setupAudioProcessing();
            setupInitialBufferListener();
        };

        // Initialization
        startSetup();
    })();
    </script>
</section2> -->

 <!-- // audioProcessingAndManagement.js -->
<!-- <section2Minified>
<script>
(async()=>{const e=window.globalData||(window.globalData={}),n=e.audioContext||(e.audioContext=new(window.AudioContext||window.webkitAudioContext)),o=e=>Uint8Array.from(atob(e),(e=>e.charCodeAt(0))).buffer,a=(e,n)=>{if("json"===n&&e.audioData){const n=e.audioData.match(/base64,([A-Za-z0-9+/=]+)/);return n?n[1]:null}if("html"===n){const n=e.match(/<audio[^>]*data-audionalSampleName[^>]*>\s*<source[^>]*src="data:audio\/[^;]+;base64,([^"]+)"/i);return n?n[1]:null}return null},t=e=>{const n=e.replace(/\s+/g,"");return n.length%4==0&&/^[A-Za-z0-9+/]+={0,2}$/.test(n)},r=(e,n=.5)=>{let o=0;for(let n=0;n<e.numberOfChannels;n++){const a=e.getChannelData(n);for(let e of a){const n=Math.abs(e);n>o&&(o=n)}}const a=o>0?n/o:1;if(1!==a){for(let n=0;n<e.numberOfChannels;n++){const o=e.getChannelData(n);for(let e=0;e<o.length;e++)o[e]*=a}console.log(`Normalized AudioBuffer to ${n} with factor ${a.toFixed(4)}`)}return e},s=e=>{const n=new Float32Array(e.length);for(let o=0,a=e.length;o<a;o++)n[o]=e[a-o-1];return n},i=e=>e.split("/").pop()||"Unknown",l=async(l,d,c)=>{const{id:u,channels:f}=l,{id:g,url:h,metadata:{trimStartTime_Percentage:m,trimEndTime_Percentage:p,requiresReversal:w}}=d;try{const l=await fetch(h);if(!l.ok)return void console.warn(`Fetch failed for ${h}. Skipping ${g}.`);const d=l.headers.get("Content-Type")||"",f=await(async(r,s,i)=>{const l=e.audioFetchCache||(e.audioFetchCache=new Map);if(l.has(i))return l.get(i);try{let e;if(/audio\/(wav|mpeg|mp4)|video\/mp4/.test(s))e=await n.decodeAudioData(await r.arrayBuffer()),console.log(`Decoded audio from ${i}`);else if(/application\/json/.test(s)){const s=JSON.parse(await r.text()),l=a(s,"json");if(!l||!t(l))return console.warn(`Invalid/missing base64 in JSON for ${i}`),null;e=await n.decodeAudioData(o(l)),console.log(`Decoded JSON audio from ${i}`)}else if(/text\/html/.test(s)){const s=await r.text(),l=a(s,"html");if(!l||!t(l))return console.warn(`Invalid/missing base64 in HTML for ${i}`),null;e=await n.decodeAudioData(o(l)),console.log(`Decoded HTML audio from ${i}`)}else{if(!/audio\//.test(s))return console.warn(`Unsupported content type (${s}) for ${i}`),null;e=await n.decodeAudioData(await r.arrayBuffer()),console.log(`Decoded audio from ${i}`)}return l.set(i,e),e}catch(e){return console.warn(`Decoding error for ${i}: ${e.message}`),null}})(l,d,h);if(!f)return void console.warn(`Decoding failed for ${u}, ${g}. Skipping.`);if(p<=m)return void console.warn(`Invalid trim percentages for ${u}, ${g}. Skipping.`);const $=Math.floor(m/100*f.duration*f.sampleRate),v=Math.floor(p/100*f.duration*f.sampleRate),y=v-$;if(y<=0)return void console.warn(`Non-positive trimmed length for ${u}, ${g}. Skipping.`);const A=n.createBuffer(f.numberOfChannels,y,f.sampleRate);for(let e=0;e<f.numberOfChannels;e++)A.getChannelData(e).set(f.getChannelData(e).subarray($,v));const C=r(A,.5);if(e.audioBuffers=e.audioBuffers||{},e.reverseAudioBuffers=e.reverseAudioBuffers||{},e.audioBuffers[u]=e.audioBuffers[u]||{},e.reverseAudioBuffers[u]=e.reverseAudioBuffers[u]||{},e.audioBuffers[u][g]=C,w){const o=(e=>{const o=n.createBuffer(e.numberOfChannels,e.length,e.sampleRate);for(let n=0;n<e.numberOfChannels;n++)o.getChannelData(n).set(s(e.getChannelData(n)));return o})(C);e.reverseAudioBuffers[u][g]=r(o,.5)}c.push({"Song ID":u,"Channel ID":g,"Audio File":i(h),"Full Duration (s)":f.duration.toFixed(2),"Trimmed Duration (s)":C.duration.toFixed(2),"Requires Reversal":w}),console.log(`Processed ${u}, ${g}${w?" (Reversed)":""}`)}catch(e){console.warn(`Error processing ${u}, ${g}: ${e.message}`)}},d=e=>{e.length?console.table(e):console.warn("No audio samples processed.")},c=async()=>{const{songsArray:o,initialSampleOrder:a}=e;if(!o.length)return void console.error("No songs to process.");const t=[],r=a.map((e=>{const n=o.find((n=>n.id===e.songId));return n&&n.channels.find((n=>n.id===e.channelId))?l(n,n.channels.find((n=>n.id===e.channelId)),t):null})).filter((e=>e));await Promise.all(r),d(t),console.log("Initial audio buffers ready."),(()=>{const o=n.createGain();o.gain.value=.7,o.connect(n.destination),e.masterGain=o,console.log("Master Gain initialized with gain:",o.gain.value)})(),document.dispatchEvent(new CustomEvent("initialAudioBuffersReady",{detail:{success:!0}}))},u=async()=>{try{await(async()=>{"suspended"===n.state&&await n.resume()})(),await c(),(async()=>{const{songsArray:n,initialSampleOrder:o}=e;if(!n.length)return void console.error("No songs to process.");const a=[],t=n.flatMap((e=>e.channels.map((n=>({song:e,channel:n}))))),r=new Set(o.map((e=>`${e.songId}-${e.channelId}`))),s=t.filter((({song:e,channel:n})=>!r.has(`${e.id}-${n.id}`))),i=[];for(;s.length;)i.push(s.splice(0,4));for(const e of i)await Promise.all(e.map((({song:e,channel:n})=>l(e,n,a))));d(a),console.log("All background audio buffers processed."),document.dispatchEvent(new CustomEvent("allAudioBuffersReady",{detail:{success:!0}}))})().catch((e=>console.error("Background processing error:",e)))}catch(e){console.error("Audio processing initialization error:",e)}};document.addEventListener("dataLoadingComplete",u),e.songsArray?.length&&u(),document.addEventListener("initialAudioBuffersReady",(()=>{console.log("Initial buffers ready. Press 'P' to play.")}))})();
</script>
</section2Minified> -->

<!-- Section 2 - Audio Processing and Management -->
 <!-- audioProdcessingAndManagement.js -->
 <script src="/content/f4cc99813b43f71b3e781d3c99f24a6a7a5b1004ea0efce3b225011e347b8df0i0"></script>


<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) -->
 <!-- // audioProcessingAndManagement.js -->

<!-- <section>
    <script>
        (() => {
            const globalData = window.globalData || (window.globalData = {});
            const audioContext = globalData.audioContext;
        
            // Initialize playback state
            globalData.isPlaying = false;
        
            // Variables
            const lookahead = 0.1; // Time in seconds to look ahead for scheduling
            const schedulerInterval = 25; // Scheduler loop interval in milliseconds
            let schedulerTimerID = null;
            let sequenceStates = {};
            let currentSongIndex = 0;
            const missingBuffers = new Set();
        
            /**
             * Toggles playback on and off.
             */
            const togglePlayback = () => {
                globalData.isPlaying ? stopPlayback() : startPlayback();
            };
        
            /**
             * Starts playback for the current song.
             * Initializes sequence states and starts the scheduler loop.
             */
            const startPlayback = () => {
                if (globalData.isPlaying) {
                    console.log('Playback is already in progress.');
                    return;
                }
        
                const { songsArray, audioBuffers, reverseAudioBuffers } = globalData;
                if (!songsArray.length) {
                    console.error("No songs available for playback.");
                    return;
                }
        
                // Update totalSongs dynamically
                const totalSongs = songsArray.length;
        
                // Ensure currentSongIndex is within bounds
                if (currentSongIndex >= totalSongs) {
                    currentSongIndex = 0;
                }
        
                const song = songsArray[currentSongIndex];
                const sequences = song.projectSequences || {};
                console.log(`Starting playback for Song: ${song.id} (${currentSongIndex + 1}/${totalSongs}) with ${Object.keys(sequences).length} sequences.`);
                console.log(`Song BPM: ${song.bpm}`);
        
                const stepsPerBeat = 4;
                const stepDuration = (60 / song.bpm) / stepsPerBeat;
                const sequenceDuration = 64 * stepDuration;
        
                // Reset sequenceStates and missingBuffers for the new song
                sequenceStates = {};
                missingBuffers.clear();
        
                let sequenceStartOffset = 0;
                for (const [sequenceName, sequence] of Object.entries(sequences)) {
                    const startTime = audioContext.currentTime + sequenceStartOffset;
                    sequenceStates[sequenceName] = {
                        nextStepIndex: 0,
                        nextStepTime: startTime,
                        stepDuration,
                        startTime,
                        endTime: startTime + sequenceDuration,
                        completed: false
                    };
                    console.log(`Initialized scheduler for sequence: ${sequenceName} starting at +${sequenceStartOffset.toFixed(2)}s`);
                    sequenceStartOffset += sequenceDuration;
                }
        
                globalData.isPlaying = true;
                schedulerTimerID = setInterval(() => schedulerLoop(song, audioBuffers, reverseAudioBuffers), schedulerInterval);
                console.log('Playback started.');
                document.dispatchEvent(new CustomEvent("playbackStarted", { detail: { success: true } }));
            };
        
            /**
             * Stops playback and resets the Playback Engine state.
             */
            const stopPlayback = () => {
                if (!globalData.isPlaying) {
                    console.log('Playback is not in progress.');
                    return;
                }
        
                if (schedulerTimerID) clearInterval(schedulerTimerID);
                globalData.isPlaying = false;
                sequenceStates = {};
                missingBuffers.clear();
                console.log('Playback stopped and sequence states reset.');
                document.dispatchEvent(new CustomEvent("playbackStopped", { detail: { success: true } }));
            };
        
            /**
             * The main scheduler loop that schedules audio playback.
             * @param {Object} song - The current song object.
             * @param {Object} audioBuffers - The loaded audio buffers.
             * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
             */
         // Add keydown event listener for arrow key navigation
document.addEventListener('keydown', (event) => {
    const totalSongs = globalData.songsArray.length;
    
    // Stop current playback before switching songs
    if (globalData.isPlaying) {
        stopPlayback(); // Simulate stopping the current song
    }

    if (event.key === 'ArrowRight') {
        // Move to the next song
        currentSongIndex = (currentSongIndex + 1) % totalSongs; // Loop back to the first song if at the end
        console.log(`Skipping to next song: ${globalData.songsArray[currentSongIndex].id}`);
    } else if (event.key === 'ArrowLeft') {
        // Move to the previous song
        currentSongIndex = (currentSongIndex - 1 + totalSongs) % totalSongs; // Loop back to the last song if at the beginning
        console.log(`Skipping to previous song: ${globalData.songsArray[currentSongIndex].id}`);
    }

    // Start playback of the next/previous song
    resetPlayback();  // Reset playback settings for the new song
    startPlayback();  // Start the new song
});

const schedulerLoop = (song, audioBuffers, reverseAudioBuffers) => {
    const currentTime = audioContext.currentTime;
    let allSequencesCompleted = true;

    for (const [sequenceName, sequence] of Object.entries(song.projectSequences || {})) {
        const state = sequenceStates[sequenceName];
        if (!state || state.completed) continue;

        // Check if the sequence has ended
        if (currentTime >= state.endTime) {
            state.completed = true;
            console.log(`Sequence ${sequenceName} has completed.`);
            continue;
        }

        allSequencesCompleted = false;

        // Schedule steps within the lookahead window
        while (state.nextStepTime < currentTime + lookahead && globalData.isPlaying) {
            const stepIndex = state.nextStepIndex;
            const stepTime = state.nextStepTime;

            for (const [trackName, trackData] of Object.entries(sequence)) {
                const channelIndex = parseInt(trackName.replace('ch', ''), 10);
                const channel = song.channels[channelIndex];

                if (!channel) {
                    console.warn(`Channel index ${channelIndex} not found in song ${song.id}.`);
                    continue;
                }

                const steps = trackData.steps || [];
                const step = steps.find(s => (typeof s === "number" && s === stepIndex) || (s.index === stepIndex));

                if (step !== undefined) {
                    const reverse = typeof step === "object" && step.reverse;
                    schedulePlayback(song, channel, stepTime, reverse, audioBuffers, reverseAudioBuffers, state.stepDuration);
                }
            }

            state.nextStepIndex += 1;
            if (state.nextStepIndex >= 64) {
                state.completed = true;
                console.log(`Sequence ${sequenceName} has completed all steps.`);
                break;
            }
            state.nextStepTime += state.stepDuration;
        }
    }

    if (allSequencesCompleted) {
        console.log("All sequences have completed.");

        const totalSongs = globalData.songsArray.length;

        // Handle looping and sequential playback based on flags
        if (globalData.isLoopedPlayback) {
            if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
                // Move to the next song in the list
                currentSongIndex += 1;
                if (currentSongIndex >= totalSongs) {
                    currentSongIndex = 0; // Loop back to the first song
                    console.log("Reached the end of the playlist. Looping back to the first song.");
                } else {
                    console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                }
                resetPlayback();
                startPlayback();
            } else {
                // Loop the current song
                console.log(`Looping the current song: ${song.id}`);
                resetPlayback();
                startPlayback();
            }
        } else if (globalData.isMultipleSongs && globalData.isSequentialPlayback) {
            // Move to the next song without looping
            currentSongIndex += 1;
            if (currentSongIndex < totalSongs) {
                console.log(`Moving to next song: ${globalData.songsArray[currentSongIndex].id} (${currentSongIndex + 1}/${totalSongs})`);
                resetPlayback();
                startPlayback();
            } else {
                // Reached the end of the playlist
                console.log("Reached the end of the playlist. Stopping playback.");
                stopPlayback();
            }
        } else {
            // Single song playback without looping
            console.log("Playback has completed the single song.");
            stopPlayback();
        }
    }
};

        
            /**
             * Schedules playback of an individual audio buffer.
             * @param {Object} song - The current song object.
             * @param {Object} channel - The current channel object.
             * @param {number} time - The scheduled start time in seconds.
             * @param {boolean} reverse - Indicates if the audio should be played in reverse.
             * @param {Object} audioBuffers - The loaded audio buffers.
             * @param {Object} reverseAudioBuffers - The loaded reverse audio buffers.
             * @param {number} stepDuration - Duration of each step in seconds.
             */
            const schedulePlayback = (song, channel, time, reverse, audioBuffers, reverseAudioBuffers, stepDuration) => {
                const bufferKey = `${song.id}_${channel.id}_${reverse ? 'reverse' : 'normal'}`;
                const buffer = reverse ? reverseAudioBuffers[song.id]?.[channel.id] : audioBuffers[song.id]?.[channel.id];
        
                if (!buffer) {
                    if (!missingBuffers.has(bufferKey)) {
                        missingBuffers.add(bufferKey);
                        console.warn(`Audio buffer missing for Song: ${song.id}, Channel: ${channel.id}${reverse ? " (Reverse)" : ""}`);
                    }
                    return;
                }
        
                const source = audioContext.createBufferSource();
                source.buffer = buffer;
                source.playbackRate.value = channel.metadata.playbackSpeed || 1;
                source.connect(globalData.masterGain || audioContext.destination);
                source.start(time);
            };
        
            /**
             * Resets the Playback Engine for the next song.
             */
            const resetPlayback = () => {
                // Stop current playback and reset states without completely stopping the engine
                if (schedulerTimerID) clearInterval(schedulerTimerID);
                sequenceStates = {};
                missingBuffers.clear();
                console.log('Playback reset for the next song.');
            };
        
            /**
             * Initializes the Playback Engine.
             * Ensures that songs are available and sets up necessary components.
             */
            const initializePlaybackEngine = () => {
                const { songsArray } = globalData;
                if (!songsArray.length) {
                    console.error("No songs available for playback.");
                    return;
                }
                console.log("Playback Engine Initialization Complete.");
                console.log("Playback is ready. Click the artwork to start.");
            };
        
            /**
             * Sets up event listeners for custom events dispatched by other sections.
             */
            const setupEventListeners = () => {
                // Listen for the initialAudioBuffersReady event to initialize the playback engine
                document.addEventListener("initialAudioBuffersReady", (event) => {
                    if (event.detail.success) {
                        initializePlaybackEngine();
                        console.log("Initial audio buffers are ready.");
                    }
                });
        
                // Listen for the allAudioBuffersReady event to log completion
                document.addEventListener("allAudioBuffersReady", (event) => {
                    if (event.detail.success) {
                        console.log("All audio buffers have been loaded and are ready.");
                    }
                });
        
                // Listen for the playbackStarted event if needed elsewhere
                document.addEventListener("playbackStarted", (event) => {
                    if (event.detail.success) {
                        console.log("Playback has been successfully started.");
                    }
                });
        
                // Listen for the playbackStopped event if needed elsewhere
                document.addEventListener("playbackStopped", (event) => {
                    if (event.detail.success) {
                        console.log("Playback has been successfully stopped.");
                    }
                });
            };
        
            /**
             * Sets up the artwork click event listener and initializes the playback engine.
             */
            const setupArtworkClickListener = () => {
                document.addEventListener('DOMContentLoaded', () => {
                    const artworkCover = document.getElementById('artworkCover');
                    const artworkImage = document.getElementById('artworkImage');
                    const displayArtworkCover = () => {
                        artworkCover.classList.remove('hidden');
                        loadingSpinner.style.display = 'none';
                    };
                    if (globalData.isArtworkCover && artworkUrl.length > 0) {
                        artworkImage.src = artworkUrl[0];
                        displayArtworkCover();
                        artworkImage.addEventListener('click', togglePlayback);
                    }
                });
            };
        
            /**
             * Starts the entire setup process.
             * If audio buffers are already loaded, initialize immediately.
             * Otherwise, wait for the initialAudioBuffersReady event.
             */
            const startSetup = () => {
                setupEventListeners();
                setupArtworkClickListener();
                if (Object.keys(globalData.audioBuffers || {}).length) {
                    // If audioBuffers are already loaded, initialize playback
                    initializePlaybackEngine();
                }
            };
        
            // Initialization
            startSetup();
        
        })();
        </script> -->


<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) MINIFIED 5kb -->
<!-- // playback,js -->
<!-- <script>
(()=>{const e=window.globalData||(window.globalData={}),o=e.audioContext;e.isPlaying=!1;let n=null,t={},s=0;const a=new Set,l=()=>{e.isPlaying?i():c()},c=()=>{if(e.isPlaying)return void console.log("Playback is already in progress.");const{songsArray:l,audioBuffers:c,reverseAudioBuffers:i}=e;if(!l.length)return void console.error("No songs available for playback.");const d=l.length;s>=d&&(s=0);const g=l[s],u=g.projectSequences||{};console.log(`Starting playback for Song: ${g.id} (${s+1}/${d}) with ${Object.keys(u).length} sequences.`),console.log(`Song BPM: ${g.bpm}`);const p=60/g.bpm/4,y=64*p;t={},a.clear();let f=0;for(const[e,n]of Object.entries(u)){const n=o.currentTime+f;t[e]={nextStepIndex:0,nextStepTime:n,stepDuration:p,startTime:n,endTime:n+y,completed:!1},console.log(`Initialized scheduler for sequence: ${e} starting at +${f.toFixed(2)}s`),f+=y}e.isPlaying=!0,n=setInterval((()=>r(g,c,i)),25),console.log("Playback started."),document.dispatchEvent(new CustomEvent("playbackStarted",{detail:{success:!0}}))},i=()=>{e.isPlaying?(n&&clearInterval(n),e.isPlaying=!1,t={},a.clear(),console.log("Playback stopped and sequence states reset."),document.dispatchEvent(new CustomEvent("playbackStopped",{detail:{success:!0}}))):console.log("Playback is not in progress.")};document.addEventListener("keydown",(o=>{const n=e.songsArray.length;e.isPlaying&&i(),"ArrowRight"===o.key?(s=(s+1)%n,console.log(`Skipping to next song: ${e.songsArray[s].id}`)):"ArrowLeft"===o.key&&(s=(s-1+n)%n,console.log(`Skipping to previous song: ${e.songsArray[s].id}`)),g(),c()}));const r=(n,a,l)=>{const r=o.currentTime;let u=!0;for(const[o,s]of Object.entries(n.projectSequences||{})){const c=t[o];if(c&&!c.completed)if(r>=c.endTime)c.completed=!0,console.log(`Sequence ${o} has completed.`);else for(u=!1;c.nextStepTime<r+.1&&e.isPlaying;){const e=c.nextStepIndex,t=c.nextStepTime;for(const[o,i]of Object.entries(s)){const s=parseInt(o.replace("ch",""),10),r=n.channels[s];if(!r){console.warn(`Channel index ${s} not found in song ${n.id}.`);continue}const g=(i.steps||[]).find((o=>"number"==typeof o&&o===e||o.index===e));if(void 0!==g){const e="object"==typeof g&&g.reverse;d(n,r,t,e,a,l,c.stepDuration)}}if(c.nextStepIndex+=1,c.nextStepIndex>=64){c.completed=!0,console.log(`Sequence ${o} has completed all steps.`);break}c.nextStepTime+=c.stepDuration}}if(u){console.log("All sequences have completed.");const o=e.songsArray.length;e.isLoopedPlayback?e.isMultipleSongs&&e.isSequentialPlayback?(s+=1,s>=o?(s=0,console.log("Reached the end of the playlist. Looping back to the first song.")):console.log(`Moving to next song: ${e.songsArray[s].id} (${s+1}/${o})`),g(),c()):(console.log(`Looping the current song: ${n.id}`),g(),c()):e.isMultipleSongs&&e.isSequentialPlayback?(s+=1,s<o?(console.log(`Moving to next song: ${e.songsArray[s].id} (${s+1}/${o})`),g(),c()):(console.log("Reached the end of the playlist. Stopping playback."),i())):(console.log("Playback has completed the single song."),i())}},d=(n,t,s,l,c,i,r)=>{const d=`${n.id}_${t.id}_${l?"reverse":"normal"}`,g=l?i[n.id]?.[t.id]:c[n.id]?.[t.id];if(!g)return void(a.has(d)||(a.add(d),console.warn(`Audio buffer missing for Song: ${n.id}, Channel: ${t.id}${l?" (Reverse)":""}`)));const u=o.createBufferSource();u.buffer=g,u.playbackRate.value=t.metadata.playbackSpeed||1,u.connect(e.masterGain||o.destination),u.start(s)},g=()=>{n&&clearInterval(n),t={},a.clear(),console.log("Playback reset for the next song.")},u=()=>{const{songsArray:o}=e;o.length?(console.log("Playback Engine Initialization Complete."),console.log("Playback is ready. Click the artwork to start.")):console.error("No songs available for playback.")},p=()=>{document.addEventListener("DOMContentLoaded",(()=>{const o=document.getElementById("artworkCover"),n=document.getElementById("artworkImage");e.isArtworkCover&&artworkUrl.length>0&&(n.src=artworkUrl[0],o.classList.remove("hidden"),loadingSpinner.style.display="none",n.addEventListener("click",l))}))};document.addEventListener("initialAudioBuffersReady",(e=>{e.detail.success&&(u(),console.log("Initial audio buffers are ready."))})),document.addEventListener("allAudioBuffersReady",(e=>{e.detail.success&&console.log("All audio buffers have been loaded and are ready.")})),document.addEventListener("playbackStarted",(e=>{e.detail.success&&console.log("Playback has been successfully started.")})),document.addEventListener("playbackStopped",(e=>{e.detail.success&&console.log("Playback has been successfully stopped.")})),p(),Object.keys(e.audioBuffers||{}).length&&u()})();
</script> -->



<!-- Section 3 - Playback Engine (Updated for Lazy Loading Integration) MINIFIED 5kb -->
<!-- // playback.js -->
<script src="/content/7e598776ae7ce4d2d1a4014ce49df45fc6cf5ecd23945fb850d8b967d9155117i0"></script> 




</body>
</html>