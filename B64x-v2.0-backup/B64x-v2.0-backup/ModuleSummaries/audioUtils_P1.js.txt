Filename: audioUtils_P1.js

Overview:
This file serves as Part 1 of the audio utilities module. Its primary role is to process, decode, and store audio data retrieved from various sources (JSON responses, HTML responses, or direct ArrayBuffers). It handles the conversion between base64 strings and ArrayBuffers, decodes audio data using the Web Audio API, creates reversed audio buffers for reverse playback, and listens for audio messages via the window.postMessage interface. The module integrates closely with a global settings object to manage audio buffers and source nodes within the overall project.

Key Variables/Constants:
	•	audioBuffers: A Map that stores decoded AudioBuffer objects using keys that denote channel information or URLs.
	•	activeAudioSources: A Set used to track currently active audio source nodes.
	•	DEBUG: A boolean flag that controls detailed logging via the helper function log.
	•	fadeChannels: An array of channel indices (e.g., [6, 7, 11, 12, 13, 15]) indicating which channels should apply fade effects during playback.
	•	log: A helper function that conditionally logs debug information based on the DEBUG flag.
	•	Helper Functions:
	•	getIDFromURL: Extracts the last segment from a URL.
	•	base64ToArrayBuffer / bufferToBase64: Convert between base64 strings and ArrayBuffers.
	•	processJSONResponse / processHTMLResponse: Parse responses to extract audio data and sample names.
	•	decodeAudioData: Decodes raw audio data using an AudioContext.
	•	decodeAndStoreAudio: Decodes audio data, creates its reverse, and stores both in the shared buffers.
	•	createReverseBuffer: Generates a reversed copy of a given AudioBuffer.
	•	fetchAudio: Fetches audio from a URL, processes the response based on its content type, and updates global settings.
	•	getIframeIdByChannelIndex: Retrieves an iframe identifier linked to a specific channel index.
	•	formatURL: A stub helper function for URL formatting.

Frameworks and Methodologies:
	•	Browser APIs: Uses native browser APIs such as fetch, DOMParser, Blob, and AudioContext from the Web Audio API.
	•	Module Pattern: Encapsulated in an Immediately Invoked Function Expression (IIFE) to avoid polluting the global scope.
	•	Asynchronous Programming: Employs Promises and async/await for asynchronous operations like fetching and decoding audio data.
	•	Event-Driven Architecture: Listens for message events to process externally sent audio data.
	•	Design Principles: Follows modular design and separation of concerns, facilitating integration with the broader project via window.unifiedSequencerSettings.

Noteworthy Implementation Details:
	•	Conditional Logging: Uses a dedicated log function that activates only when DEBUG is true, aiding in debugging without cluttering production logs.
	•	Multi-Format Response Handling: Supports both JSON and HTML responses, adapting its processing logic accordingly.
	•	Reversed Audio Buffer Creation: Implements a custom function to generate reversed audio buffers, enhancing playback versatility.
	•	Global Integration: Directly interacts with a global settings object (window.unifiedSequencerSettings) to manage audio context, source nodes, and UI updates.
	•	Message Event Listener: Processes incoming audio data messages, decodes them, and dynamically updates channel settings based on the data received.

Potential Optimizations:
	•	URL Formatting: The formatURL helper is currently a stub; implementing or refining it could improve URL management consistency.
	•	Error Handling: Centralize and standardize error handling to reduce code duplication and improve clarity.
	•	Memory Management: Ensure proper cleanup of audio buffers and source nodes to avoid memory leaks, especially when replacing or disconnecting nodes.
	•	Decoupling: Reduce the tight coupling with the global settings object (window.unifiedSequencerSettings) to enhance modularity and testability.